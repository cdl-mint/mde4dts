;title;abstract;dc:publisher;prism:aggregationType;prism:publicationName;prism:coverDate;prism:url
0;A Catalog of Design Patterns for Compositional Language Engineering;When composing a domain-specific language from several language components, it is also necessary to compose analysis and synthesis techniques, which are individually defined on these components in an efficient, ideally black-box form. An effective way of allowing such compositions is to use specific design patterns, which are partly reflected in the tooling code, partly reflected in the language, but also partly reflected in the language workbench (one meta-level higher), and the generated/synthesized product code (one meta-level downward). Based on the experiences gained in compositional language development using the language workbench MontiCore, we in detail discuss several of those design patterns, namely the Mill, the RealThis object composition, the Template/Hook, and the TOP-Generator Patterns, and the hidden complexity of an extended visitor infrastructure coping with the above patterns. The patterns are recorded and described in a reusable way, as usual, allowing readers to participate from the gained insights and possible solutions.;Association Internationale pour les Technologies Objets;Journal;Journal of Object Technology;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85141747625
1;A conceptual framework for smart production planning and control in Industry 4.0;"This article aims to introduce the challenge (i.e., integration of new collaborative models and tools) posed by the automation and collaboration of industrial processes in Industry 4.0 (I4.0) smart factories. Small- and medium-sized enterprises (SMEs) are particularly confronted with new technological and organisational changes, but a conceptual framework for production planning and control (PPC) systems in the I4.0 context is lacking. The main contributions of this article are to: (i) identify the functions making up traditional PPC and smart production planning and control in I4.0 (SPPC 4.0); (ii) analyse the impact of I4.0 technologies on PPC systems; (iii) propose a conceptual framework that provides the systematic structuring of how a PPC system operates in the I4.0 context, dubbed SPPC 4.0. Thus SPPC 4.0 is proposed by adopting the axes of the RAMI 4.0 reference architecture model, which compiles and contains the main concepts of PPC systems and I4.0. It also provides the technical description, organisation and understanding of each aspect, which can provide a guide for academic research and industrial practitioners to transform PPC systems towards I4.0 implementations. Finally, theoretical implications and research gaps are provided.";Elsevier Ltd;Journal;Computers and Industrial Engineering;2022-11-01;https://api.elsevier.com/content/abstract/scopus_id/85138158661
2;A Conceptual Model for Digital Shadows in Industry and Its Application;Smart manufacturing demands to process data in domain-specific real-time. Engineering models created for constructing, commissioning, planning, or simulating manufacturing systems can facilitate aggregating and abstracting the wealth of manufacturing data to faster processable data structures for more timely decision making. Current research lacks conceptual foundations for how data and engineering models can be exploited in an integrated way to achieve this. Such research demands expertise from different smart manufacturing domains to harmonize the notion space. We propose a conceptual model to describe digital shadows, data structures tailored to exploit models and data in smart manufacturing, through a metamodel and its notion space. This conceptual model was established through interdisciplinary research in the German excellence cluster “Internet of Production” and evaluated in various real-world manufacturing scenarios. This foundation for an understanding helps to manage complexity, automated analyses, and syntheses, and, ultimately, facilitates cross-domain collaboration.;Springer Science and Business Media Deutschland GmbH;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85118142665
3;A Conceptual Model for Digital Shadows in Industry and Its Application;Smart manufacturing demands to process data in domain-specific real-time. Engineering models created for constructing, commissioning, planning, or simulating manufacturing systems can facilitate aggregating and abstracting the wealth of manufacturing data to faster processable data structures for more timely decision making. Current research lacks conceptual foundations for how data and engineering models can be exploited in an integrated way to achieve this. Such research demands expertise from different smart manufacturing domains to harmonize the notion space. We propose a conceptual model to describe digital shadows, data structures tailored to exploit models and data in smart manufacturing, through a metamodel and its notion space. This conceptual model was established through interdisciplinary research in the German excellence cluster “Internet of Production” and evaluated in various real-world manufacturing scenarios. This foundation for an understanding helps to manage complexity, automated analyses, and syntheses, and, ultimately, facilitates cross-domain collaboration.;Springer Science and Business Media Deutschland GmbH;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85118142665
4;A Cost–Benefit Analysis Simulation for the Digitalisation of Cold Supply Chains;This paper investigates using simulation to predict the benefits and costs of digitalising cold distribution chains. The study focuses on the distribution of refrigerated beef in the UK, where digitalisation was implemented to re-route cargo carriers. By comparing simulations of both digitalised and non-digitalised supply chains, the study found that digitalisation can reduce beef waste and decrease the number of miles driven per successful delivery, leading to potential cost savings. Note that this work is not attempting to prove that digitalisation is appropriate for the chosen scenario, only to justify a simulation approach as a decision making tool. The proposed modelling approach provides decision-makers with more accurate predictions of the cost–benefit of increased sensorisation in supply chains. By accounting for stochastic and variable parameters, such as weather and demand fluctuations, simulation can be used to identify potential challenges and estimate the economic benefits of digitalisation. Moreover, qualitative assessments of the impact on customer satisfaction and product quality can help decision-makers consider the broader impacts of digitalisation. Overall, the study suggests that simulation can play a crucial role in facilitating informed decisions about the implementation of digital technologies in the food supply chain. By providing a better understanding of the potential costs and benefits of digitalisation, simulation can help organisations make more strategic and effective decisions.;MDPI;Journal;Sensors;2023-04-01;https://api.elsevier.com/content/abstract/scopus_id/85153957715
5;A digital twin ecosystem for additive manufacturing using a real-time development platform;Additive manufacturing is often used in rapid prototyping and manufacturing, allowing the creation of lighter, more complex designs that are difficult or too expensive to build using traditional manufacturing methods. This work considers the implementation of a novel digital twin ecosystem that can be used for testing, process monitoring, and remote management of an additive manufacturing–fused deposition modeling machine in a simulated virtual environment. The digital twin ecosystem is comprised of two approaches. One approach is data-driven by an open-source 3D printer web controller application that is used to capture its status and key parameters. The other approach is data-driven by externally mounted sensors to approximate the actual behavior of the 3D printer and achieve accurate synchronization between the physical and virtual 3D printers. We evaluate the sensor-data-driven approach against the web controller approach, which is considered to be the ground truth. We achieve near-real-time synchronization between the physical machine and its digital counterpart and have validated the digital twin in terms of position, temperature, and run duration. Our digital twin ecosystem is cost-efficient, reliable, replicable, and hence can be utilized to provide legacy equipment with digital twin capabilities, collect historical data, and generate analytics.;Springer Science and Business Media Deutschland GmbH;Journal;International Journal of Advanced Manufacturing Technology;2022-06-01;https://api.elsevier.com/content/abstract/scopus_id/85128054645
6;A digital twin framework for prognostics and health management;Despite rapid advances in modeling and analysis technology, the manufacturing industry has been slow to implement prognostic and health management strategies. A cause of this delay is the individualized focus of most health monitoring solutions, which makes it difficult to deploy and reuse modeling resources across manufacturing equipment fleets. This paper presents a digital twin-based framework that standardizes communication and organization of modeling resources used for health monitoring, a critical aspect of prognostics and health management. The framework is based on a novel, state-based model of mechanical system health that can be reused across manufacturing machines and components. A set of modular digital twin classes enables the creation of extensible digital twin hierarchies for monitoring the health of complex systems. A case study implements this framework to standardize fault detection results for the seal and bearing systems of an industrial pump. The framework's standardized DT classes and aggregation relationships allow component-level models to be re-used and aggregated to predict faults in the pump's bearing system.;Elsevier B.V.;Journal;Computers in Industry;2023-09-01;https://api.elsevier.com/content/abstract/scopus_id/85160517500
7;A Digital Twin-Based Distributed Manufacturing Execution System for Industry 4.0 with AI-Powered On-The-Fly Replanning Capabilities;Industry 4.0 smart production systems comprise industrial systems and subsystems that need to be integrated in such a way that they are able to support high modularity and reconfigurability of all system components. In today’s industrial production, manufacturing execution systems (MESs) and supervisory control and data acquisition (SCADA) systems are typically in charge of orchestrating and monitoring automated production processes. This article explicates an MES architecture that is capable of autonomously composing, verifying, interpreting, and executing production plans using digital twins and symbolic planning methods. To support more efficient production, the proposed solution assumes that the manufacturing process can be started with an initial production plan that may be relatively inefficient but quickly found by an AI. While executing this initial plan, the AI searches for more efficient alternatives and forwards better solutions to the proposed MES, which is able to seamlessly switch between the currently executed plan and the new plan, even during production. Further, this on-the-fly replanning capability is also applicable when newly identified production circumstances/objectives appear, such as a malfunctioning robot, material shortage, or a last-minute change to a customizable product. Another feature of the proposed MES solution is its distributed operation with multiple instances. Each instance can interpret its part of the production plan, dedicated to a location within the entire production site. All of these MES instances are continuously synchronized, and the actual global or partial (i.e., from the instance perspective) progress of the production is handled in real-time within one common digital twin. This article presents three main contributions: (i) an execution system that is capable of switching seamlessly between an original and a subsequently introduced alternative production plan, (ii) on-the-fly AI-powered planning and replanning of industrial production integrated into a digital twin, and (iii) a distributed MES, which allows for running multiple instances that may depend on topology or specific conditions of a real production plant. All of these outcomes are demonstrated and validated on a use-case utilizing an Industry 4.0 testbed, which is equipped with an automated transport system and several industrial robots. While our solution is tested on a lab-sized production system, the technological base is prepared to be scaled up to larger systems.;MDPI;Journal;Sustainability (Switzerland);2023-04-01;https://api.elsevier.com/content/abstract/scopus_id/85152785660
8;A Flow Graph based Approach for controlled Generation of AAS Digital Twin Instances for the Verification of Compliance Check Tools;Digital twins are a fundamental building block for the Industrie 4.0. With the Asset Administration Shell, a standard has been published that describes a meta model of such digital twins and the interfaces to access them. One of these interfaces is file-based access. Since the advent of the standard, various implementations have been developed. To ensure interoperability between different implementations, compliance with the specification must be verified. To test the correctness of a compliance check tool, a set of digital twins with known properties is used as test input. Since manually specifying such test models is error-prone, this work contributes an automated generation approach. It leverages flow graphs to represent the space of possible models. The subsequent path selection aims to generate expressive, yet efficient test input.;IEEE Computer Society;Conference Proceeding;IECON Proceedings (Industrial Electronics Conference);2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85143907362
9;A Novel Implementation Framework of Digital Twins for Intelligent Manufacturing Based on Container Technology and Cloud Manufacturing Services;Many core technologies of Industry 4.0 have gained substantial advancement in recent years. Digital Twin (DT) has become the key technology and tool for manufacturing industries to realize intelligent cyber-physical integration and digital transformation by leveraging these technologies. Although there have been many DT-related works, there is no standard definition, unified framework, and implementation approach of DT until now. Widely developing DTs for the manufacturing industry is still challenging. Thus, this paper proposes a novel implementation framework of digital twins for intelligent manufacturing, denoted as IF-DTiM, which possesses several distinct merits to distinguish itself from previous works. First, IF-DTiM fully utilizes new-generation container technology so that DT-related applications and services can be packaged in a self-contained way, rapidly deployed, and robustly operated with the capabilities of failover, autoscaling, and load balancing. Second, it leverages existing intelligent cloud manufacturing services to realize the intelligence for DT externally in a scalable and plug-and-play manner instead of using traditional approaches to embed intelligence in DT. Third, IF-DTiM contains Product DT for products, Equipment DT (i.e., EQ DT) for equipment, and Process DT for production lines, which can generically fulfill the demands and scenarios to achieve intelligent manufacturing for various manufacturing industries. Testing results show that IF-DTiM can achieve remarkable performance in rapid deployment and real-time data exchanges of DT-related applications. Finally, we develop an example DTiM system for CNC machining based on IF-DTiM to demonstrate its efficacy and applicability in facilitating the manufacturing industry to build their DT systems. Note to Practitioners - Developing Digital Twin (DT) systems to realize intelligent manufacturing is challenging. The proposed IF-DTiM (Implementation Framework of Digital Twins for Intelligent Manufacturing) provides a novel container-technology and cloud-manufacturing-service-based systematic methodology for building DTiM. In this paper, we present the system architecture and several operational scenarios (e.g., how to create and use DTs) of IF-DTiM, together with the design of its core functional mechanisms (e.g., rapid deployment scheme for DT, real-time data exchange for DT, DT interface pattern, and general workflow architecture for DT). Also, an example DTiM system for CNC machining based on IF-DTiM is presented to facilitate the practitioners to adopt the designs and niches in IF-DTiM to build their desired DTiM systems.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Transactions on Automation Science and Engineering;2022-07-01;https://api.elsevier.com/content/abstract/scopus_id/85124199123
10;A pattern catalog for augmenting Digital Twin models with behavior Ein Musterkatalog zur Erweiterung von digitalen Zwillingsmodellen um Verhaltenssichten;Digital Twins are emerging as a solution to build and extend existing software systems to make better use of data produced by physical systems. For supporting the development of Digital Twins, several software vendors are offering dedicated tool support, often referred to as Digital Twin platforms. The modeling capabilities of these platforms are mostly concerned with structural viewpoints, i.e., providing an overview of available components including their current and historical sensor values. However, behavioral viewpoints did not yet receive much attention on these platforms. As behavioral models are often used during the design processes, e.g., for simulation and synthesis, it would be beneficial for having them included in Digital Twin platforms, e.g., for reasoning on the set of possible next actions or for checking the execution history to perform runtime validation. In this paper, we present a catalog of modeling patterns for augmenting Digital Twin models with behavioral models and their corresponding runtime information without requiring any extension of the code bases of Digital Twin platforms. We demonstrate the presented modeling patterns by applying them to the Digital Twin platform offered by Microsoft, in an additive manufacturing use case of a 3D printer in a production line.;De Gruyter Oldenbourg;Journal;At-Automatisierungstechnik;2023-06-01;https://api.elsevier.com/content/abstract/scopus_id/85161546216
11;A pattern catalog for augmenting Digital Twin models with behavior Ein Musterkatalog zur Erweiterung von digitalen Zwillingsmodellen um Verhaltenssichten;Digital Twins are emerging as a solution to build and extend existing software systems to make better use of data produced by physical systems. For supporting the development of Digital Twins, several software vendors are offering dedicated tool support, often referred to as Digital Twin platforms. The modeling capabilities of these platforms are mostly concerned with structural viewpoints, i.e., providing an overview of available components including their current and historical sensor values. However, behavioral viewpoints did not yet receive much attention on these platforms. As behavioral models are often used during the design processes, e.g., for simulation and synthesis, it would be beneficial for having them included in Digital Twin platforms, e.g., for reasoning on the set of possible next actions or for checking the execution history to perform runtime validation. In this paper, we present a catalog of modeling patterns for augmenting Digital Twin models with behavioral models and their corresponding runtime information without requiring any extension of the code bases of Digital Twin platforms. We demonstrate the presented modeling patterns by applying them to the Digital Twin platform offered by Microsoft, in an additive manufacturing use case of a 3D printer in a production line.;De Gruyter Oldenbourg;Journal;At-Automatisierungstechnik;2023-06-01;https://api.elsevier.com/content/abstract/scopus_id/85161546216
12;A pattern catalog for augmenting Digital Twin models with behavior Ein Musterkatalog zur Erweiterung von digitalen Zwillingsmodellen um Verhaltenssichten;Digital Twins are emerging as a solution to build and extend existing software systems to make better use of data produced by physical systems. For supporting the development of Digital Twins, several software vendors are offering dedicated tool support, often referred to as Digital Twin platforms. The modeling capabilities of these platforms are mostly concerned with structural viewpoints, i.e., providing an overview of available components including their current and historical sensor values. However, behavioral viewpoints did not yet receive much attention on these platforms. As behavioral models are often used during the design processes, e.g., for simulation and synthesis, it would be beneficial for having them included in Digital Twin platforms, e.g., for reasoning on the set of possible next actions or for checking the execution history to perform runtime validation. In this paper, we present a catalog of modeling patterns for augmenting Digital Twin models with behavioral models and their corresponding runtime information without requiring any extension of the code bases of Digital Twin platforms. We demonstrate the presented modeling patterns by applying them to the Digital Twin platform offered by Microsoft, in an additive manufacturing use case of a 3D printer in a production line.;De Gruyter Oldenbourg;Journal;At-Automatisierungstechnik;2023-06-01;https://api.elsevier.com/content/abstract/scopus_id/85161546216
13;A pattern catalog for augmenting Digital Twin models with behavior Ein Musterkatalog zur Erweiterung von digitalen Zwillingsmodellen um Verhaltenssichten;Digital Twins are emerging as a solution to build and extend existing software systems to make better use of data produced by physical systems. For supporting the development of Digital Twins, several software vendors are offering dedicated tool support, often referred to as Digital Twin platforms. The modeling capabilities of these platforms are mostly concerned with structural viewpoints, i.e., providing an overview of available components including their current and historical sensor values. However, behavioral viewpoints did not yet receive much attention on these platforms. As behavioral models are often used during the design processes, e.g., for simulation and synthesis, it would be beneficial for having them included in Digital Twin platforms, e.g., for reasoning on the set of possible next actions or for checking the execution history to perform runtime validation. In this paper, we present a catalog of modeling patterns for augmenting Digital Twin models with behavioral models and their corresponding runtime information without requiring any extension of the code bases of Digital Twin platforms. We demonstrate the presented modeling patterns by applying them to the Digital Twin platform offered by Microsoft, in an additive manufacturing use case of a 3D printer in a production line.;De Gruyter Oldenbourg;Journal;At-Automatisierungstechnik;2023-06-01;https://api.elsevier.com/content/abstract/scopus_id/85161546216
14;A pattern catalog for augmenting Digital Twin models with behavior Ein Musterkatalog zur Erweiterung von digitalen Zwillingsmodellen um Verhaltenssichten;Digital Twins are emerging as a solution to build and extend existing software systems to make better use of data produced by physical systems. For supporting the development of Digital Twins, several software vendors are offering dedicated tool support, often referred to as Digital Twin platforms. The modeling capabilities of these platforms are mostly concerned with structural viewpoints, i.e., providing an overview of available components including their current and historical sensor values. However, behavioral viewpoints did not yet receive much attention on these platforms. As behavioral models are often used during the design processes, e.g., for simulation and synthesis, it would be beneficial for having them included in Digital Twin platforms, e.g., for reasoning on the set of possible next actions or for checking the execution history to perform runtime validation. In this paper, we present a catalog of modeling patterns for augmenting Digital Twin models with behavioral models and their corresponding runtime information without requiring any extension of the code bases of Digital Twin platforms. We demonstrate the presented modeling patterns by applying them to the Digital Twin platform offered by Microsoft, in an additive manufacturing use case of a 3D printer in a production line.;De Gruyter Oldenbourg;Journal;At-Automatisierungstechnik;2023-06-01;https://api.elsevier.com/content/abstract/scopus_id/85161546216
15;A pattern catalog for augmenting Digital Twin models with behavior Ein Musterkatalog zur Erweiterung von digitalen Zwillingsmodellen um Verhaltenssichten;Digital Twins are emerging as a solution to build and extend existing software systems to make better use of data produced by physical systems. For supporting the development of Digital Twins, several software vendors are offering dedicated tool support, often referred to as Digital Twin platforms. The modeling capabilities of these platforms are mostly concerned with structural viewpoints, i.e., providing an overview of available components including their current and historical sensor values. However, behavioral viewpoints did not yet receive much attention on these platforms. As behavioral models are often used during the design processes, e.g., for simulation and synthesis, it would be beneficial for having them included in Digital Twin platforms, e.g., for reasoning on the set of possible next actions or for checking the execution history to perform runtime validation. In this paper, we present a catalog of modeling patterns for augmenting Digital Twin models with behavioral models and their corresponding runtime information without requiring any extension of the code bases of Digital Twin platforms. We demonstrate the presented modeling patterns by applying them to the Digital Twin platform offered by Microsoft, in an additive manufacturing use case of a 3D printer in a production line.;De Gruyter Oldenbourg;Journal;At-Automatisierungstechnik;2023-06-01;https://api.elsevier.com/content/abstract/scopus_id/85161546216
16;A subject-oriented reference model for Digital Twins;The term “Digital Twin” is used in context of a wide range of applications but neither research nor industry have agreed upon one singular definition. Presented here is a novel and formal, subject-oriented reference model for Digital Twin systems that does not focus on technical architectural concepts or particular implementation specific details, but rather on the general possibilities and functionalities that can be expected or missed from Digital Twins. The model depicts the interactions of a Digital Twin system with other entities (i.e. humans, IT-systems and other Digital Twin systems). The purpose of the model is to help practitioners understand and especially communicate about Digital Twins and improve their ability to assess and express their own needs and role in context of designing specific Industry 4.0 use cases accordingly.;Elsevier Ltd;Journal;Computers and Industrial Engineering;2022-10-01;https://api.elsevier.com/content/abstract/scopus_id/85136257331
17;A Survey on Digital Twins: Architecture, Enabling Technologies, Security and Privacy, and Future Prospects;By interacting, synchronizing, and cooperating with its physical counterpart in real time, digital twin is promised to promote an intelligent, predictive, and optimized modern city. Via interconnecting massive physical entities and their virtual twins with inter-twin and intra-twin communications, the Internet of digital twins (IoDT) enables free data exchange, dynamic mission cooperation, and efficient information aggregation for composite insights across vast physical/virtual entities. However, as IoDT incorporates various cutting-edge technologies to spawn the new ecology, severe known/unknown security flaws and privacy invasions of IoDT hinders its wide deployment. Besides, the intrinsic characteristics of IoDT such as decentralized structure, information-centric routing and semantic communications entail critical challenges for security service provisioning in IoDT. To this end, this paper presents an in-depth review of the IoDT with respect to system architecture, enabling technologies, and security/privacy issues. Specifically, we first explore a novel distributed IoDT architecture with cyber-physical interactions and discuss its key characteristics and communication modes. Afterward, we investigate the taxonomy of security and privacy threats in IoDT, discuss the key research challenges, and review the state-of-the-art defense approaches. Finally, we point out the new trends and open research directions related to IoDT.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Internet of Things Journal;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85153393414
18;A Survey on Digital Twins: Architecture, Enabling Technologies, Security and Privacy, and Future Prospects;By interacting, synchronizing, and cooperating with its physical counterpart in real time, digital twin is promised to promote an intelligent, predictive, and optimized modern city. Via interconnecting massive physical entities and their virtual twins with inter-twin and intra-twin communications, the Internet of digital twins (IoDT) enables free data exchange, dynamic mission cooperation, and efficient information aggregation for composite insights across vast physical/virtual entities. However, as IoDT incorporates various cutting-edge technologies to spawn the new ecology, severe known/unknown security flaws and privacy invasions of IoDT hinders its wide deployment. Besides, the intrinsic characteristics of IoDT such as decentralized structure, information-centric routing and semantic communications entail critical challenges for security service provisioning in IoDT. To this end, this paper presents an in-depth review of the IoDT with respect to system architecture, enabling technologies, and security/privacy issues. Specifically, we first explore a novel distributed IoDT architecture with cyber-physical interactions and discuss its key characteristics and communication modes. Afterward, we investigate the taxonomy of security and privacy threats in IoDT, discuss the key research challenges, and review the state-of-the-art defense approaches. Finally, we point out the new trends and open research directions related to IoDT.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Internet of Things Journal;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85153393414
19;A TOSCA-Based Conceptual Architecture to Support the Federation of Heterogeneous MSaaS Infrastructures †;Modeling and simulation (M&S) techniques are effectively used in many application domains to support various operational tasks ranging from system analyses to innovative training activities. Any (M&S) effort might strongly benefit from the adoption of service orientation and cloud computing to ease the development and provision of M&S applications. Such an emerging paradigm is commonly referred to as M&S-as-a-Service (MSaaS). The need for orchestrating M&S services provided by different partners in a heterogeneous cloud infrastructure introduces new challenges. In this respect, the adoption of an effective architectural approach might significantly help the design and development of MSaaS infrastructure implementations that cooperate in a federated environment. In this context, this work introduces a MSaaS reference architecture (RA) that aims to investigate innovative approaches to ease the building of inter-cloud MSaaS applications. Moreover, this work presents ArTIC-MS, a conceptual architecture that refines the proposed RA for introducing the TOSCA (topology and orchestration specification for cloud applications) standard. ArTIC-MS’s main objective is to enable effective portability and interoperability among M&S services provided by different partners in heterogeneous federations of cloud-based MSaaS infrastructure. To show the validity of the proposed architectural approach, the results of concrete experimentation are provided.;MDPI;Journal;Future Internet;2023-02-01;https://api.elsevier.com/content/abstract/scopus_id/85148891162
20;Accurate and Efficient Digital Twin Construction Using Concurrent End-to-End Synchronization and Multi-Attribute Data Resampling;Accurate and efficient digital twin construction through real-time multi-attribute sensing and remote concurrent data analysis is essential in supporting complex connected industrial applications. Given the unsynchronized nature and heterogeneous sampling rates of distributed sensing processes, the varying time misalignment among different attributes will inevitably deteriorate the remote correlation analysis and digital twin construction. Furthermore, application-agnostic digital twin construction approaches could potentially involve high communication and computation overhead for comprehensive digital twin construction. In this article, a concurrent end-to-end time synchronization and multi-attribute data resampling scheme is proposed to enable accurate and efficient digital twin construction at the remote end. Specifically, digital clocks are concurrently established at the remote end, with each of them associated with a sampling rate of a unique sensing attribute. To tackle the temporal misalignment among multiple sensing attributes, raw data are accurately resampled according to the same reference frequency, with attribute-specific synchronized digital clocks providing cohesively aligned time information. An edge-centric platform is established to efficiently guide the multidimensional data processing during digital twin construction. Simulation results demonstrate that the proposed scheme can achieve more accurate and efficient digital twin construction than existing modeling methods. In the end, the digital twin-driven predictive maintenance is presented as a case study, aiming at illustrating the potential applications and benefits expected of the proposed scheme in industrial environments.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Internet of Things Journal;2023-03-15;https://api.elsevier.com/content/abstract/scopus_id/85141631359
21;Air Quality Management: An Exemplar for Model-Driven Digital Twin Engineering;Since its first mentioning in the literature, the concept of Digital Twin has gained traction in both industry and academia. However, there are still many open challenges when applying Digital Twins to industry-scale use cases. Applying Model-Driven Engineering techniques to the creation and maintenance of Digital Twins (also referred to as Model-Driven Digital Twin Engineering) promises automation and consistency throughout the life cycle of a Digital Twin. The exemplar provided in this paper can be used to identify open challenges when it comes to Model-Driven Digital Twin Engineering, and to demonstrate how approaches can solve them. This exemplar applies Digital Twins to an indoor air quality management use case, where CO2, temperature, and humidity values of rooms within a building are measured. These values can be used to derive actions to improve work productivity and reduce the risk for virus infections. We describe three applications that make use of this Digital Twin (i.e., runtime visualization, physical simulation, and ML-based predictions), and provide an online repository with the artefacts of this exemplar.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Companion Proceedings - 24th International Conference on Model-Driven Engineering Languages and Systems, MODELS-C 2021;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85124047367
22;AML4DT: A Model-Driven Framework for Developing and Maintaining Digital Twins with AutomationML;As technologies such as the Internet of Things (IoT) and Cyber-Physical Systems (CPS) are becoming ubiquitous, systems adopting these technologies are getting increasingly complex. Digital Twins (DTs) provide comprehensive views on such systems, the data they generate during runtime, as well as their usage and evolution over time. Setting up the required infrastructure to run a Digital Twin is still an ambitious task that involves significant upfront efforts from domain experts, although existing knowledge about the systems, such as engineering models, may be already available for reuse. To address this issue, we present AML4DT, a model-driven framework supporting the development and maintenance of Digital Twin infrastructures by employing AutomationML (AML) models. We automatically establish a connection between systems and their DTs based on dedicated DT models. These DT models are automatically derived from existing AutomationML models, which are produced in the engineering phases of a system. Additionally, to alleviate the maintenance of the DTs, AML4DT facilitates the synchronization of the AutomationML models with the DT infrastructure for several evolution cases. A case study shows the benefits of developing and maintaining DTs based on AutomationML models using the proposed AML4DT framework. For this particular study, the effort of performing the required tasks could be reduced by about 50%.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;IEEE International Conference on Emerging Technologies and Factory Automation, ETFA;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85122957318
23;An Algorithm for Offline Measurement of Motor Stator Resistance and Voltage Drop Across Inverter Switches for Washing Machine Drives;The knowledge of the exact value of motor phase resistance is extremely important for modern electrical drives, which use it for tuning of current controllers, position estimators, temperature monitoring, and so on. At the same time, the value of voltage drop across inverter switches is necessary for providing proper and efficient control, especially in the low-speed region, where the impact of system nonlinearities is significant. This article proposes a novel algorithm for the offline measurement of motor resistance and voltage drop across inverter switches, which significantly improved the performance of washing machines in open-loop starting and low-speed operation. The proposed technique uses two step injection of dc current into stator windings, which provides data for the estimation of resistance and voltage drop. This article describes traps and pitfalls on the way of implementation and tuning and provides recommendations on avoiding them. After analysis of detailed experimental results, the author gives recommendation on a selection of algorithm parameters in order to provide low estimation errors. Following successful implementation and a series of tests, this technique has been accepted for mass production and has become an inevitable part of the control system of washing machines.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Journal of Emerging and Selected Topics in Power Electronics;2022-10-01;https://api.elsevier.com/content/abstract/scopus_id/85130785745
24;An Approach to Support Digital Process Twin;Nowadays, the digitalization of business processes goes hand in hand with the adoption of IoT and robotic systems for automating work activities, leading to the birth of new ways of representing organizational information, i.e. digital twins. However, interpreting the behavior of autonomous systems, especially those with several devices, and keeping track of their execution status can be very difficult even using ad-hoc simulators. Therefore, there is the need for a digital process twin representing, simulating, and visualizing systems' behavior. In this regard, this work proposes an approach to support the digital process twins of autonomous systems by representing, simulating, and visualizing the system behavior. We demonstrate the benefits of the approach by applying it to a robotic scenario.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings of the 2022 IEEE International Conference on Dependable, Autonomic and Secure Computing, International Conference on Pervasive Intelligence and Computing, International Conference on Cloud and Big Data Computing, International Conference on Cyber Science and Technology Congress, DASC/PiCom/CBDCom/CyberSciTech 2022;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85145355941
25;An update method for digital twin multi-dimension models;Digital twin, as an effective means to realize the fusion between physical and virtual spaces, has attracted more and more attention in the past few years. Based on ultra-fidelity models, more accurate service, e.g. real-time monitoring and failure prediction, can be reached. Against the background, some scholars studied the related theories and methods on modeling to depict various features of physical objects. Some scholars studied how to use Internet of Things to realize the connections and interactions, thereby keeping the consistency between the virtual and physical spaces. During this process, a new question arises that how to update the models once digital twin models are inconsistent with the practical situations. To solve the problem, this paper proposed a general digital twin model update framework at first. Then, the update methods for multi-dimension models are further explored. The cutting tool is the core component of machine tools which are the key equipment in industry. The precise cutting tool models are essential for realizing the digitalization and servitization of machine tools. Therefore, this paper takes a cutting tool as the application object to discuss how to conduct physics model update based on the proposed framework and methods. Through model update, a more accurate and updated tool wear model could be obtained, which contributes to the prognostics and health management for machine tools.;Elsevier Ltd;Journal;Robotics and Computer-Integrated Manufacturing;2023-04-01;https://api.elsevier.com/content/abstract/scopus_id/85143832601
26;Decentralized Real-Time Anomaly Detection in Cyber-Physical Production Systems under Industry Constraints;Anomaly detection is essential for realizing modern and secure cyber-physical production systems. By detecting anomalies, there is the possibility to recognize, react early, and in the best case, fix the anomaly to prevent the rise or the carryover of a failure throughout the entire manufacture. While current centralized methods demonstrate good detection abilities, they do not consider the limitations of industrial setups. To address all these constraints, in this study, we introduce an unsupervised, decentralized, and real-time process anomaly detection concept for cyber-physical production systems. We employ several 1D convolutional autoencoders in a sliding window approach to achieve adequate prediction performance and fulfill real-time requirements. To increase the flexibility and meet communication interface and processing constraints in typical cyber-physical production systems, we decentralize the execution of the anomaly detection into each separate cyber-physical system. The installation is fully automated, and no expert knowledge is needed to tackle data-driven limitations. The concept is evaluated in a real industrial cyber-physical production system. The test result confirms that the presented concept can be successfully applied to detect anomalies in all separate processes of each cyber-physical system. Therefore, the concept is promising for decentralized anomaly detection in cyber-physical production systems.;MDPI;Journal;Sensors;2023-05-01;https://api.elsevier.com/content/abstract/scopus_id/85159179690
27;A novel application architecture of digital twin in smart grid;Digital twin (DT) is a hot topic in information engineering, which has been introduced into the intelligent solution of the power grid system to deal with the reliability assurance issues of complex systems. Due to the lack of an operational application architecture model, it is impossible to map the complex system comprehensively. Based on the review of the concept model of DT and the current research situation in the smart grid (SG), an OKDD [i.e., ontology-body (OB), knowledge-body (KB), data-body (DB), and digital-portal (DP)] model of digital twin body (DTB) is proposed and specified in detail. Taking a vacuum circuit breaker and a 35 kV substation of the power grid as examples, the OKDD is applied in the DTB construction, and the developed prognostic and health management (PHM) system demo is practiced in a 110 kV substation simply. The approach is proved to be feasible preliminarily. This model provides a novel method for the unified description and standardization of DTB, which is conducive to the hierarchical creation (unit-system-system of systems) for complex systems. Meanwhile, it can represent complex physical entities more comprehensively, and enable the reuse of knowledge and the duplication of similar unit-level DTB rapidly. Thus, this research provides a new reference for the practical application of DT.;Springer Science and Business Media Deutschland GmbH;Journal;Journal of Ambient Intelligence and Humanized Computing;2022-08-01;https://api.elsevier.com/content/abstract/scopus_id/85107510174
28;Applied Artificial Intelligence in Manufacturing and Industrial Production Systems: PEST Considerations for Engineering Managers;Presently, artificial intelligence (AI) is playing a leading role in our contemporary world via numerous applications. Despite its many advantages, analytical frameworks highlighting the implications of AI applications are still evolving. Particularly, in manufacturing and industrial production where novel technologies are continuously being harnessed. Consequently, AI and the implications of its applications have relatively remained a gray area for many engineering managers who are key players in the gravitation of manufacturing and industrial production toward the fourth industrial revolution and more recently, the fifth industrial revolution, generally termed as Industry 4.0 (I4.0) and Industry 5.0 (I5.0), respectively. In this study, the implications of AI applications in the general context of manufacturing and industrial production, are presented to provide insight for engineering managers. These implications are discussed via political, economic, social, and technological (PEST) considerations of the broad impact of the adoption of AI techniques in manufacturing and industrial production systems. A new engineering management model has not been proposed in this article. Rather, a discussion aimed at serving as a tool for the appraisal of the implications of the general applications of AI by engineering managers, who may not be AI specialists or data science experts is presented.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Engineering Management Review;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85139489635
29;Automatic Synthesis of Containerized Industrial Cyber-Physical Systems: A Case Study;Industrial cyber-physical systems (ICPSs) are widely regarded as the next generation industrial control systems and as one of the core technologies of the ongoing fourth industrial revolution. Despite its advantages, ICPSs are heavily dependent on the underlying physical process and their synthesis is a customized effort, demanding in terms of resources, which if not conducted carefully may impact the performance of the system. This work proposes a methodology to tackle ICPS synthesis in a systematic way, by using a set of industrial agents that take as input and standardized process description file and automatically deploy a modular ICPS from predesigned functional containers. Concrete examples on a tanks system and an industrial paste thickener are presented to illustrate the potential of the proposed methodology.;IEEE Computer Society;Journal;IEEE Transactions on Industrial Informatics;2023-07-01;https://api.elsevier.com/content/abstract/scopus_id/85141515926
30;Automatic Synthesis of Containerized Industrial Cyber-Physical Systems: A Case Study;Industrial cyber-physical systems (ICPSs) are widely regarded as the next generation industrial control systems and as one of the core technologies of the ongoing fourth industrial revolution. Despite its advantages, ICPSs are heavily dependent on the underlying physical process and their synthesis is a customized effort, demanding in terms of resources, which if not conducted carefully may impact the performance of the system. This work proposes a methodology to tackle ICPS synthesis in a systematic way, by using a set of industrial agents that take as input and standardized process description file and automatically deploy a modular ICPS from predesigned functional containers. Concrete examples on a tanks system and an industrial paste thickener are presented to illustrate the potential of the proposed methodology.;IEEE Computer Society;Journal;IEEE Transactions on Industrial Informatics;2023-07-01;https://api.elsevier.com/content/abstract/scopus_id/85141515926
31;Benefits and limitations of using low-code development to support digitalization in the construction industry;Low-code development is a technology enabling people with no advanced computing or coding skills to develop custom-made applications and digital solutions to address specific operational needs. Low-code has gained significant momentum in the last years and some studies have already reported the use of this technology to digitalize workflows and processes in a variety of business scenarios. Nevertheless, to-date there is no research evaluating the implications of this technology to support digitalization in construction industry. Based on a hybrid research approach combining literature review, case study, and surveys, this paper addresses this gap by evaluating the benefits and limitations of using low-code in the construction industry context. The study reveals that low-code productive application development practices have the potential to enable different degrees of digitalization and innovation in specific construction processes. The study also recognizes the relevance of adopting a strategic approach to fully leverage low-code at an organizational construction firm level and identifies several areas for further research. This includes leveraging synergies with industry-relevant subjects such as lean construction, Building Information Modelling, the Internet of Things, and Industry 4.0, among others.;Elsevier B.V.;Journal;Automation in Construction;2023-08-01;https://api.elsevier.com/content/abstract/scopus_id/85158877298
32;Benefits and limitations of using low-code development to support digitalization in the construction industry;Low-code development is a technology enabling people with no advanced computing or coding skills to develop custom-made applications and digital solutions to address specific operational needs. Low-code has gained significant momentum in the last years and some studies have already reported the use of this technology to digitalize workflows and processes in a variety of business scenarios. Nevertheless, to-date there is no research evaluating the implications of this technology to support digitalization in construction industry. Based on a hybrid research approach combining literature review, case study, and surveys, this paper addresses this gap by evaluating the benefits and limitations of using low-code in the construction industry context. The study reveals that low-code productive application development practices have the potential to enable different degrees of digitalization and innovation in specific construction processes. The study also recognizes the relevance of adopting a strategic approach to fully leverage low-code at an organizational construction firm level and identifies several areas for further research. This includes leveraging synergies with industry-relevant subjects such as lean construction, Building Information Modelling, the Internet of Things, and Industry 4.0, among others.;Elsevier B.V.;Journal;Automation in Construction;2023-08-01;https://api.elsevier.com/content/abstract/scopus_id/85158877298
33;Broken Bar Fault Detection and Diagnosis Techniques for Induction Motors and Drives: State of the Art;Motors are the higher energy-conversion devices that consume around 40% of the global electrical generated energy. Induction motors are the most popular motor type due to their reliability, robustness, and low cost. Therefore, both condition monitoring and fault diagnosis of induction motor faults have motivated considerable research efforts. In this paper, a comprehensive review of the recent techniques proposed in the literature for broken bar faults detection and diagnosis is presented. This paper mainly investigates the fault detection methods in line-fed and inverter-fed motors proposed after 2015 and published in most relevant journals and conferences. The introduced review has deeply discussed the main features of the reported methods and compared them in many different aspects. Finally, the study has highlighted the main issues and the gaps that require more attention from researchers in this field.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85136709295
34;Cognitive neuroscience and robotics: Advancements and future research directions;In recent years, brain-based technologies that capitalise on human abilities to facilitate human–system/robot interactions have been actively explored, especially in brain robotics. Brain–computer interfaces, as applications of this conception, have set a path to convert neural activities recorded by sensors from the human scalp via electroencephalography into valid commands for robot control and task execution. Thanks to the advancement of sensor technologies, non-invasive and invasive sensor headsets have been designed and developed to achieve stable recording of brainwave signals. However, robust and accurate extraction and interpretation of brain signals in brain robotics are critical to reliable task-oriented and opportunistic applications such as brainwave-controlled robotic interactions. In response to this need, pervasive technologies and advanced analytical approaches to translating and merging critical brain functions, behaviours, tasks, and environmental information have been a focus in brain-controlled robotic applications. These methods are composed of signal processing, feature extraction, representation of neural activities, command conversion and robot control. Artificial intelligence algorithms, especially deep learning, are used for the classification, recognition, and identification of patterns and intent underlying brainwaves as a form of electroencephalography. Within the context, this paper provides a comprehensive review of the past and the current status at the intersection of robotics, neuroscience, and artificial intelligence and highlights future research directions.;Elsevier Ltd;Journal;Robotics and Computer-Integrated Manufacturing;2024-02-01;https://api.elsevier.com/content/abstract/scopus_id/85165534271
35;Collaborative Modeling of Interoperable Digital Twins in a SoS Context;In an Industry 4.0 compliant production plant components from different value chain partners must work together. Digital Twins (DTs) are an essential part of that system of systems because all relevant assets will need those digital representations to be integrated into such kind of environment, as they establish the required flexibility for formerly rigid structures. This does not begin at the time of delivery of products but already during engineering of the production plant, where relevant data and information are needed. The DT topic is not exclusively a software topic, as it cannot be considered without the associated physical twins. This leads to a need for a holistic Model-Based Systems Engineering approach that integrates all necessary aspects into an architecture for interoperable DTs. This contribution presents an approach and guidelines for modeling DTs based on industry use cases. The goal is to support the implementation of interoperable DTs in Industry 4.0 by using formal modeling techniques. This closes the gap between informal discussions about DTs between value chain partners and the implemented interoperable DTs needed for a specific use case. Compatibility with emerging standards such as the asset administration shell is assured. Focus is the modeling of the DT environment, e.g. a production plant as a system of systems as well as the description of logical DT content elements. Main elements in the environment of a DT are other linked DTs, their relationships and interactions. Users of the modeling approach are developers or management responsible for the company's DTs. They can use it to develop the correct DTs for relevant use cases of their assets.;Elsevier B.V.;Conference Proceeding;Procedia CIRP;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85132298278
36;Compressor acoustic profile improvement in preheating mode;Quite operation of home appliances is one of the most significant criteria used by customers, when they select the exact device among several devices with similar functionality. In such circumstances, even minor noise, which happens quite rarely, may negatively impact on the choice of customers. Thus, makers of various device for home wage a war on every excessive noise. As a result, various methods for noise control became an attractive and popular topic, involving talented researchers. This paper studies acoustic noise in preheating mode of compressors, where motor does not rotate thus decreasing background noise. In these conditions other minor noises become notable and significantly impact noise profile of the compressors. In the preheating mode of compressor, the DC current is injected into motor windings warming them. This heat transfers through the motor parts and compressor shell to the oil located at the bottom of compressor. This operation is required in order to decrease oil viscosity and guarantee normal operation of mechanical part. However injected current produces noise, which is undesired and should be decreased as much as possible. This research proposes and analyzes several approaches to compressor preheating and select the most silent one.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2023 19th International Scientific Technical Conference Alternating Current Electric Drives, ACED 2023 - Proceedings;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85163725156
37;Construction of digital twin model of other-excited DC motor and application of simulation experiments;For the study of digital twin models, this paper analyzes the electromagnetic characteristics, mechanical characteristics, thermodynamic characteristics, and mutual coupling relationship of the other-excited DC motor, and constructs a mathematical model of 'electric-mechanical-thermal' integration suitable for digital twin technology. The model is built under the experimental data parameters and experimental information of the solid DC motor, which increases the generality, accuracy and timeliness of the model. The digital twin simulation system is built and used in simulation experiments on high-speed motor accidents using 3dsMax, Unity3D, and C#. The results show that the digital twin model is reasonably constructed, and the operation is stable and reliable in the built digital twin system, which can well map the various experimental data conditions of the real DC motor, and the simulation experiment is well applied, also solve the barrier that the real experiment can't conduct experimental operation on the high-speed motor accident, the experiment can be conducted anytime and anywhere, which is conducive to improving the efficiency, safety and accuracy of engineering teaching and saving resources.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2022 9th International Forum on Electrical Engineering and Automation, IFEEA 2022;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85149107741
38;Coupled Models in Electromagnetic and Energy Conversion Systems from Smart Theories Paradigm to That of Complex Events: A Review;In this article, we evaluate the modeling of a real operation of a real system using the corresponding adequate theory. We show that the smart theories often used do not directly correspond to reality because these theories have been established in idealized frameworks. The need to adapt such frames to real landscape situations necessitates modifying the models used. This can be achieved by taking into account the different existing physical phenomena, which are normally overlooked in smart idealized models, in a revised coupled model. This contribution aims to analyze and illustrate the relationship between smart theories and coupled realistic models through a literature review. The strategy for constructing such models is discussed and highlighted. The understanding of this approach is illustrated by an application to the case of electromagnetic and energy conversion systems. In these systems, intelligent energy management, conversion and control involve the use of an accurate realistic coupled model in system design, optimization and control. It is a question of coupling and solving equations representing these systems by taking into account the real phenomena involved, which are electrical, magnetic, mechanical, thermal and material. The obvious advantage of using such realistic models in computer-aided design and optimization tools is illustrated. Moreover, the interest of using such models in the supervision of systems is assessed. These demonstrations are supported by a review of examples of work carried out in the field.;MDPI;Journal;Applied Sciences (Switzerland);2022-05-01;https://api.elsevier.com/content/abstract/scopus_id/85132599610
39;Cyber-Physical Urban Mobility Systems: Opportunities and Challenges in Developing Countries;Rapid population growth and the number of vehicles in cities have complicated urban mobility management. Digitalization supported by the internet of things and wireless communication has allowed some cities to mitigate the problem by taking advantage of the multiple benefits offered. These are cyber-physical systems (CPS), which are systems where a number of devices collaborate for the control of physical entities. This recent technology finds its application in urban mobility. However, in the context of developing countries, there are many local specificities one needs to consider. How could the integration of cyber-physical systems help urban decision makers to design sustainable urban mobility systems that meet the needs of the population? The paper proposed not only a recent review of the literature, but also a framework of CPS of urban mobility to guide decision makers. The challenges, opportunities, and barriers to innovation of CPS in urban environments in developing countries have also been identified.;Taru Publications;Journal;International Journal of Software Innovation;2022-12-23;https://api.elsevier.com/content/abstract/scopus_id/85146133118
40;Dandelion: A scalable, cloud-based graphical language workbench for industrial low-code development;There is an increasing demand nowadays for low-code development platforms (LCDPs). As they rely heavily on graphical languages rather than writing code, these platforms enable citizen developers to participate in software development. However, creating new LCDPs is very costly, since it requires building support for graphical modelling and its integration with services like model validation, recommendation systems, or code generation. While Model-driven Engineering (MDE) has developed technologies to create these components, most of them are not cloud-based, as required by LCDPs. In particular, a cloud-based graphical workbench capable of providing the scalability required by industrial applications and adequately supporting technological heterogeneity is currently missing. To fill this gap we introduce Dandelion, a cloud-based graphical language workbench for LCDPs built following an MDE approach. The tool handles model heterogeneity by using a harmonising meta-model to uniformly represent models from diverse technologies, and supports a customisable level of conformance between models and meta-models. Scalability is addressed by persisting models in a distributed, highly flexible database whose infrastructure is designed to conform to the harmonising meta-model, thus favouring model retrieval. Additionally, a customisable scalability component is introduced for lazy model loading. This paper describes the concepts and principles behind the tool design and reports on an evaluation on large synthetic process mining models, and on domain-specific languages and large industrial models used within the UGROUND company, showing promising results.;Elsevier Ltd;Journal;Journal of Computer Languages;2023-08-01;https://api.elsevier.com/content/abstract/scopus_id/85160517467
41;Data sharing in Industry 4.0 - AutomationML, B2MML and International Data Spaces-based solutions;The concept of a data ecosystem and Industry 4.0 requires high-level vertical and horizontal interconnectivity across the entire value chain. Its successful realization demands standardized data models to ensure transparent, secure and widely integrable data sharing within and between enterprises. This paper provides a PRISMA method-based systematic review about data sharing in Industry 4.0 via AutomationML, B2MML and International Data Spaces-based solutions. The interconnection of these data models and the ISA-95 standard is emphasized. This review describes the major application areas of these standards and their extension as well as supporting technologies and their contribution towards horizontal integration and data ecosystems. This review highlights how much value interconnected, exchanged and shared data gained in recent years. Standardized data sharing mechanisms enable real-time, flexible and transparent communication, which features became top requirements to gain a competitive advantage. However, to foster the shift from within company data communication towards the data ecosystem, IT- and people-oriented cultures must be well-established to ensure data protection and digital trust. We believe that this review of these standardized data exchange and sharing solutions can contribute to the development and design of Industry 4.0-related systems as well as support related scientific research.;Elsevier B.V.;Journal;Journal of Industrial Information Integration;2023-06-01;https://api.elsevier.com/content/abstract/scopus_id/85149327374
42;Data sharing in Industry 4.0 - AutomationML, B2MML and International Data Spaces-based solutions;The concept of a data ecosystem and Industry 4.0 requires high-level vertical and horizontal interconnectivity across the entire value chain. Its successful realization demands standardized data models to ensure transparent, secure and widely integrable data sharing within and between enterprises. This paper provides a PRISMA method-based systematic review about data sharing in Industry 4.0 via AutomationML, B2MML and International Data Spaces-based solutions. The interconnection of these data models and the ISA-95 standard is emphasized. This review describes the major application areas of these standards and their extension as well as supporting technologies and their contribution towards horizontal integration and data ecosystems. This review highlights how much value interconnected, exchanged and shared data gained in recent years. Standardized data sharing mechanisms enable real-time, flexible and transparent communication, which features became top requirements to gain a competitive advantage. However, to foster the shift from within company data communication towards the data ecosystem, IT- and people-oriented cultures must be well-established to ensure data protection and digital trust. We believe that this review of these standardized data exchange and sharing solutions can contribute to the development and design of Industry 4.0-related systems as well as support related scientific research.;Elsevier B.V.;Journal;Journal of Industrial Information Integration;2023-06-01;https://api.elsevier.com/content/abstract/scopus_id/85149327374
43;Design, Modeling and Implementation of Digital Twins;A Digital Twin (DT) is a set of computer-generated models that map a physical object into a virtual space. Both physical and virtual elements exchange information to monitor, simulate, predict, diagnose and control the state and behavior of the physical object within the virtual space. DTs supply a system with information and operating status, providing capabilities to create new business models. In this paper, we focus on the construction of DTs. More specifically, we focus on determining (methodologically) how to design, create and connect physical objects with their virtual counterpart. We explore the problem into several phases: from functional requirement selection and architecture planning to integration and verification of the final (digital) models. We address as well how physical components exchange real-time information with DTs, as well as experimental platforms to build DTs (including protocols and standards). We conclude with a discussion and open challenges.;MDPI;Journal;Sensors;2022-07-01;https://api.elsevier.com/content/abstract/scopus_id/85135120136
44;Diagnosability Enforcement in Labeled Petri Nets Based on Digital Twins;This paper deals with the problem of diagnosability enforcement of discrete event systems. Given a non-diagnosable discrete event system modelled with Petri nets, which may enter a deadlock state or an unobservable live-lock (that each composed transition is unobservable), a digital twin system (derived from the original labeled Petri net model) can be established as a particular Petri net such that the original system under the control of its digital twin system is diagnosable. An example is given to illustrate the proposed method and the correctness of the method is proved by theoretical proof.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2022 8th International Conference on Control, Decision and Information Technologies, CoDIT 2022;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85134319241
45;Digital Resilience to Normal Accidents in High-Reliability Organizations;Digital technologies play a dual role on organizational resilience. On one side, digital systems introduce new technological risks. On the other side, digital systems increase the performances in response to hazardous accidents. Normal Accident Theory (NAT) and High-Reliability Organization (HRO) provide useful ground to explain the dynamics of digital resilience. However, the two theories have been either used as alternatives or with one theory dominating the other. We posit that to fully understand digital resilience we need to integrate NAT and HRO concepts instead of using them in isolation. We conduct a bibliometric analysis to identify major themes and application domains characterizing HRO and NAT research. We look at similarities and differences between the two streams and we build an integrated framework for the analysis of digital resilience. With our systematic analysis of the NAT and HRO discourses we advance the current understanding on resilience in digitally enabled operations.;Springer International Publishing;Book;Engineering the Transformation of the Enterprise: A Design Science Research Perspective;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85118718809
46;Digital Twin and Industrial Internet of Things Architecture to Reduce Carbon Emissions;The rapid growth of digital technology implies the progress of industry, by utilizing Industrial Internet of Things and Digital Twins, in collecting data through sensors and digitally monitoring and testing a product, with a view to improving its features, before the production of the physical product, in real world. At the same time, industrial carbon emissions are a major issue to be confronted. Since, Digital Twin is a connection between the physical and digital world, transferring data bidirectionally and providing insights into the lifecycle of a production process, it also can be utilized for the reduction of industrial carbon emissions. In this paper, we implement a method for the reduction of carbon emissions, by applying the Industrial Internet of Things to collect past data from manufacturing factors and a Digital Twin architecture to monitor present data, compose a model and predict its future behavior, considering renewable energy resources and less carbon emissions. This method contributes in improved decision making regarding the manufacturing process and energy efficient industrial operation.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2022 4th International Conference on Computer Communication and the Internet, ICCCI 2022;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85137073549
47;Digital Twin applications toward Industry 4.0: A Review;Digital Twin is a virtual representation of objects, processes, and systems that exist in real-time. While Digital Twin can represent digital objects, they are often used to connect the physical and digital worlds. This technology plays a vital role in fulfilling various requirements of Industry 4.0. It gives a digital image of a factory's operations, a communications network's activities, or the movement of items through a logistics system. This paper studies Digital Twin and its need in Industry 4.0. Then the process and supportive features of Digital Twin for Industry 4.0 are diagrammatically discussed, and finally, the major applications of Digital Twin for Industry 4.0 are identified. Digital Twin sophistication depends on the process or product represented and the data available. Manufacturers can learn how assets will behave in real-time, in the physical world, by putting sensors on particular assets, gathering data, creating digital duplicates, and employing machine intelligence. They can confidently make wise judgments, which helps improve company performance. Digital Twin assesses material usage to save costs, discover inefficiencies, replicate tool tracking systems, and do other things. Manufacturers construct a digital clone for specific equipment and tools, exclusive products or systems, entire procedures, or anything else they want to improve on the factory floor. Sensors and other equipment that collect real-time data on the state of the process or product collect this information, which on the other hand, must be handled and processed appropriately. It is made feasible by IoT sensors, which collect data from the physical environment and transmit it to be virtually recreated. This information comprises design and engineering details that explain the asset's shape, materials, components, and behaviour or performance.;KeAi Communications Co.;Journal;Cognitive Robotics;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85152954260
48;Digital Twin based Cyber Range for Industrial Internet of Things;With the continuous integration of information technology and operation technology, Industrial Internet of Things(IIoT) is gradually changing from closed to open. Operators can configure, monitor, or control the industrial production process remotely via Internet, which brings security threats to IIoTs. Since the IIoT focuses on the availability of industrial production, it is unfeasible to study security issues directly on the industrial field. Thus, constructing an IIoT cyber range to reproduce industrial scenarios for offensive and defensive confrontation research is necessary. However, the traditional IIoT cyber range relies on physical industrial field devices that are not reproducible and hard to recover from cyber attacks. To solve these problems, in this paper, we propose a framework for a digital twin based cyber range and a digital twin construction method with multiple models. Cyber ranges with digital twins are more flexible and convenient. Based on the proposed method, an industrial scenario is reproduced using machine learning algorithms to predict temperature changes from different perspectives. The experimental result shows the ability of digital twins to construct an IIoT cyber range to reproduce production processes and replace field devices.;Institute of Electrical and Electronics Engineers Inc.;Trade Journal;IEEE Consumer Electronics Magazine;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85137911695
49;Digital Twin connectivity topologies;Digital Twin (DT) is one of the key concepts in the industry 4.0. Through the Internet of Things (IoT), it brings the ability of having a virtual representation of a real-world element which enables many possibilities such as saving and tracking its life-cycle, perform simulations, learning based on all this data and so on. However, it is still an ongoing concept that is continuously being evolved. Therefore, a well defined topology of how a DT can be build is still needed. In this context, this paper specifies six ways of how a DT can be build in different kind of applications. Examples of models for each proposed topology are given in AutomationML for better understanding of the proposal.;Elsevier B.V.;Conference Proceeding;IFAC-PapersOnLine;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85120719325
50;Design and Implementation of Hierarchical Digital Twins in Industrial Production Environments;The increasing requirements for industrial production environments due to customer expectations, the implementation of batch size 1, and further automation of production processes are confronting companies with new challenges. In particular, the emergence of cyber-physical systems is influencing and complicating manufacturing processes by capturing an increasing amount of information within production facilities. Digital twins are an interdisciplinary technology that may solve these issues because they serve to monitor, control, and optimize cyber-physical systems by creating a digital representation of real-world objects. Existing concepts for digital twins usually only consider individual machines without their context. This is of limited use for production environments due to a multitude of different machines and associated sensor types. Therefore, we propose a requirements catalog, concept, and prototypical implementation for the hierarchical structuring of digital twins in this paper.;IEEE Computer Society;Conference Proceeding;Proceedings of the Annual Hawaii International Conference on System Sciences;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85152136621
51;Design and Implementation of Hierarchical Digital Twins in Industrial Production Environments;The increasing requirements for industrial production environments due to customer expectations, the implementation of batch size 1, and further automation of production processes are confronting companies with new challenges. In particular, the emergence of cyber-physical systems is influencing and complicating manufacturing processes by capturing an increasing amount of information within production facilities. Digital twins are an interdisciplinary technology that may solve these issues because they serve to monitor, control, and optimize cyber-physical systems by creating a digital representation of real-world objects. Existing concepts for digital twins usually only consider individual machines without their context. This is of limited use for production environments due to a multitude of different machines and associated sensor types. Therefore, we propose a requirements catalog, concept, and prototypical implementation for the hierarchical structuring of digital twins in this paper.;IEEE Computer Society;Conference Proceeding;Proceedings of the Annual Hawaii International Conference on System Sciences;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85152136621
52;Digital twin for electric vehicle battery management with incremental learning;The current Industry 4.0 revolution promotes the use of cyber–physical systems to enhance manufacturing and other industrial processes via automation, real-time analysis, etc. Data communication between individual systems plays an important role in this revolution's success. As defined by researchers, Digital Twin is the digital representation of a physical system that enables predictive maintenance. Due to the increase in environmental pollution, battery-powered electric vehicles (EVs) are regarded as the urgent solution to internal combustion engines in the transportation business, despite obstacles such as safety concerns and range estimation. State of Health (SoH) and State of Charge (SoC) are two battery metrics that, when precisely anticipated, permit safer and longer battery use. Predicting these parameters online is computationally and financially expensive. Alternately, some of these factors could be predicted in the cloud rather than on the vehicle, hence cutting costs. Consequently, the EV business is one example where cloud-to-vehicle data connection saves total costs. A digital twin for an EV battery would aid in the estimate of battery parameters for predictive maintenance. This paper presents a Digital Twin paradigm for EV battery management in which SoH is predicted in the cloud and SoC is estimated on-vehicle. A continuous learning method is also proposed for forecasting SoH, whereas the Kalman filter is used to estimate SoC. The proposed framework predicts the SoH with a mean square error of 0.022.;Elsevier Ltd;Journal;Expert Systems with Applications;2023-11-01;https://api.elsevier.com/content/abstract/scopus_id/85160202665
53;Digital Twin for Monitoring an Industrial Process Using Augmented Reality;A Digital Twin (DT) is a virtual representation of a physical object which plays an important role in the digital transformation of industry, where an important requirement for intelligent manufacturing is cyber-physical integration. One of the objectives is to improve the performance of the real system using the information generated in the virtual part. The present paper shows the development of a low-cost DT used for monitoring the state of the process and the product development using augmented reality (AR) and free software for its configuration and programming. The design was tested in the MPS 500 classification station, which is a modular production station that has industrial sensors and actuators and was controlled with a Raspberry Pi (RPi) board responsible for sending data to the Firebase cloud to further show the DT in real-time in a mobile phone. Results show that with the help of the DT and AR, it is possible to automate industrial processes and monitor them from different places, collecting and analyzing data to achieve the implementation of solutions based on the data generated by the DT, enabling a greater level of digitalization and information to increase the efficiency and reliability of the processes.;IEEE Computer Society;Conference Proceeding;Iberian Conference on Information Systems and Technologies, CISTI;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85134849730
54;Meta-model-based shop-floor digital twin architecture, modeling and application;Digital twin is regarded as the virtual counterpart of physical entities, which can mirror the physical behavior and performance. Digital twin technology provides strong support for the achievement of cyber-physical system and intelligent manufacturing. Many investigations have been carried out for the digital twin of specific products. However, there are less researches on digital twin in the shop-floor domain, and there is a lack of model-driven digital twin comprehensive architecture. The modeling approach to the full lifecycle of digital twin is not considered enough. This paper proposes a meta-model-based shop-floor digital twin construction approach and a comprehensive architecture. A meta-model based on RAMI 4.0 is constructed, which provide a novel idea for the description of manufacturing resources and their status. The proposed shop-floor digital twin architecture consists of three key implementation elements: the meta-model construction, data modeling (including data interaction between cyber-physical spaces) and constructing different integration level models of shop-floor digital twin based on iteration feedback between the demands and models. The proposed approach is validated through a case study of the fischer learning factory 4.0.;Elsevier Ltd;Journal;Robotics and Computer-Integrated Manufacturing;2023-12-01;https://api.elsevier.com/content/abstract/scopus_id/85160515920
55;Digital Twin Techniques for Power Electronics-Based Energy Conversion Systems: A Survey of Concepts, Application Scenarios, Future Challenges, and Trends;The steady increase in energy demands has led to ever-increasing 'energy generation.' This, coupled with the need for higher efficiency, flexibility, and reliability, has boosted the use of power electronics in power and energy systems. Therefore, power electronics-based energy conversion systems (PEECSs) have become prominent in power generation, power transmission, and end user applications. Given the relevance of such systems, and by considering their trend of digitalization, it is crucial to establish digital and intelligent PEECSs. To this end, digital twins (DTs) can be adopted, as they integrate many cutting-edge information techniques to realize the life cycle management of complex systems by constructing real-time mappings of them. In this article, existing DT techniques for PEECSs are reviewed. The concept, system layers, and key technologies of DTs are described first. Some application cases of DTs are then elaborated. Finally, future trends and challenges of DTs are discussed to provide a valuable reference for subsequent research.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Industrial Electronics Magazine;2023-06-01;https://api.elsevier.com/content/abstract/scopus_id/85142826632
56;Digital Twin Techniques for Power Electronics-Based Energy Conversion Systems: A Survey of Concepts, Application Scenarios, Future Challenges, and Trends;The steady increase in energy demands has led to ever-increasing 'energy generation.' This, coupled with the need for higher efficiency, flexibility, and reliability, has boosted the use of power electronics in power and energy systems. Therefore, power electronics-based energy conversion systems (PEECSs) have become prominent in power generation, power transmission, and end user applications. Given the relevance of such systems, and by considering their trend of digitalization, it is crucial to establish digital and intelligent PEECSs. To this end, digital twins (DTs) can be adopted, as they integrate many cutting-edge information techniques to realize the life cycle management of complex systems by constructing real-time mappings of them. In this article, existing DT techniques for PEECSs are reviewed. The concept, system layers, and key technologies of DTs are described first. Some application cases of DTs are then elaborated. Finally, future trends and challenges of DTs are discussed to provide a valuable reference for subsequent research.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Industrial Electronics Magazine;2023-06-01;https://api.elsevier.com/content/abstract/scopus_id/85142826632
57;Digital Twin Techniques for Power Electronics-Based Energy Conversion Systems: A Survey of Concepts, Application Scenarios, Future Challenges, and Trends;The steady increase in energy demands has led to ever-increasing 'energy generation.' This, coupled with the need for higher efficiency, flexibility, and reliability, has boosted the use of power electronics in power and energy systems. Therefore, power electronics-based energy conversion systems (PEECSs) have become prominent in power generation, power transmission, and end user applications. Given the relevance of such systems, and by considering their trend of digitalization, it is crucial to establish digital and intelligent PEECSs. To this end, digital twins (DTs) can be adopted, as they integrate many cutting-edge information techniques to realize the life cycle management of complex systems by constructing real-time mappings of them. In this article, existing DT techniques for PEECSs are reviewed. The concept, system layers, and key technologies of DTs are described first. Some application cases of DTs are then elaborated. Finally, future trends and challenges of DTs are discussed to provide a valuable reference for subsequent research.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Industrial Electronics Magazine;2023-06-01;https://api.elsevier.com/content/abstract/scopus_id/85142826632
58;Digital Twin Techniques for Power Electronics-Based Energy Conversion Systems: A Survey of Concepts, Application Scenarios, Future Challenges, and Trends;The steady increase in energy demands has led to ever-increasing 'energy generation.' This, coupled with the need for higher efficiency, flexibility, and reliability, has boosted the use of power electronics in power and energy systems. Therefore, power electronics-based energy conversion systems (PEECSs) have become prominent in power generation, power transmission, and end user applications. Given the relevance of such systems, and by considering their trend of digitalization, it is crucial to establish digital and intelligent PEECSs. To this end, digital twins (DTs) can be adopted, as they integrate many cutting-edge information techniques to realize the life cycle management of complex systems by constructing real-time mappings of them. In this article, existing DT techniques for PEECSs are reviewed. The concept, system layers, and key technologies of DTs are described first. Some application cases of DTs are then elaborated. Finally, future trends and challenges of DTs are discussed to provide a valuable reference for subsequent research.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Industrial Electronics Magazine;2023-06-01;https://api.elsevier.com/content/abstract/scopus_id/85142826632
59;Digital Twin Technologies for Diesel Generator Sets in Backup and Emergency Power Supply Systems;In the electric power industry, the cost of work required to restore power generation and distribution equipment increases significantly with an increase in the energy intensity of power supply systems. This is determined not only by expensive repairs, but also by contractual relations between the generating company and the consumer. One of the ways to improve the power supply system's reliability is the formation of forecast estimates regarding the signs of the origin and emergency modes development of electrical equipment operation. A modern trend is the development of digital twin technologies for industrial equipment. The mathematical model of the diesel generator digital twin is considered. The possibilities of developing universal control and revision electronic modules with the accumulating information function about the operating modes of generating electrical equipment are analyzed.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2022 International Conference on Industrial Engineering, Applications and Manufacturing, ICIEAM 2022;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85133126732
60;Digital Twin: A Comprehensive Survey of Security Threats;Industry 4.0 is having an increasingly positive impact on the value chain by modernizing and optimizing the production and distribution processes. In this streamline, the digital twin (DT) is one of the most cutting-edge technologies of Industry 4.0, providing simulation capabilities to forecast, optimize and estimate states and configurations. In turn, these technological capabilities are encouraging industrial stakeholders to invest in the new paradigm, though an increased focus on the risks involved is really needed. More precisely, the deployment of a DT is based on the composition of technologies such as cyber-physical systems, the Industrial Internet of Things, edge computing, virtualization infrastructures, artificial intelligence and big data. However, the confluence of all these technologies and the implicit interaction with the physical counterpart of the DT in the real world generate multiple security threats that have not yet been sufficiently studied. In that context, this paper analyzes the current state of the DT paradigm and classifies the potential threats associated with it, taking into consideration its functionality layers and the operational requirements in order to achieve a more complete and useful classification. We also provide a preliminary set of security recommendations and approaches that can help to ensure the appropriate and trustworthy use of a DT.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Communications Surveys and Tutorials;2022-09-05;https://api.elsevier.com/content/abstract/scopus_id/85129610160
61;Digital Twin: Technology Evolution Stages and Implementation Layers with Technology Elements;A digital twin has recently received considerable attention in various industry domains. The digital twin replicates physical objects (e.g., people, objects, spaces, systems, and processes) in the real world into digital objects in the digital world. It also provides various simulations to solve problems in the real world or to improve situational operations. Therefore, the digital twin is a convergence of various technologies, such as advanced machine-learning algorithms, data analytics, super-resolution visualization and modeling, and simulation. Because the digital twin is a complicated technology, a step-by-step implementation that includes many technology elements should be considered to create a digital twin model. In this study, implementation layers are introduced to guide practical implementations of the digital twin. In addition, technology elements were suggested for the presented implementation layers. Because the suggested technology elements include clear technology definitions, various application domains (e.g., energy, transportation, logistics, environment, manufacturing, and smart cities) can easily utilize the introduced implementation layers and technology elements according to the intended purpose. Furthermore, this paper describes the evolution of digital twins. Digital twin technology has evolved continuously since 2002, when the digital twin concept was first introduced. In the described evolution levels, we show the future aspects of digital twin technology, according to the technological evolution direction. Therefore, the digital twin model can be efficiently created by considering the evolution direction and future aspects by using the suggested digital twin evolution levels.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85131586546
62;Digital Twin-Based Automated Fault Diagnosis in Industrial IoT Applications;In recent years, Digital Twin (DT) has gained significant interest from academia and industry due to the advanced in information technology, communication systems, Artificial Intelligence (AI), Cloud Computing (CC), and Industrial Internet of Things (IIoT). The main concept of the DT is to provide a comprehensive tangible, and operational explanation of any element, asset, or system. However, it is an extremely dynamic taxonomy developing in complexity during the life cycle that produces a massive amount of engendered data and information. Likewise, with the development of AI, digital twins can be redefined and could be a crucial approach to aid the Internet of Things (IoT)-based DT applications for transferring the data and value onto the Internet with better decision-making. Therefore, this paper introduces an efficient DT-based fault diagnosis model based on machine learning (ML) tools. In this framework, the DT model of the machine is constructed by creating the simulation model. In the proposed framework, the Genetic algorithm (GA) is used for the optimization task to improve the classification accuracy. Furthermore, we evaluate the proposed fault diagnosis framework using performance metrics such as precision, accuracy, F-measure, and recall. The proposed framework is comprehensively examined using the triplex pump fault diagnosis. The experimental results demonstrated that the hybrid GA-ML method gives outstanding results compared to ML methods like Logistic Regression (LR), Naïve Bayes (NB), and Support Vector Machine (SVM). The suggested framework achieves the highest accuracy of 95% for the employed hybrid GA-SVM. The proposed framework will effectively help industrial operators make an appropriate decision concerning the fault analysis for IIoT applications in the context of Industry 4.0.;Tech Science Press;Journal;Computers, Materials and Continua;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85148227180
63;Digital twins as run-time predictive models for the resilience of cyber-physical systems: A conceptual framework;Digital twins (DT) are emerging as an extremely promising paradigm for run-time modelling and performability prediction of cyber-physical systems (CPS) in various domains. Although several different definitions and industrial applications of DT exist, ranging from purely visual three-dimensional models to predictive maintenance tools, in this paper, we focus on data-driven evaluation and prediction of critical dependability attributes such as safety. To that end, we introduce a conceptual framework based on autonomic systems to host DT run-time models based on a structured and systematic approach. We argue that the convergence between DT and self-adaptation is the key to building smarter, resilient and trustworthy CPS that can self-monitor, self-diagnose and - ultimately - self-heal. The conceptual framework eases dependability assessment, which is essential for the certification of autonomous CPS operating with artificial intelligence and machine learning in critical applications. This article is part of the theme issue 'Towards symbiotic autonomous systems'.;Royal Society Publishing;Journal;Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences;2021-10-04;https://api.elsevier.com/content/abstract/scopus_id/85113299831
64;Digital Twins for 5G Networks: A Modeling and Deployment Methodology;A Mobile Networks Digital Twin (MNDT) is a virtual replica of a mobile communication network that accurately models the devices, the communication links, the operating environment, and the applications that run on the physical network. By replicating different environments in a laboratory and running multiple scenarios, Digital Twins provide a cost-effective way to evaluate performance, predict the effects of network changes, optimize network management, and make appropriate decisions. This paper presents a methodology for automatically creating and using Network Digital Twins, along with a proposed architecture for performing this implementation. This work is framed in the context of the B5GEMINI project, whose goal is to develop an MNDT applied to a 5G core environment and its evolution towards 6G, being able to apply it to use cases in advanced scenarios such as cybersecurity or Industry 4.0. The proposed methodology covers the entire lifecycle of the MNDT, from the initial phases of data acquisition and modeling to the phases of use and bidirectional connection between physical and digital elements.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85153479862
65;Digital Twins for Anomaly Detection in the Industrial Internet of Things: Conceptual Architecture and Proof-of-Concept;Modern cyber-physical systems based on the Industrial Internet of Things (IIoT) can be highly distributed and heterogeneous, and that increases the risk of failures due to misbehavior of interconnected components, or other interaction anomalies. In this paper, we introduce a conceptual architecture for IIoT anomaly detection based on the paradigms of Digital Twins (DT) and Autonomic Computing (AC), and we test it through a proof-of-concept of industrial relevance. The architecture is derived from the current state-of-the-art in DT research and leverages on the MAPE-K feedback loop of AC in order to monitor, analyze, plan, and execute appropriate reconfiguration or mitigation strategies based on the detected deviation from prescriptive behavior stored as shared knowledge. We demonstrate the approach and discuss results by using a reference operational scenario of adequate complexity and criticality within the European Railway Traffic Management System.;IEEE Computer Society;Journal;IEEE Transactions on Industrial Informatics;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85149357939
66;Digital Twins in Healthcare: an architectural proposal and its application in a social distancing case study;"The digital transformation process fostered by the development of Industry 4.0 technologies has largely affected the health sector, increasing diagnostic capabilities and improving drug effectiveness and treatment delivery. The Digital Twin (DT) technology, based on the virtualization of physical assets/processes and on a bidirectional communication between the digital and physical space for data exchange, is considered a game changer in modern health systems. Digital Twin applications in healthcare are various, ranging from virtualization of hospitals&#x0027; physical spaces/organizational processes to individuals&#x0027; physiological/genetic/lifestyle characteristics replication, and include the modeling of public health-related processes for monitoring, optimization and planning purposes. In this paper, motivated by the current COVID-19 pandemic, we focus on the application of the Digital Twin technology for virus containment on the workplace through social distancing. The contribution of this paper is three-fold: i) we review the existing literature on the adoption of the Digital Twin technology in the healthcare domain, and propose a classification of DT applications into four categories; ii) we propose a generalized Digital Twin architecture that can be used as reference to identify the main functional components of a Digital Twin system; iii) we present CanTwin, a real-life industrial case study developed by Hitachi and representing the Digital Twin of a canteen service serving 1100 workers, set up for social distancing monitoring, queue inspection, people counting and tracking, table occupancy supervision.";Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Journal of Biomedical and Health Informatics;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85137900898
67;Human Digital Twin in the context of Industry 5.0;Human-centricity, a core value of Industry 5.0, places humans in the center of production. It leads to the prioritization of human needs, spanning from health and safety to self-actualization and personal growth. The concept of the Human Digital Twin (HDT) is proposed as a critical method to realize human-centricity in smart manufacturing systems towards Industry 5.0. HDTs are digital representations of humans, aiming to change the practice of human-system integration by coupling humans’ characteristics directly to the system design and its performance. In-depth analysis, critical insights, and application guidelines of HDT are essential to realize the concept of Industry 5.0 in practice and evolve the smart manufacturing paradigm in modern factories. However, the investigation on the development of HDT to evolve humans’ roles and develop humans to their full potential is limited to date. Recent studies are rarely geared towards designing a standardized framework and architecture of HDT for diverse real-world applications. Thus, this work aims to close this research gap by carrying out a comprehensive survey on HDT in the context of Industry 5.0, summarizing the ongoing evolution, and proposing a proper connotation of HDT, before discussing the conceptual framework and system architecture of HDT and analyzing enabling technologies and industrial applications. This work provides guidance on possible avenues as well as challenges for the further development of HDT and its related concepts, allowing humans to reach their potential and accommodating their diverse needs in the futuristic smart manufacturing systems shaped by Industry 5.0.;Elsevier Ltd;Journal;Robotics and Computer-Integrated Manufacturing;2024-02-01;https://api.elsevier.com/content/abstract/scopus_id/85166028251
68;Digital Twins: A Survey on Enabling Technologies, Challenges, Trends and Future Prospects;Digital Twin (DT) is an emerging technology surrounded by many promises, and potentials to reshape the future of industries and society overall. A DT is a system-of-systems which goes far beyond the traditional computer-based simulations and analysis. It is a replication of all the elements, processes, dynamics, and firmware of a physical system into a digital counterpart. The two systems (physical and digital) exist side by side, sharing all the inputs and operations using real-time data communications and information transfer. With the incorporation of Internet of Things (IoT), Artificial Intelligence (AI), 3D models, next generation mobile communications (5G/6G), Augmented Reality (AR), Virtual Reality (VR), distributed computing, Transfer Learning (TL), and electronic sensors, the digital/virtual counterpart of the real-world system is able to provide seamless monitoring, analysis, evaluation and predictions. The DT offers a platform for the testing and analysing of complex systems, which would be impossible in traditional simulations and modular evaluations. However, the development of this technology faces many challenges including the complexities in effective communication and data accumulation, data unavailability to train Machine Learning (ML) models, lack of processing power to support high fidelity twins, the high need for interdisciplinary collaboration, and the absence of standardized development methodologies and validation measures. Being in the early stages of development, DTs lack sufficient documentation. In this context, this survey paper aims to cover the important aspects in realization of the technology. The key enabling technologies, challenges and prospects of DTs are highlighted. The paper provides a deep insight into the technology, lists design goals and objectives, highlights design challenges and limitations across industries, discusses research and commercial developments, provides its applications and use cases, offers case studies in industry, infrastructure and healthcare, lists main service providers and stakeholders, and covers developments to date, as well as viable research dimensions for future developments in DTs.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Communications Surveys and Tutorials;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85139416099
69;Digital twins: An analysis framework and open issues;The concept of twinning an operational physical system with a functional replica is not new, having been practiced in the space sector for over 50 years. Advances in digitalisation have created opportunities to extract data, obtain insights and achieve greater situational awareness of a physical system's performance. Increasing interest in the concept has led to a proliferation of digital twin definitions, which are used to frame discussions about specific digital twins. Consequentially comparison of the capabilities of specific digital twins is difficult as they are analysed using different definitions. This paper proposes an analysis framework that enables the characteristics of all digital twins to be matched to this framework. Using this framework, a digital twin may be characterised, or two or more digital twins may be compared. By establishing a framework that contains common functional characteristics, we aim to reduce the confusion caused by the plethora of digital twin definitions and their interpretation by suppliers. By focusing only on functionality and not addressing non-functional requirements the analysis allows comparison of different physical and logical instantiations of digital twins.;Elsevier B.V.;Journal;Computers in Industry;2022-12-01;https://api.elsevier.com/content/abstract/scopus_id/85136148334
70;Digital-twin based real-time resource allocation for hull parts picking and processing;The development of Industrial Internet of Things, big data, and multi-domain modeling, led to the emergence of digital twin (DT), providing a new approach to the cyber-physical production systems. In the traditional shipbuilding industry, a large number of hull parts are often tracked and transferred. During the hull parts picking and processing, the uncertainty from parts transfer tasks and logistics information often leads to low resource utilization. Therefore, a real-time resource allocation method based on DT for hull part smart picking and processing system (SPPS) is proposed. Firstly, a multi-agent model of the multi-gantry crane system is established in virtual space to achieve real-time task allocation, hence minimizing the transport time. Next, a real-time picking and processing scheduling policy is proposed to reduce the idle time of all workstations by estimating the time of parts arriving at target station and processing completion time. Finally, the services available in the DT platform can be applied to optimize the system performance, taking the number of devices and the takt time optimization as examples. Several experiments in case study are carried out to verify the proposed method. The average utilization rate of all workstations is increased by 17.39%, and the standard deviation is reduced by 83.31%. The results have shown that the proposed method can effectively improve the workstation utilization rate and load balance. The maximum average number of parts in the station buffer, which is limited to 0.33, is kept at a low level.;Springer;Journal;Journal of Intelligent Manufacturing;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85144154842
71;Drivers and Inhibitors of Low Code Development Platform Adoption;When done right, the use of low code development promises a significant competitive advantage in the software development process for organizations. Thus, multiple vendors have created low code development platforms to ease the use of low code development. However, current research on low code development platforms mainly focuses on the technological aspects of the platforms but not on their adoption. Hence, it remains unclear what drives and inhibits the adoption of low code development platforms. We conducted a literature review and identified thirteen factors that inhibit the adoption and seven factors that drive it. We structure these factors along with the diffusion of innovation framework that helps to disentangle drivers and inhibitors. As a result, we provide an initial explanation of the adoption of low code development platforms. Nevertheless, we conclude that existing research on the adoption of low code development platforms is not specific enough to understand the phenomenon substantially. Further, for some factors (e.g., cost), there is a disagreement in the academic literature on whether they are drivers or inhibitors. Hence, we identify gaps and derive avenues for future research.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2022 IEEE 24th Conference on Business Informatics, CBI 2022;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85142823139
72;DTMN a Modelling Notation for Digital Twins;Modelling and developing digital twin solutions is a growing and promising trend followed by enterprises with the ambition to improve decision-making and accelerate risk assessment and production time. However, as a current emerging trend, there is no recognised standard nor a unique solution that provides support for all the characteristics of a digital twin. This article builds upon the result of a literature review that we conducted to extract the main characteristics attributed to Digital Twins. The identified characteristics guided the proposal of a Digital Twin Modelling Notation (DTMN). In this work we present the DTMN meta-model supported by a graphical modelling notation. This modelling notation can be used as a starting point to design and reason about Digital Twin solutions.;Springer Science and Business Media Deutschland GmbH;Book Series;Lecture Notes in Business Information Processing;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85149833934
73;DTMN a Modelling Notation for Digital Twins;Modelling and developing digital twin solutions is a growing and promising trend followed by enterprises with the ambition to improve decision-making and accelerate risk assessment and production time. However, as a current emerging trend, there is no recognised standard nor a unique solution that provides support for all the characteristics of a digital twin. This article builds upon the result of a literature review that we conducted to extract the main characteristics attributed to Digital Twins. The identified characteristics guided the proposal of a Digital Twin Modelling Notation (DTMN). In this work we present the DTMN meta-model supported by a graphical modelling notation. This modelling notation can be used as a starting point to design and reason about Digital Twin solutions.;Springer Science and Business Media Deutschland GmbH;Book Series;Lecture Notes in Business Information Processing;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85149833934
74;Edge Artificial Intelligence for 6G: Vision, Enabling Technologies, and Applications;The thriving of artificial intelligence (AI) applications is driving the further evolution of wireless networks. It has been envisioned that 6G will be transformative and will revolutionize the evolution of wireless from 'connected things' to 'connected intelligence'. However, state-of-the-art deep learning and big data analytics based AI systems require tremendous computation and communication resources, causing significant latency, energy consumption, network congestion, and privacy leakage in both of the training and inference processes. By embedding model training and inference capabilities into the network edge, edge AI stands out as a disruptive technology for 6G to seamlessly integrate sensing, communication, computation, and intelligence, thereby improving the efficiency, effectiveness, privacy, and security of 6G networks. In this paper, we shall provide our vision for scalable and trustworthy edge AI systems with integrated design of wireless communication strategies and decentralized machine learning models. New design principles of wireless networks, service-driven resource allocation optimization methods, as well as a holistic end-to-end system architecture to support edge AI will be described. Standardization, software and hardware platforms, and application scenarios are also discussed to facilitate the industrialization and commercialization of edge AI systems.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Journal on Selected Areas in Communications;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85119402748
75;Enabling and supporting car-as-a-service by digital twin modeling and deployment;Smart City is one area of application for the Internet of Things (IoT) and it has been attracting attention from both academia and industry. Cities will be composed by autonomous parts that communicate and provide services to each other. For instance, cars (autonomous or not) may be seen as a service that transports people from one point to another. Interactions between users and these kinds of services will grow, making it necessary to have digitization of all these parts of the Smart City. The Digital Twin (DT) concept proposes that real-world assets have a virtual representation connecting the physical world with the cyber world. This allows to track the whole life-cycle of this object as well as perform simulations with current or previously stored data. In this context, this work proposes the use of Digital Twin for enabling and supporting car-as-a-service (CaaS). A case study has been developed to demonstrate the modeling and the deployment of the Digital Twin, highlighting how this concept can be one of the key enablers for CaaS.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings -Design, Automation and Test in Europe, DATE;2021-02-01;https://api.elsevier.com/content/abstract/scopus_id/85111062915
76;Essential Technologies and Concepts for Massive Space Exploration: Challenges and Opportunities;The space industry is growing at a tremendous pace generating attraction both from the industry and academia. Various governmental and industrial institutions are embarking on new programs aiming for more exploration of the industry. The impact of recent advances in the control system, computational technology, networking, Internet of Things (IoT), robotics, manufacturing, and machine learning (ML)/artificial intelligence could further support the space industry by providing the possibility of detailed and mass exploration of the deeper space. In that regard, this article reviews this multidiscipline area from the space exploration perspectives. This article focus on the most recent advancement in the aforementioned technologies along with control system theory considering the impact of long-distance between the controlling station and the intended site of exploration. We also provided a case-study analysis for the Martian surface while identifying technical and research challenges.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Transactions on Aerospace and Electronic Systems;2023-02-01;https://api.elsevier.com/content/abstract/scopus_id/85128640153
77;FaultFlow: A tool supporting an MDE approach for Timed Failure Logic Analysis;In the application of software intensive systems to business-critical processes, tool-supported connection between the perspectives of Software Engineering and Reliability Engineering may largely help conciliation of the contrasting needs of reliability and complexity. In this paper, we present FaultFlow, a newborn tool enabling a Model-Driven Engineering approach for supporting specification, analysis, and simulation of failure logic in component-based systems. The tool exploits a meta-model combining the representation of system configuration hierarchies together with a decoupled representation of its stochastically-timed failure logic. FaultFlow is available in a as-a-service mode through a Web Application deployed on the cloud as well as in a standalone mode, featuring a well-crafted Java API enabling effective specification of the system hierarchy as well as of intra-component fault-to-failure and inter-component failure-to-fault propagation models, respectively starting from SysML Block Definition Diagrams and stochastic Fault Trees representations. The automated transformation towards Stochastic Time Petri Nets enables integration with external reliability tools for quantitative evaluation through numerical solution or simulation. We illustrate FaultFlow key benefits by experimenting the approach on a case study contextualised in an Internet of Things scenario modelling a Pollution Monitor System within a Smart City.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2021 17th European Dependable Computing Conference, EDCC 2021;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85123504177
78;Generating Digital Twin Cockpits for Parameter Management in the Engineering of Wind Turbines;The complexity of wind energy systems combined with an increased trend towards mass customization require the collaboration of many experts to achieve high quality products. Currently, a major issue arises from the lack of data integration among the different tools used during the engineering process which may cause system failures eventually. Existing tools largely do not support automatic detection and indication of erroneous or contradictory parameter values between artifacts of different tools. Employing a model-driven and functional engineering approach enables to establish an integrated toolchain for the management and visualization of engineering artifacts that consume and produce the data. Within this paper, we present an automatic approach to derive an engineering digital twin for the cooperative development and management of engineering artifacts from functional models of the system under development. We evaluate our approach on the example of a hydraulic pump within the cooling system of a wind turbine. The prototype can be coupled with an existing engineering tool ecosystem. The approach enables to exchange the data produced by engineering artifacts according to a functional system model which facilitates the cooperation between different stakeholders throughout the development process.;Gesellschaft fur Informatik (GI);Conference Proceeding;Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI);2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85138312179
79;Geo-Spatial Context Provision for Digital Twin Generation;Light detection and ranging technology allows for the creation of detailed 3D point clouds of physical objects and environments. Therefore, it has the potential to provide valuable information for the operation of various kinds of cyber-physical systems that need to be aware of, and interact with, their surroundings, such as autonomous vehicles and robots. Point clouds can also become the basis for the creation of digital representations of different assets and a system’s operational environment. This article outlines a system architecture that integrates the geo-spatial context information provided by LiDAR scans with behavioral models of the components of a cyber-physical system to create a digital twin. The clear distinction between behavior and data sets the proposed digital twin architecture apart from existing approaches (that primarily focus on the data aspect), and promotes contextual digital twin generation through executable process models. A vaccine logistics automation use case is detailed to illustrate how information regarding the environment can be used for the operation of an autonomous robot carrying out transport preparation tasks. Besides supporting operation, we propose to combine context data retrieved from the system at different points in the logistics process with information regarding instances of executable behavior models as part of the digital twin architecture. The twin can subsequently be used to facilitate system and process monitoring through relevant stakeholders and structure context data in a user-centric fashion.;MDPI;Journal;Applied Sciences (Switzerland);2022-11-01;https://api.elsevier.com/content/abstract/scopus_id/85141843177
80;Guidelines for Digital Twins in 5G Agriculture;New devices for the Internet of Things (IoT) and 5G enable monitoring and controlling of environments and objects in agriculture and other areas. Digital Twins is a growing concept connecting IoT with applications to automate agriculture, predicting crop behavior through data analysis. However, there is a conceptual gap between the digital twin concept and its application to real development. This work proposes a novel meta classes model to guide designs on digital twins in agriculture based on a bibliometric analysis to identify the current works in the area. The proposed design considers several meta classes such as communication devices, sensors, actuators, historical sensing, visualization, Human-Machine Interfaces, decisions, physical objects, and physical sectors. These meta-classes can work on a Jetson nano processor or a Raspberry Pi because they can be implemented in several languages and frameworks.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2022 13th International Symposium on Communication Systems, Networks and Digital Signal Processing, CSNDSP 2022;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85140429598
81;Hardware-in-loop based Digital Twin Technology for Integrated Energy System: A Case Study of Guangyang Island in Chongqing;Digital twin technology is a virtual representation technology for representing the dynamic process or states of physical object. This paper explore the feasible approach of using digital twin technologies in integrated energy system (IES) and propose a hardware-in-loop based digital twin solution infrastructure. The infrastructure combines the digital simulator, external communication terminal, physical equipment and independent physical equipment simulators as a feasible digital twin system for integrated energy system that can support the planning and operation. The case study establishes a digital twin system and model the IES on Guangyang Island, Chongqing. The digital twin model can verify the operation plan of the IES and let the system operation in various optional environments, which can effectively support the design and operational scheme of the IES.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings of 2022 IEEE 5th International Electrical and Energy Conference, CIEEC 2022;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85137333303
82;HomeView: Automatically Building Smart Home Digital Twins With Augmented Reality Headsets;Digital twins have demonstrated great capabilities in the industrial setting, but the cost of building them prohibits their usage in home environments. We present HomeView, a system that automatically builds and maintains a digital twin using data from Augmented Reality (AR) headsets and Internet of Things (IoT) devices. We evaluated the system in a simulator and found it performs better than the baseline algorithm. The user feedback on programming IoT devices also suggests that contextual information rendered by HomeView is preferable to text descriptions.;Association for Computing Machinery, Inc;Conference Proceeding;UIST 2022 Adjunct - Adjunct Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology;2022-10-29;https://api.elsevier.com/content/abstract/scopus_id/85141358399
83;Human-Focused Digital Twin Applications for Occupational Safety and Health in Workplaces: A Brief Survey and Research Directions;Occupational safety and health is among the most challenging issues in many industrial workplaces, in that various factors can cause occupational illness and injury. Robotics, automation, and other state-of-the-art technologies represent risks that can cause further injuries and accidents. However, the tools currently used to assess risks in workplaces require manual work and are highly subjective. These tools include checklists and work assessments conducted by experts. Modern Industry 4.0 technologies such as a digital twin, a computerized representation in the digital world of a physical asset in the real world, can be used to provide a safe and healthy work environment to human workers and can reduce occupational injuries and accidents. These digital twins should be designed to collect, process, and analyze data about human workers. The problem is that building a human-focused digital twin is quite challenging and requires the integration of various modern hardware and software components. This paper aims to provide a brief survey of recent research papers on digital twins, focusing on occupational safety and health applications, which is considered an emerging research area. The authors focus on enabling technologies for human data acquisition and human representation in a virtual environment, on data processing procedures, and on the objectives of such applications. Additionally, this paper discusses the limitations of existing studies and proposes future research directions.;MDPI;Journal;Applied Sciences (Switzerland);2023-04-01;https://api.elsevier.com/content/abstract/scopus_id/85152549776
84;Implementation and Deployment of Digital Twin in Cloud-Native Network;Virtual-reality fusion is becoming increasingly important for innovative applications such as intelligent manufacturing. Digital twin (DT) is a promising method of realizing virtual-reality fusion by creating high-fidelity digital models of physical objects and interacting with them in real time. However, there is currently a lack of solutions for the implementationand deployment of digital twins on the network, which hinders the in-depth application of digital twins in related fields. In this paper, we propose a scheme for implementing and deploying digital twins in cloud-native networks, with the goal of supporting innovative virtual-reality fusion-based applications. We propose an adaptive organizational form of digital twin components that enables the distributed deployment and execution of digital twins in cloud-native networks and design a digital twin representation method based on the idea of objectoriented programming (OOP). In this scheme, we also design the naming and operation mechanisms for digital twins, and present the trust mechanism among the components of a digital twin using the Merkle tree. Furthermore, we propose an optimization strategy for deploying digital twin components in a cloud-native network. The results of the experiments show that the proposed scheme is both feasible and effective.;Springer Science and Business Media Deutschland GmbH;Book Series;Communications in Computer and Information Science;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85151054115
85;Investigating Digital Twin: A Systematic Mapping Study;The term digital twin refers to a comprehensive digital representation of a physical system that serves as its real-time digital counterpart. Digital twin goes beyond traditional computer-aided applications and represents a two-way communication bridge between the physical and the digital worlds. In 2020, Gartner identified digital twin as one of the ten technology trends capable of a profound impact on modern society. While digital twin originates from the manufacturing domain, its recent underpinning technology maturation makes it suitable to all those domains where there is a need for studying virtual interactions with the physical environment. Despite its peak of research and adoption, there are still some grey areas related to certain aspects of digital twin such as enabling technologies and reported benefits. In this paper, we report on the planning, execution and results of a systematic mapping study, which aimed at providing a structured and detailed snapshot of the current application of digital twin, enabling technologies, reported benefits and application domains. Starting from an initial set of 675 publications, we identified 26 primary studies, which we have analysed through a rigorous data extraction, analysis and synthesis process. Based on the collected data, we drew relations between digital twin and the production domain.;IOS Press BV;Conference Proceeding;Advances in Transdisciplinary Engineering;2022-04-20;https://api.elsevier.com/content/abstract/scopus_id/85132800357
86;IoT, AI and Digital Twin For Smart Campus;The objective of this research is to Present the use of Digital Twin. Internet of Things and Intelligence Technology to Intelligently Develop The Energy Management Potential of Campuses By using Digital Twin to manage energy consumption, it enables the creation of work and life on campus, whether it is personal. Teachers and students, including those with disabilities, have a better quality of life. Living on campus is more comfortable Collect energy consumption data, organizations to manage power management systems, reduce energy consumption, simplify management in all departments, and reduce campus costs. It can transparently monitor energy consumption and use educational equipment on campus, especially cost and expenditure management, and sustainable energy consumption, as well as management. Control usage data, energy consumption results, and budget allocations related to educational institutions can create reliability in managing information about electrical energy and energy competency assessment results, and can be recorded and controlled in Digital Twin that can be as if it were with a control center. IoT and Cloud Computing are also integrated with AI systems embedded in state-of-the-art equipment for use in environmental management and intelligent energy management. As well as creating new energy models and management that can resolve future emergencies by controlling virtual energy within the organization from outside anytime, anywhere.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2022 Research, Invention, and Innovation Congress: Innovative Electricals and Electronics, RI2C 2022;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85141750791
87;IoTwins: Design and implementation of a platform for the management of digital twins in industrial scenarios;With the increase of the volume of data produced by IoT devices, there is a growing demand of applications capable of elaborating data anywhere along the IoT-to-Cloud path (Edge/Fog). In industrial environments, strict real-time constraints require computation to run as close to the data origin as possible (e.g., IoT Gateway or Edge nodes), whilst batch-wise tasks such as Big Data analytics and Machine Learning model training are advised to run on the Cloud, where computing resources are abundant. The H2020 IoTwins project leverages the digital twin concept to implement virtual representation of physical assets (e.g., machine parts, machines, production/control processes) and deliver a software platform that will help enterprises, and in particular SMEs, to build highly innovative, AI-based services that exploit the potential of IoT/Edge/Cloud computing paradigms. In this paper, we discuss the design principles of the IoTwins reference architecture, delving into technical details of its components and offered functionalities, and propose an exemplary software implementation.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 21st IEEE/ACM International Symposium on Cluster, Cloud and Internet Computing, CCGrid 2021;2021-05-01;https://api.elsevier.com/content/abstract/scopus_id/85114856329
88;Key-Components for Digital Twin Modeling with Granularity: Use Case Car-as-a-Service;Digital technologies are changing the way people interact with the world. The Digital Twin (DT) is one of the key enablers of Industry 4.0. It provides a virtual representation of an observable element of the real world. These elements can be both physical objects such as devices or non-physical such as interactions and processes. Digitalization of the real world enables new business models, transforming traditional products into services, as for instance, the Car-as-a-Service (CaaS). To integrate all components that will be part of systems like CaaS or Smart Cities, it is necessary to have well-defined standards for modeling and defining an architecture especially taking into consideration the granularity level of the system. This paper proposes the main components needed for building DT-based systems with different levels of granularity. These components have been arranged in layers to specify the concerns of each part of the system. A case study has been developed to demonstrate the modeling and the deployment of the Digital Twin, highlighting how this concept can be one of the key enablers for CaaS.;IEEE Computer Society;Journal;IEEE Transactions on Emerging Topics in Computing;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85121355175
89;Knowledge-graph-based multi-domain model integration method for digital-twin workshops;The digital twin workshop is a new workshop operation paradigm that enables precise decision-making by fusing virtual and physical space. As a complex manufacturing system, the digital twin model of the workshop must integrate models from different domains in order to provide personalized services. The interoperability of multi-domain models and the dynamic update of parameters become obstacles. In this paper, a knowledge graph (KG)-based multi-domain model integration method for digital twin workshops is proposed. The multi-domain model integration architecture based on KG is consisted of model element, model ontology, model data, semantic integration, and network connection. Then, the KG of multi-domain model for design, manufacturing, and simulation is constructed through ontology modeling and knowledge extraction. On this basis, multi-domain model integration is realized through semantic inference and knowledge query. The model parameters are updated through file exchange during the dynamic simulation. Finally, multiple scenarios in the subassembly workshop for hull construction are used to verify the efficacy of the proposed method. During the assembly and welding of hull parts, the integration of the product model, equipment model, and simulation model is realized, which assists in meeting the service requirements of multiple business scenarios.;Springer Science and Business Media Deutschland GmbH;Journal;International Journal of Advanced Manufacturing Technology;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85164577836
90;Language Composition via Kind-Typed Symbol Tables;"The modularization of domain-specific modeling languages (DSMLs) fosters individual reuse of DSMLs in different contexts. Within this article, we discuss how it is possible to refer to model elements of other languages when composing different DSMLs. Related approaches usually rely on a DSML-agnostic language infrastructure that tests the compatibility of model elements via types encoded in Strings without any consistency checks. We propose the ""strongly kind-typed"" symbol table as an extension to the compiler approach to integrate the syntax of the languages using symbol tables that assign a symbol kind to each name definition. Our approach can be integrated into language workbenches that provide a symbol table infrastructure as part of a DSML implementation. The kind-typed symbol tables are integrated into the language workbench MontiCore. Strongly kind-typed symbol tables utilize the type system of the language workbench’s host language to ensure type consistency between the language-specific symbol table infrastructures during DSML composition, which ultimately supports DSML engineering in the large.";Association Internationale pour les Technologies Objets;Journal;Journal of Object Technology;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85141766053
91;Leveraging the Role of Dynamic Reconfigurable Antennas in Viewpoint of Industry 4.0 and Beyond;Industry 4.0 is a digital paradigm that refers to the integration of cutting-edge computing and digital technologies into global industries because of which the state of manufacturing, communication, and control of smart industries has changed altogether. Industry 4.0 has been profoundly influenced by some major disruptive technologies such as the Internet of Things (IoT), smart sensors, machine learning and artificial intelligence, cloud computing, big data analytics, advanced robotics, augmented reality, 3D printing, and smart adaptive communication. In this review paper, we discuss physical layer-based solutions with a focus on high reliability and seamless connectivity for Industry 4.0 and beyond applications. First, we present a harmonized review of the industrial revolution journey, industrial communication infrastructure, key performance requirements, and potential sub-6-GHz frequency bands. Then, based on that, we present a comprehensive review of intelligent tunable dynamic antenna systems at sub-6 GHz as key enablers for next-generation smart industrial applications. State-of-the-art smart antenna techniques such as agile pattern reconfigurability using electrical components, machine learning- and artificial intelligencebased agile beam-scanning antennas, and beam-steerable dynamic metasurface antennas are thoroughly reviewed and emphasized. We unfolded the exciting prospects of reconfigurable dynamic antennas for intelligent and reliable connectivity in application scenarios of Industry 4.0 and beyond such as Industrial IoT and smart manufacturing.;American Association for the Advancement of Science;Journal;Research;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85152958483
92;Low-code/No-code Platforms and Modern ERP Systems;The idea of low-code/no-code (LCNC) platforms is not new. It roots back in time of software engineering approach called Model Driven Development (MDD) [1]. But since new technological development, growing business demands and changes based on digital transformation and accompanying technologies are omnipresent, they will try to transform ways of modern businesses and their information system. These platforms have opened up a new world of possibilities, enabling businesses, or to be exact business/non-developer users, to develop small software solutions faster, with greater agility, scalability and smaller software development cost. This paper discusses the nature of applying LCNC platforms in the context of ERP systems. To be more precise, focus of paper is on presenting domains in which extensions or small apps can be develop by LCNC platforms and in that way improve ERP systems.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2023 9th International Conference on Information Management, ICIM 2023;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85163713850
93;Machine learning for design optimization of electromagnetic devices: Recent developments and future directions;This paper reviews the recent developments of design optimization methods for electromagnetic devices, with a focus on machine learning methods. First, the recent advances in multi-objective, multidisciplinary, multilevel, topology, fuzzy, and robust design optimization of electromagnetic devices are overviewed. Second, a review is presented to the performance prediction and design optimization of electromagnetic devices based on the machine learning algorithms, including artificial neural network, support vector machine, extreme learning machine, random forest, and deep learning. Last, to meet modern requirements of high manufacturing/production quality and lifetime reliability, several promising topics, including the application of cloud services and digital twin, are discussed as future directions for design optimization of electromagnetic devices.;MDPI AG;Journal;Applied Sciences (Switzerland);2021-02-02;https://api.elsevier.com/content/abstract/scopus_id/85100943857
94;Methodology for Commodity Cost Estimation Through Production Line Analysis and Simulation;In a growing competitive environment, it is essential to have a clear idea of a product’s total expenditure by estimating the component costs and correctly allocate cost drivers. Assigning exact commodity consumption costs is one of the most complicated aspects of cost engineering activities, which should be performed during the product design stage using Product Lifecycle Management (PLM). However, during the design stage, information is not complete, and it is not sufficient to guarantee the cost estimate’s adequacy and reliability. Therefore, it is necessary to monitor the production process to identify each cost variable carefully. This article aims to propose a methodology to evaluate the proper commodity consumption during manufacturing activities for the assessment of the total part cost. Moreover, it helps to generate validated data useful for decision support systems. The proposed approach is studied by analyzing a machining production line of an Italian manufacturer of components for the automotive industry. It consists of three main parts: (i) description of the production line, (ii) definition of IT architecture, and (iii) asynchronous digital twin design. Thus, after the model’s validation, the simulated data allows to analyze and estimate production expenditure accurately by the exact allocation of commodity consumption.;Springer Science and Business Media Deutschland GmbH;Book Series;IFIP Advances in Information and Communication Technology;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85125264911
95;Model-Driven Engineering of Process-Aware Information Systems;Enterprise information systems created with model-driven software engineering methods need to handle not only data but also business processes in an automated way. This paper shows how to engineer process-aware information systems following the model-driven and generative software engineering paradigms. Existing approaches realize either the generation of automated or manual activities but do not employ model-driven engineering of all system aspects through systematic language composition. A generative approach that additionally uses process modeling languages allows developers to evolve generated data-centric information systems into process-aware information systems. To be usable within our generation process, we have developed a textual BPMN version and a corresponding language tooling to check the soundness of the models. We have included these process models into the generation process of an information system together with other domain-specific modeling languages, e.g., for data structures, and generate an extendable, process-aware information system that is open for continuous regeneration and hand-written additions. This approach allows us to lift a generated data-centric information system to a process-aware information system. Agile development enabled through the opportunity to validate assumptions automatically and adapt changes efficiently, enhances the engineering process as well as the generated systems themselves.;Springer;Journal;SN Computer Science;2022-11-01;https://api.elsevier.com/content/abstract/scopus_id/85139200076
96;Model-Driven Engineering of Process-Aware Information Systems;Enterprise information systems created with model-driven software engineering methods need to handle not only data but also business processes in an automated way. This paper shows how to engineer process-aware information systems following the model-driven and generative software engineering paradigms. Existing approaches realize either the generation of automated or manual activities but do not employ model-driven engineering of all system aspects through systematic language composition. A generative approach that additionally uses process modeling languages allows developers to evolve generated data-centric information systems into process-aware information systems. To be usable within our generation process, we have developed a textual BPMN version and a corresponding language tooling to check the soundness of the models. We have included these process models into the generation process of an information system together with other domain-specific modeling languages, e.g., for data structures, and generate an extendable, process-aware information system that is open for continuous regeneration and hand-written additions. This approach allows us to lift a generated data-centric information system to a process-aware information system. Agile development enabled through the opportunity to validate assumptions automatically and adapt changes efficiently, enhances the engineering process as well as the generated systems themselves.;Springer;Journal;SN Computer Science;2022-11-01;https://api.elsevier.com/content/abstract/scopus_id/85139200076
97;Modeling Methods of 3D Model in Digital Twins;To understand the current application and development of 3D modeling in Digital Twins (DTs), abundant literatures on DTs and 3D modeling are investigated by means of literature review. The transition process from 3D modeling to DTs modeling is analyzed, as well as the current application of DTs modeling in various industries. The application of 3D DTs modeling in the fields of smart manufacturing, smart ecology, smart transportation, and smart buildings in smart cities is analyzed in detail, and the current limitations are summarized. It is found that the 3D modeling technology in DTs has broad prospects for development and has a huge impact on all walks of life and even human lifestyles. At the same time, the development of DTs modeling relies on the development and support capabilities of mature technologies such as Big Data, Internet of Things, Cloud Computing, Artificial Intelligence, and game technology. Therefore, although some results have been achieved, there are still limitations. This work aims to provide a good theoretical support for the further development of 3D DTs modeling.;Tech Science Press;Journal;CMES - Computer Modeling in Engineering and Sciences;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85148225357
98;Modelling with AAS and RDF in Industry 4.0;Industry 4.0 has proposed the Asset Administration Shell (AAS) model for digital twins. This model should help to solve interoperability issues, a topic that is also addressed by the Semantic Web and its Resource Description Framework (RDF). AAS and RDF-based models have their own strengths. AAS models are easier to integrate with operational technologies in a production environment, whereas RDF-based models offer more semantic expressiveness and advanced querying. In the Horizon MAS4AI project we found that both modelling paradigms can complement each other to develop agentbased digital twins for modular production environments. In this work we propose two different approaches to bridge both modelling paradigms. First we define a set of mapping rules to generate an AAS model from a given RDF-based model, supporting model development. Secondly, we propose to use RDF-based models to generate a digital shadow of AASs to improve semantic discoverability. Preliminary results demonstrate that heterogeneity of metamodels does not exclude achieving semantic interoperability, as well as that greater functionality can be obtained compared to using both models in isolation. The solutions will be further developed in collaboration with pilot lines in the MAS4AI project.;Elsevier B.V.;Journal;Computers in Industry;2023-06-01;https://api.elsevier.com/content/abstract/scopus_id/85151535036
99;Orthogonal Combinatorial Raman Codes Enable Rapid High-Throughput-Out Library Screening of Cell-Targeting Ligands;High-throughput assays play an important role in the fields of drug discovery, genetic analysis, and clinical diagnostics. Although super-capacity coding strategies may facilitate labeling and detecting large numbers of targets in a single assay, practically, the constructed large-capacity codes have to be decoded with complicated procedures or are lack of survivability under the required reaction conditions. This challenge results in either inaccurate or insufficient decoding outputs. Here, we identified chemical-resistant Raman compounds to build a combinatorial coding system for the high-throughput screening of cell-targeting ligands from a focused 8-mer cyclic peptide library. The accurate insitu decoding results proved the signal, synthetic, and functional orthogonality for this Raman coding strategy. The orthogonal Raman codes allowed for a rapid identification of 63 positive hits at one time, evidencing a high-throughput-out capability in the screening process. We anticipate this orthogonal Raman coding strategy being generalized to enable efficient high-throughput-out screening of more useful ligands for cell targeting and drug discovery.;American Association for the Advancement of Science;Journal;Research;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85163302259
100;Past, present, and future research of digital twin for smart manufacturing;In the era of the Fourth Industrial Revolution, there is a growing focus on digital twin (DT) in order to advance toward smart manufacturing. Thus, researchers have conducted numerous studies on DT and extensively developed related technologies. There are many studies that apply and analyse DT to actual manufacturing sites for the realization of a smart factory, but it is necessary to clearly consider which part of DT is applied and what function it performs in manufacturing. As such, this study analysed and classified prior literature based on various phases of product lifecycle management, an application field of DT in manufacturing, and the hierarchy level axis of Reference Architecture Model Industry 4.0, the target scope of DT. Accordingly, this study identified research trends in the past and present as well as analysed and identified the major functions of DT (prototyping, pilot testing, monitoring, improvement, and control). Through a gab study on the inadequate aspects of past and present researches, this study proposes directions for future studies on DT and a system architecture that can perform all the functions of DT.;Oxford University Press;Journal;Journal of Computational Design and Engineering;2022-02-01;https://api.elsevier.com/content/abstract/scopus_id/85125012028
101;Petri nets-based digital twin drives dual-arm cooperative manipulation;The emerging concept of digital twin (DT) creates a holistic vision to change how we view the design and operation of a cyber-physical system (CPS), and how to reconfigure its function and structure to deal with the scenario of complexity and uncertainty that arises from reality. In this work, we firstly surveyed the typical narrative frameworks of DT modelling: generalized layered method, decomposition and composition method, Asset Administration Shell framework, and standardized architecture. Secondly, the Petri nets-based digital twin framework for the robotic dual-arm cooperative system was presented in detail through the domain-based and entity-based systematization methodology. The proposed framework generated a conceptually embodied and situated DT environment, which not only represented the highly hybrid nature (i.e., continuous, discrete and cooperative) of the dual-arm cooperative operation process, but also avoided the complex decoupling calculation of closed kinematic chains in the bi-manual manipulation of industrial arms. Furthermore, two digital twin instances clearly demonstrated that the holonic integration of operational technologies equipment, information technologies and DT through the industrial internet of things manifested a game-changing potential to upgrade the capability of an existing brownfield CPS to perform complex tasks. Concluding, by coupling the discrete event simulation at the highly abstract level and the 3D offline programming simulation in the intuitively DT environment, this comprehensive practice of DT to transform the loose DT metaphor into strictly industrial domains provided an illuminating cross-increment for both the robotic community and the DT facilitators.;Elsevier B.V.;Journal;Computers in Industry;2023-05-01;https://api.elsevier.com/content/abstract/scopus_id/85149057658
102;Research on Remaining Useful Life Prediction Method of Rolling Bearing Based on Digital Twin;Bearing is a key part of rotating machinery. Accurate prediction of bearing life can avoid serious failures. To address the current problem of low accuracy and poor predictability of bearing life prediction, a bearing life prediction method based on digital twins is proposed. Firstly, the vibration signals of rolling bearings are collected, and the time-domain and frequency-domain features of the actual data set are extracted to construct the feature matrix. Then unsupervised classification and feature selection are carried out by improving the self-organizing feature mapping method. Using sensitive features to construct a twin dataset framework and using the integrated learning CatBoost method to supplement the missing data sets, a complete digital twin dataset is formed. Secondly, important information is extracted through macro and micro attention mechanisms to achieve weight amplification. The life prediction of rolling bearing is realized by using fusion features. Finally, the proposed method is verified by experiments. The experimental results show that this method can predict the bearing life with a limited amount of measured data, which is superior to other prediction methods and can provide a new idea for the health prediction and management of mechanical components.;MDPI;Journal;Entropy;2022-11-01;https://api.elsevier.com/content/abstract/scopus_id/85149544623
103;Resilience Enhancing Mechanisms for Cyber-Manufacturing Systems against Cyber-Attacks;The advent of cyber-attacks against cyber-manufacturing systems (CMS) is recognized as one of the most prominent nontraditional risks that need to be addressed to facilitate widespread adoption of such a system. In current literature, the notion of resilience has been recognized as an effective way to deal with those threats. Resilience is the ability of CMS to perform its intended goals in the presence of a deliberate disruptions-cyber-attacks. A more resilient CMS would show reduced failure probability, less disastrous consequences, and a faster recovery from disruptions caused by cyber-attacks. The goal of the work presented in this paper is to identify resilience-increasing mechanisms and provide a framework for their classification. A resilience-increasing mechanism is defined as an action implemented in CMS, aimed to a) reduce the probability of a successful cyber-attack, b) reduce the time to detection of a cyber-attack, c) reduce the adverse effects of a successful cyber-attack, or d) reduce the time to recover from a cyber-attack. A non-exhaustive list of resilience-increasing mechanisms is provided that had been published on peer reviewed publication and applied to the specific context of cyber-manufacturing.;Elsevier B.V.;Conference Proceeding;IFAC-PapersOnLine;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85144557596
104;Saving Energy with Comfort: A Semantic Digital Twin Approach for Smart Buildings;Building Energy Management Systems (BEMS) aim to optimize building assets for saving energy without compromising humans' comfort. BEMS must integrate heterogeneous components and complex architectures for monitoring building conditions and controlling building assets such as lights, heating, and air ventilation systems. To tackle interoperability issues and support heterogeneity in smart environments (smart buildings), semantic technologies have been extensively used. Semantically interlinked/integrated information related to energy optimization and comfort in smart buildings can be effectively utilized in decision support tools/systems, if it is efficiently provided to decision makers, via their digital twins. Visualizing semantically integrated real-time sensor information within the digital asset, and supporting the real-time actuation of semantically annotated assets via the interaction with their digital twin, can support decision making in smart buildings for saving energy with comfort. In this paper, a semantic digital twin approach for smart buildings is proposed, along with a first prototype implementation in the energy-saving domain.;CEUR-WS;Conference Proceeding;CEUR Workshop Proceedings;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85143768393
105;Self-Adaptation Driven by SysML and Goal Models – A Literature Review;Background: Socio-cyber-physical systems (SCPSs) are a type of cyber-physical systems with social concerns. Many SCPSs, such as smart homes, must be able to adapt to reach an optimal symbiosis with users and their contexts. The Systems Modeling Language (SysML) is frequently used to specify ordinary CPSs, whereas goal modeling is a requirements engineering approach used to describe and reason about social concerns. Objective: This paper aims to assess existing modeling techniques that support adaptation in SCPSs, and in particular those that integrate SysML with goal modeling. Method: A systematic literature review presents the main contributions of 52 English articles selected from five databases that use both SysML and goal models (17 techniques), SysML models only (11 techniques), or goal models only (8 techniques) for analysis and self-adaptation. Result: Existing techniques have provided increasingly better modeling support for adaptation in a SCPS context, but overall analysis support remains weak. The techniques that combine SysML and goal modeling offer interesting benefits by tracing goals to SysML (requirements) diagrams and influencing the generation of predefined adaptation strategies for expected contexts, but few target adaptation explicitly and most still suffer from a partial coverage of important goal modeling concepts and of traceability management issues.;Wroclaw University of Science and Technology;Journal;E-Informatica Software Engineering Journal;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85122587764
106;Semantic Interoperability of Digital Twins: Ontology-based Capability Checking in AAS Modeling Framework;Industry 4.0 currently prepares a major shift towards extreme flexibility into production lines management. Digital Twins are one of the key enabling technologies for Industry 4.0. However, the interoperability gap among digital representation of Industry 4.0 assets is still one of the obstacles to the development and adoption of digital twins. If the Asset Administration Shell (AAS), the standard proposed to represent the I4.0 components, caters for syntactic interoperability, a more semantic kind of interoperability is deeply needed to develop flexible and adaptable production lines. In our work, we overcome the limitation of current syntactic-only resource matching algorithms by implementing semantic interoperability based on ontologies i.e., by transforming AAS-based plant models into MaRCO (Manufacturing Resource Capability Ontology) instances and then query the expanded ontology to find the needed resources. This article presents this ontology-based approach as the first step towards the design and implementation of an automated I4.0 flexible plant supervision and control system based on model-driven engineering (MDE) within the 'Papyrus for Manufacturing' toolset. We show how an MDE approach can aggregate around digital twin modeling tools from the Papyrus platform both I4.0 technologies and AI (Knowledge Representation and Reasoning) tools. Our platform aligns modeling and ontological elements to get the best of both worlds. This method has two main advantages: (1) to provide semantic descriptions for digital twin models, (2) to complement model-driven engineering tools with automated reasoning. This paper showcases this approach through a robotic cell use case.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2023 IEEE 6th International Conference on Industrial Cyber-Physical Systems, ICPS 2023;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85163130919
107;Semi-Automatic Testing of Data-Focused Software Development Kits for Industrie 4.0;The digital twin, or more precisely the Asset Administration Shell, is the key element for interoperability in Industrie 4.0. Together with the asset, it forms the I4.0 component. For the development of I4.0 components, the availability of suitable software development tools is becoming increasingly relevant. However, it is not yet specified how these tools are to be systematically tested for correctness, compliance and conformity. These topics are the focus of this work. We show different established testing methods, evaluate their suitability and describe an approach for a capable test environment.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;IEEE International Conference on Industrial Informatics (INDIN);2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85145783224
108;Standardisation in Digital Twin Architectures in Manufacturing;Engineering digital twins following standardised reference architectures is an upcoming requirement for ensuring their adoption and facilitating their creation, processing, and integration. The ISO 23247 standard proposes a reference architecture for digital twins in manufacturing, including an entity-based reference model and a functional view specified in terms of functional entities. During our experience with projects in the field, we noticed that standards, and in particular the ISO 23247 standard, are not completely followed. In this paper, we analyse to what extent digital twin architectures documented in the literature are aligned with the reference architecture presented in the ISO 23247 standard. We achieved this through a mixed-methods research methodology that includes the analysis of 29 digital twin architectures in the manufacturing domain resulting from a systematic literature review of 140 peer-reviewed studies, a survey with 33 respondents, and four semi-structured, in-depth expert interviews. On the basis of our findings, practitioners and researchers can reflect, discuss, and plan actions for future research and development activities.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - IEEE 20th International Conference on Software Architecture, ICSA 2023;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85159222904
109;Stochastic Digital-Twin Service Demand With Edge Response: An Incentive-Based Congestion Control Approach;The emergence of Digital Twin Edge Networks (DTENs) achieves the mapping of real physical entities to digital models of cyberspace. By offloading real-time mobile data to Mobile Edge Computing (MEC) servers for processing and modeling, communication-efficient Digital Twin (DT) services could be achieved. However, the spatio-temporal dynamic DT service demand stochastically generated by mobile users easily causes service congestion, which challenges the long-term DT service stability. Meanwhile, current DT services still lack long-term effective incentive designs for participants. To solve these issues, we design an incentive-based congestion control scheme for stochastic demand response in DTENs. First, we adopt the Lyapunov optimization theory to decompose the long-term congestion control decision into a sequence of online edge association decisions, with no need for future system information. We then present a contract-based incentive design to optimize the long-term profit of the DT service provider, comprehensively considering the delay sensitivity, incentive compatibility, and individual rationality. Finally, experimental simulations are carried out to verify the superiority of the proposed scheme with the base station dataset of Shanghai Telecom. Theoretical and simulation analysis demonstrates that compared with benchmarks, our scheme could effectively avoid long-term service congestion with an arbitrarily near-optimal profit.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Transactions on Mobile Computing;2023-04-01;https://api.elsevier.com/content/abstract/scopus_id/85150052273
110;Supporting the Implementation of Digital Twins for IoT-Enhanced BPs;IoT-Enhanced Business Processes make use of Internet of Things technology to integrate physical devices into the process as digital actors. Closely related to this topic arises the concept of Digital Twin, which is a virtual representation of real-world entities and processes that connect to the physical counterpart to represent, simulate, or predict changes in the physical system. There are many works that focus on supporting the high-fidelity implementation of Digital Twins for specific physical devices. However, few of them consider the process as a real-world entity to be integrated into the Digital Twin. In this work, we present a microservice architecture to support the implementation of Digital Twins for IoT-Enhanced Business Processes, considering not only the physical devices but also the process itself and the relationship among them. This architectural solution is supported by a model-driven development approach, which proposes (1) the construction of a BPMN model to represent an IoT-enhanced Business Process and (2) the application of model transformation to automatically generate both Digital Twin Definition Language (DTDL) models and microservice Java code templates. DTDL models are used in the implementation of the Digital Twins for the IoT-Enhanced Business Process. Java code templates are used to facilitate the implementation of the microservices required to deploy the IoT-enhanced Business Process and its Digital Twins into the proposed architecture and maintain the digital and physical parts synchronised.;Springer Science and Business Media Deutschland GmbH;Book Series;Lecture Notes in Business Information Processing;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85163280406
111;Agile Software Requirements Engineering Challenges-Solutions—A Conceptual Framework from Systematic Literature Review;"Agile software requirements engineering processes enable quick responses to reflect changes in the client’s software requirements. However, there are challenges associated with agile requirements engineering processes, which hinder fast, sustainable software development. Research addressing the challenges with available solutions is patchy, diverse and inclusive. In this study, we use a systematic literature review coupled with thematic classification and gap mapping analysis to examine extant solutions against challenges; the typologies/classifications of challenges faced with agile software development in general and specifically in requirements engineering and how the solutions address the challenges. Our study covers the period from 2009 to 2023. Scopus—the largest database for credible academic publications was searched. Using the exclusion criteria to filter the articles, a total of 78 valid papers were selected and reviewed. Following our investigation, we develop a framework that takes a three-dimensional view of agile requirements engineering solutions and suggest an orchestrated approach balancing the focus between the business context, project management and agile techniques. This study contributes to the theoretical frontier of agile software requirement engineering approaches and guidelines for practice.";MDPI;Journal;Information (Switzerland);2023-06-01;https://api.elsevier.com/content/abstract/scopus_id/85163610313
112;The Challenges of Coupling Digital-Twins with Multiple Classes of Faults;In modern industrial contexts, a factory becomes a complex and heterogeneous ecosystem, where many technologies, systems, and workers cooperate. Such a class of systems is named Cyber-Physical Production Systems (CPPSs), since their design requires to merge control, network, and physical aspects. In such a context, it is fundamental to guarantee safe human-machine interactions. Therefore, evaluating and adopting techniques is necessary to ensure functional safety. This article analyzes the challenges of creating digital twins coupled with multiple classes of faults to simulate and verify the system under design. In particular, challenges can be collected under three main categories: modeling, simulation and assessment. Exploiting a language capable of capturing the complexity of such systems is necessary to model CPPSs and support the creation of digital twins. Efficient simulation of CPPSs needs different abstraction techniques and requires to combine discrete and continuous components. Moreover, different classes of faults must be injected into the models to verify the cyber and the physical parts. This would allow assessing the functional safety of each machinery composing the plant.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2022 IEEE 23rd Latin American Test Symposium, LATS 2022;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85142794104
113;Three-Dimension Digital Twin Reference Architecture Model for Functionality, Dependability, and Life Cycle Development Across Industries;The Digital Twin concept promises numerous applications across industries and its physical twin’s entire life cycle. Although numerous architectures have been proposed to develop and describe the setup of Digital Twin applications, current Digital Twin architectures do not address the versatile cross-industry character of the Digital Twin concept, its safety, security, and privacy aspects, and are often use case-specific and inflexible. We propose a three-dimensional Digital Twin reference architecture model for application across industries, considering functionality, dependability, and life cycle aspects. Our model provides practitioners a common platform to develop and discuss Digital Twin applications of different complexities and dependability aspects along varying life cycles and independent of the industry. Its applicability is validated and showcased by examples from the fields of mechatronic products, healthcare, construction, transportation, astronautics, and the energy sector. We compare our reference architecture model to existing architectures, discuss its advantages and limitations, and position the model within previous literature.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85137612454
114;Toward the Adoption of Secure Cyber Digital Twins to Enhance Cyber-Physical Systems Security;Cyber-Physical Systems (CPSs) and Digital Twins (DTs) currently represent the two most notable examples of cyber-physical integration enabled by modern ICT technologies, and their adoption is becoming predominant to implement and analyse complex systems in several application domains. So-called cyber DTs are increasingly being used to carry out security analysis, monitoring and testing on the virtual replicas of complex systems rather than on the physical counterparts, especially when these may not be directly feasible due to cost and other constraints. However, since physical and virtual replicas live side by side in complex ecosystems, the need for secure and trustworthy DTs arises. In this paper, we introduce a preliminary conceptual framework aimed to increase the level of security of a complex CPS by leveraging a cyber DT providing advanced anomaly detection capabilities, achieved by means of state-of-art machine learning solutions (i.e., federated learning). The framework will also address the security and trustworthiness of the cyber DT itself, by leveraging both HW and SW solutions to support a secure communication and storage of the critical data exchanged among the physical and virtual worlds. To this aim, the integration of the blockchain technology into the DT architecture will be investigated.;Springer Science and Business Media Deutschland GmbH;Book Series;Communications in Computer and Information Science;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85137982364
115;Toward the Adoption of Secure Cyber Digital Twins to Enhance Cyber-Physical Systems Security;Cyber-Physical Systems (CPSs) and Digital Twins (DTs) currently represent the two most notable examples of cyber-physical integration enabled by modern ICT technologies, and their adoption is becoming predominant to implement and analyse complex systems in several application domains. So-called cyber DTs are increasingly being used to carry out security analysis, monitoring and testing on the virtual replicas of complex systems rather than on the physical counterparts, especially when these may not be directly feasible due to cost and other constraints. However, since physical and virtual replicas live side by side in complex ecosystems, the need for secure and trustworthy DTs arises. In this paper, we introduce a preliminary conceptual framework aimed to increase the level of security of a complex CPS by leveraging a cyber DT providing advanced anomaly detection capabilities, achieved by means of state-of-art machine learning solutions (i.e., federated learning). The framework will also address the security and trustworthiness of the cyber DT itself, by leveraging both HW and SW solutions to support a secure communication and storage of the critical data exchanged among the physical and virtual worlds. To this aim, the integration of the blockchain technology into the DT architecture will be investigated.;Springer Science and Business Media Deutschland GmbH;Book Series;Communications in Computer and Information Science;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85137982364
116;Towards a Digital Twin for Simulation of Organizational and Semantic Interoperability in IDS Ecosystems;"An International Data Space (IDS) aims to support sharing sensitive data among trusted actors, enabling data owners to control how other agents could use their data, a property commonly denoted as data sovereignty. Data sharing with autonomy is increasingly essential for modern businesses to form ecosystems providing complex services to demanding clients. An IDS ecosystem requires the formation of data-sharing agreements involving different business roles. A data usage contract constitutes a central artifact to formalize this type of agreement. It can also guide actors in implementing or selecting the software components required to enforce data sovereignty. However, there are at least two critical challenges to overcome before forming data-sharing agreements in IDS. First, actors may interpret or represent data usage contracts differently, resulting in a semantic interoperability problem. Second, even assuming semantic mismatches as resolved, contract formation, in this case, would require business process alignment, which leads to an organizational interoperability problem. To address these issues, we envision a digital twin to simulate the formation of data-sharing agreements in IDS, which could support companies exploring semantic and organizational mismatches in this kind of environment. It could also help them assess the risks of adopting and implementing IDS technology. The contribution of this paper is threefold: (1) a research design based on the problem-solving perspective of Design Science; (2) a preliminary architectural model of the digital twin; and (3) a capability assessment of tools for modeling the digital twins envisioned by this research.";CEUR-WS;Conference Proceeding;CEUR Workshop Proceedings;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85138732617
117;Towards a Digital Twin Modelling Notation;Digital Twins (DTs) constitute a growing and promising trend recognised by academia and industry. They are virtual replicas of distinctive objects, processes, buildings, or humans. DTs are used to reason about their physical counterparts' functionalities, interactions, behaviours, and overall to plan optimal actions that they can perform or be subjected to. Given their intrinsic complexity, no standard definition nor a unified solution is yet available for designing and developing DTs. Intending to shed light on such a complex topic, we analysed the literature and derived a list of twelve pivotal characteristics of DTs. Such characteristics will be used as requirements for defining a Digital Twin Modelling Notation that will enable reasoning about the design of DT solutions.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings of the 2022 IEEE International Conference on Dependable, Autonomic and Secure Computing, International Conference on Pervasive Intelligence and Computing, International Conference on Cloud and Big Data Computing, International Conference on Cyber Science and Technology Congress, DASC/PiCom/CBDCom/CyberSciTech 2022;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85145346103
118;Towards AI-assisted digital twins for smart railways: preliminary guideline and reference architecture;In the last years, there has been a growing interest in the emerging concept of digital twins (DTs) among software engineers and researchers. DTs not only represent a promising paradigm to improve product quality and optimize production processes, but they also may help enhance the predictability and resilience of cyber-physical systems operating in critical contexts. In this work, we investigate the adoption of DTs in the railway sector, focusing in particular on the role of artificial intelligence (AI) technologies as key enablers for building added-value services and applications related to smart decision-making. In this paper, in particular, we address predictive maintenance which represents one of the most promising services benefiting from the combination of DT and AI. To cope with the lack of mature DT development methodologies and standardized frameworks, we detail a workflow for DT design and development specifically tailored to a predictive maintenance scenario and propose a high-level architecture for AI-enabled DTs supporting such workflow.;Springer Science and Business Media Deutschland GmbH;Journal;Journal of Reliable Intelligent Environments;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85161629381
119;Towards an ontology-based dictionary for production planning and control in the domain of injection molding as a basis for standardized asset administration shells;The use of digital technologies in the industrial environment enables great potential for increasing efficiency in manufacturing. One building block are production environments that plan and control their production flow autonomously and decentrally. To this end, all machines and systems (so-called “assets”) need to communicate with each other and derive suitable actions based on the exchanged information. Therefore, all assets need to be represented in the virtual world. This can be realized with digital twins. A concrete implementation of digital twins is the asset administration shell, which comprises all the assets’ properties and the endpoint of the corresponding asset, so intercommunication is possible. Here, the challenges comprise establishing a manufacturer-independent vocabulary that standardizes the assets’ properties and enabling the machines and systems to interpret this vocabulary semantically. Existing standards and information models represent only a fraction of the information requirements (i.e., terms) in this domain, making autonomous production planning and control (PPC) challenging to implement. Furthermore, the information requirements of the machines and peripheral assets as well as the corresponding information flows are insufficiently defined. Therefore, this contribution aims to build a comprehensive vocabulary for the domain of PPC, which serves as a basis for standardized asset administration shells that realize machine-to-machine communication. In particular, PPC processes concerning the injection molding domain's characteristics are considered since the interaction between the domain's assets, i.e., injection molding machines, molds, peripheral assets, raw materials, and operators, are especially complex. For this purpose, the relevant input and output information within the injection molding domain was first collected for each process step in PPC. After that, a UML class diagram was modeled under consideration of established standards. The result of this work is an ontology, which can be used as a dictionary for the PPC in the injection molding domain and as a foundation of standardized digital twins in the form of asset administration shells.;Elsevier B.V.;Journal;Journal of Industrial Information Integration;2023-10-01;https://api.elsevier.com/content/abstract/scopus_id/85164690457
120;Towards Flexible Evolution of Digital Twins with Fluent APIs;With the increase of technologies such as the Internet of Things (IoT) and Cyber-Physical Systems, a huge amount of data is generated by current systems. To gain insights from this data, it must be combined with meta-information about its origins. Therefore, Digital Twins (DTs), as a common representation of a system and its data, are currently gaining traction in both industry and academia. However, these DTs have of course to be evolvable in order to reflect the high need of flexibility of the systems to support extensions, adaptations, customizations, etc. Evolving the DT representations currently not only involves a lot of manual effort, but might also lead to loss of data if not done correctly. To provide dedicated evolution support, we propose a dedicated framework for realizing evolution strategies between the schema, instance, and data level of a DT. In particular, we present a fluent API which allows the flexible but systematic manipulation of DTs during runtime and demonstrate its usage for a use case.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;IEEE International Conference on Emerging Technologies and Factory Automation, ETFA;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85122939172
121;Virtual Prototyping for Modern Internet-of-Things Applications: A Survey;Modern technological industries fused with the Internet-of-Things (IoT) have been advancing rapidly. The joint usage of several technologies has led to the reshaping of the modeling and simulation techniques into the virtualization of physical systems. Thus, the concept of virtual prototyping has emerged as a significant development in distributed IoT applications that includes early exploration, optimization, and security assessments. Several industries have been employing various types of prototyping e.g., virtual platforms, digital twins, and application-specific virtualization techniques, to achieve individual needs for development. In this survey, we clarify some of these concepts and the distinctions between them, provide a comprehensive overview of various prototyping technologies, and discuss how several virtualization technologies play a transformative role in the design and operation of intelligent cyber-physical systems.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85151520746
122;When Softbots Meet Digital Twins: Towards Supporting the Cognitive Operator 4.0;Digital Twins (DT) represent one of the most powerful technologies related to Industry 4.0 implementation. Combined with the advances in Computer Science and Production Management, DTs have become an emerging trend in many applications. Despite the DT potentials, Industry 4.0 is pushing companies to adopt digital solutions that provide higher human satisfaction to increase operational excellence. One approach to handle this involves how workers should interact with systems and smart machines. Softbots is a prominent direction to underpin this goal. This paper presents ongoing results of a research that exploits how softbots can be combined with DTs to create a more “symbiotic” human-machine/computer interaction within a smarter decision-making environment.;Springer Science and Business Media Deutschland GmbH;Book Series;IFIP Advances in Information and Communication Technology;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85115325151
123;A case for SysML in robotics;As robotics continues to integrate into society, systems and interactions become increasingly complex. To be able to accurately model such systems, a method is needed that can scale with this complexity, but that can also be standardized. This paper proposes the use of the Systems Modeling Language, or SysML, as such a modeling approach. Based on the popular UML standard, and designed for systems engineering, SysML can scale up for complex systems and is already an industry standard for modeling systems. In this paper we introduce SysML, compare SysML to other formal modeling languages, and discuss its benefits and drawbacks as a modeling language for robotic systems. We also provide an example of how SysML can be used to model robot manipulation tasks.;IEEE Computer Societyhelp@computer.org;Conference Proceeding;IEEE International Conference on Automation Science and Engineering;2014-01-01;https://api.elsevier.com/content/abstract/scopus_id/84939796205
124;A Case Study for a Digital Twin of Body-in-White Production Systems General Concept for Automated Updating of Planning Projects in the Digital Factory;Increasing competition in the automotive industry makes cost-saving integration of more and more vehicle derivatives and variants such as sedans, coupes, cabriolets as well as electrical and combustion engine models into existing production systems necessary. At the same time, the production planners face a major challenge while integrating vehicle bodies-in-white. In contrast to the original concept and rough planning state, the automated production plants are continuously optimized during the detail planning phase as well as after the start of production as a result of improved processes and model upgrading. For fast integration of new vehicles, a current digital image of the real production plant-the so-called Digital Twin-is groundbreaking. This Digital Twin of a factory consists of a current bill of resources for cost calculation and a current layout planning state. The paper describes a concept for creating a Digital Twin of a body-in-white production system for the concept and rough planning projects. In the internal concept planning phase, planners do cost calculations and layouts for ordering factory suppliers. However, for integration planning, the original concept and rough planning project have to be updated. Therefore, a new concept has been developed which uses current information from the cyber-physical system and a current 3D scan to update the bill of resources and the layout planning on demand.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;IEEE International Conference on Emerging Technologies and Factory Automation, ETFA;2018-10-22;https://api.elsevier.com/content/abstract/scopus_id/85057237609
125;A compositional framework for systematic modeling language reuse;Many engineering domains started using generic modeling languages, such as SysML, to describe or prescribe the systems under development. This raises a gap between the generic modeling languages and the domains of experience of the engineers using these. Engineering truly domain-specific languages (DSLs) for experts of these domains still is too challenging for their wide-spread adoption. One major obstacle, the inability to reuse multi-dimensional (encapsulating constituents of syntax and semantics) language components in a black-box fashion, prevents the effective engineering of novel DSLs. To facilitate engineering DSLs, we devised a concept of 3D components for textual, external, and translational DSLs that relies on systematic reuse through systematic closed and open variability in which DSL syntaxes can be embedded, well-formedness rules joined, and code generators integrated in a black-box fashion. We present this concept, a method for its systematic application, an integrated collection of modeling languages supporting systematic language reuse, and an extensible framework that leverages these languages to derive novel DSLs from language product lines. These can greatly mitigate many of the challenges in DSL reuse and, hence, can advance the engineering of truly domain-specific modeling languages.;Association for Computing Machinery, Inc;Conference Proceeding;Proceedings - 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS 2020;2020-10-16;https://api.elsevier.com/content/abstract/scopus_id/85096955321
126;A Conceptual Model for Digital Shadows in Industry and Its Application;Smart manufacturing demands to process data in domain-specific real-time. Engineering models created for constructing, commissioning, planning, or simulating manufacturing systems can facilitate aggregating and abstracting the wealth of manufacturing data to faster processable data structures for more timely decision making. Current research lacks conceptual foundations for how data and engineering models can be exploited in an integrated way to achieve this. Such research demands expertise from different smart manufacturing domains to harmonize the notion space. We propose a conceptual model to describe digital shadows, data structures tailored to exploit models and data in smart manufacturing, through a metamodel and its notion space. This conceptual model was established through interdisciplinary research in the German excellence cluster “Internet of Production” and evaluated in various real-world manufacturing scenarios. This foundation for an understanding helps to manage complexity, automated analyses, and syntheses, and, ultimately, facilitates cross-domain collaboration.;Springer Science and Business Media Deutschland GmbH;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85118142665
127;A Conceptual Model for Digital Shadows in Industry and Its Application;Smart manufacturing demands to process data in domain-specific real-time. Engineering models created for constructing, commissioning, planning, or simulating manufacturing systems can facilitate aggregating and abstracting the wealth of manufacturing data to faster processable data structures for more timely decision making. Current research lacks conceptual foundations for how data and engineering models can be exploited in an integrated way to achieve this. Such research demands expertise from different smart manufacturing domains to harmonize the notion space. We propose a conceptual model to describe digital shadows, data structures tailored to exploit models and data in smart manufacturing, through a metamodel and its notion space. This conceptual model was established through interdisciplinary research in the German excellence cluster “Internet of Production” and evaluated in various real-world manufacturing scenarios. This foundation for an understanding helps to manage complexity, automated analyses, and syntheses, and, ultimately, facilitates cross-domain collaboration.;Springer Science and Business Media Deutschland GmbH;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85118142665
128;A Cyber-Physical Systems architecture for Industry 4.0-based manufacturing systems;Recent advances in manufacturing industry has paved way for a systematical deployment of Cyber-Physical Systems (CPS), within which information from all related perspectives is closely monitored and synchronized between the physical factory floor and the cyber computational space. Moreover, by utilizing advanced information analytics, networked machines will be able to perform more efficiently, collaboratively and resiliently. Such trend is transforming manufacturing industry to the next generation, namely Industry 4.0. At this early development phase, there is an urgent need for a clear definition of CPS. In this paper, a unified 5-level architecture is proposed as a guideline for implementation of CPS.;Elsevier Ltd;Journal;Manufacturing Letters;2015-01-01;https://api.elsevier.com/content/abstract/scopus_id/84921300723
129;A digital twin based industrial automation and control system security architecture;The digital twin is a rather new industrial control and automation systems concept. While the approach so far has gained interest mainly due to capabilities to make advanced simulations and optimizations, recently the possibilities for enhanced security have got attention within the research community. In this article, we discuss how a digital twin replication model and corresponding security architecture can be used to allow data sharing and control of security-critical processes. We identify design-driving security requirements for digital twin based data sharing and control. We show that the proposed state synchronization design meets the expected digital twin synchronization requirements and give a high-level design and evaluation of other security components of the architecture. We also make performance evaluations of a proof of concept for protected software upgrade using the proposed digital twin design. Our new security framework provides a foundation for future research work in this promising new area.;IEEE Computer Societyhelp@computer.org;Journal;IEEE Transactions on Industrial Informatics;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85078224349
130;A digital twin reference model for smart manufacturing;Digital Twin, as an integral enabling technology that integrates multi-physics and multi-scale digital models of physical assets, is critical for achieving interaction and integration between the physical space and virtual world. Though some preliminary research work has proved the potential of Digital Twin to enable efficient smart manufacturing, a limitation to the implementation of Digital Twin is the lack of a reference model for Digital Twin. Targeting at this knowledge gap, the research work in this paper proposes a Digital Twin reference model, with a focus on the enabling technologies to construct a Digital Twin.;Curran Associates Inc.;Conference Proceeding;Proceedings of International Conference on Computers and Industrial Engineering, CIE;2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85061302492
131;A Digital Twin-Based Approach for Designing and Multi-Objective Optimization of Hollow Glass Production Line;Various new national advanced manufacturing strategies, such as Industry 4.0, Industrial Internet, and Made in China 2025, are issued to achieve smart manufacturing, resulting in the increasing number of newly designed production lines in both developed and developing countries. Under the individualized designing demands, more realistic virtual models mirroring the real worlds of production lines are essential to bridge the gap between design and operation. This paper presents a digital twin-based approach for rapid individualized designing of the hollow glass production line. The digital twin merges physics-based system modeling and distributed real-time process data to generate an authoritative digital design of the system at pre-production phase. A digital twin-based analytical decoupling framework is also developed to provide engineering analysis capabilities and support the decision-making over the system designing and solution evaluation. Three key enabling techniques as well as a case study in hollow glass production line are addressed to validate the proposed approach.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2017-10-24;https://api.elsevier.com/content/abstract/scopus_id/85032451877
132;A dynamic bayesian network approach for electro-optical system performance monitoring digital twin;This paper proposes a digital twin model based on dynamic Bayesian network (DBN) for the electro-optical system for its performance monitoring. In this model, a system-level performance indicator from the perspective of the energy domain using Modulation Transfer Function (MTF) is first developed, which avoids tedious modeling of performance interactions between the multiple subsystems of the electro-optical system. Then, a DBN is constructed from the evolution of MTF to denote the dynamic performance degradation process and the propagation of epistemic uncertainty. In order to make the digital twin model capable of tracking and predicting the system performance states, an improved Gaussian particle fdter with kernel smoothing (GPF-KS) is proposed as the inference algorithm for DBN. A real dataset collected in the laboratory environment is used to validate the feasibility of the digital twin model and verify the effectiveness of the GPF-KS inference algorithm. The results show that our method is effective forjoint estimation of states andparameters, leading to reliable estimation andprediction of the electro-optical system on-line health-status.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2019 14th IEEE International Conference on Electronic Measurement and Instruments, ICEMI 2019;2019-11-01;https://api.elsevier.com/content/abstract/scopus_id/85085972257
133;A flexible web-based PDM approach to support virtual engineering cooperation;The objective of the work presented in this paper is to provide a methodology and tools for distributed PDM environments especially suited for virtual project based cooperation in engineering design. A research project called WebFlex-PDM (Web-enabled Flexible PDM federation) is introduced. This project mainly deals with extensions to existing PDM systems to provide the capability for easy integration into different PDM environments of cooperation partners and to enable use of various geographically dispersed WWW-based engineering information resources. In order to analyze the requirements for a flexible management of distributed engineering information resources the paper first describes an application case study. The requirements are compared to the state of the art of distributed PDM solutions and the existing deficits are shown. Finally the main ideas, the architecture, and prototype modules of the WebFlex-PDM approach are presented.;IEEE Computer Societyhelp@computer.org;Conference Proceeding;Proceedings of the Annual Hawaii International Conference on System Sciences;2000-01-01;https://api.elsevier.com/content/abstract/scopus_id/85094134326
134;A generic tri-model-based approach for product-level digital twin development in a smart manufacturing environment;Smart manufacturing, as an emerging manufacturing paradigm, leverages massive in-context data from manufacturing systems for intelligent decision makings. In such context, Cyber-Physical Systems (CPS) play a key role in digitizing manufacturing systems and integrating multiple systems together for collaborative works. Amongst different levels of smartness and connectedness of CPS, Digital Twin (DT), as an exact digital copy of a physical object or system including its properties and relationship with the environment, has a significant impact on realizing smart manufacturing. A DT constantly synchronizes with its physical system and provides real-time high-fidelity simulations of the system and offers ubiquitous control over the system. Despite its great advantages, few works have been discussed about DT reference models, let alone a generic manner to establish it for smart manufacturing. Aiming to fill the gap, this research introduces a generic CPS system architecture for DT establishment in smart manufacturing with a novel tri-model-based approach (i.e. digital model, computational model and graph-based model) for product-level DT development. The tri-model works concurrently to simulate real-world physical behaviour and characteristics of the digital model. To validate the proposed architecture and approach, a case study of an open source 3D printer DT establishment is further conducted. Conclusions and future works are also highlighted to provide insightful knowledge to both academia and industries at last.;Elsevier Ltd;Journal;Robotics and Computer-Integrated Manufacturing;2020-08-01;https://api.elsevier.com/content/abstract/scopus_id/85079352073
135;A hierarchical digital twin model framework for dynamic cyber-physical system design;Cyber-physical system (CPS) is a new trend in the complex system related research works, where network connectivity enhances computing power and systemic behavior emerges through the competition, interaction, collaboration and integration among individual interweaving, which consists of real-time monitoring, data management, physical feedback control. From this perspective, CPS is a dynamic entity with rich functions. However, designers may encounter a difficult situation, in which subsequent dynamic changes of the system are discussed and appropriate functionalities are added in the early design phase. Since the digital twin is the digital duplicate of the physical entity, it can dynamically evolve following the product life cycle. In this paper, we propose a hierarchical digital twin model framework for CPS design. In the light of digital twin concept, the hierarchical high-level models facilitate storage of information from the entire product life cycle. Finally, an industrial robot application is presented to demonstrate the efficacy of the model framework.;Association for Computing Machinery;Conference Proceeding;ACM International Conference Proceeding Series;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85065215650
136;A Methodology for Digital Twin Modeling and Deployment for Industry 4.0;"The digital twin (DT) is a virtual representation of a physical object, which has been proposed as one of the key concepts for Industry 4.0. The DT provides a virtual representation of products along their lifecycle that enables the prediction and optimization of the behavior of a production system and its components. A methodology design using model-driven engineering (MDE) is proposed that strives toward being both flexible and generic. This approach is presented at two levels: first, a DT is modeled as a composition of basic components that provide basic functionalities, such as identification, storage, communication, security, data management, human-machine interface (HMI), and simulation; second, an aggregated DT is defined as a hierarchical composition of other DTs. A generic reference architecture based on these concepts and a concrete implementation methodology are proposed using AutomationML. This methodology follows an MDE approach that supports most of the DT features currently proposed in the literature. A case study has been developed, the proposed ideas are being evaluated with industrial case studies, and some of the preliminary results are described in this article. With the case study, it is possible to verify that the proposed methodology supports the creation and the deployment process of a DT.";Institute of Electrical and Electronics Engineers Inc.;Journal;Proceedings of the IEEE;2021-04-01;https://api.elsevier.com/content/abstract/scopus_id/85098780861
137;A model centered perspective on software-intensive systems;"The aim of this paper contributing to resurrect research interest in conceptual modeling as a means for designing and producing software-intensive systems, as there is still no comprehensive and consistent use of conceptual modeling in practice. The idea is to see any software and information system as a construct consisting of model handlers (model consumers and/or producers). This leads to the paradigm of ""Model Centered Architecture"", which treats all processes, as well as the data they process, as instances of models. These models in turn are instances of metamodels, described using a particular domain specific modeling language (DSML), and represented using a corresponding domain specific representation language. Consequently, all system interfaces are defined through models (via an appropriate DSML) as well. The paper introduces the relevant MCA concepts and sketches open research questions in this field.";CEUR-WSceurws@sunsite.informatik.rwth-aachen.de;Conference Proceeding;CEUR Workshop Proceedings;2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85048362692
138;A model order reduction approach to create patient-specific mechanical models of human liver in computational medicine applications.;Background and objective: This paper focuses on computer simulation aspects of Digital Twin models in the medical framework. In particular, it addresses the need of fast and accurate simulators for the mechanical response at tissue and organ scale and the capability of integrating patient-specific anatomy from medical images to pinpoint the individual variations from standard anatomical models. Methods: We propose an automated procedure to create mechanical models of the human liver with patient-specific geometry and real time capabilities. The method hinges on the use of Statistical Shape Analysis to extract the relevant anatomical features from a database of medical images and Model Order Reduction to compute an explicit parametric solution for the mechanical response as a function of such features. The Sparse Subspace Learning, coupled with a Finite Element solver, was chosen to create low-rank solutions using a non-intrusive sparse sampling of the feature space. Results: In the application presented in the paper, the statistical shape model was trained on a database of 385 three dimensional liver shapes, extracted from medical images, in order to create a parametrized representation of the liver anatomy. This parametrization and an additional parameter describing the breathing motion in linear elasticity were then used as input in the reduced order model. Results show a consistent agreement with the high fidelity Finite Element models built from liver images that were excluded from the training dataset. However, we evidence in the discussion the difficulty of having compact shape parametrizations arising from the extreme variability of the shapes found in the dataset and we propose potential strategies to tackle this issue. Conclusions: A method to represent patient-specific real-time liver deformations during breathing is proposed in linear elasticity. Since the proposed method does not require any adaptation to the direct Finite Element solver used in the training phase, the procedure can be easily extended to more complex non-linear constitutive behaviors - such as hyperelasticity - and more general load cases. Therefore it can be integrated with little intrusiveness to generic simulation software including more sophisticated and realistic models.;Elsevier Ireland Ltd;Journal;Computer Methods and Programs in Biomedicine;2019-03-01;https://api.elsevier.com/content/abstract/scopus_id/85060193310
139;A model-driven approach on object-oriented PLC programming for manufacturing systems with regard to usability;This paper presents the modular automation for reuse in manufacturing systems (modAT4rMS) approach to support the model-driven engineering (MDE) of object-oriented manufacturing automation software with regard to its usability and software modularity. With usability, we refer to the aspects' effectiveness, efficiency, and user acceptance as defined by ISO 9241-11. The modAT4rMS notations are based on selected features from the unified modeling language (UML) and the systems modeling language (SysML), and iteratively further developed by a series of empirical studies with industrial practitioners, as well as mechatronics trainees. With modAT4rMS, an MDE approach for programmable logic controller (PLC) programming was developed with the goal to facilitate modular object-oriented programming of PLC software by improving the representation of the relationships between the structure and behavior diagram types, and by reducing the level of abstraction in the structure model. modAT4rMS notations for PLC software structure and software behavior modeling are presented and illustrated with a modeling example using a modAT4rMS editor prototype. For the evaluation of the developed notations, the results from a study with 168 participants are presented, showing the benefits of this new approach in comparison with the classic procedural paradigm (IEC 61131-3) and the domain-specific UML profile (plcML) in regard to programming performance and usability aspects. Finally, the advantages and limitations of the approach are discussed, and an outlook for further development is given.;IEEE Computer Societyhelp@computer.org;Journal;IEEE Transactions on Industrial Informatics;2015-06-01;https://api.elsevier.com/content/abstract/scopus_id/84933044599
140;A model-driven approach to automate data visualization in big data analytics;In big data analytics, advanced analytic techniques operate on big datasets aimed at complementing the role of traditional OLAP for decision making. To enable companies to take benefit of these techniques despite the lack of in-house technical skills, the H2020 TOREADOR Project adopts a model-driven architecture for streamlining analysis processes, from data preparation to their visualization. In this article, we propose a new approach named SkyViz focused on the visualization area, in particular on (1) how to specify the user’s objectives and describe the dataset to be visualized, (2) how to translate this specification into a platform-independent visualization type, and (3) how to concretely implement this visualization type on the target execution platform. To support step (1), we define a visualization context based on seven prioritizable coordinates for assessing the user’s objectives and conceptually describing the data to be visualized. To automate step (2), we propose a skyline-based technique that translates a visualization context into a set of most suitable visualization types. Finally, to automate step (3), we propose a skyline-based technique that, with reference to a specific platform, finds the best bindings between the columns of the dataset and the graphical coordinates used by the visualization type chosen by the user. SkyViz can be transparently extended to include more visualization types on one hand, more visualization coordinates on the other. The article is completed by an evaluation of SkyViz based on a case study excerpted from the pilot applications of the TOREADOR Project.;SAGE Publications Ltdinfo@sagepub.co.uk;Journal;Information Visualization;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85070335103
141;A Model-Driven Approach to Unravel the Interoperability Problem of the Internet of Things;The Internet of Things (IoT) aims for connecting Anything, Anywhere, Anytime (AAA). This premise brings about heterogeneity that creates connectivity challenges. These challenges constitutes a serious obstacle to interoperability between things. Most existing approaches tackles the interoperability problem by avoiding heterogeneity with standards at runtime. While heterogeneity is an intrinsic feature of the IoT, there is a need for an approach that embraces it to connect AAA. In this paper we propose a model-based methodology to tackle the interoperability problem. It relies on a Domain-Specific Language (DSL) for a model-based specification of the network and a transformation process to generate the network artifacts from this specification. The principle consists of achieving interoperability at the model-level, then during a transformation process, ensuring that it is preserved in the low-level code. Adopting this methodology makes the engineering of the IoT more rigorous, prevents bugs earlier and saves time.;Springer;Book Series;Advances in Intelligent Systems and Computing;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85083744618
142;A Model-Driven Engineering Workbench for CAEX Supporting Language Customization and Evolution;Computer Aided Engineering Exchange (CAEX) is one of the most promising standards when it comes to data exchange between engineering tools in the production system automation domain. This is also reflected by the current emergence of AutomationML (AML), which uses CAEX as its core representation language. However, with the increasing use of CAEX, important language engineering challenges arise. One of these challenges is the customization of CAEX for its usage in superior standards, such as AML, which requires the precise specification of the language including the formalization and validation of additional usage rules. Another highly topical challenge is the ongoing evolution of CAEX as has recently happened with the transition from version 2.15 to version 3.0. Further challenges include the provisioning of editing facilities and visualizations of CAEX documents such that they can be inspected and modified by engineers, and the development of transformations from and to CAEX such that different engineering artifacts can be exchanged via CAEX. In this paper, we take a language engineering point of view and present a model-driven engineering (MDE) workbench for CAEX that allows to address these and other challenges. In particular, we present how CAEX can be formulated in a model-based framework, which allows the application of MDE techniques, such as model validation, migration, editing, visualization, and transformation techniques, to solve a diverse set of language engineering challenges experienced for CAEX. We give an overview of the developed workbench and illustrate its benefits with a focus on customizing CAEX for AML and evolving CAEX documents from version 2.15 to 3.0.;IEEE Computer Societyhelp@computer.org;Journal;IEEE Transactions on Industrial Informatics;2018-06-01;https://api.elsevier.com/content/abstract/scopus_id/85039804401
143;A modular CPS architecture design based on ROS and Docker;In this paper a modular generic architecture for cyber-physical systems based on free open software components is presented. The architecture is implemented over inexpensive components frequently found in information and communication technology contexts. More specifically, the robot operating system middleware abstracts communication among multiple networked modules, whereas the Docker lightweight virtualization container is proposed to wrap up software modules. Focus is on mobile robotics in production systems and industrial automation environments. Actually, an automated guided vehicle problem is demonstrated by means of a proof of concept aimed at industrial automation applications illustrating the potential of the proposed architecture and its implementation, built with low cost hardware modules.;Springer-Verlag France22, Rue de PalestroParis75002york@springer-paris.fr;Journal;International Journal on Interactive Design and Manufacturing;2017-11-01;https://api.elsevier.com/content/abstract/scopus_id/84964196260
144;A Novel Cloud-Based Framework for the Elderly Healthcare Services Using Digital Twin;With the development of technologies, such as big data, cloud computing, and the Internet of Things (IoT), digital twin is being applied in industry as a precision simulation technology from concept to practice. Further, simulation plays a very important role in the healthcare field, especially in research on medical pathway planning, medical resource allocation, medical activity prediction, etc. By combining digital twin and healthcare, there will be a new and efficient way to provide more accurate and fast services for elderly healthcare. However, how to achieve personal health management throughout the entire lifecycle of elderly patients, and how to converge the medical physical world and the virtual world to realize real smart healthcare, are still two key challenges in the era of precision medicine. In this paper, a framework of the cloud healthcare system is proposed based on digital twin healthcare (CloudDTH). This is a novel, generalized, and extensible framework in the cloud environment for monitoring, diagnosing and predicting aspects of the health of individuals using, for example, wearable medical devices, toward the goal of personal health management, especially for the elderly. CloudDTH aims to achieve interaction and convergence between medical physical and virtual spaces. Accordingly, a novel concept of digital twin healthcare (DTH) is proposed and discussed, and a DTH model is implemented. Next, a reference framework of CloudDTH based on DTH is constructed, and its key enabling technologies are explored. Finally, the feasibility of some application scenarios and a case study for real-time supervision are demonstrated.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85065103886
145;A novel digital twin-centric approach for driver intention prediction and traffic congestion avoidance;Road traffic has been exponentially growing with surging people and vehicle population. Road connectivity infrastructure has not been growing correspondingly and hence the research endeavors for optimal resource allocation and utilization of connectivity resources has gained a lot these days. Therefore, insights-driven real-time traffic management is turning out to be an important component in establishing and sustaining smarter cities across the globe. IT solution and service organizations have come forth with a number of automated traffic management solutions and the primary problem with them is they are unfortunately reactive and hence an inefficient solution for the increasingly connected and dynamic city environments. Therefore, unveiling real-time, adaptive, precision-centric and predictive traffic monitoring, measurement, management and enhancement solutions are being insisted as an indispensable requirement toward sustainable cities. We have come out with a novel approach leveraging a few potential and promising technologies and tools such as a reliable and reusable virtual model for vehicles, a machine learning model, the IoT fog or edge data analytics, a data lake for traffic and vehicle data on public cloud environments, and 5G communication. The paper details all these in a cogent fashion and how these technological advancements come handy in avoiding the frequent traffic congestions and snarls due to various reasons.;Springer Science and Business Media Deutschland GmbH;Journal;Journal of Reliable Intelligent Environments;2018-12-01;https://api.elsevier.com/content/abstract/scopus_id/85062692056
146;A Practical Guide to SysML: The Systems Modeling Language, Third Edition;A Practical Guide to SysML, Third Edition, fully updated for SysML version 1.4, provides a comprehensive and practical guide for modeling systems with SysML. With their unique perspective as leading contributors to the language, Friedenthal, Moore, and Steiner provide a full description of the language along with a quick reference guide and practical examples to help you use SysML. The book begins with guidance on the most commonly used features to help you get started quickly. Part 1 explains the benefits of a model-based approach, providing an overview of the language and how to apply SysML to model systems. Part 2 includes a comprehensive description of SysML that provides a detailed understanding that can serve as a foundation for modeling with SysML, and as a reference for practitioners. Part 3 includes methods for applying model-based systems engineering using SysML to specify and design systems, and how these methods can help manage complexity. Part 4 deals with topics related to transitioning MBSE practice into your organization, including integration of the system model with other engineering models, and strategies for adoption of MBSE.;Elsevier;Book;A Practical Guide to SysML: The Systems Modeling Language, Third Edition;2014-01-01;https://api.elsevier.com/content/abstract/scopus_id/85107187033
147;A probabilistic and timed verification approach of SysML state machine diagram;Timed-constrained and probabilistic verification approaches gain a great importance in system behavior validation. They enable the evaluation of system behavior according to the design requirements and ensure their correctness before any implementation. In this paper, we propose a probabilistic and timed verification framework of State Machine diagrams extended with time and probability features. The approach consists on mapping the extended State Machine diagram to its equivalent probabilistic timed automata that is expressed in PRISM language. To check the functional correctness of the system under test, the properties are expressed in PCTL temporal logic. We demonstrate the approach efficiency by analyzing performability properties on a Automatic Teller Machine (ATM) case study.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;12th International Symposium on Programming and Systems, ISPS 2015;2015-09-08;https://api.elsevier.com/content/abstract/scopus_id/84957990996
148;A resilient Internet of Things architecture for smart cities;Nowadays, technology is such an integral part of our lives that the dependency on its benefits is growing faster than ever. With the arrival of the paradigms of smart cities and the Internet of Things, citizens are able to improve their quality of life. Given that sensors and actuators deployed in smart cities usually have limited resources, today, it is a common practice to use cloud computing to extend the scope and benefits of smart cities. Taking into consideration that communication between applications and devices is vital for a good performance of services in a smart city, it is necessary to design new architectures and mechanisms to provide reliability in communications. A key aspect that has to be addressed by the new communications approaches is the possibility to recover the network and its services in case of faults, without human intervention. In this paper, a novel architecture to improve the resilience level of the infrastructure in the Internet of Things is proposed. Moreover, technologies to implement the components from the architecture are suggested. This proposal is discussed within the scope of the SusCity project.;Springer-Verlag France22, Rue de PalestroParis75002york@springer-paris.fr;Journal;Annales des Telecommunications/Annals of Telecommunications;2017-02-01;https://api.elsevier.com/content/abstract/scopus_id/84975127016
149;A simulation-based architecture for smart cyber-physical systems;In order to accurately predict future states of a smart cyber-physical system, which can change its behavior to a large degree in response to environmental influences, the existence of precise models of the system and its surroundings is demandable. In machine engineering, ultra-high fidelity simulations have been developed to better understand both constraints in system design and possible consequences of external influences during the system's operation. These digital twins enable further applications in software design for complex cyber-physical systems as online planning methods can utilize good simulations to continuously optimize the system behavior, yielding a software architecture framework based on the information flow between the cyber-physical system, its physical environment and the digital twin model.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2016 IEEE International Conference on Autonomic Computing, ICAC 2016;2016-09-21;https://api.elsevier.com/content/abstract/scopus_id/84991687905
150;A simulation-based architecture for smart cyber-physical systems;In order to accurately predict future states of a smart cyber-physical system, which can change its behavior to a large degree in response to environmental influences, the existence of precise models of the system and its surroundings is demandable. In machine engineering, ultra-high fidelity simulations have been developed to better understand both constraints in system design and possible consequences of external influences during the system's operation. These digital twins enable further applications in software design for complex cyber-physical systems as online planning methods can utilize good simulations to continuously optimize the system behavior, yielding a software architecture framework based on the information flow between the cyber-physical system, its physical environment and the digital twin model.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2016 IEEE International Conference on Autonomic Computing, ICAC 2016;2016-09-21;https://api.elsevier.com/content/abstract/scopus_id/84991687905
151;A survey of modeling language specification techniques;Visual modeling languages such as the Business Process Model and Notation and the Unified Modeling Language are widely used in industry and academia for the analysis and design of information systems. Such modeling languages are usually introduced in overarching specifications which are maintained by standardization institutions such as the Object Management Group or the Open Group. Being the primary – often the single – source of information, such specifications are of paramount importance for modelers, researchers, and tool vendors. However, structure, content, and specification techniques of such documents have never been systematically analyzed. This paper addresses this gap by reporting on a Systematic Literature Review aimed to analyze published standard modeling language specifications. In total, eleven specifications were found and comprehensively analyzed. The survey reveals heterogeneity in: (i) the modeling language concepts being specified, and (ii) the techniques being employed for the specification of these concepts. The identified specification techniques are analyzed and presented by referring to their utilization in the specifications. This survey provides a foundation for research aiming to increase consistency and improve comprehensiveness of information systems modeling languages.;Elsevier Ltd;Journal;Information Systems;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85070716326
152;A survey on digital twin: Definitions, characteristics, applications, and design implications;When, in 1956, Artificial Intelligence (AI) was officially declared a research field, no one would have ever predicted the huge influence and impact its description, prediction, and prescription capabilities were going to have on our daily lives. In parallel to continuous advances in AI, the past decade has seen the spread of broadband and ubiquitous connectivity, (embedded) sensors collecting descriptive high dimensional data, and improvements in big data processing techniques and cloud computing. The joint usage of such technologies has led to the creation of digital twins, artificial intelligent virtual replicas of physical systems. Digital Twin (DT) technology is nowadays being developed and commercialized to optimize several manufacturing and aviation processes, while in the healthcare and medicine fields this technology is still at its early development stage. This paper presents the results of a study focused on the analysis of the state-of-the-art definitions of DT, the investigation of the main characteristics that a DT should possess, and the exploration of the domains in which DT applications are currently being developed. The design implications derived from the study are then presented: they focus on socio-technical design aspects and DT lifecycle. Open issues and challenges that require to be addressed in the future are finally discussed.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85076680404
153;A survey on digital twin: Definitions, characteristics, applications, and design implications;When, in 1956, Artificial Intelligence (AI) was officially declared a research field, no one would have ever predicted the huge influence and impact its description, prediction, and prescription capabilities were going to have on our daily lives. In parallel to continuous advances in AI, the past decade has seen the spread of broadband and ubiquitous connectivity, (embedded) sensors collecting descriptive high dimensional data, and improvements in big data processing techniques and cloud computing. The joint usage of such technologies has led to the creation of digital twins, artificial intelligent virtual replicas of physical systems. Digital Twin (DT) technology is nowadays being developed and commercialized to optimize several manufacturing and aviation processes, while in the healthcare and medicine fields this technology is still at its early development stage. This paper presents the results of a study focused on the analysis of the state-of-the-art definitions of DT, the investigation of the main characteristics that a DT should possess, and the exploration of the domains in which DT applications are currently being developed. The design implications derived from the study are then presented: they focus on socio-technical design aspects and DT lifecycle. Open issues and challenges that require to be addressed in the future are finally discussed.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85076680404
154;A systematic literature review on methods that handle multiple quality attributes in architecture-based self-adaptive systems;Context Handling multiple quality attributes (QAs) in the domain of self-adaptive systems is an understudied research area. One well-known approach to engineer adaptive software systems and fulfill QAs of the system is architecture-based self-adaptation. In order to develop models that capture the required knowledge of the QAs of interest, and to investigate how these models can be employed at runtime to handle multiple quality attributes, we need to first examine current architecture-based self-adaptive methods. Objective In this paper we review the state-of-the-art of architecture-based methods for handling multiple QAs in self-adaptive systems. We also provide a descriptive analysis of the collected data from the literature. Method We conducted a systematic literature review by performing an automatic search on 28 selected venues and books in the domain of self-adaptive systems. As a result, we selected 54 primary studies which we used for data extraction and analysis. Results Performance and cost are the most frequently addressed set of QAs. Current self-adaptive systems dealing with multiple QAs mostly belong to the domain of robotics and web-based systems paradigm. The most widely used mechanisms/models to measure and quantify QAs sets are QA data variables. After QA data variables, utility functions and Markov chain models are the most common models which are also used for decision making process and selection of the best solution in presence of many alternatives. The most widely used tools to deal with multiple QAs are PRISM and IBM's autonomic computing toolkit. KLAPER is the only language that has been specifically developed to deal with quality properties analysis. Conclusions Our results help researchers to understand the current state of research regarding architecture-based methods for handling multiple QAs in self-adaptive systems, and to identity areas for improvement in the future. To summarize, further research is required to improve existing methods performing tradeoff analysis and preemption, and in particular, new methods may be proposed to make use of models to handle multiple QAs and to enhance and facilitate the tradeoffs analysis and decision making mechanism at runtime.;Elsevier B.V.;Journal;Information and Software Technology;2017-10-01;https://api.elsevier.com/content/abstract/scopus_id/85019033585
155;A systems engineering approach for a dynamic co-simulation of a SysML tool and Matlab;Industry is in a debate about the potential of the Systems Modeling Language (SysML). One part sees the advantage in development and project planning. The other part argues that the employment of SysML results in unnecessary additional work. The description of systems is still largely managed by the widely-used Microsoft Office software like Excel or PowerPoint. Indeed, this software has its limitations, especially when it comes to complex systems. Regarding SysML, the aim of this publication is to show the practical benefit and to open a further field of application. The cyclic coupling of SysML with a calculation software enables periodic data exchange in a flexible toolchain. This is a fundamental step, which leads to a new approach of systems development and domain collaboration. The SysML tool is intended to be the highest instance in the toolchain. A calculation software translates all the instructions coming from the highest instance into physical behavior, which can be simultaneously displayed with the aid of a visualization tool. As a significant result, an early validation of the behavior of a system under development can be performed with the aid of the overall model. In order to demonstrate this concept, a high-level simulation of a «Traffic Alert and Collision Avoidance System (TCAS)» serves as an example. Tests show that the SysML controlled TCAS simulation is a proper application to demonstrate the execution of important decisions. By means of the visualization, the TCAS behavior becomes transparent. The advantages of the dynamic co-simulation are particularly in the application of Model-Based Systems Engineering (MBSE) to heterogeneous complex systems.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;10th Annual International Systems Conference, SysCon 2016 - Proceedings;2016-06-13;https://api.elsevier.com/content/abstract/scopus_id/84979210486
156;AAS Capability-Based Operation and Engineering of Flexible Production Lines;"Lot-size-one systems as well as plug and produce concepts imply (1) producing increased variety of products in a highly flexible and timely manner, and (2) making commissioning and maintenance more flexible. The speed with which manufacturers, in particular SMEs, can reconfigure the production to a new run and thus respond to clients and avoid costly machine downtime is critical to maintaining commercial success and profit margins. The manufacturing systems of tomorrow must offer a high degree of autonomy, be quickly re-planned to other operations, and cope with a wide variety of unforeseen situations, in a secure and safe manner. In this context, the Asset Administration Shell (AAS) is an emergent standard that leverages the digital twin approach and provides concepts for describing capabilities and skills of I4.0 components in order to automate the reconfiguration process. This article proposes a capability-based operation and engineering approach to tackle the syntactic and semantic interoperability problems in flexible production lines. We demonstrate the implementation of the AAS standard in the open source model-driven workbench Papyrus; then we assess its usability for modeling a production cell use case in order to implement a capability-based reconfiguration approach for flexible production lines.";Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;IEEE International Conference on Emerging Technologies and Factory Automation, ETFA;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85122963448
157;Adapting an agile manufacturing concept to the reference architecture model industry 4.0: A survey and case study;Industry 4.0 architecture has been studied in a large number of publications in the fields of Industrial Internet of Things, Cyber Physical Production Systems, Enterprise Architectures, Enterprise Integration and Cloud Manufacturing. A large number of architectures have been proposed, but none of them has been adopted by a large number of research groups. Two major Industry 4.0 reference architectures have been developed by industry-driven initiatives, namely the German Industry 4.0 and the US-led Industrial Internet Consortium. These are the Reference Architecture Model Industry 4.0 and Industrial Internet Reference Architecture, which are being standardized by the International Electrotechnical Commission and the Object Management Group, respectively. The first research goal of this article is to survey the literature on Industry 4.0 architectures in a factory context and assess awareness and compatibility with Reference Architecture Model Industry 4.0 and Industrial Internet Reference Architecture. The second research goal is to adapt a previously proposed advanced manufacturing concept to Reference Architecture Model Industry 4.0. With respect to the first research goal, it was discovered that only a minority of researchers were aware of the said reference architectures and that in general authors offered no discussion about the compatibility of their proposals with any internationally standardized reference architecture for Industry 4.0. With respect to the second research goal, it was discovered that Reference Architecture Model Industry 4.0 was mature with respect to communication and information sharing in the scope of the connected world, that further standardization enabling interoperability of different vendors’ technology is still under development and that technology standardization enabling executable business processes between networked enterprises was lacking.;Elsevier B.V.;Journal;Journal of Industrial Information Integration;2019-09-01;https://api.elsevier.com/content/abstract/scopus_id/85059234018
158;Development of an Agile Requirements Risk Prioritization Method: A Design Science Research Study;The practice of information systems development (ISD) has changed during the past two decades from very structured approaches to agile ISD methods. However, in the literature many methods available for managing requirements-related risks follow a structured approach to ISD. Few, if any, available methods offer solutions that prioritize requirements risks for agile ISD projects based on recognizing requirements-related risks and patterns in order to mitigate these. To fill this gap in the literature, we apply the design science research methodology to develop an agile requirements risk prioritization method together with industry experts (n=54) in Finland and New Zealand in a multi-year study. The method was developed by applying contingency theory, and our study makes an artifactual contribution to the literature. The method helps practitioners prioritize the overall requirements-related risks for ISD projects.;Association for Information Systems;Journal;Communications of the Association for Information Systems;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85163136181
159;Agile Generator-Based GUI Modeling for Information Systems;We use two code generators for the model-based continuous development of information systems including its graphical user interfaces (GUIs). As our goal is to develop full-size real-world systems for different domains, the continuous and iterative model-based engineering of their GUIs comes along with challenges regarding their extension and modification. These challenges concern models, the languages they are written in and hand-written code. In this work we present four complementary approaches to allow extensions for GUIs that we encounter with the generator-based framework MontiGem to tackle these challenges. We discuss the four approaches in detail and present extensions of the framework in the grammar of the language, via atomic components, via hand-written amendments of generated models and by generating connections between the GUI and data structure models. These techniques can be used to create a flexible DSL for engineering information systems, adaptable for different domains and rapidly changing requirements.;Springer Science and Business Media Deutschland GmbH;Book Series;Communications in Computer and Information Science;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85107450806
160;Air Quality Management: An Exemplar for Model-Driven Digital Twin Engineering;Since its first mentioning in the literature, the concept of Digital Twin has gained traction in both industry and academia. However, there are still many open challenges when applying Digital Twins to industry-scale use cases. Applying Model-Driven Engineering techniques to the creation and maintenance of Digital Twins (also referred to as Model-Driven Digital Twin Engineering) promises automation and consistency throughout the life cycle of a Digital Twin. The exemplar provided in this paper can be used to identify open challenges when it comes to Model-Driven Digital Twin Engineering, and to demonstrate how approaches can solve them. This exemplar applies Digital Twins to an indoor air quality management use case, where CO2, temperature, and humidity values of rooms within a building are measured. These values can be used to derive actions to improve work productivity and reduce the risk for virus infections. We describe three applications that make use of this Digital Twin (i.e., runtime visualization, physical simulation, and ML-based predictions), and provide an online repository with the artefacts of this exemplar.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Companion Proceedings - 24th International Conference on Model-Driven Engineering Languages and Systems, MODELS-C 2021;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85124047367
161;An AADL model-based safety analysis method for flight control software;This paper proposes a model-based software safety analysis method for flight control software. Firstly, the AADL architecture model and error model of flight control software are constructed separately. Then we convert the AADL model of flight control software into extended Markov chain model. We can evaluate safety of software component by calculate the probability of component state in different hazardous levels with the extended Markov chain model. Finally, safety of entire flight control software system can be calculated according to AADL error states composition relation, which can avoid states explosion problem of Markov chain model.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2014 6th International Conference on Computational Intelligence and Communication Networks, CICN 2014;2014-03-23;https://api.elsevier.com/content/abstract/scopus_id/84946685269
162;An AAS Modeling Tool for Capability-Based Engineering of Flexible Production Lines;The future intelligent manufacturing systems should possess a high degree of autonomy, which is able to monitor the entire production process, quickly re-plan operations, and respond to various unforeseen situations in a secure and safe manner. This can achieve rapid response to customers and avoid costly machine downtime, which is crucial to maintaining business success and profitability. The Asset Administration Shell (AAS) is an emerging standard in the I4.0 (Industry 4.0) domain. Based on the concept of digital twins, it provides concepts for describing the digital representation of I4.0 assets including their capabilities and skills. The AAS provides also responses to the challenge of syntactic and semantic interoperability that the flexible and autonomous production lines are facing. In this article, we propose a capability-based operation and engineering approach for flexible production lines. Our approach is relying on the AAS standard which is a very wide and rich specification. Consequently, we describe the subset of AAS modelling concepts necessary for our approach, we clarify their semantics and we show their usage through a production cell use case. Furthermore, we demonstrate how these modelling concepts were tooled as an extension of the open source model-driven workbench Papyrus.;IEEE Computer Society;Conference Proceeding;IECON Proceedings (Industrial Electronics Conference);2021-10-13;https://api.elsevier.com/content/abstract/scopus_id/85119507003
163;An analytical model for multi-tier internet services and its applications;Since many Internet applications employ a multi-tier architecture, in this paper, we focus on the problem of analytically modeling the behavior of such applications. We present a model based on a network of queues, where the queues represent different tiers of the application. Our model is sufficiently general to capture (i) the behavior of tiers with significantly different performance characteristics and (ii) application idiosyncrasies such as session-based workloads, concurrency limits, and caching at intermediate tiers. We validate our model using real multi-tier applications running on a Linux server cluster. Our experiments indicate that our model faithfully captures the performance of these applications for a number of workloads and configurations. For a variety of scenarios, including those with caching at one of the application tiers, the average response times predicted by our model were within the 95% confidence intervals of the observed average response times. Our experiments also demonstrate the utility of the model for dynamic capacity provisioning, performance prediction, bottleneck identification, and session policing. In one scenario, where the request arrival rate increased from less than 1500 to nearly 4200 requests/min, a dynamic provisioning technique employing our model was able to maintain response time targets by increasing the capacity of two of the application tiers by factors of 2 and 3.5, respectively. Copyright 2005 ACM.;Association for Computing Machineryacmhelp@acm.org;Conference Proceeding;Performance Evaluation Review;2005-01-01;https://api.elsevier.com/content/abstract/scopus_id/33244472642
164;An approach based on model driven engineering for big data visualization in different visual modes;Data visualization consists of transforming complex data into simple visual representations to facilitate understanding and exploitation of data. The goal of this strategy is to make information accessible to everyone, or more specifically to people who can make decisions based on the data collected. During our research project, we have worked on the application of techniques related to model engineering to propose a universal meta-model for the different layers of a Big Data system. In continuous efforts, we present in this paper a model engineering approach that allows displaying the data in several visual modes, by using Atlas Transformation Language (ATL).;International Journal of Scientific and Technology Researcheditor@ijstr.org;Journal;International Journal of Scientific and Technology Research;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85078854282
165;An approach to develop a digital twin for industry 4.0 systems: manufacturing automation case studies;The new paradigm of digital manufacturing and the concept of Industry 4.0 has led to the integration of recent manufacturing advances with modern information and communication technologies. Therefore, digital simulation tools fused into production systems can improve time and cost-effectiveness and enable faster, more flexible, and more efficient processes to produce higher-quality goods. The advancement of digital simulation with sensory data may support the credibility of production systems and improve the efficiency of production planning and execution processes. In this paper, an approach is proposed to develop a Digital Twin of production systems in order to optimize the planning and commissioning process. The proposed virtual cell interacts with the physical system with the help of different Digital Manufacturing Tools (DMT), which allows for the testing of various programs in a different scenario to check for any shortcomings before it is implemented on the physical system. Case studies from the different production systems are demonstrated to realize the feasibility of the proposed approach.;Taylor and Francis Ltd.;Journal;International Journal of Computer Integrated Manufacturing;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85109762696
166;An architecture for mission coordination of heterogeneous robots;Context: Robots can potentially collaborate to execute a variety of tasks in the service robots domain. However, developing applications of service robots can be complex due to the high level of uncertainty and required level of autonomy. Objective: We aim at contributing an architecture for the development of applications, capable of coordinating multi-robot missions, and that promotes modifiability and seamless integration of independently developed components. Method: In this work, we introduce MissionControl: an ensemble-based architecture to coordinate missions of heterogeneous robots to autonomously form coalitions. MissionControl comprises a component model and a runtime environment. The component model specifies how the system can be extended for different robot's behaviors and environments. The runtime environment provides the processes required for coordinating the execution of missions at runtime. Results: We evaluated MissionControl in a simulated environment in the healthcare domain. We randomly generated 81 scenarios with uncertainty in the robots’ initial configurations. Then, each scenario was executed 8 times (i.e. 648 runs), where we evaluated the feasibility and efficiency of MissionControl for autonomously forming coalitions against a baseline approach that uses a random robot allocation. Statistical hypotheses testing yielded that MissionControl was able to achieve higher success rates while reducing the required time to conclude a mission, when compared to a baseline approach. We also perform an evaluation of the key quality attributes of the architecture, i.e. modifiability and integrability. Conclusions: MissionControl demonstrated itself able to coordinate multi-robot missions by autonomously assigning missions. Despite the error-prone robotic mission environment and demanding computational resources, MissionControl led to a significant increase in the success rate, while also decreasing the time required to conclude robotic missions when compared to a baseline approach.;Elsevier Inc.;Journal;Journal of Systems and Software;2022-09-01;https://api.elsevier.com/content/abstract/scopus_id/85131043669
167;An architecture of an Intelligent Digital Twin in a Cyber-Physical Production System;The role of a Digital Twin is increasingly discussed within the context of Cyber-Physical Production Systems. Accordingly, various architectures for the realization of Digital Twin use cases are conceptualized. There lacks, however, a clear, encompassing architecture covering necessary components of a Digital Twin to realize various use cases in an intelligent automation system. In this contribution, the added value of a Digital Twin in an intelligent automation system is highlighted and various existing definitions and architectures of the Digital Twin are discussed. Flowingly, an architecture for a Digital Twin and an architecture for an Intelligent Digital Twin and their required components are proposed, with which use cases such as plug and produce, self-x and predictive maintenance are enabled. In the opinion of the authors, a Digital Twin requires three main characteristics: Synchronization with the real asset, active data acquisition from the real environment and the ability of simulation. In addition to all the characteristics of a Digital Twin, an Intelligent Digital Twin must also include the characteristics of Artificial Intelligence. The Intelligent Digital Twin can be used for the realization of the autonomous Cyber-Physical Production Systems. In order to realize the proposed architecture for a Digital Twin, several methods, namely the Anchor-Point-Method, a method for heterogeneous data acquisition and data integration as well as an agent-based method for the development of a co-simulation between Digital Twins were implemented and evaluated.;De Gruyter Oldenbourg;Journal;At-Automatisierungstechnik;2019-09-25;https://api.elsevier.com/content/abstract/scopus_id/85073869890
168;An open source approach to the design and implementation of Digital Twins for Smart Manufacturing;This paper discusses the design of a Digital Twin (DT) demonstrator for Smart Manufacturing, following an open source approach for implementation. Open source technology can comprise of software, hardware and hybrid solutions that nowadays drive Smart Manufacturing. The major potential of open source technology in Smart Manufacturing lies in enabling interoperability and in reducing the capital costs of designing and implementing new manufacturing solutions. After presenting our motivation to adopt an open source approach for the design of a DT demonstrator, we identify the major implementation requirements of Smart Cyber Physical Systems (CPSs) and DTs. A conceptualisation of the core components of a DT demonstrator is provided and three technology building blocks for the realisation of a DT have been identified. These technology building blocks include components for the management of data, models and services. From the conceptual model of the DT demonstrator, we derived a high-level micro-services architecture and provided a case study infrastructure for the implementation of the DT demonstrator based on available open source technologies. The paper closes with research questions to be addressed in the future.;Taylor and Francis Ltd.michael.wagreich@univie.ac.at;Journal;International Journal of Computer Integrated Manufacturing;2019-05-04;https://api.elsevier.com/content/abstract/scopus_id/85064532610
169;An overview on how to develop a low-code application using OutSystems;The motivation for developing a self-service platform for employees arises precisely from the idea that in all organizations there are tasks that could be automated in order to redirect work resources to more important tasks. The proposed application consists of the development of a self-service platform, for personal information and scheduling tasks, aimed at the employees instead of all the solutions that are in the market that aim their platform to the Human Resources. We focus on the employers giving them more responsibility to make their own personal management like, change their personal info, book their vacations and other, giving to the Human Resources the tasks of managing all these actions made by the employers. At the end of the work, it is expected that the final solution to be considered as an example of success with regards to the theme of business automation and innovation, using the low-code application Outsystems to perform the full proposed application development.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings of the International Conference on Smart Technologies in Computing, Electrical and Electronics, ICSTCEE 2020;2020-10-09;https://api.elsevier.com/content/abstract/scopus_id/85099472780
170;Architecting System of Systems Solutions with Security and Data-Protection Principles;The rapid advancement of communication technology realized the dream of interconnected systems. In addition to enabling scalability and flexibility of solutions, this paradigm created new system design challenges. One such challenge is to holistically address security and privacy concerns of solutions early in design while respecting the system of systems context. This paper proposes a method for the concept design phase on how to create design alternatives with the help of security and data-protection principles. The outcome is a set of design concepts that reflect stakeholders' concerns and best practices.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2021 16th International System of Systems Engineering Conference, SoSE 2021;2021-06-14;https://api.elsevier.com/content/abstract/scopus_id/85112470275
171;Architectural aspects of digital twins in IIoT systems;Industrial Internet of Things (IIoT) systems enable the connectivity of numerous devices, which are heterogeneous in terms of their interfaces and supported protocols, into one system to derive more intelligent actions from data. Digital Twins are a key enabler for IIoT systems, which allow the acquisition, access, and exchange of far greater variety of data than today and previously unseen interoperability out of the box. This paper elaborates on the definitions of digital twins, their role in IIoT systems and the necessary architectural decisions that software/system architects have to make to design digital twins.;Association for Computing Machineryacmhelp@acm.org;Conference Proceeding;ACM International Conference Proceeding Series;2018-09-24;https://api.elsevier.com/content/abstract/scopus_id/85055721125
172;Empirical resilience evaluation of an architecture-based self-adaptive software system;Architecture-based self-adaptation is considered as a promising approach to drive down the development and operation costs of complex software systems operating in ever changing environments. However, there is still a lack of evidence supporting the arguments for the beneficial impact of architecture-based self-adaptation on resilience with respect to other customary approaches, such as embedded code-based adaptation. In this paper, we report on an empirical study about the impact on resilience of incorporating architecture-based self-adaptation in an industrial middle- ware used to collect data in highly populated networks of devices. To this end, we compare the results of resilience evaluation between the original version of the middleware, in which adaptation mechanisms are embedded at the code- level, and a modified version of that middleware in which the adaptation mechanisms are implemented using Rainbow, a framework for architecture-based self-adaptation. Our results show improved levels of resilience in architecture-based compared to embedded code-based self-adaptation. Copyright © 2014 ACM 978-1-4503-2577-6/14/06 ...$15.00.;Association for Computing Machineryacmhelpacm.org;Conference Proceeding;QoSA 2014 - Proceedings of the 10th International ACM SIGSOFT Conference on Quality of Software Architectures (Part of CompArch 2014);2014-01-01;https://api.elsevier.com/content/abstract/scopus_id/84904463526
173;Assistance system for the automated composition and configuration of a co-simulation;Simulation plays an essential role in modular mechanical and plant engineering. The required models are, like the real modules, provided by different manufacturers or company divisions. Especially with regards to virtual commissioning, but also in operation-parallel simulation, numerous module models from different sources must be gathered, coupled, and kept up-to-date. This paper presents a concept for reducing the associated manual activities based on an agent-based assistance system. The aim is to generate, configure and operate simulation models with the least possible effort. In this paper, the focus is on supporting the commissioning phase.;EUROSIS;Conference Proceeding;Modelling and Simulation 2020 - The European Simulation and Modelling Conference, ESM 2020;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85096781081
174;Automatic assembly planning based on digital product descriptions;This paper proposes a new concept in which a digital twin derived from a digital product description will automatically perform assembly planning and orchestrate the production resources in a manufacturing cell. Thus the manufacturing cell has generic services with minimal assumptions about what kind of product will be assembled, while the digital product description is designed collaboratively between the designer at an OEM and automated services at potential manufacturers. This has several advantages. Firstly, the resulting versatile manufacturing facility can handle a broad variety of products with minimal or no reconfiguration effort, so it can cost-effectively offer its services to a large number of OEMs. Secondly, a solution is presented to the problem of performing concurrent product design and assembly planning over the organizational boundary. Thirdly, the product design at the OEM is not constrained to the capabilities of specific manufacturing facilities. The concept is presented in general terms in UML and an implementation is provided in a 3D simulation environment using Automation Markup Language for digital product descriptions. Finally, two case studies are presented and applications in a real industrial context are discussed.;Elsevier B.V.;Journal;Computers in Industry;2018-05-01;https://api.elsevier.com/content/abstract/scopus_id/85041407539
175;Automatic Reverse Engineering of Interaction Models from System Logs;Nowadays, software-as well as hardware systems produce log files that enable a continuous monitoring of the system during its execution. Unfortunately, such text-based log traces are very long and difficult to read, and therefore, reasoning and analyzing runtime behavior is not straightforward. However, dealing with log traces is especially needed in cases, where (i) the execution of the system did not perform as intended, (ii) the process flow is unknown because there are no records, and/or (iii) the design models do not correspond to its real-world counterpart. These facts cause that log data has to be prepared in a more user-friendly way (e.g., in form of graphical representations) and algorithms are needed for automatically monitoring the system's operation, and for tracking the system components interaction patterns. For this purpose we present an approach for transforming raw sensor data logs to a UML or SysML sequence diagram in order to provide a graphical representation for tracking log traces in a time-ordered manner. Based on this sequence diagram, we automatically identify interaction models in order to analyze the runtime behavior of system components. We implement this approach as prototypical plug-in in the modeling tool Enterprise Architect and evaluate it by an example of a self-driving car.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;IEEE International Conference on Emerging Technologies and Factory Automation, ETFA;2019-09-01;https://api.elsevier.com/content/abstract/scopus_id/85074212135
176;Automatic Tolerance Analysis of Permanent Magnet Machines with Encapsuled FEM Models Using Digital-Twin-Distiller;Tolerance analysis is crucial in every manufacturing process, such as electrical machine design, because tight tolerances lead to high manufacturing costs. A FEM-based solution of the tolerance analysis of an electrical machine can easily lead to a computationally expensive problem. Many papers have proposed the design of experiments, surrogate-model-based methodologies, to reduce the computational demand of this problem. However, these papers did not focus on the information loss and the limitations of the applied methodologies. Regardless, the absolute value of the calculated tolerance and the numerical error of the applied numerical methods can be in the same order of magnitude. In this paper, the tolerance and the sensitivity of BLDC machines’ cogging torque are analysed using different methodologies. The results show that the manufacturing tolerances can have a significant effect on the calculated parameters, and that the mean value of the calculated cogging torque increases. The design of the experiment-based methodologies significantly reduced the calculation time, and shows that the encapsulated FEM model can be invoked from an external system-level optimization to examine the design from different aspects.;MDPI;Journal;Processes;2021-11-01;https://api.elsevier.com/content/abstract/scopus_id/85122032099
177;Block-based versus flow-based programming for naive programmers;There is wide consensus that most people should have some programming capability, whether to control the Internet of Things, or to analyse the world of data around them. While some people focus on teaching conventional text-based languages like Javascript or Python, there is evidence that visual programming languages are more accessible for naive programmers. Visual programming languages fall into two broad categories: block-based, imperative programming, or flow-based, functional programming. However there have not been empirical studies to evaluate the relative merits of the two categories. This paper describes a study of hundreds of random people via Amazon Mechanical Turk attempting to program some simple problems in one or the other of two environments designed to be as similar as possible, except for the choice of paradigm.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2017 IEEE Blocks and Beyond Workshop, B and B 2017;2017-11-27;https://api.elsevier.com/content/abstract/scopus_id/85048290286
178;Predicting compressive strength of eco-friendly plastic sand paver blocks using gene expression and artificial intelligence programming;Plastic sand paver blocks provide a sustainable alternative by using plastic waste and reducing the need for cement. This innovative approach leads to a more sustainable construction sector by promoting environmental preservation. No model or Equation has been devised that can predict the compressive strength of these blocks. This study utilized gene expression programming (GEP) and multi-expression programming (MEP) to develop empirical models to forecast the compressive strength of plastic sand paver blocks (PSPB) comprised of plastic, sand, and fibre in an effort to advance the field. The database contains 135 results for compressive strength with seven input parameters. The R2 values of 0.87 for GEP and 0.91 for MEP for compressive strength reveal a relatively significant relationship between predicted and actual values. MEP outperformed GEP by displaying a higher R2 and lower values for statistical evaluations. In addition, a sensitivity analysis was conducted, which revealed that the sand grain size and percentage of fibres play an essential part in compressive strength. It was estimated that they contributed almost 50% of the total. The outcomes of this research have the potential to promote the reuse of PSPB in the building of green environments, hence boosting environmental protection and economic advantage.;Nature Research;Journal;Scientific Reports;2023-12-01;https://api.elsevier.com/content/abstract/scopus_id/85165920988
179;Bonita BPM: An open-source BPM-based application development platform to build adaptable business applications;"Companies today need business applications that can support continuous change in business environments and in technical/IS environments. The innovative technology of the recently released, open source Bonita BPM version 7 offers developers a new way to develop process-based applications that permits adaptability after deployment. By decoupling the user interface, business logic, and business data, this BPM-based application platform enables application developers to modify live applications ""on the fly."" This demo shows application development using Bonita BPM 7 Studio to model business logic in BPMN 2.0, and the UI Designer based on AngularJS to independently create the end user interfaces. The demo will cover how user interface can be changed in a live, deployed application. This demo is of particular interest to developers who are responsible for business application development, to business analysts who want flexible, userfriendly business applications, and to researchers who need flexible redeployment cycles allowing changes to be made and tested over time.";CEUR-WS;Conference Proceeding;CEUR Workshop Proceedings;2015-01-01;https://api.elsevier.com/content/abstract/scopus_id/84940426369
180;Building blocks for a digital twin of additive manufacturing;Properties and serviceability of additively manufactured components are affected by their geometry, microstructure and defects. These important attributes are now optimized by trial and error because the essential process variables cannot currently be selected from scientific principles. A recourse is to build and rigorously validate a digital twin of the additive manufacturing process that can provide accurate predictions of the spatial and temporal variations of metallurgical parameters that affect the structure and properties of components. Key building blocks of a computationally efficient first-generation digital twin of laser-based directed energy deposition additive manufacturing utilize a transient, three-dimensional model that calculates temperature and velocity fields, cooling rates, solidification parameters and deposit geometry. The measured profiles of stainless steel 316L and Alloy 800H deposits as well as the secondary dendrite arm spacing (SDAS) and Vickers hardness measurements are used to validate the proposed digital twin. The predicted cooling rates, temperature gradients, solidification rates, SDAS and micro-hardness values are shown to be more accurate than those obtained from a commonly used heat conduction calculation. These metallurgical building blocks serve as a phenomenological framework for the development of a digital twin that will make the expanding knowledge base of additive manufacturing usable in a practical way for all scientists and engineers.;Acta Materialia Incactachair@actamaterialia.org;Journal;Acta Materialia;2017-08-15;https://api.elsevier.com/content/abstract/scopus_id/85021415524
181;C2PS: A digital twin architecture reference model for the cloud-based cyber-physical systems;Cyber-physical system (CPS) is a new trend in the Internet-of-Things related research works, where physical systems act as the sensors to collect real-world information and communicate them to the computation modules (i.e. cyber layer), which further analyze and notify the findings to the corresponding physical systems through a feedback loop. Contemporary researchers recommend integrating cloud technologies in the CPS cyber layer to ensure the scalability of storage, computation, and cross domain communication capabilities. Though there exist a few descriptive models of the cloud-based CPS architecture, it is important to analytically describe the key CPS properties: computation, control, and communication. In this paper, we present a digital twin architecture reference model for the cloud-based CPS, C2PS, where we analytically describe the key properties of the C2PS. The model helps in identifying various degrees of basic and hybrid computation-interaction modes in this paradigm. We have designed C2PS smart interaction controller using a Bayesian belief network, so that the system dynamically considers current contexts. The composition of fuzzy rule base with the Bayes network further enables the system with reconfiguration capability. We also describe analytically, how C2PS subsystem communications can generate even more complex system-of-systems. Later, we present a telematics-based prototype driving assistance application for the vehicular domain of C2PS, VCPS, to demonstrate the efficacy of the architecture reference model.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/85015767302
182;C2PS: A digital twin architecture reference model for the cloud-based cyber-physical systems;Cyber-physical system (CPS) is a new trend in the Internet-of-Things related research works, where physical systems act as the sensors to collect real-world information and communicate them to the computation modules (i.e. cyber layer), which further analyze and notify the findings to the corresponding physical systems through a feedback loop. Contemporary researchers recommend integrating cloud technologies in the CPS cyber layer to ensure the scalability of storage, computation, and cross domain communication capabilities. Though there exist a few descriptive models of the cloud-based CPS architecture, it is important to analytically describe the key CPS properties: computation, control, and communication. In this paper, we present a digital twin architecture reference model for the cloud-based CPS, C2PS, where we analytically describe the key properties of the C2PS. The model helps in identifying various degrees of basic and hybrid computation-interaction modes in this paradigm. We have designed C2PS smart interaction controller using a Bayesian belief network, so that the system dynamically considers current contexts. The composition of fuzzy rule base with the Bayes network further enables the system with reconfiguration capability. We also describe analytically, how C2PS subsystem communications can generate even more complex system-of-systems. Later, we present a telematics-based prototype driving assistance application for the vehicular domain of C2PS, VCPS, to demonstrate the efficacy of the architecture reference model.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/85015767302
183;Capability matchmaking software for rapid production system design and reconfiguration planning;Traditionally, the production system design and reconfiguration planning are manual processes, which rely heavily on the designers' expertise and tacit knowledge to find feasible system configuration solutions. Rapid responsiveness of future production systems calls for new computer-aided intelligent design and planning solutions, that would reduce the time and effort put into system design, both in brownfield and greenfield scenarios. This paper describes the implementation of a capability matchmaking software, which automatizes the matchmaking between product requirements and resource capabilities. The interaction of the matchmaking system with external design and planning tools is explained and illustrated with a case example. The matchmaking approach supports production system design and reconfiguration planning by providing automatic means for checking if the existing system already fulfills the new product requirements, and for finding alternative resources and resource combinations to specific product requirements from large search spaces, e.g. from global resource catalogues.;Elsevier B.V.;Conference Proceeding;Procedia CIRP;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85100851587
184;Chatbots as assistants: An architectural framework;Automated text-based or speech-based personal assistants, also known as chatbots, have been prevalent in several domains including marketing and technical support. Through mainstream applications, such as Siri or Alexa, their popularity has increased and we now see them being used in even more domains. Although the purpose of chatbots varies among domains, there are common elements that all chatbots share. By identifying these elements, it is possible to streamline the development of chatbots en masse and in a structured manner. Additionally, there can be common challenges in the development of such applications, for example, how to treat novice versus expert users or how to establish memory of the conversation. In this work, we propose a reference architecture for chatbots using concepts from Software Product Lines and Feature Models, where we outline the common elements as well as the common challenges. Using Watson and Bluemix as the basic platforms, we also present the creation of two chatbots, for different purposes, based on this reference architecture to highlight these commonalities.;IBM / ACM;Conference Proceeding;Proceedings of the 27th Annual International Conference on Computer Science and Software Engineering, CASCON 2017;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85091338262
185;Closing the gap between designers and developers in a low code ecosystem;Nowadays, going digital is a must for a company to thrive and remain competitive. The digital transformation allows companies to react timely and adequately to the constantly evolving markets. This transformation is not without challenges. Among these is the growing demand for skilled software developers. Low-code platforms have risen to mitigate this pressure point by allowing people with non-programming backgrounds to craft digital systems capable of solving business relevant problems. Professional development teams are composed of many different profiles - product owners, analysts, UX and UI designers, front-end and back-end developers, among others. Market competition puts unprecedented demands on the collaboration of these professionals. Current methodologies provide tools and approaches for many of these types of collaboration. However, the reality of established industry practices for UX and UI designers collaborating with front-end developers, still leaves a lot to improve in terms of effectiveness and efficiency. This work developed an innovative approach using model transformation and meta-modelling techniques that drastically improves the efficiency of transforming UX/UI design artefacts into low-code web-technology. The approach has been applied to a recognized and established enterprise-grade low-code platform and evaluated in practice by a team of professional designers and front-end developers. Preliminary practical results show savings between 20 and 75% according to the project complexity in the effort invested by development teams in the above mentioned process.;Association for Computing Machinery, Inc;Conference Proceeding;Proceedings - 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS-C 2020 - Companion Proceedings;2020-10-16;https://api.elsevier.com/content/abstract/scopus_id/85096772345
186;Closing the gap between designers and developers in a low code ecosystem;Nowadays, going digital is a must for a company to thrive and remain competitive. The digital transformation allows companies to react timely and adequately to the constantly evolving markets. This transformation is not without challenges. Among these is the growing demand for skilled software developers. Low-code platforms have risen to mitigate this pressure point by allowing people with non-programming backgrounds to craft digital systems capable of solving business relevant problems. Professional development teams are composed of many different profiles - product owners, analysts, UX and UI designers, front-end and back-end developers, among others. Market competition puts unprecedented demands on the collaboration of these professionals. Current methodologies provide tools and approaches for many of these types of collaboration. However, the reality of established industry practices for UX and UI designers collaborating with front-end developers, still leaves a lot to improve in terms of effectiveness and efficiency. This work developed an innovative approach using model transformation and meta-modelling techniques that drastically improves the efficiency of transforming UX/UI design artefacts into low-code web-technology. The approach has been applied to a recognized and established enterprise-grade low-code platform and evaluated in practice by a team of professional designers and front-end developers. Preliminary practical results show savings between 20 and 75% according to the project complexity in the effort invested by development teams in the above mentioned process.;Association for Computing Machinery, Inc;Conference Proceeding;Proceedings - 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS-C 2020 - Companion Proceedings;2020-10-16;https://api.elsevier.com/content/abstract/scopus_id/85096772345
187;Collaborative model-driven software engineering: A classification framework and a research map;"Context: Collaborative Model-Driven Software Engineering (MDSE) consists of methods and techniques where multiple stakeholders manage, collaborate, and are aware of each others' work on shared models. Objective: Collaborative MDSE is attracting research efforts from different areas, resulting in a variegated scientific body of knowledge. This study aims at identifying, classifying, and understanding existing collaborative MDSE approaches. Method: We designed and conducted a systematic mapping study. Starting from over 3,000 potentially relevant studies, we applied a rigorous selection procedure resulting in 106 selected papers, further clustered into 48 primary studies along a time span of 19 years. We rigorously defined and applied a classification framework and extracted key information from each selected study for subsequent analysis. Results: Our analysis revealed the following main fidings: (i) there is a growing scientific interest on collaborative MDSE in the last years; (ii) multi-view modeling, validation support, reuse, and branching are more rarely covered with respect to other aspects about collaborative MDSE; (iii) different primary studies focus differently on individual dimensions of collaborative MDSE (i.e., model management, collaboration, and communication); (iv) most approaches are language-specific, with a prominence of UML-based approaches; (v) few approaches support the interplay between synchronous and asynchronous collaboration. Conclusion: This study gives a solid foundation for classifying existing and future approaches for collaborative MDSE. Researchers and practitioners can use our results for identifying existing research/technical gaps to attack, better scoping their own contributions, or understanding existing ones.";Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Transactions on Software Engineering;2018-12-01;https://api.elsevier.com/content/abstract/scopus_id/85030632465
188;Complex system governance: Theory to practice challenges for system of systems engineering;This paper explores challenges in moving Complex System Governance (CSG) from the theoretical/conceptual formulation to practice. CSG is an emerging field with potential to complement and extend System of Systems Engineering (SoSE). We begin with a brief introduction to CSG and the nature of the problem domain of interest for this field. Next, the nature of the CSG field is developed in light of SoSE. Focus is then turned to the spectrum of challenges faced for deployment of CSG. Finally, a path forward to addressing these challenges is explored. The paper concludes with several contributions that CSG can offer to SoSE in the struggle to deal with increasingly complex systems and their associated problems.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2015 10th System of Systems Engineering Conference, SoSE 2015;2015-07-07;https://api.elsevier.com/content/abstract/scopus_id/84941130244
189;Comprehensible and dependable self-learning self-adaptive systems;Self-adaptivity enables flexible solutions in dynamically changing environments. However, due to the increasing complexity, uncertainty, and topology changes in cyber-physical systems (CPS), static adaptation mechanisms are insufficient as they do not always achieve appropriate effects. Furthermore, CPS are used in safety-critical domains, which requires them and their autonomous adaptations to be dependable. To overcome these problems, we extend the MAPE-K feedback loop architecture by imposing a structure and requirements on the knowledge base and by introducing a meta-adaptation layer. This enables us to continuously evaluate the accuracy of previous adaptations, learn new adaptation rules based on executable run-time models, and verify the correctness of the adaptation logic in the current system context. We demonstrate the effectiveness of our approach using a temperature control system. With our framework, we enable the design of comprehensible and dependable dynamically evolving adaptation logics.;Elsevier B.V.;Journal;Journal of Systems Architecture;2018-05-01;https://api.elsevier.com/content/abstract/scopus_id/85049321228
190;Conceptualizing Digital Twins;Properly arranging models, data sources, and their relations to engineer digital twins is challenging. We propose a conceptual modeling framework for digital twins that captures the combined usage of heterogeneous models and their respective evolving data for the twinâs entire lifecycle.;IEEE Computer Society;Journal;IEEE Software;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85120045327
191;Conceptualizing Digital Twins;Properly arranging models, data sources, and their relations to engineer digital twins is challenging. We propose a conceptual modeling framework for digital twins that captures the combined usage of heterogeneous models and their respective evolving data for the twinâs entire lifecycle.;IEEE Computer Society;Journal;IEEE Software;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85120045327
192;Continuous transition from model-driven prototype to full-size real-world enterprise information systems;This paper presents our approach to create an executable prototype of an enterprise information system based only on a data structure model. This prototype, which is still easily adaptable and extendable, can be used for analysis exploration and builds a solid foundation for the final system. The presented approach transforms a data structure model to changeable and extendable graphical user interface models. In a second step, the data structure model and the GUI models are used to generate the resulting system. This approach allows the developer to generate (a) persistence, (b) basic application logic, (c) transportation layers, and (d) a variety of possible graphical representations for the prototype based only on a data structure model. Extensions and changes of the GUI are still possible on model and code level. This is possible by synthetization of GUI models and change operations defined in the same domain-specific language.;Association for Information Systems;Conference Proceeding;26th Americas Conference on Information Systems, AMCIS 2020;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85096970269
193;Continuously analyzing finite, message-driven, time-synchronous component & connector systems during architecture evolution;Understanding the semantic differences of continuously evolving system architectures by semantic analyses facilitates engineers during evolution analysis in understanding the impact of the syntactical changes between two architecture versions. To enable effective semantic differencing usable in practice, this requires means to fully automatically check whether one version of a system admits behaviors that are not possible in another version. Previous work produced very general system models for message-driven time-synchronous (MDTS) systems that impede fully automated semantic differencing but very adequately describe such systems from a black-box viewpoint abstracting from hidden internal component behavior. This paper presents a system model for MDTS systems from a white-box viewpoint (assuming component implementation availability) and presents a sound and complete method for semantic differencing of finite MDTS system architectures. This method relies on representing (sub-)architectures as channel automata and a reduction from the semantic differencing problem for such automata to the language inclusion problem for Büchi automata. The system model perfectly captures the logical basics of MDTS systems from a white-box viewpoint and the method enables to fully automatically calculate semantic differences between two finite MDTS systems on push-button basis, yields witnesses, and ultimately facilitates semantic evolution analysis of such systems.;Elsevier Inc.usjcs@elsevier.com;Journal;Journal of Systems and Software;2019-03-01;https://api.elsevier.com/content/abstract/scopus_id/85058783827
194;Coupling heterogeneous production systems by a multi-agent based cyber-physical production system;Todays increasing volatility of market demands and customer requirements are forcing industrial enterprises to realize and ensure an increased flexibility of production systems. Since current automation concepts and architectures for production systems do not provide the required flexibility sufficiently, new approaches have to be developed. This paper proposes an approach that implements the quickly evolving concept of Cyber-Physical Systems for the special case of production systems by means of software agents. A joined demonstrator of such Cyber-Physical Production System is described and used for the evaluation of the proposed multi-agent approach.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2014 12th IEEE International Conference on Industrial Informatics, INDIN 2014;2014-11-03;https://api.elsevier.com/content/abstract/scopus_id/84914127107
195;Design Space Exploration for Distributed Cyber-Physical Systems: State-of-the-art, Challenges, and Directions;Industrial Cyber-Physical Systems (CPS) are com-plex heterogeneous and distributed computing systems, typically integrating and interconnecting a large number of subsystems and containing a substantial number of hardware and software components. Producers of these distributed Cyber-Physical Systems (dCPS) face serious challenges with respect to designing the next generations of these machines and require proper support in making (early) design decisions to avoid expensive and time consuming oversights. This calls for efficient and scalable system-level Design Space Exploration (DSE) methods for dCPS. In this position paper, we review the current state of the art in DSE, and argue that efficient and scalable DSE technology for dCPS is more or less non-existing and constitutes a largely unchartered research area. Moreover, we identify several re-search challenges that need to be addressed and discuss possible directions for targeting such DSE technolozy for dCPS.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2022 25th Euromicro Conference on Digital System Design, DSD 2022;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85146654310
196;Cyber-physical production systems: Roots, expectations and R&D challenges;One of the most significant directions in the development of computer science and information and communication technologies is represented by Cyber-Physical Systems (CPSs) which are systems of collaborating computational entities which are in intensive connection with the surrounding physical world and its on-going processes, providing and using, at the same time, data-Accessing and data-processing services available on the internet. Cyber-Physical Production Systems (CPPSs), relying on the newest and foreseeable further developments of computer science, information and communication technologies on the one hand, and of manufacturing science and technology, on the other, may lead to the 4th Industrial Revolution, frequently noted as Industry 4.0. The key-note will underline that there are significant roots generally -And particularly in the CIRP community -which point towards CPPSs. Expectations and the related new R&D challenges will be outlined. © 2014 Elsevier B.V. This is an open access article under the CC BY-NC-ND license.;Elsevier B.V.;Conference Proceeding;Procedia CIRP;2014-01-01;https://api.elsevier.com/content/abstract/scopus_id/84904510850
197;Integrating the manufacturer usage description standard in the modelling of cyber–physical systems;The continuous growth of cyber–physical systems (CPS) attacks, especially due to the conflict in Ukraine, has highlighted the need for cybersecurity management mechanisms, due to the catastrophic consequences that a failure or attack on critical infrastructures such as power plants. Indeed, Gartner predicts that by 2025, 30% of critical infrastructures will suffer a cyberattack. In this context, defining the expected behaviour of the system is key to detecting and mitigating possible vulnerabilities both in the design and runtime phases. Modelling emerges as a tool that facilitates the analysis of the security offered by the system even before the system is implemented, allowing an early risk analysis. However, creating such a model is usually challenging due to its intrinsic complexity, or the reconfiguration needed after a security assessment due to a new vulnerability. The situation gets even worse when the system is a complex CPS-of-Systems, where different Constituent Systems (CS) are interconnected since cascade effects and dependencies are stronger and we might not have all the information from the third-party CS. Also, the results of the evaluation are typically used only during the design phase, thus missing out on potential security policies and mitigations that could be used during the system operation. In this sense, the Manufacturer Usage Description (MUD) allows the manufacturer to define access control policies that reduce the attack surface of a device. However, the limited expressiveness of this standard reduces the possibilities of its application in systems with more complex policies beyond the network level. We propose the usage of the MUD standard as a source of information for CPS modelling, providing information on interactions about third-party components of the system. In addition, we define an extended MUD model that deals with the expressiveness problems of the MUD and allows to automatically generate a behavioural profile that integrates the recommendations obtained from the assessment and modelling processes. The extended MUD could be used during runtime to reduce the attack surface of the system, enforce security configuration or even discern if a component is secure enough to be part of the ecosystem. Our approach has been validated in a real use case in the context of smart grid, to show its applicability.;Elsevier B.V.;Journal;Computer Standards and Interfaces;2024-01-01;https://api.elsevier.com/content/abstract/scopus_id/85166306008
198;Data transformation of UML diagram by using model driven architecture;When dealing with the quality of software system there are many Complex issues and challenges established, Such complex issue appears due to uncleared, ambiguous, and non-compete of functional as well as non-functional requirements during the requirement gathering process. This MDA is well known and used by Object Management Group(OMG) which raises abstraction level. The work has been done on model-based development which is very helpful to reduce the efforts and time and also achieve pure and error-free code. This paper describes the use of Model Driven architecture in web application area, to reduce the web application system problem. The model-driven web engineering facilitates to develop the web application using models to explain web site in different detail level. The existing web developments strategy can be polished by using MDA process. This paper discusses the basic concepts and presents the software development strategy based on MDA. Our focus is on code generation by using models. We take the scenario of Multi-Level marketing in order to design the UML diagram of Multi-level marketing for code generation. We have successfully received our desired code by Using ANDROMDA source code generator supported by MDA.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2018 3rd IEEE International Conference on Cloud Computing and Big Data Analysis, ICCCBDA 2018;2018-06-14;https://api.elsevier.com/content/abstract/scopus_id/85050069812
199;Data-centric middleware based digital twin platform for dependable cyber-physical systems;The concept of digital twin, a kind of virtual things with the precise states of the corresponding physical systems, is suggested by industrial domains to accurately estimate the status and predict the operation of machines. Digital twin can be used for development of critical systems, such as self-driving cars and auto-production factories. There, however, will be so different digital twins in terms of resolution, complexity, modelling languages and formats. It is required to cooperate heterogeneous digital twins in standardized ways. Since a centralized digital twin system uses too big resources and energies, it is preferable to make large-scale digital twin system geographically and logically distributed over the Internet. In addition, efficient interworking functions between digital twins and the physical systems are required also. In this paper, we propose a novel architecture of large-scale digital twin platform including distributed digital twin cooperation framework, flexible data-centric communication middleware, and the platform based digital twin application to develop a reliable advanced driver assistance system.;IEEE Computer Societyhelp@computer.org;Conference Proceeding;International Conference on Ubiquitous and Future Networks, ICUFN;2017-07-26;https://api.elsevier.com/content/abstract/scopus_id/85028079218
200;Defining a Digital Twin-based Cyber-Physical Production System for autonomous manufacturing in smart shop floors;Smart manufacturing is the core idea of the fourth industrial evolution. For a smart manufacturing shop floor, real-time monitoring, simulation and prediction of manufacturing operations are vital to improve the production efficiency and flexibility. In this paper, the Cyber-Physical System (CPS) and Digital Twin technologies are introduced to build the interconnection and interoperability of a physical shop floor and corresponding cybershop floor. A Digital Twin-based Cyber-Physical Production System (DT-CPPS) is further established, and the configuring mechanism, operating mechanism and real-time data-driven operations control of DT-CPPS are discussed in detail. It is expected that DT-CPPS will provide the basis for shop floors to march towards smart manufacturing.;Taylor and Francis Ltd.michael.wagreich@univie.ac.at;Journal;International Journal of Production Research;2019-10-18;https://api.elsevier.com/content/abstract/scopus_id/85060183300
201;Definition of modeling vs. programming languages;Modeling languages (like UML and SysML) are those used in model-based specification of software-intensive systems. Like programming languages, they are defined using their syntax and semantics. However, both kinds of languages are defined by different communities, and in response to different requirements, which makes their methodologies and tools different. In this paper, we highlight the main differences between the definition methodologies of modeling and programming languages. We also discuss the impact of these differences on language tool support. We illustrate our ideas using examples from known programming and modeling languages. We also present a case study, where we analyze the definition of a new modeling language called the Ontology Modeling Language (OML). We highlight the requirements that have driven OML definition and explain how they are different from those driving typical programming languages. Finally, we discuss how these differences are being abstracted away using new language definition tools.;Springer Verlagservice@springer.de;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85056487138
202;Design of a Hybrid Digital-Twin Flight Performance Model Through Machine Learning;This study implements deep learning techniques to estimate fuel burn of a jet aircraft. Current ground-based flight planning systems utilize aircraft type specific performance tables to determine fuel flows for given flight conditions and parameters such as altitude, mass and speed. These tables are corrected by a performance factor as the aircraft ages. Despite this update, planned fuel consumption may indeed not overlap with the actual one. In order to synchronize the base aircraft model with aircraft's actual performance, we propose using state-of-the-art deep learning algorithms for building data-driven models of fuel flows. Towards this goal, aircraft's on-board recorded trajectory and parameter data, namely Quick Access Recorder (QAR) data are utilized. The total dataset used within this study comprises of more than 1000 B777-300ER flights from a major European flag carrier airline. The deep neural network architecture is utilized for modeling the actual fuel flow specific to each aircraft and for each major flight mode (climb, cruise and descent namely). We have developed three neural network architectures (according to in-flight and ground based planning use cases) to present a tail-number specific correction factor to Base of Aircraft Data (BADA) models. First architecture involves a QAR data based black-box fuel flow model utilizing in-flight throttle data from all the engines. Comparison of this model with real flight data shows that precise estimation of fuel flow with mean errors lower than %0.1 can be achieved. The second architecture utilizes a physically consistent data regeneration of \delta-{T} (delta thrust) using BADA formulation as to account for the ground planning phase where throttle information is not available. The third model involves a cascaded architecture which utilizes a neural network throttle estimator and the black-box QAR fuel flow model for again the ground planning phase. Comparison of the latter models with real flight data shows that precise estimation of fuel flow with mean absolute errors lower than %0.7 can be achieved at all the flight modes. Initial tests reflect the fact that even better accuracy can be achieved for all models as the data set size increases. Finally, ground based planning fuel flow models are applied to actual flight plans generated by ground based systems. Total trip fuel comparisons show discrepancies up to %3.5 total fuel loading weight, which may result in potential fuel savings by decreasing the fuel load during take-off. Comparison of the planned and the estimated fuel boarding weights (following the actual filed flight plans) for 91 long-haul flights show that fuel burn savings of around 800 [k g] per flight could have been achieved by the proposed methodology at the ground planning phase. For a typical operation of 100 long-haul flights per day, this represents yearly savings on the order of around 17 million USD at current jet fuel prices. This 'tail-number specific' performance modeling approach is projected to open considerable frontiers including the in-flight update of performance models through machine learning methods.;IEEE Computer Societyhelp@computer.org;Conference Proceeding;IEEE Aerospace Conference Proceedings;2019-03-01;https://api.elsevier.com/content/abstract/scopus_id/85068350610
203;Self-reporting Limitations in Information Systems Design Science Research: Typology and Guidelines;Besides increasing transparency and demonstrating awareness of the author, self-reported limitations enable other researchers to effectively learn from, build on, validate, and extend the original work. However, this topic is understudied in information systems design science research (IS DSR). The study has assessed 243 IS DSR papers published in the period 2013–2022 and built a typology of the 19 most relevant limitations, organized into four categories: (1) Input Knowledge and Technology, (2) Research Process, (3) Resulting Artifact, and (4) Design Knowledge. Further, the contribution suggests actions to mitigate each type of limitation throughout the entire IS DSR project lifecycle. The authors have also created guidelines to report the limitations in a useful way for knowledge accumulation. The proposed typology and guidelines enable reviewers and editors to better frame self-reported limitations, assess rigor and relevance more systematically, and provide more precise feedback. Moreover, the contribution may help design researchers identify, mitigate, and effectively communicate the uncertainties inherent to all scientific advances.;Springer Gabler;Journal;Business and Information Systems Engineering;2023-04-01;https://api.elsevier.com/content/abstract/scopus_id/85143337521
204;Designing a resilient deployment and reconfiguration infrastructure for remotely managed cyber-physical systems;Multi-module Cyber-Physical Systems (CPS), such as satellite clusters, swarms of Unmanned Aerial Vehicles (UAV), and fleets of Unmanned Underwater Vehicles (UUV) provide a CPS cluster-asa- service for CPS applications. The distributed and remote nature of these systems often necessitates the use of Deployment and Configuration (D&C) services to manage the lifecycle of these applications. Fluctuating resources, volatile cluster membership and changing environmental conditions necessitate resilience. Thus, the D&C infrastructure does not only have to undertake basic management actions, such as activation of new applications and deactivation of existing applications, but also has to autonomously reconfigure existing applications to mitigate failures including D&C infrastructure failures. This paper describes the design and architectural considerations to realize such a D&C infrastructure for component-based distributed systems. Experimental results demonstrating the autonomous resilience capabilities are presented.;Springer Verlagservice@springer.de;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2016-01-01;https://api.elsevier.com/content/abstract/scopus_id/84992709147
205;DevOpsML: Towards modeling DevOps processes and platforms;DevOps and Model Driven Engineering (MDE) provide differently skilled IT stakeholders with methodologies and tools for organizing and automating continuous software engineering activities-from development to operations, and using models as key engineering artifacts, respectively. Both DevOps and MDE aim at shortening the development life-cycle, dealing with complexity, and improve software process and product quality. The integration of DevOps and MDE principles and practices in low-code engineering platforms (LCEP) are gaining attention by the research community. However, at the same time, new requirements are upcoming for DevOps and MDE as LCEPs are often used by non-technical users, to deliver fully functional software. This is in particular challenging for current DevOps processes, which are mostly considered on the technological level, and thus, excluding most of the current LCEP users. The systematic use of models and modeling to lowering the learning curve of DevOps processes and platforms seems beneficial to make them also accessible for non-technical users. In this paper, we introduce DevOpsML, a conceptual framework for modeling and combining DevOps processes and platforms. Tools along with their interfaces and capabilities are the building blocks of DevOps platform configurations, which can be mapped to software engineering processes of arbitrary complexity. We show our initial endeavors on DevOpsML and present a research roadmap how to employ the resulting DevOpsML framework for different use cases.;Association for Computing Machinery, Inc;Conference Proceeding;Proceedings - 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS-C 2020 - Companion Proceedings;2020-10-16;https://api.elsevier.com/content/abstract/scopus_id/85096806448
206;Digital behavioral twins for safe connected cars;Driving is a social activity which involves endless interactions with other agents on the road. Failing to locate these agents and predict their possible future actions may result in serious safety hazards. Traditionally, the responsibility for avoiding these safety hazards is solely on the drivers. With improved sensor quantity and quality, modern ADAS systems are able to accurately perceive the location and speed of other nearby vehicles and warn the driver about potential safety hazards. However, accurately predicting the behavior of a driver remains a challenging problem. In this paper, we propose a framework in which behavioral models of drivers (Digital Behavioral Twins) are shared among connected cars to predict potential future actions of neighboring vehicles, therefore improving the safety of driving. We provide mathematical formulations of models of driver behavior and the environment, and discuss challenging problems during model construction and risk analysis. We also demonstrate that our digital twins framework can accurately predict driver behaviors and effectively prevent collisions using a case study in a virtual driving simulation environment.;Association for Computing Machinery, Incacmhelp@acm.org;Conference Proceeding;Proceedings - 21st ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS 2018;2018-10-14;https://api.elsevier.com/content/abstract/scopus_id/85056832496
207;Digital Twin and Big Data Towards Smart Manufacturing and Industry 4.0: 360 Degree Comparison;With the advances in new-generation information technologies, especially big data and digital twin, smart manufacturing is becoming the focus of global manufacturing transformation and upgrading. Intelligence comes from data. Integrated analysis for the manufacturing big data is beneficial to all aspects of manufacturing. Besides, the digital twin paves a way for the cyber-physical integration of manufacturing, which is an important bottleneck to achieve smart manufacturing. In this paper, the big data and digital twin in manufacturing are reviewed, including their concept as well as their applications in product design, production planning, manufacturing, and predictive maintenance. On this basis, the similarities and differences between big data and digital twin are compared from the general and data perspectives. Since the big data and digital twin can be complementary, how they can be integrated to promote smart manufacturing are discussed.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2018-01-12;https://api.elsevier.com/content/abstract/scopus_id/85041173790
208;Digital twin based synchronised control and simulation of the industrial robotic cell using virtual reality;During the years common understanding of the possibilities and perspectives of Virtual Reality (VR) usage has been changed. It is thought that VR is mainly used in entertainment purposes, but it is being used already for many years in different industries, and now with easier access to the hardware it became a helpful and accessible tool that could be used and developed in any field of human activities. In manufacturing, immersive technologies are mainly used nowadays for the visualisation of processes and products combining those visuals into the factory Digital Twin (DT) which is possible to view from the inside look. This feature is already being used in several manufacturing simulation tools, which enable to view onto industrial line / robotic cells via Virtual Reality glasses. However, the potential of using simulations with VR in manufacturing is not fully uncovered. The main aim of this, industrial robotics targeted research is to enable besides simulation also universal control algorithms through Virtual Reality experience, produced by game engine Unity3D, which can be easily modified for a wide range of industrial equipment. The primary outcome of this work is the development of the synchro-nisation model of real and virtual industrial robots and experimental testing the developed model in Virtual Reality and shop floor labs.;Editorial Institution of Wrocaw Board of Scientificjerzy.jedrzejewski@pwr.edu.pl;Journal;Journal of Machine Engineering;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85064769107
209;Digital Twin Data Modeling with AutomationML and a Communication Methodology for Data Exchange;In the context of the Cyber Physical Systems toward the realization of a Digital Twin system for future manufacturing and product service systems we propose the use of AutomationML to model attributes related to the Digital Twin. Also, we propose that this model is very useful for data exchange between different systems that are connected with the Digital Twin. We present a case study where a industrial component was modeled and simulated to prove that our methodology works.;Elsevier B.V.;Conference Proceeding;IFAC-PapersOnLine;2016-01-01;https://api.elsevier.com/content/abstract/scopus_id/85006391498
210;Digital Twin Data Modeling with AutomationML and a Communication Methodology for Data Exchange;In the context of the Cyber Physical Systems toward the realization of a Digital Twin system for future manufacturing and product service systems we propose the use of AutomationML to model attributes related to the Digital Twin. Also, we propose that this model is very useful for data exchange between different systems that are connected with the Digital Twin. We present a case study where a industrial component was modeled and simulated to prove that our methodology works.;Elsevier B.V.;Conference Proceeding;IFAC-PapersOnLine;2016-01-01;https://api.elsevier.com/content/abstract/scopus_id/85006391498
211;Digital Twin Data Modeling with AutomationML and a Communication Methodology for Data Exchange;In the context of the Cyber Physical Systems toward the realization of a Digital Twin system for future manufacturing and product service systems we propose the use of AutomationML to model attributes related to the Digital Twin. Also, we propose that this model is very useful for data exchange between different systems that are connected with the Digital Twin. We present a case study where a industrial component was modeled and simulated to prove that our methodology works.;Elsevier B.V.;Conference Proceeding;IFAC-PapersOnLine;2016-01-01;https://api.elsevier.com/content/abstract/scopus_id/85006391498
212;Digital twin for energy optimization in an SMT-PCB assembly line;This paper presents a case study for the use of an IoT-driven digital twin for energy optimization in an automated Surface Mount Technology (SMT) PCB assembly line containing legacy machines. The line was instrumented with multiple sensors for measuring machine-wise activity and energy consumption. A software platform for data aggregation and a discrete-event digital twin of the line were built entirely using open-source tools. Based on the insights gained from data collected over several days, we propose a buffering-based solution for improving the energy efficiency of the line, and evaluate its impact using simulations of the digital twin. The results show that a 2.7x reduction in the energy consumption is possible via buffer insertion without significantly affecting line throughput.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2018 IEEE International Conference on Internet of Things and Intelligence System, IOTAIS 2018;2019-01-03;https://api.elsevier.com/content/abstract/scopus_id/85061704099
213;Digital twin for machining tool condition prediction;Digital twin introduces new opportunities for predictive maintenance of manufacturing machines which can consider the influence of working condition on cutting tool and contribute to the understanding and application of the predicted results. This paper presents a data-driven model for digital twin, together with a hybrid model prediction method based on deep learning that creates a prediction technique for enhanced machining tool condition prediction. First, a five-dimensional digital twin model is introduced that highlights the performance of the data analytics in model construction. Next, a deep learning technique, termed Deep Stacked GRU (DSGRU), is demonstrated that enables system identification and prediction. Experimental studies using vibration data measured on milling machine tool have shown the effectiveness of the presented digital twin model for tool wear prediction.;Elsevier B.V.;Conference Proceeding;Procedia CIRP;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85068465743
214;Digital Twin Data Handling for Propulsion Drive System of Autonomous Electric Vehicle: Case Study;Nowadays, data is not just a collection of static documents, but a continuous flow of information. Research projects are required not only to manage data efficiently but also to keep it safe to ensure that it can be later correctly interpreted and reused. The Data Management Plan (DMP) is a document that describes the data management life cycle for the data to be collected, processed and/or generated during the project workflow. The DMP is not a fixed but rather a living document that will evolve through the lifespan of the project. A general idea of the paper is to give a brief description of the data (including any existing data, data taken from third-party sources or produced data) that is used during the project lifetime. Special attention is paid on how the data is created and collected, how the data is organized during the project (naming conventions, version control, and folder structures). Moreover, the choice of format and implications of data format and data volumes in terms of storage, backup, and access is discussed.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2020 IEEE 61st Annual International Scientific Conference on Power and Electrical Engineering of Riga Technical University, RTUCON 2020 - Proceedings;2020-11-05;https://api.elsevier.com/content/abstract/scopus_id/85100007285
215;Knowledge map and forecast of digital twin in the construction industry: State-of-the-art review using scientometric analysis;"With the advancement of Industry 4.0 and the development of science and technology, industries have seen the advantages of digital twin (DT) implementations and concepts. Although the construction industry is still in the early stage of DT development and implementation, it is urgent for the industry to have a DT agenda. This paper identifies 1158 related bibliographic records from the Web of Science and 745 records from the Derwent Patent Database and quantitatively analyzed them to describe patterns of publications. Two knowledge mapping tools were selected to visualize and analyze the literature in the relevant scientific domain. Then, we integrated clustering, knowledge mapping, and network analysis methods to show the current foci and future directions of DT-MT derived from the data of time distribution, journal areas, and subject distribution. The results indicate that DT is a cross-disciplinary information technology with great development potential, and its development in the construction industry is scattered with the leading advancement in the manufacturing of construction materials and components. The derived knowledge map shows three stages of construction DT, including (1) data collection and creation of DT framework and database; (2) implementation of planning and design modules in detail and control of construction sites; and (3) carrying out asset management and fault prediction in the operation and maintenance phase of projects. The novelty of this paper is the specific analysis of DT in the construction industry. This study adds value to the architecture, engineering, and construction industries by shedding light on the focus of DT practical applications and the formation of a development path of construction DT.";Elsevier Ltd;Journal;Journal of Cleaner Production;2023-01-10;https://api.elsevier.com/content/abstract/scopus_id/85143719809
216;Knowledge map and forecast of digital twin in the construction industry: State-of-the-art review using scientometric analysis;"With the advancement of Industry 4.0 and the development of science and technology, industries have seen the advantages of digital twin (DT) implementations and concepts. Although the construction industry is still in the early stage of DT development and implementation, it is urgent for the industry to have a DT agenda. This paper identifies 1158 related bibliographic records from the Web of Science and 745 records from the Derwent Patent Database and quantitatively analyzed them to describe patterns of publications. Two knowledge mapping tools were selected to visualize and analyze the literature in the relevant scientific domain. Then, we integrated clustering, knowledge mapping, and network analysis methods to show the current foci and future directions of DT-MT derived from the data of time distribution, journal areas, and subject distribution. The results indicate that DT is a cross-disciplinary information technology with great development potential, and its development in the construction industry is scattered with the leading advancement in the manufacturing of construction materials and components. The derived knowledge map shows three stages of construction DT, including (1) data collection and creation of DT framework and database; (2) implementation of planning and design modules in detail and control of construction sites; and (3) carrying out asset management and fault prediction in the operation and maintenance phase of projects. The novelty of this paper is the specific analysis of DT in the construction industry. This study adds value to the architecture, engineering, and construction industries by shedding light on the focus of DT practical applications and the formation of a development path of construction DT.";Elsevier Ltd;Journal;Journal of Cleaner Production;2023-01-10;https://api.elsevier.com/content/abstract/scopus_id/85143719809
217;Knowledge map and forecast of digital twin in the construction industry: State-of-the-art review using scientometric analysis;"With the advancement of Industry 4.0 and the development of science and technology, industries have seen the advantages of digital twin (DT) implementations and concepts. Although the construction industry is still in the early stage of DT development and implementation, it is urgent for the industry to have a DT agenda. This paper identifies 1158 related bibliographic records from the Web of Science and 745 records from the Derwent Patent Database and quantitatively analyzed them to describe patterns of publications. Two knowledge mapping tools were selected to visualize and analyze the literature in the relevant scientific domain. Then, we integrated clustering, knowledge mapping, and network analysis methods to show the current foci and future directions of DT-MT derived from the data of time distribution, journal areas, and subject distribution. The results indicate that DT is a cross-disciplinary information technology with great development potential, and its development in the construction industry is scattered with the leading advancement in the manufacturing of construction materials and components. The derived knowledge map shows three stages of construction DT, including (1) data collection and creation of DT framework and database; (2) implementation of planning and design modules in detail and control of construction sites; and (3) carrying out asset management and fault prediction in the operation and maintenance phase of projects. The novelty of this paper is the specific analysis of DT in the construction industry. This study adds value to the architecture, engineering, and construction industries by shedding light on the focus of DT practical applications and the formation of a development path of construction DT.";Elsevier Ltd;Journal;Journal of Cleaner Production;2023-01-10;https://api.elsevier.com/content/abstract/scopus_id/85143719809
218;Digital Twin in manufacturing: A categorical literature review and classification;The Digital Twin (DT) is commonly known as a key enabler for the digital transformation, however, in literature is no common understanding concerning this term. It is used slightly different over the disparate disciplines. The aim of this paper is to provide a categorical literature review of the DT in manufacturing and to classify existing publication according to their level of integration of the DT. Therefore, it is distinct between Digital Model (DM), Digital Shadow (DS) and Digital Twin. The results are showing, that literature concerning the highest development stage, the DT, is scarce, whilst there is more literature about DM and DS.;Elsevier B.V.;Conference Proceeding;IFAC-PapersOnLine;2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85052915281
219;Digital Twin in manufacturing: A categorical literature review and classification;The Digital Twin (DT) is commonly known as a key enabler for the digital transformation, however, in literature is no common understanding concerning this term. It is used slightly different over the disparate disciplines. The aim of this paper is to provide a categorical literature review of the DT in manufacturing and to classify existing publication according to their level of integration of the DT. Therefore, it is distinct between Digital Model (DM), Digital Shadow (DS) and Digital Twin. The results are showing, that literature concerning the highest development stage, the DT, is scarce, whilst there is more literature about DM and DS.;Elsevier B.V.;Conference Proceeding;IFAC-PapersOnLine;2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85052915281
220;Digital Twin models in industrial operations: State-of-the-art and future research directions;A Digital Twin is a virtual representation of a physical product, asset, process, system, or service that allows us to understand, predict, and optimise their performance for better business outcomes. Recently, the use of Digital Twin in industrial operations has attracted the attention of many scholars and industrial sectors. Despite this, there is still a need to identify its value in industrial operations mainly in production, predictive maintenance, and after-sales services. Similarly, the implementation of a Digital Twin still faces many challenges. In response, a systematic literature review and analysis of 41 papers published between 2016 and 11 July 2020 have been carried out to examine recently published works in the field. Future research directions in the area are also highlighted. The result reveals that, regardless of the challenges, the role of Digital Twin in the advancement of industrial operations, especially production and predictive maintenance is highly significant. However, its role in after-sales services remains limited. Insights are offered for research scholars, companies, and practitioners to understand the current state-of-the-art and challenges, and to indicate future research possibilities in the field.;John Wiley and Sons Inc;Journal;IET Collaborative Intelligent Manufacturing;2021-03-01;https://api.elsevier.com/content/abstract/scopus_id/85104100632
221;Digital twin of the rotor-shaft of a lightweight electric motor during aerobatics loads;Purpose: This paper aims to present airworthiness considerations regarding a shaft of an electric motor. A fatigue lifetime prediction analysis based on one-step load spectrum is performed during high-cycle fatigue. Time-dependent normal and shear stress components are estimated using a high-fidelity digital twin built in Siemens PLM Nx Nastran as a finite element model (FEM). Linear and centrifugal acceleration as well as gyroscopic moment, motor torque, propeller thrust and thermal loads are considered. The equivalent cyclic degree of utilisation and a safety margin against the slip of a press-fitted shaft to rotor hub connection is estimated. Design/methodology/approach: A load analysis using FEM is presented. The numerically obtained results are verified on an analytical and a semi-empirical basis. Findings: The shaft of the electric motor can sustain 74 h of operation if burdened with aerobatic loads. Its load capacity equals 48% for the overall safety factor of 2.25. Practical implications: The paper presents a specific, easily identifiable advance in knowledge that can be applicable in safety flight analysis issues. Originality/value: The work presents a rotor of a novel lightweight electric motor for aircraft applications, which is a successor of the electric motor set recently in Extra 330E. The work delivers a computational estimation of the shaft life.;Emerald Group Holdings Ltd.;Journal;Aircraft Engineering and Aerospace Technology;2020-10-27;https://api.elsevier.com/content/abstract/scopus_id/85084226364
222;Digital Twin Service Unit for AC Motor Stator Inter-Turn Short Circuit Fault Detection;A modern trend for industry digitalization brings new demands for the development and application of the modeling and simulation approach. It is already not enough to have only a virtual representation of the object and run it independently from the physical object. The Digital Twin (DT) aspect indicates a connection between the physical object and the corresponding virtual twin established by generating real-time data using sensors. The DT represents physical object operation throughout its life cycle, making it an essential tool for improving that object's reliability. In this paper, an application of the DT service unit for AC motor stator inter-turn short circuit fault detection is presented. According to real-time measurements, Linux Robot Operation System (ROS) simulates AC electrical machine-specific behavior in case of unbalanced stator currents and notify about possible fault appearance and propagation. Fault, such as discussed in the paper (AC machine stator inter-turn) is considered one of the most prevalent possible electrical motor failure.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2021 28th International Workshop on Electric Drives: Improving Reliability of Electric Drives, IWED 2021 - Proceedings;2021-01-27;https://api.elsevier.com/content/abstract/scopus_id/85103860218
223;Digital Twin-Driven Design: A Framework to Enhance System Interoperability in the Era of Industry 4.0;Product development and manufacturing is entering a digital era, thanks to the progress made in data science and virtual technologies. The digital twin (DT) is one of the key concepts associated with this transition to Industry 4.0. Yet, in the literature, the term is differently used in various communities. In addition, the DT implementation in the product development process (PDP) lacks a conceptual ground, which hinders the proper use and wider application of this technology in engineering design and product life cycle management. This paper proposes an interoperability framework for digital twin-driven product design, based on data integration at different stages of the respective life cycles of the product and its digital twin. Such a framework can greatly help companies optimize their PDP.;Springer Science and Business Media Deutschland GmbH;Conference Proceeding;Proceedings of the I-ESA Conferences;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85149692057
224;Digital twin: Mitigating unpredictable, undesirable emergent behavior in complex systems;Systems do not simply pop into existence. They progress through lifecycle phases of creation, production, operations, and disposal. The issues leading to undesirable and unpredicted emergent behavior are set in place during the phases of creation and production and realized during the operational phase, with many of those problematic issues due to human interaction. We propose that the idea of the Digital Twin, which links the physical system with its virtual equivalent can mitigate these problematic issues. We describe the Digital Twin concept and its development, show how it applies across the product lifecycle in defining and understanding system behavior, and define tests to evaluate how we are progressing. We discuss how the Digital Twin relates to Systems Engineering and how it can address the human interactions that lead to “normal accidents.” We address both Digital Twin obstacles and opportunities, such as system replication and front running. We finish with NASA's current work with the Digital Twin.;Springer International Publishing;Book;Transdisciplinary Perspectives on Complex Systems: New Findings and Approaches;2016-01-01;https://api.elsevier.com/content/abstract/scopus_id/85006339863
225;Digital twin: Mitigating unpredictable, undesirable emergent behavior in complex systems;Systems do not simply pop into existence. They progress through lifecycle phases of creation, production, operations, and disposal. The issues leading to undesirable and unpredicted emergent behavior are set in place during the phases of creation and production and realized during the operational phase, with many of those problematic issues due to human interaction. We propose that the idea of the Digital Twin, which links the physical system with its virtual equivalent can mitigate these problematic issues. We describe the Digital Twin concept and its development, show how it applies across the product lifecycle in defining and understanding system behavior, and define tests to evaluate how we are progressing. We discuss how the Digital Twin relates to Systems Engineering and how it can address the human interactions that lead to “normal accidents.” We address both Digital Twin obstacles and opportunities, such as system replication and front running. We finish with NASA's current work with the Digital Twin.;Springer International Publishing;Book;Transdisciplinary Perspectives on Complex Systems: New Findings and Approaches;2016-01-01;https://api.elsevier.com/content/abstract/scopus_id/85006339863
226;Digital twin: Mitigating unpredictable, undesirable emergent behavior in complex systems;Systems do not simply pop into existence. They progress through lifecycle phases of creation, production, operations, and disposal. The issues leading to undesirable and unpredicted emergent behavior are set in place during the phases of creation and production and realized during the operational phase, with many of those problematic issues due to human interaction. We propose that the idea of the Digital Twin, which links the physical system with its virtual equivalent can mitigate these problematic issues. We describe the Digital Twin concept and its development, show how it applies across the product lifecycle in defining and understanding system behavior, and define tests to evaluate how we are progressing. We discuss how the Digital Twin relates to Systems Engineering and how it can address the human interactions that lead to “normal accidents.” We address both Digital Twin obstacles and opportunities, such as system replication and front running. We finish with NASA's current work with the Digital Twin.;Springer International Publishing;Book;Transdisciplinary Perspectives on Complex Systems: New Findings and Approaches;2016-01-01;https://api.elsevier.com/content/abstract/scopus_id/85006339863
227;Digital twin: Values, challenges and enablers from a modeling perspective;Digital twin can be defined as a virtual representation of a physical asset enabled through data and simulators for real-time prediction, optimization, monitoring, controlling, and improved decision making. Recent advances in computational pipelines, multiphysics solvers, artificial intelligence, big data cybernetics, data processing and management tools bring the promise of digital twins and their impact on society closer to reality. Digital twinning is now an important and emerging trend in many applications. Also referred to as a computational megamodel, device shadow, mirrored system, avatar or a synchronized virtual prototype, there can be no doubt that a digital twin plays a transformative role not only in how we design and operate cyber-physical intelligent systems, but also in how we advance the modularity of multi-disciplinary systems to tackle fundamental barriers not addressed by the current, evolutionary modeling practices. In this work, we review the recent status of methodologies and techniques related to the construction of digital twins mostly from a modeling perspective. Our aim is to provide a detailed coverage of the current challenges and enabling technologies along with recommendations and reflections for various stakeholders.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85081090770
228;Digital twin driven smart product design framework;With the advent of new generation information technologies (new IT) in industry and product design, the big data–driven product design era has arrived. However, current research mainly places emphasis on the analysis of physical data rather than the virtual models. In other words, the convergence between product’s physical and virtual spaces is usually absent. Fortunately, digital twin (DT), an emerging and fast-growing technology, provides a promising way to connect and integrate the physical and virtual spaces seamlessly, thus to solve the previous problem efficiently. Therefore this chapter introduces DT into product design and presents a new design method based on the DT approach. First, related theories and technologies of product design are reviewed and the concept of DT is explored. Then a five-dimension DT and its abilities enabled by new IT are proposed. Based on this, a DT-driven smart product design (DTPD) framework is discussed, in terms of key processes and related technologies. Finally, DTPD applications in bicycle and landing gear are presented as two case studies to illustrate the proposed method.;Elsevier;Book;Digital Twin Driven Smart Design;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85092714647
229;Digital twin-driven product design, manufacturing and service with big data;Nowadays, along with the application of new-generation information technologies in industry and manufacturing, the big data-driven manufacturing era is coming. However, although various big data in the entire product lifecycle, including product design, manufacturing, and service, can be obtained, it can be found that the current research on product lifecycle data mainly focuses on physical products rather than virtual models. Besides, due to the lack of convergence between product physical and virtual space, the data in product lifecycle is isolated, fragmented, and stagnant, which is useless for manufacturing enterprises. These problems lead to low level of efficiency, intelligence, sustainability in product design, manufacturing, and service phases. However, physical product data, virtual product data, and connected data that tie physical and virtual product are needed to support product design, manufacturing, and service. Therefore, how to generate and use converged cyber-physical data to better serve product lifecycle, so as to drive product design, manufacturing, and service to be more efficient, smart, and sustainable, is emphasized and investigated based on our previous study on big data in product lifecycle management. In this paper, a new method for product design, manufacturing, and service driven by digital twin is proposed. The detailed application methods and frameworks of digital twin-driven product design, manufacturing, and service are investigated. Furthermore, three cases are given to illustrate the future applications of digital twin in the three phases of a product respectively.;Springer London;Journal;International Journal of Advanced Manufacturing Technology;2018-02-01;https://api.elsevier.com/content/abstract/scopus_id/85015707925
230;Digital Twin-driven smart manufacturing: Connotation, reference model, applications and research issues;This paper reviews the recent development of Digital Twin technologies in manufacturing systems and processes, to analyze the connotation, application scenarios, and research issues of Digital Twin-driven smart manufacturing in the context of Industry 4.0. To understand Digital Twin and its future potential in manufacturing, we summarized the definition and state-of-the-art development outcomes of Digital Twin. Existing technologies for developing a Digital Twin for smart manufacturing are reviewed under a Digital Twin reference model to systematize the development methodology for Digital Twin. Representative applications are reviewed with a focus on the alignment with the proposed reference model. Outstanding research issues of developing Digital Twins for smart manufacturing are identified at the end of the paper.;Elsevier Ltd;Journal;Robotics and Computer-Integrated Manufacturing;2020-02-01;https://api.elsevier.com/content/abstract/scopus_id/85070213247
231;Digital twin-enabled decision support services in industrial ecosystems;The goal of this paper is to further elaborate a new concept for value creation by decision support services in industrial service ecosystems using digital twins and to apply it to an extended case study. The aim of the original model was to design and integrate an architecture of digital twins derived from business needs that leveraged the potential of the synergies in the ecosystem. The conceptual framework presented in this paper extends the semantic ontology model for integrating the digital twins. For the original model, technical modeling approaches were developed and integrated into an ecosystem perspective based on a modeling of the ecosystem and the actors’ decision jobs. In a service ecosystem comprising several enterprises and a multitude of actors, decision making is based on the interlinkage of the digital twins of the equipment and the processes, which is achieved by the semantic ontology model further elaborated in this paper. The implementation of the digital twin architecture is shown in the example of a manufacturing SME (small and medium-sized enterprise) case that was introduced in. The mixed semantic modeling and model-based systems engineering for this implementation is discussed in further detail in this paper. The findings of this detailed study provide a theoretical concept for implementing digital twins on the level of service ecosystems and integrating digital twins based on a unified ontology. This provides a practical blueprint to companies for developing digital twin based services in their own operations and beyond in their ecosystem.;MDPI;Journal;Applied Sciences (Switzerland);2021-12-01;https://api.elsevier.com/content/abstract/scopus_id/85120790758
232;Digital Twins for Manufacturing Using UML and Behavioral Specifications;Using digital twins, physical manufacturing objects can be virtualized and represented as digital models which are seamlessly integrated in both the physical and the digital space. This allows to simulate, verify and optimize production systems, from the logistical aspects to the manufacturing process and the involved components. A key challenge, in this area, is how to describe digital twins in complex manufacturing systems such that all physical details, processes, and verification needs are modeled at an appropriate and efficient abstraction level, e.g., modeling and detecting divers faults in production processes. To address this challenge, in this paper we present our work on modeling digital twins of manufacturing facilities using UML. UML class diagrams are used to describe static dependencies between entities, as well as to monitor and analyze the dynamic verification and quality aspects of manufacturing such as fault detection and consistency checks. Utilizing the key relevant features of UML in our approach, the designed class diagrams are used and enriched with behavioral models serving as digital twins which can be updated by live data from the manufacturing plant. We present a small example based on simulation programs and a demonstrator. The presented modeling approach and example provide useful insights to UML-based design of digital twins in complex manufacturing systems.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;IEEE International Conference on Emerging Technologies and Factory Automation, ETFA;2020-09-01;https://api.elsevier.com/content/abstract/scopus_id/85093359308
233;Domain Specific Models as System Links;Digital Ecosystems consist of a variety of interlinked subsystems. This paper presents a flexible approach to define the links between such subsystems. The idea is to exploit the paradigm of Model Centered Architecture (MCA) and to specify all links/interfaces by means of appropriate Domain Specific Modeling Languages. The approach has been successfully applied and evaluated in several projects. As a proof of concept, we present the model-based interfacing between assistive systems and human activity recognition systems, which showed good performance as needed in real-world applications.;Springer Verlagservice@springer.de;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85055442265
234;Embedding component behavior DSLs into the MontiArcAutomaton ADL;Component & connector architecture description languages often need to capture application-specific or company-specific requirements. Therefore, it is a crucial prerequisite for their successful application to adapt the ADLs by customizing the languages themselves. Pervasive modeling with tailored ADLs can benefit from integration of DSLs to model-specific forms of component behavior. This requires expertise of the underlying language integration mechanisms. Current research in integrating heterogeneous component behavior DSLs into an ADL focuses on integration of specific kinds of DSLs or is restricted to syntactic integration. However, language integrators can be liberated from requiring in-depth language integration expertise using appropriate abstractions. To this effect, we present a compact DSL for the integration of behavior DSLs into a component & connector ADL that guides and facilitates this form of language integration. Modeling the embedding of behavior DSLs into ADLs facilitates their composition and ultimately the pervasive modeling of complex architectures.;CEUR-WS;Conference Proceeding;CEUR Workshop Proceedings;2016-01-01;https://api.elsevier.com/content/abstract/scopus_id/84999133847
235;Emergence of open supply chain management: the role of open innovation in the future smart industry using digital twin network;Alongside many research studies that have been presented in the open innovation domain and smart manufacturing systems, there is a research gap on integrating the outbound individual capabilities with the new smart manufacturing machines to satisfy the customers' varied and uncertain requirements. In this paper, Open Supply Chain Management (OSCM) is conceptualized as a new paradigm in the evolution of SCM. Companies can benefit from integrated physical and conceptual resources to promote efficiency and flexibility throughout the supply chain's main processes, including supplying, manufacturing, distributing, and marketing. The OSCM concept is undergoing several drivers including crowdsourcing, open innovation, Industry 4.0, cloud manufacturing, Internet of Things (IoT), big data, and the digital twin that appeared in the last decades. To validate OSCM in practice, a subset of this concept is investigated to incorporate the designing process with supply chain production planning applying a digital twin network. Additionally, dealing with epistemic uncertainty, a fuzzy tactical planning model is developed, and to study the developed model in more detail, an industrial study in the clothes manufacturing industry is employed. The results illustrate that the products' designing cost consists of only 2% of the supply chain total cost.;Springer;Journal;Annals of Operations Research;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85122277063
236;EMF-REST: Generation of RESTful APIs from models;In the last years, there has been an increasing interest for Model-Driven Engineering (MDE) solutions in the Web. Web-based modeling solutions can leverage on better support for distributed management (i.e., the Cloud) and collaboration. However, current modeling environments and frameworks are usually restricted to desktop-based scenarios and therefore their capabilities to move to the Web are still very limited. In this paper we present an approach to generate Web APIs out of models, thus paving the way for managing models and collaborating on them online. The approach, called EMF-REST, takes Eclipse Modeling Framework (EMF) data models as input and generates Web APIs following the REST principles and relying on well-known libraries and standards, thus facilitating its comprehension and maintainability. Also, EMF-REST integrates model and Web-specific features to provide model validation and security capabilities, respectively, to the generated API.;Association for Computing Machineryacmhelp@acm.org;Conference Proceeding;Proceedings of the ACM Symposium on Applied Computing;2016-04-04;https://api.elsevier.com/content/abstract/scopus_id/84975864604
237;Data-driven engineering design: A systematic review using scientometric approach;"In the last two decades, data regarding engineering design and product development has increased rapidly. Big data exploration and mining offer numerous opportunities for engineering design; however, owing to the multitude of data sources and formats coupled with the high complexity of the design process, these techniques are yet to be utilised to the best of their full potential. In this study, a comprehensive assessment of the state-of-the-art data-driven engineering design (DDED) in the last 20 years was conducted. A scientometric approach was employed wherein first, a systematic article acquisition procedure was performed, where a dataset of 3339 articles related to engineering design and big data analytics applications were extracted from Web of Science (WoS) and Scopus. Thereafter, this dataset was reduced to a dataset of 366 articles based on concise data screening. The resulting articles were used to analyse the dynamics of research in DDED throughout the last 20 years and to detect the primary research topics related to DDED, the most influential authors, and the papers with the highest impact in the DDED domain. Furthermore, the co-occurrence network of keywords/keyphrases and co-authorship networks were constructed and analysed to reveal the interconnection of the research topics and the collaboration between the most prolific authors. Finally, an insight how big data analytics is being applied through product development activities to support decision-making in engineering design was presented.";Elsevier Ltd;Journal;Advanced Engineering Informatics;2022-10-01;https://api.elsevier.com/content/abstract/scopus_id/85140741445
238;Engineering tagging languages for DSLs;To keep a DSL clean, readable and reusable in different contexts, it is useful to define a separate tagging language. A tag model logically adds information to the tagged DSL model while technically keeping the artifacts separated. Using a generic tagging language leads to promiscuous tag models, whereas defining a target DSL-specific tag language has a high initial overhead. This paper presents a systematic approach to define a DSL-specific tag language and a corresponding schema language, combining the advantages of both worlds: (a) the tag language specifically fits to the DSL, (b) the artifacts are kept separated and enabling reuse with different tag decorations, (c) the tag language follows a defined type schema, and (d) systematic derivation considerably reduces the effort necessary to implement the tag language. An example shows that it can at least partially be realized by a generator and applied for any kind of DSL.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2015 ACM/IEEE 18th International Conference on Model Driven Engineering Languages and Systems, MODELS 2015 - Proceedings;2015-11-25;https://api.elsevier.com/content/abstract/scopus_id/84961634193
239;Enterprise Information Systems in Academia and Practice: Lessons learned from a MBSE Project;The development of domain-specific information systems, especially web information systems, takes a certain amount of time, needs intensive testing to ensure a certain quality and lacks the consistency of front- and backend. Using model-based strategies for the creation of information systems helps to overcome these problems by fastening the development process, facilitating testing and ensuring consistency-by-construction. In practice, however, they are still rarely used. In this paper, we show that model-based engineering is beneficial for the creation of an enterprise information system and improves the quality of the resulting product. We present the basic functionalities of our Generator for Enterprise Management (MontiGEM) and discuss identified problems and lessons learned in a project in practice. The generator was developed simultaneously with and for an enterprise management system. Our research shows that the use of generative methods and MBSE improves the adaptability and reusability of parts of the application on the one hand but on the other hand, there are still obstacles that slow down its broad application in practice.;Gesellschaft fur Informatik (GI);Conference Proceeding;Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI);2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85115262972
240;Enterprise Information Systems in Academia and Practice: Lessons learned from a MBSE Project;The development of domain-specific information systems, especially web information systems, takes a certain amount of time, needs intensive testing to ensure a certain quality and lacks the consistency of front- and backend. Using model-based strategies for the creation of information systems helps to overcome these problems by fastening the development process, facilitating testing and ensuring consistency-by-construction. In practice, however, they are still rarely used. In this paper, we show that model-based engineering is beneficial for the creation of an enterprise information system and improves the quality of the resulting product. We present the basic functionalities of our Generator for Enterprise Management (MontiGEM) and discuss identified problems and lessons learned in a project in practice. The generator was developed simultaneously with and for an enterprise management system. Our research shows that the use of generative methods and MBSE improves the adaptability and reusability of parts of the application on the one hand but on the other hand, there are still obstacles that slow down its broad application in practice.;Gesellschaft fur Informatik (GI);Conference Proceeding;Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI);2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85115262972
241;Enterprise Information Systems in Academia and Practice: Lessons learned from a MBSE Project;The development of domain-specific information systems, especially web information systems, takes a certain amount of time, needs intensive testing to ensure a certain quality and lacks the consistency of front- and backend. Using model-based strategies for the creation of information systems helps to overcome these problems by fastening the development process, facilitating testing and ensuring consistency-by-construction. In practice, however, they are still rarely used. In this paper, we show that model-based engineering is beneficial for the creation of an enterprise information system and improves the quality of the resulting product. We present the basic functionalities of our Generator for Enterprise Management (MontiGEM) and discuss identified problems and lessons learned in a project in practice. The generator was developed simultaneously with and for an enterprise management system. Our research shows that the use of generative methods and MBSE improves the adaptability and reusability of parts of the application on the one hand but on the other hand, there are still obstacles that slow down its broad application in practice.;Gesellschaft fur Informatik (GI);Conference Proceeding;Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI);2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85115262972
242;Enterprise Service Bus Construction in SOA Architecture for SIEM Implementation in Critical Information Infrastructure;The number of cyber threats in ICT is increasing and the development of new security oriented instrumental tools is very important and relevant scientific task. Security incident and event management (SIEM) systems are category of such tools, directed on log analysis and incident management to prevent negative consequences minimize damage of cyber threats for end user. In the previous works authors have analyzed existed SIEM systems and database types for them as well as created new architecture of cloud-based SIEM. Next step of this research project is enterprise service bus architecture justification. The paper defines the place of distributed data bus in the concept of service oriented architecture, identifies the functions and benefits. Also authors analyzed most popular up-to-date enterprise service bus solutions and provides recommendations in context of developed SIEM implementation in the critical infrastructure. Besides, the data sheet for SIEM in critical infrastructure was formed and proposed in this paper.;CEUR-WS;Conference Proceeding;CEUR Workshop Proceedings;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85143797481
243;Evaluating model-driven development claims with respect to quality: A family of experiments;Context: There is a lack of empirical evidence on the differences between model-driven development (MDD), where code is automatically derived from conceptual models, and traditional software development method, where code is manually written. In our previous work, we compared both methods in a baseline experiment concluding that quality of the software developed following MDD was significantly better only for more complex problems (with more function points). Quality was measured through test cases run on a functional system. Objective: This paper reports six replications of the baseline to study the impact of problem complexity on software quality in the context of MDD. Method: We conducted replications of two types: strict replications and object replications. Strict replications were similar to the baseline, whereas we used more complex experimental objects (problems) in the object replications. Results: MDD yields better quality independently of problem complexity with a moderate effect size. This effect is bigger for problems that are more complex. Conclusions: Thanks to the bigger size of the sample after aggregating replications, we discovered an effect that the baseline had not revealed due to the small sample size. The baseline results hold, which suggests that MDD yields better quality for more complex problems.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Transactions on Software Engineering;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85058097392
244;Dynamic event tree analysis of a severe accident sequence in a boiling water reactor experiencing a cyberattack scenario;Over the last decade, probabilistic risk assessment (PRA) for nuclear power plants shifted its focus toward simulation-based methods of evaluating safety and risk aspects. Classical reliability modeling based on static Boolean structures does not capture the dynamic nature of plants experiencing accident sequences. Dynamic PRA extends conventional reliability modeling, adding a higher degree of variability to events occuring during accident sequences. This paper demonstrates the capability of a new dynamic event tree (DET) analysis tool applicable to severe accident sequences. A cyberattack was assumed to penetrate the instrumentation system of a boiling water reactor during its hot shutdown phase, altering the thermal–hydraulic variables being processed. The analysis focused on scenarios that lead to the core being uncovered, in which the peak cladding temperature is reached due to the disabling of the cooling systems. A limiting surface is defined, associating the cyberattack timing to the recovery time limit that would compromise the core integrity.;Elsevier Ltd;Journal;Annals of Nuclear Energy;2023-11-01;https://api.elsevier.com/content/abstract/scopus_id/85162995788
245;Executable Models to Support Automated Software FMEA;Safety analysis is increasingly important for a wide class of systems. In the automotive field, the recent ISO26262 standard foresees safety analysis to be performed at system, hardware, and software levels. Failure Modes and Effects Analysis (FMEA) is an important step in any safety analysis process, and its application at hardware and system levels has been extensively addressed in the literature. Conversely, its application to software architectures is still to a large extent an open problem, especially concerning its integration into a general certification process. The approach we propose in this paper aims at performing semi-automated FMEA on component-based software architectures described in UML. The foundations of our approach are model-execution and fault-injection at model-level, which allows us to compare the nominal and faulty system behaviors and thus assess the effectiveness of safety countermeasures. Besides introducing the detailed workflow for SW FMEA, the work in this paper focuses on the process for obtaining an executable model from a component-based software architecture specified in UML.;IEEE Computer Societyhelp@computer.org;Conference Proceeding;Proceedings of IEEE International Symposium on High Assurance Systems Engineering;2015-01-01;https://api.elsevier.com/content/abstract/scopus_id/84936849926
246;Characterization of continuous experimentation in software engineering: Expressions, models, and strategies;Context: Continuous Experimentation (CE) has become increasingly popular across industry and academic communities. Major software organizations use CE to increase their revenue by adding value to end-users, and researchers are investigating the CE adoption process and usage to expand its success. Given this rapid evolution, observing a shared understanding of CE definitions, processes, and experiment strategies is difficult, potentially jeopardizing new implementations and focused research efforts. Objective: To characterize CE from the perspective of its definitions, processes, and strategies for experimentation available in the technical literature and to evolve the understanding perspectives for “continuous experimentation” and “data-driven development” definitions. Method: To select and analyze sources of information in the technical literature dealing with different aspects of continuous experimentation through a Literature Study using an ad hoc search improved with snowballing (backward and forward). Organize the findings into new perspectives for CE definitions, processes, and experiment strategies. Results: It was possible to identify many different definitions, processes, and experimental strategies used to describe CE in the 72 analyzed empirical papers, making it difficult to decide on their combination to be applied in a real software development project. Therefore, it has been proposed to evolve the CE understanding perspective, to categorize its experiment strategies, and to offer a combined development process for CE combining parts of other processes. Besides, conjectural requirements have been identified, which can contribute to better differentiating requirements and hypotheses in the CE context. Conclusion: Likely, a better understanding of CE is still missing. It can contribute towards organizing a common taxonomy to facilitate the possible choices for the experiment strategies. Therefore, there is space for more investigations on its applicability and value in different categories of software systems, despite all the advancements of CE and its promotion in developing modern software systems.;Elsevier B.V.;Journal;Science of Computer Programming;2023-07-01;https://api.elsevier.com/content/abstract/scopus_id/85159759787
247;Fault Diagnosis of the On-board Equipment in CTCS-3 Based on Timed Automata and Mutation Theoy;In this paper, a method of fault diagnosis for the on-board equipment based on Timed Automata (TA) and mutation theory is proposed. Firstly, several kinds of mutation operators were injected in TA model to get Fault Timed Automta (FTA), in which the fault with timed features is described. Secondly, the approach of fault diagnosis and the verification of the diagnosability were proposed by parallel product A, in which the necessary and sufficient conditions of fault diagnosiability were discussed. Finally, we take the Ceiling Speed Monitoring (CSM) and Target Speed Monitoring (TSM) functions as a case study to present the feasibility of the method. Based on the CSM diagnoser, the fault set with events and time behaviors was effectively divided into two categories: diagnosable and non-diagnosable. The result is shown that the fault diagnosis and verification of diagnosability can be performed and it is of great significance for fault diagnosis of the on-board equipment.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2019 IEEE Intelligent Transportation Systems Conference, ITSC 2019;2019-10-01;https://api.elsevier.com/content/abstract/scopus_id/85076807638
248;Performance evaluation of the 3d printing system through fault tree analysis method (FTAM);This study focuses on the performance analysis of the 3D printing process using cementitious material on equipment installed at the Structures Laboratory (LabEst-UnB) of the University of Brasilia. A research direction was defined for the 3D printing with the aim of identifying which steps need to be further developed and which improvements should be made for this specific process to evolve. Following the execution of the proposed experimental program, evaluations of cementitious material pieces printed with the InovaHouse3D’s Alya 130 printer were conducted, documenting the encountered issues and classifying them into failure groups. The causes, consequences, and affected components were defined and used in the application of the Fault Tree Analysis (FTA) method in the search for critical system events. It was observed that the most critical system failures were related to the material composition and printing parameters, focusing on events that trigger variations in the material's consistency. Thus, through this work, it was possible to identify improvement opportunities and suggest scientific research topics to enhance the 3D printing process according to the established priority levels.;Springer Nature;Journal;Journal of Building Pathology and Rehabilitation;2023-12-01;https://api.elsevier.com/content/abstract/scopus_id/85161051524
249;Performance evaluation of the 3d printing system through fault tree analysis method (FTAM);This study focuses on the performance analysis of the 3D printing process using cementitious material on equipment installed at the Structures Laboratory (LabEst-UnB) of the University of Brasilia. A research direction was defined for the 3D printing with the aim of identifying which steps need to be further developed and which improvements should be made for this specific process to evolve. Following the execution of the proposed experimental program, evaluations of cementitious material pieces printed with the InovaHouse3D’s Alya 130 printer were conducted, documenting the encountered issues and classifying them into failure groups. The causes, consequences, and affected components were defined and used in the application of the Fault Tree Analysis (FTA) method in the search for critical system events. It was observed that the most critical system failures were related to the material composition and printing parameters, focusing on events that trigger variations in the material's consistency. Thus, through this work, it was possible to identify improvement opportunities and suggest scientific research topics to enhance the 3D printing process according to the established priority levels.;Springer Nature;Journal;Journal of Building Pathology and Rehabilitation;2023-12-01;https://api.elsevier.com/content/abstract/scopus_id/85161051524
250;Fault tree analysis: A survey of the state-of-the-art in modeling, analysis and tools;Fault tree analysis (FTA) is a very prominent method to analyze the risks related to safety and economically critical assets, like power plants, airplanes, data centers and web shops. FTA methods comprise of a wide variety of modeling and analysis techniques, supported by a wide range of software tools. This paper surveys over 150 papers on fault tree analysis, providing an in-depth overview of the state-of-the-art in FTA. Concretely, we review standard fault trees, as well as extensions such as dynamic FT, repairable FT, and extended FT. For these models, we review both qualitative analysis methods, like cut sets and common cause failures, and quantitative techniques, including a wide variety of stochastic methods to compute failure probabilities. Numerous examples illustrate the various approaches, and tables present a quick overview of results.;Elsevier Ireland Ltd;Journal;Computer Science Review;2015-02-01;https://api.elsevier.com/content/abstract/scopus_id/84929709003
251;Fault tree analysis: A survey of the state-of-the-art in modeling, analysis and tools;Fault tree analysis (FTA) is a very prominent method to analyze the risks related to safety and economically critical assets, like power plants, airplanes, data centers and web shops. FTA methods comprise of a wide variety of modeling and analysis techniques, supported by a wide range of software tools. This paper surveys over 150 papers on fault tree analysis, providing an in-depth overview of the state-of-the-art in FTA. Concretely, we review standard fault trees, as well as extensions such as dynamic FT, repairable FT, and extended FT. For these models, we review both qualitative analysis methods, like cut sets and common cause failures, and quantitative techniques, including a wide variety of stochastic methods to compute failure probabilities. Numerous examples illustrate the various approaches, and tables present a quick overview of results.;Elsevier Ireland Ltd;Journal;Computer Science Review;2015-02-01;https://api.elsevier.com/content/abstract/scopus_id/84929709003
252;Formation principles of digital twins of Cyber-Physical Systems in the smart factories of Industry 4.0;The task of organizing the production of instrument-making enterprises of Industry 4.0 using digital twins of Cyber-Physical Systems (CPS) based on cloud services is considered. Cloud services are a component of SPS, acting in production as active Internet agents for the manufacture of instrumentation products. The combination of CPS, united by a single computerized control system, forms the production infrastructure of a smart factory. Smart Factory is a manufacturing plant of Industry 4.0, operating in automatic mode. A scheme of interaction between the components of the smart factory Industry 4.0 and cloud services for the production activity of the instrument-making enterprise is proposed.;Institute of Physics Publishinghelen.craven@iop.org;Conference Proceeding;IOP Conference Series: Materials Science and Engineering;2019-03-20;https://api.elsevier.com/content/abstract/scopus_id/85063942809
253;Framework to support the aircraft digital counterpart concept with an industrial design view;With a specific focus on the aerospace sector, this paper is a starting point in the definition of a framework, based on a commercial software system, to facilitate the biunivocal relation between a physical individual aircraft, identified by means of a 'manufacturing serial number' (MSN), and its equivalent digital counterpart. It reviews the different topics involved in the creation of an aircraft digital counterpart, i.e., complexity, identification, lifecycle, information and configuration, and the main software applications involved. Then, it shows the implications on the digital counterpart creation from the view of the aircraft industrial design. Finally, it discusses the proposal of a supporting framework based on dassault systemès V6 solution. The framework is based on the collaborative paradigm for the creation of an aircraft industrial digital mock-up (iDMU), which is substantiated by a functional model and an iDMU dataset structure.;Inderscience Publishers29, route de Pre-BoisCase Postale 856, CH-1215 Geneva 15CH-1215editor@inderscience.com;Journal;International Journal of Agile Systems and Management;2016-01-01;https://api.elsevier.com/content/abstract/scopus_id/84994091508
254;From the cyber-physical system to the digital twin: The process development for behaviour modelling of a cyber guided vehicle in M2M logic;"This paper describes a research whose aim was to prototype a Digital Twin (DT) which meets the logistic behavior of a new family of automated guided vehicles (AGVs), based on the Cyber-Physical System (CPS) paradigm. The research consists of two steps. First, the implementation of CPS logic on an existing micro-controlled rover is examined; then, a traditional discrete event simulation (DES) software is used to simulate different environment application for the DT, including some modifications that allow identifying the most suitable solutions for the research aim. The specific design process has limited the stochastic variability of the simulated system to the mechanical component of the CPS-AGV. This because of the absolute identity of the logistic logic, operating both in the code used by the CPS-AGV micro-controller and in the code of simulating the system. The results show that the combined CPS-DT architecture allows a strategic optimization of the plant resources in Industry 4.0 configuration. To this end, different policy have been implemented to optimize the autoadaptive behavior of CPS-AGV, and each one of them has proven to be effective in a specific scenario. Outcomes of this study provide an industrial justification to the design and managing costs of Digital Twin implementation in an Industry 4.0 production system.";AIDI - Italian Association of Industrial Operations Professors;Conference Proceeding;Proceedings of the Summer School Francesco Turco;2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/85040447784
255;Generated enterprise information systems: MDSE for maintainable co-development of frontend and backend;Universities, like any application domain and industry sector, have to establish a well functioning, reliable management accounting, and financial reporting software system. Currently, chairs have different technical solutions for their financial management such as commercial accounting software tailored to the needs of the central administration as well as the chairs' own data collections with additional information in other software tools. Previous work did not investigate the use of model-driven software engineering methods for the maintainable development of a full-size real-world enterprise information system. This paper shows the application of model-driven software engineering methods to create this system and support the maintainable co-development of frontend and backend written in different programming languages. We are using a variety of models and modeling languages in addition to an application generator that allows for continuous re-generation. Our approach can be easily adapted to other problem domains to create a functional prototype out of models with minimal manual effort.;CEUR-WSceurws@sunsite.informatik.rwth-aachen.de;Conference Proceeding;CEUR Workshop Proceedings;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85080937709
256;Generating customized low-code development platforms for digital twins;A digital twin improves our use of a cyber–physical system and understanding of its emerging behavior. To this effect, a digital twin is to be developed and configured and potentially also operated by domain experts, who rarely have a professional software engineering background and for whom easy access and support, e.g., in form of low-code platforms are missing. In this paper, we report on an integrated method for the model-driven engineering of low-code development platforms for digital twins that enables domain experts to create and operate digital twins for cyber–physical systems using the most appropriate modeling languages. The foundation of this method is (1) a code generation infrastructure for information systems combined with (2) an extensible base architecture for self-adaptive digital twins and (3) reusable language components for their configuration. Using this method, software engineers first configure the information system with the required modeling languages to generate the low-code development platform for digital twins before domain experts leverage the generated platform to create digital twins. This two-step method facilitates creating tailored low-code development platforms as well as creating and operating customized digital twins for a variety of applications.;Elsevier Ltd;Journal;Journal of Computer Languages;2022-06-01;https://api.elsevier.com/content/abstract/scopus_id/85129984615
257;Grand challenges in the science of wind energy;Harvested by advanced technical systems honed over decades of research and development, wind energy has become a mainstream energy resource. However, continued innovation is needed to realize the potential of wind to serve the global demand for clean energy. Here, we outline three interdependent, cross-disciplinary grand challenges underpinning this research endeavor. The first is the need for a deeper understanding of the physics of atmospheric flow in the critical zone of plant operation. The second involves science and engineering of the largest dynamic, rotating machines in the world. The third encompasses optimization and control of fleets of wind plants working synergistically within the electricity grid. Addressing these challenges could enable wind power to provide as much as half of our global electricity needs and perhaps beyond.;American Association for the Advancement of Science;Journal;Science;2019-10-25;https://api.elsevier.com/content/abstract/scopus_id/85074117909
258;Hardware-in-the-Loop Testing of Modern On-Board Power Systems Using Digital Twins;"Simulation has always played an important role in the development, integration and deployment of aircraft, land vehicles and naval ships. Ever-increasing system design complexity also increased the necessity for more stringent testing and integration capabilities of these new topologies. Real-time simulators can be very useful tools to test, validate and integrate these complex devices. Maintenance and subsystem upgrades, common issues in such complex systems, cannot be easily done on the real systems, especially on larger systems like those in navy ships. This is when a real-time digital replica with Hardware-In-the-Loop capability is very useful. This type of system is also known as a 'Digital Twin'. This approach is compatible with model-based design; a design philosophy that is based entirely on simulation models, from the specifications to release and field commissioning. In this paper, we describe the Digital Twin approach and explain it in the context of navy ships. Such systems usually integrate many subsystems, such as traction systems, power generation and auxiliary systems, all connected through various communication links. The test and integration requirements for such vehicle or land systems affect several levels of the control hierarchy; from low-level power electronic converters used for propulsion and auxiliary systems to high-level supervisory controls. In this paper, we will describe a HIL test made on a simplified zonal power system of a navy ship.";Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;SPEEDAM 2018 - Proceedings: International Symposium on Power Electronics, Electrical Drives, Automation and Motion;2018-08-23;https://api.elsevier.com/content/abstract/scopus_id/85053836160
259;Health monitoring and prognosis of electric vehicle motor using intelligent-digital twin;Electric mobility has become an essential part of the future of transportation. Detection, diagnosis and prognosis of fault in electric drives are improving the reliability, of electric vehicles (EV). Permanent magnet synchronous motor (PMSM) drives are used in a large variety of applications due to their dynamic performances, higher power density and higher efficiency. In this study, health monitoring and prognosis of PMSM is developed by creating intelligent digital twin (i-DT) in MATLAB/ Simulink. An artificial neural network (ANN) and fuzzy logic are used for mapping inputs distance, time of travel of EV and outputs casing temperature, winding temperature, time to refill the bearing lubricant, percentage deterioration of magnetic flux to compute remaining useful life (RUL) of permanent magnet (PM). Health monitoring and prognosis of EV motor using i-DT is developed with two approaches. Firstly, in-house health monitoring and prognosis is developed to monitor the performance of the motor in-house. Secondly, Remote Health Monitoring and Prognosis Centre (RHMPC) is developed to monitor the performance of the motor remotely using cloud communication by the service provider of the EV. The simulation results prove that the RUL of PM and time to refill the bearing lubricant obtained by i-DT twins theoretical results.;Institution of Engineering and TechnologyJBristow@theiet.org;Journal;IET Electric Power Applications;2019-09-01;https://api.elsevier.com/content/abstract/scopus_id/85072282683
260;Hierarchical combination of internal and external domain-specific languages for scientific computing;To adapt established methods of software engineering for scientific computing, we propose a software development approach for interdisciplinary teams of scientists called Sprat. The approach is organized around a hierarchical architecture that combines internal and external domain-specific languages (DSLs). For its evaluation, Sprat is employed in the implementation of a marine ecosystem model. We highlight what is to be observed while integrating the DSLs into the hierarchy in order to enable a successful cooperation of scientists in interdisciplinary teams as well as to achieve a maintainable code base. © 2014 ACM.;Association for Computing Machineryacmhelpacm.org;Conference Proceeding;ACM International Conference Proceeding Series;2014-01-01;https://api.elsevier.com/content/abstract/scopus_id/84907393298
261;How to create a new generation of industrial processes simulation by coupling simulation tools with VR platforms;"In a world which is continuously evolving, different industrial actors need to react in order to remain competitive. To achieve this, they are required to improve their industrial management methods: both at the strategic level, to adapt to technological advances, and by following market trends. At the strategic level, it prompts manufacturers to update and adapt their production management methods; to improve the performance of the manufacturing process; and to accelerate production delivery dates to deal with the arrival of new products as well as new competitors. The aim of this paper is to present the main advantages of using virtual reality (VR) in the manufacturing processes in a lean environment. To this end, a state of the art of the different research works in VR that treats issues related to the industry will compose the first part of this paper. In the second part, we propose a first approach by addressing the issue of the contribution of the VR to the simulation of production flows through an architecture that allows implementing a solution for interactive and immersive simulation. Finally, we present two scenarios using our approach.";International Society of Computers and Their Applications (ISCA);Conference Proceeding;28th International Conference on Computer Applications in Industry and Engineering, CAINE 2015;2015-01-01;https://api.elsevier.com/content/abstract/scopus_id/84983661921
262;How to tell the difference between a model and a digital twin;“When I use a word, it means whatever I want it to mean”: Humpty Dumpty in Alice’s Adventures Through The Looking Glass, Lewis Carroll. “Digital twin” is currently a term applied in a wide variety of ways. Some differences are variations from sector to sector, but definitions within a sector can also vary significantly. Within engineering, claims are made regarding the benefits of using digital twinning for design, optimisation, process control, virtual testing, predictive maintenance, and lifetime estimation. In many of its usages, the distinction between a model and a digital twin is not made clear. The danger of this variety and vagueness is that a poor or inconsistent definition and explanation of a digital twin may lead people to reject it as just hype, so that once the hype and the inevitable backlash are over the final level of interest and use (the “plateau of productivity”) may fall well below the maximum potential of the technology. The basic components of a digital twin (essentially a model and some data) are generally comparatively mature and well-understood. Many of the aspects of using data in models are similarly well-understood, from long experience in model validation and verification and from development of boundary, initial and loading conditions from measured values. However, many interesting open questions exist, some connected with the volume and speed of data, some connected with reliability and uncertainty, and some to do with dynamic model updating. In this paper we highlight the essential differences between a model and a digital twin, outline some of the key benefits of using digital twins, and suggest directions for further research to fully exploit the potential of the approach.;Springer;Journal;Advanced Modeling and Simulation in Engineering Sciences;2020-12-01;https://api.elsevier.com/content/abstract/scopus_id/85081715350
263;Human behavior, goals and model-driven software engineering for assistive systems;Assistive systems might reason about human behavior and specific actions to be able to assist human activities in everyday life or working situations. It is a challenge to create an adaptive, unobtrusive system with high accuracy of supporting actions. Previous work assumes that either a concrete goal is preset for a whole support application, or is chosen from a finite set of goals by the user or is calculated over a finite set of goals by heuristic algorithms. This novel directions paper discusses ideas to reduce the solution space for assistive systems by using observations of human behavior together with domain-specific and general knowledge. We discuss especially challenges for creating goal models, how to combine them with other existing models, and how to use them in model-based software engineering approaches with automatic code generation. A concrete realization of these ideas enables a variety of design decisions regarding modeling languages, the interplay of different languages, and how to handle goals at run-time.;CEUR-WSceurws@sunsite.informatik.rwth-aachen.de;Conference Proceeding;CEUR Workshop Proceedings;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85094179134
264;Human behavior, goals and model-driven software engineering for assistive systems;Assistive systems might reason about human behavior and specific actions to be able to assist human activities in everyday life or working situations. It is a challenge to create an adaptive, unobtrusive system with high accuracy of supporting actions. Previous work assumes that either a concrete goal is preset for a whole support application, or is chosen from a finite set of goals by the user or is calculated over a finite set of goals by heuristic algorithms. This novel directions paper discusses ideas to reduce the solution space for assistive systems by using observations of human behavior together with domain-specific and general knowledge. We discuss especially challenges for creating goal models, how to combine them with other existing models, and how to use them in model-based software engineering approaches with automatic code generation. A concrete realization of these ideas enables a variety of design decisions regarding modeling languages, the interplay of different languages, and how to handle goals at run-time.;CEUR-WSceurws@sunsite.informatik.rwth-aachen.de;Conference Proceeding;CEUR Workshop Proceedings;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85094179134
265;On the use of the hybrid causal logic methodology in ship collision risk assessment;A ship collision accident is one of the most dangerous and common types of maritime accidents. Traditional probabilistic risk assessment (PRA) of ship collision accidents is a methodology that can be adopted to ensure maritime safety. Nevertheless, a need for better approaches to model human behavior, such as risk identification, communication, and decision-making, has been identified. Such advanced PRA methods require a more explicit way of taking human factors into consideration than the traditional risk assessment methods. Hybrid causal logic (HCL) is an advanced PRA method due to its unique three-level framework that includes event sequence diagrams, fault trees, and Bayesian networks, which makes it suitable for modeling human behavior that is important to ship collision accidents. This paper discusses the applicability of the HCL methodology for the ship collision accident. Firstly, the event sequences of typical ship collision accidents are summarized based on the study of 50 accident investigation reports. Then, fault trees for mechanical failure events and the Bayesian networks for human error events are constructed to analyze the events in a structured way at a more detailed level. Finally, the three main end-state types of ship collision avoidance scenario have been quantified. The result of the probability of a ship collision accident is verified by estimating the annual frequency of collision accidents in the Singapore Strait. Comparing with the historical data, the estimation results are quite near to the real case. By taking advantage of the HCL methodology, the modeling of ship collision scenarios can be carried out at a deep logical level. At the same time, it is possible to combine a detailed analysis of various primary events with a comprehensive analysis at the system level.;MDPI AGPostfachBaselCH-4005rasetti@mdpi.com;Journal;Journal of Marine Science and Engineering;2020-07-01;https://api.elsevier.com/content/abstract/scopus_id/85088444218
266;I4.0-compliant integration of assets utilizing the Asset Administration Shell;Global trends such as mass customization and lot size one, demand flexibility, autonomy and adaptability in production. Interoperability of devices is a key challenge as production systems evolve into Cyber-Physical Production Systems (CPPS). As part of the German strategic project Industrie 4.0 (I4.0), concepts and solutions for continuous digitization of production are being developed, in order to meet these numerous challenges. The concept of the Asset Administration Shell (AAS) was introduced in order to provide data and information in a standardized and semantically described manner, thus enabling interoperability and easy interaction. In this paper, we show how users can translate a semantic description of plants, machines or individual components that are based on a standardized Open Platform Communication Unified Architecture (OPC UA) information model, into the AAS information model.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;IEEE International Conference on Emerging Technologies and Factory Automation, ETFA;2019-09-01;https://api.elsevier.com/content/abstract/scopus_id/85074196812
267;Integrating Hierarchical Task Analysis into Model-Based System Design using Airbus XHTA and IBM Rational Rhapsody;Current tools for Hierarchical Task Analysis (HTA) were designed to meet the special needs of psychologists or ergonomists, and therefore typically lack the capability to interchange data with modelling or engineering tools. As a consequence, essential information on tasks, operational processes and procedures is segregated from the development process, with the inherent risk that it is not fully taken into account. However, particularly in safety-critical systems, optimized human machine interfaces are essential to ensure safe operations, and may be decisive to guarantee a timely response. In this paper, we present our approach to bridge the gap through integrating task analysis results in a SysML model. For this, the possibility to translate a full HTA into corresponding SysML elements was investigated, and a converter tool was implemented. The converter's output is an XML-file following the OMG XMI standard containing the HTA in SysML, which is compatible with the IBM Rational Rhapsody importing interface. Integrating the HTA results in a system modeling tool offers important additional knowledge for utilization in the subsequent System Engineering process.;IEEE Computer Societyhelp@computer.org;Conference Proceeding;IEEE International Conference on Industrial Engineering and Engineering Management;2019-01-09;https://api.elsevier.com/content/abstract/scopus_id/85061835252
268;In Search of the Essence of Low-Code: An Exploratory Study of Seven Development Platforms;Rapidly growing attention has been directed in recent years toward a type of software development and execution environment now passing under the name of 'low-code development platforms.' The fundamental claim is that limiting traditional coding mechanisms in favor of a variety of alternative means of design and specification yields substantial efficiency gains in professional and private software development. But although much stir at present surrounds low-code development platforms, it is by no means clear what, if any, features are distinctive of these systems, and whether any of these features mark out a technology which can be considered original. This paper presents an exploratory study of seven low-code development platforms, with the aim of discovering their essence and assessing them critically in the light of research in information systems development. An analysis framework covering a number of criteria regarding professional information systems development is used to characterize the selected platforms, and to point out features commonly, occasionally, and rarely possessed by them. The study reveals that hardly any features of low-code development are innovative in and of themselves, with novelty primarily consisting in their combination and integration. Still, we argue in conclusion, a number of research opportunities can be made out with an eye on the leitmotif of low-code development.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Companion Proceedings - 24th International Conference on Model-Driven Engineering Languages and Systems, MODELS-C 2021;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85119105792
269;In Search of the Essence of Low-Code: An Exploratory Study of Seven Development Platforms;Rapidly growing attention has been directed in recent years toward a type of software development and execution environment now passing under the name of 'low-code development platforms.' The fundamental claim is that limiting traditional coding mechanisms in favor of a variety of alternative means of design and specification yields substantial efficiency gains in professional and private software development. But although much stir at present surrounds low-code development platforms, it is by no means clear what, if any, features are distinctive of these systems, and whether any of these features mark out a technology which can be considered original. This paper presents an exploratory study of seven low-code development platforms, with the aim of discovering their essence and assessing them critically in the light of research in information systems development. An analysis framework covering a number of criteria regarding professional information systems development is used to characterize the selected platforms, and to point out features commonly, occasionally, and rarely possessed by them. The study reveals that hardly any features of low-code development are innovative in and of themselves, with novelty primarily consisting in their combination and integration. Still, we argue in conclusion, a number of research opportunities can be made out with an eye on the leitmotif of low-code development.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Companion Proceedings - 24th International Conference on Model-Driven Engineering Languages and Systems, MODELS-C 2021;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85119105792
270;Industry 4.0 Impacts on Lean Production Systems;The fourth industrial revolution and its Industry 4.0 or connected industry technologies dominates the current discussion of production research. Digital developments like cyber-physical Systems are the key technologies for future, more agile production systems but a common understanding of the term Industry 4.0 is not established in this time. First generic implementation approaches present manifold technical solutions but miss an integrated consideration with existing Lean Production Systems. The actual impact of Industry 4.0 solutions is mostly not clearly specified and a method to evaluate is missing. This paper introduces the Industry 4.0 in an environment of connectability in the Internet of Things and Services with the vision of a smart factory. The initial situation of industrial companies is characterized by Lean Production Systems and Lean Principles. For companies, Industry 4.0 offers an estimated benefit by stabilizing Lean processes with Industry 4.0 applications. To support the development process the presented Concept of an Industry 4.0 impact matrix on lean production systems gives a useable framework. The matrix considers elements of lean production systems with Industry 4.0 technologies and gives a first estimation of impact. In the described development process of a cyber-physical Just-in-Time delivery the matrix is used to find a stabilizing application for a Just-in-Time material supply process.;Elsevier B.V.;Conference Proceeding;Procedia CIRP;2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/85028664452
271;Industry 4.0 smart reconfigurable manufacturing machines;"This paper provides a fundamental research review of Reconfigurable Manufacturing Systems (RMS), which uniquely explores the state-of-the-art in distributed and decentralized machine control and machine intelligence. The aim of this review is to draw objective answers to two proposed research questions, relating to: (1) reconfigurable design and industry adoption; and (2) enabling present and future state technology. Key areas reviewed include: (a) RMS – fundamentals, design rational, economic benefits, needs and challenges; (b) Machine Control – modern operational technology, vertical and horizontal system integration, advanced distributed and decentralized control; (c) Machine Intelligence – distributed and decentralized paradigms, technology landscape, smart machine modelling, simulation, and smart reconfigurable synergy. Uniquely, this paper establishes a vision for next-generation Industry 4.0 manufacturing machines, which will exhibit extraordinary Smart and Reconfigurable (SR*) capabilities.";Elsevier B.V.;Journal;Journal of Manufacturing Systems;2021-04-01;https://api.elsevier.com/content/abstract/scopus_id/85103928385
272;Information Model of a Digital Process Twin for Machining Processes;The development of digital process twins goes hand in hand with the digitalization of manufacturing's production chain, especially in the machining of parts. The essential basis of these digital process twins is the information model, which describes the properties and relationships of all relevant data and information required to realize the processing task and a digital representation. This paper describes such an information model and presents the benefits and application potentials of digital process twins in the machining of parts.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;IEEE International Conference on Emerging Technologies and Factory Automation, ETFA;2020-09-01;https://api.elsevier.com/content/abstract/scopus_id/85093357343
273;Information modeling for cyber-physical production system based on digital twin and AutomationML;Production systems play an important role in intelligent manufacturing. A large number of manufacturing resources are designed and developed with virtual (digital) ones, which will be associated with the physical ones throughout their lifecycle. With the recent emergence of information and communications technologies (ICTs), such as internet of things, big data, virtual reality, artificial intelligence, and 5G, the interconnection and interaction between physical resources and virtual ones become possible in production systems. Digital twin (DT) shows great potential to realize the cyber-physical production system (CPPS) in the era of Industry 4.0. In this paper, we present our vision on integrating various physical resources into CPPS via DT and AutomationML. To elaborate on how to apply ICTs, this paper firstly explores a generic architecture of CPPS based on DT. DT is a virtual and authoritative representation of physical manufacturing resource, since DT includes various models and manufacturing big data of resource. The proposed architecture is illustrated in detail as follows: (1) physical layer, (2) network layer, (3) virtual layer, and (4) application layer. A case of expert fault diagnose for aircraft engine is presented using the proposed information fusion in the architecture. Secondly, this paper proposes an approach of information modeling for CPPS based on AutomationML. Various manufacturing services can be encapsulated and defined in the standardized format (AutomationML), and then the corresponding virtual manufacturing resources (DTs) will be integrated into CPPS. Finally, this paper describes a case of information modeling for blisk machining and demonstrates the modeling approach in real-life scenarios for support manufacturing resource sharing via DT. Furthermore, the conclusion and further work is briefly summarized.;Springer;Journal;International Journal of Advanced Manufacturing Technology;2020-03-01;https://api.elsevier.com/content/abstract/scopus_id/85081887346
274;Handbook of Metal Injection Molding;Metal injection molding combines the most useful characteristics of powder metallurgy and plastic injection molding to facilitate the production of small, complex-shaped metal components with outstanding mechanical properties. Handbook of Metal Injection Molding, Second Edition provides an authoritative guide to this important technology and its applications. Building upon the success of the first edition, this new edition includes the latest developments in the field and expands upon specific processing technologies. Part one discusses the fundamentals of the metal injection molding process with chapters on topics such as component design, important powder characteristics, compound manufacture, tooling design, molding optimization, debinding, and sintering. Part two provides a detailed review of quality issues, including feedstock characterisation, modeling and simulation, methods to qualify a MIM process, common defects and carbon content control. Special metal injection molding processes are the focus of part three, which provides comprehensive coverage of micro components, two material/two color structures, and porous metal techniques. Finally, part four explores metal injection molding of particular materials, and has been expanded to include super alloys and precious metals. With its distinguished editor and expert team of international contributors, the Handbook of Metal Injection Molding is an essential guide for all those involved in the high-volume manufacture of small precision parts, across a wide range of high-tech industries such as microelectronics, biomedical and aerospace engineering.;Elsevier;Book;Handbook of Metal Injection Molding;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85093925624
275;Innovations in digital modelling for next generation manufacturing system design;Interlinked and autonomous manufacturing systems provide new opportunities in smart manufacturing. Today's manufacturing system design processes and architecture still are based on traditional engineering methods and can hardly cope with increased system complexity. Hence new cyber physical production systems (CPPS) design and architecture principles as well as corresponding validation and verification methods are necessary. This paper presents firstly a new architecture design approach for modularised design of CPPS. Secondly, new capabilities in designing with modular construction kits, simulating functional behaviour and validating with virtual, functional prototype are introduced. Thirdly, a proposal for the development approach and virtual validation is presented and risks as well as challenges are discussed.;Elsevier USA;Journal;CIRP Annals - Manufacturing Technology;2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/85018625620
276;Innovations in model-based software and systems engineering;Engineering software and software intensive systems has become increasingly complex over the last decades. In the ongoing digitalization of all aspects of our lives in almost every domain, including, e.g., mechanical engineering, electrical engineering, medicine, entertainment, or jurisdiction, software is not only used to enable low-level controls of machines, but also to understand system conditions and optimizations potentials. To remain in control of all these heterogeneous systems of systems, a precise, but abstract understanding of these systems is necessary. To this end, models in their various forms are an important prerequisite to gain this understanding. In this article, we summarize research activities focusing on the development and use of models in software and systems engineering. This research has been carried out by the working group of Bernhard Rumpe, which started 25 years ago in Munich, continued in Braunschweig, and since 10 years carries on at RWTH Aachen University.;Association Internationale pour les Technologies Objetseditor@jot.fm;Journal;Journal of Object Technology;2019-03-01;https://api.elsevier.com/content/abstract/scopus_id/85071393498
277;Integrate Digital Twin to Exist Production System for Industry 4.0;Nowadays, Industry 4.0 is widely known in the industry. Many large companies have pushed and adapted to Industry 4.0 to increase their business competitiveness, so small and medium-sized companies must adjust to improve their production capabilities to keep up with the technological development of Industry 4.0. Industry 4.0 development can be done in many ways as outsourcing or self-developing systems, but outsourcing and purchasing systems Installation have a high cost. This paper proposes a digital twin focuses on self-development. By using digital twins combined with existing production systems to develop data following the concept of Industry 4.0, digital twins are used to creating digital data from physical forms to inspect, record production data and create digital communication channels to other systems. In summary, this paper uses a digital twin to show another way to develop into Industry 4.0, which starts with the development of data. This way is using the cost of starting a very lower without automation structure and get the data to analyze for adapting with automatic layer systems in maximum efficiency.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;TIMES-iCON 2019 - 2019 4th Technology Innovation Management and Engineering Science International Conference;2019-12-01;https://api.elsevier.com/content/abstract/scopus_id/85082384934
278;Integrating multibody simulations with sysml;In this paper we will show an integration of a JPL-internal multi body simulation tool within the Systems Modeling Language (SysML) tool MagicDraw. The SysML provides the means to model requirements, functions, structure and behavior of a system. Integrating a multi body physics simulation with this language creates a seamless way to combine system level questions with the detailed design. The integration allows for the import and export of the simulation models as well as the definition of metrics on the simulation. The system model can be used to express the requirements, the tests that verify the satisfaction and the implementation of the system according to these requirements. Having all the different aspects in one central model reduces the thread of inconsistencies through reuse and linking of model elements. The SysML model allows for an easier creation of large models and the integration with other disciplines is already prepared.;American Society of Mechanical Engineers (ASME)infocentral@asme.org;Conference Proceeding;Proceedings of the ASME Design Engineering Technical Conference;2015-01-01;https://api.elsevier.com/content/abstract/scopus_id/84982170067
279;Proceedings of the European Conference on Data Mining 2015, ECDM 2015 and International Conferences on Intelligent Systems and Agents 2015, ISA 2015 and Theory and Practice in Modern Computing 2015, TPMC 2015 - Part of the Multi Conference on Computer Science and Information Systems 2015;"The proceedings contain 29 papers. The topics discussed include: a tool supporting mining based approach selection to automatic ontology construction; RSR : related search recommendation with user feedback session; profit-based artificial neural network (ANN) trained by migrating birds optimization: a case study in credit card fraud detection; a Hadoop-based data processing platform for fresh agro-products traceability; a synthetic and computational language model for interactive dialogue system; probabilistic trust monitoring model for mobile ad hoc networks; coordinating energy allocation and process performance using an agent-based approach; protecting online banking on a smartphone with signed transaction summaries; applying set partitioning methods in the construction of operating theatre schedules; cross-sectoral analysis using mobile communication traces; improving relational data modelling through learning from errors; and stone monument text image database.";IADISsecretariat@iadis.org;Conference Proceeding;Proceedings of the European Conference on Data Mining 2015, ECDM 2015 and International Conferences on Intelligent Systems and Agents 2015, ISA 2015 and Theory and Practice in Modern Computing 2015, TPMC 2015 - Part of the Multi Conference on Computer Science and Information Systems 2015;2015-01-01;https://api.elsevier.com/content/abstract/scopus_id/84969940560
280;Introduction to Probability and Inference;Probability is a fundamental concept in physics because the outcome of experiments is determined by random processes. Different approaches to probability are introduced: classical probability, frequentist and Bayesian approaches, that are more extensively discussed in dedicated chapters. The problem to generalize classical probability to the continuum is discussed, and the axiomatic approach to probability due to Kolmogorov is introduced. The general problem of inference is introduced, with the two main interpretations under the frequentist and the Bayesian approaches. Parameters of interest and nuisance parameters, required to treat systematic uncertainties, are defined.;Springer Science and Business Media Deutschland GmbH;Book Series;Lecture Notes in Physics;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85156097488
281;JARVIS, A Hardware/Software Framework for Resilient Industry 4.0 Systems;JARVIS is a Research & Development project, jointly developed by industrial SME partners and by the University of Florence, aimed at development of a hardware/software framework supporting integration among physical IoT devices, data analytic software agents, and human operators involved in operation and maintenance of resilient Industry 4.0 systems. At the heart of the JARVIS architecture, a suite of software digital twins deployed in a Java EE environment supports runtime monitoring and control of the hierarchy of hardware configuration items of the system, capturing their composition and representing their failure modes through a reflection architectural pattern enabling agile adaptation to the evolution of configurations. Besides, analytic modules can be deployed as micro-services leveraging both the knowledge base provided by digital twins and the data flowing from the ingestion layer. This enables agile development of advanced monitoring and control services supporting maintainability and resilience. We describe the JARVIS architecture, outlining responsibilities and collaborations among its modules, and we provide details on the structure of representation of digital twins, showing how this is exploited in a data analytic agent providing an executable representation of fault trees associated with failure modes of configuration items.;Springer Verlagservice@springer.de;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85072861981
282;Knowledge-driven digital twin manufacturing cell towards intelligent manufacturing;Rapid advances in new generation information technologies, such as big data analytics, internet of things (IoT), edge computing and artificial intelligence, have nowadays driven traditional manufacturing all the way to intelligent manufacturing. Intelligent manufacturing is characterised by autonomy and self-optimisation, which proposes new demands such as learning and cognitive capacities for manufacturing cell, known as the minimum implementation unit for intelligent manufacturing. Consequently, this paper proposes a general framework for knowledge-driven digital twin manufacturing cell (KDTMC) towards intelligent manufacturing, which could support autonomous manufacturing by an intelligent perceiving, simulating, understanding, predicting, optimising and controlling strategy. Three key enabling technologies including digital twin model, dynamic knowledge bases and knowledge-based intelligent skills for supporting the above strategy are analysed, which equip KDTMC with the capacities of self-thinking, self-decision-making, self-execution and self-improving. The implementing methods of KDTMC are also introduced by a thus constructed test bed. Three application examples about intelligent process planning, intelligent production scheduling and production process analysis and dynamic regulation demonstrate the feasibility of KDTMC, which provides a practical insight into the intelligent manufacturing paradigm.;Taylor and Francis Ltd.michael.wagreich@univie.ac.at;Journal;International Journal of Production Research;2020-02-16;https://api.elsevier.com/content/abstract/scopus_id/85065139151
283;Leveraging digital twin technology in model-based systems engineering;Digital twin, a concept introduced in 2002, is becoming increasingly relevant to systems engineering and, more specifically, to model-based system engineering (MBSE). A digital twin, like a virtual prototype, is a dynamic digital representation of a physical system. However, unlike a virtual prototype, a digital twin is a virtual instance of a physical system (twin) that is continually updated with the latter’s performance, maintenance, and health status data throughout the physical system’s life cycle. This paper presents an overall vision and rationale for incorporating digital twin technology into MBSE. The paper discusses the benefits of integrating digital twins with system simulation and Internet of Things (IoT) in support of MBSE and provides specific examples of the use and benefits of digital twin technology in different industries. It concludes with a recommendation to make digital twin technology an integral part of MBSE methodology and experimentation testbeds.;MDPI AG;Journal;Systems;2019-03-01;https://api.elsevier.com/content/abstract/scopus_id/85111581098
284;Leveraging digital twin technology in model-based systems engineering;Digital twin, a concept introduced in 2002, is becoming increasingly relevant to systems engineering and, more specifically, to model-based system engineering (MBSE). A digital twin, like a virtual prototype, is a dynamic digital representation of a physical system. However, unlike a virtual prototype, a digital twin is a virtual instance of a physical system (twin) that is continually updated with the latter’s performance, maintenance, and health status data throughout the physical system’s life cycle. This paper presents an overall vision and rationale for incorporating digital twin technology into MBSE. The paper discusses the benefits of integrating digital twins with system simulation and Internet of Things (IoT) in support of MBSE and provides specific examples of the use and benefits of digital twin technology in different industries. It concludes with a recommendation to make digital twin technology an integral part of MBSE methodology and experimentation testbeds.;MDPI AG;Journal;Systems;2019-03-01;https://api.elsevier.com/content/abstract/scopus_id/85111581098
285;Leveraging digital twin technology in model-based systems engineering;Digital twin, a concept introduced in 2002, is becoming increasingly relevant to systems engineering and, more specifically, to model-based system engineering (MBSE). A digital twin, like a virtual prototype, is a dynamic digital representation of a physical system. However, unlike a virtual prototype, a digital twin is a virtual instance of a physical system (twin) that is continually updated with the latter’s performance, maintenance, and health status data throughout the physical system’s life cycle. This paper presents an overall vision and rationale for incorporating digital twin technology into MBSE. The paper discusses the benefits of integrating digital twins with system simulation and Internet of Things (IoT) in support of MBSE and provides specific examples of the use and benefits of digital twin technology in different industries. It concludes with a recommendation to make digital twin technology an integral part of MBSE methodology and experimentation testbeds.;MDPI AG;Journal;Systems;2019-03-01;https://api.elsevier.com/content/abstract/scopus_id/85111581098
286;Leveraging digital twin technology in model-based systems engineering;Digital twin, a concept introduced in 2002, is becoming increasingly relevant to systems engineering and, more specifically, to model-based system engineering (MBSE). A digital twin, like a virtual prototype, is a dynamic digital representation of a physical system. However, unlike a virtual prototype, a digital twin is a virtual instance of a physical system (twin) that is continually updated with the latter’s performance, maintenance, and health status data throughout the physical system’s life cycle. This paper presents an overall vision and rationale for incorporating digital twin technology into MBSE. The paper discusses the benefits of integrating digital twins with system simulation and Internet of Things (IoT) in support of MBSE and provides specific examples of the use and benefits of digital twin technology in different industries. It concludes with a recommendation to make digital twin technology an integral part of MBSE methodology and experimentation testbeds.;MDPI AG;Journal;Systems;2019-03-01;https://api.elsevier.com/content/abstract/scopus_id/85111581098
287;LISSU: Integrating Semantic Web Concepts into SOA Frameworks;In recent years, microservice-based architectures have become the de-facto standard for cloud-native applications and enable modular and scalable systems. The lack of communication standards however complicates reliable information exchange. While syntactic checks like datatypes or ranges are mostly solved nowadays, semantic mismatches (e.g., different units) are still problematic. Semantic Web Services and their derivatives tackle this challenge but are mostly too ambitious for practical use. In this paper, we propose Lightweight Semantic Web Services for Units (LISSU) to support Semantic Web experts in their collaboration with domain experts. LISSU allows developers specify semantics for their services via URI ontology references, and automatically validates these before initiating communication. It automatically corrects unit mismatches via conversions whenever possible. A real-world demonstrator setup in the manufacturing domain proves that LISSU leads to a more predictable communication.;Science and Technology Publications, Lda;Conference Proceeding;International Conference on Enterprise Information Systems, ICEIS - Proceedings;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85121785817
288;EDALoCo: Enhancing the accessibility of blockchains through a low-code approach to the development of event-driven applications for smart contract management;Blockchain is a cutting-edge technology based on a distributed, secure and immutable ledger that facilitates the registration of transactions and the traceability of tangible and intangible assets without requiring central governance. The agreements between the nodes participating in a blockchain network are defined through smart contracts. However, the compilation, deployment, interaction and monitoring of these smart contracts is a barrier compromising the accessibility of blockchains by non-expert developers. To address this challenge, in this paper, we propose a low-code approach, called EDALoCo, that facilitates the development of event-driven applications for smart contract management. These applications make blockchain more accessible for software developers who are non-experts in this technology as these can be modeled through graphical flows, which specify the communications between data producers, data processors and data consumers. Specifically, we have enhanced the open-source Node-RED low-code platform with blockchain technology, giving support for the creation of user-friendly and lightweight event-driven applications that can compile and deploy smart contracts in a particular blockchain. Additionally, this platform extension allows users to interact with and monitor the smart contracts already deployed in a blockchain network, hiding the implementation details from non-experts in blockchain. This approach was successfully applied to a case study of COVID-19 vaccines to monitor and obtain the temperatures to which these vaccines are continuously exposed, to process them and then to store them in a blockchain network with the aim of making them immutable and traceable to any user. As a conclusion, our approach enables the integration of blockchain with the low-code paradigm, simplifying the development of lightweight event-driven applications for smart contract management. The approach comprises a novel open-source solution that makes data security, immutability and traceability more accessible to software developers who are non-blockchain experts.;Elsevier B.V.;Journal;Computer Standards and Interfaces;2023-03-01;https://api.elsevier.com/content/abstract/scopus_id/85135882397
289;Low-code as enabler of digital transformation in manufacturing industry;Currently, enterprises have to make quick and resilient responses to changing market requirements. In light of this, low-code development platforms provide the technology mechanisms to facilitate and automate the development of software applications to support current enterprise needs and promote digital transformation. Based on a theory-building research methodology through the literature and other information sources review, the main contribution of this paper is the current characterisation of the emerging low-code domain following the foundations of the computer-aided software engineering field. A context analysis, focused on the current status of research related to the low-code development platforms, is performed. Moreover, benchmarking among the existing low-code development platforms addressed to manufacturing industry is analysed to identify the current lacking features. As an illustrative example of the emerging low-code paradigm and respond to the identified uncovered features, the virtual factory open operating system (vf-OS) platform is described as an open multi-sided low-code framework able to manage the overall network of a collaborative manufacturing and logistics environment that enables humans, applications, and Internet of Things (IoT) devices to seamlessly communicate and interoperate in the interconnected environment, promoting resilient digital transformation.;MDPI AGindexing@mdpi.com;Journal;Applied Sciences (Switzerland);2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85077580109
290;Low-code platform for automating business processes in manufacturing;The low-code platform enables quick generation and delivery of business applications with minimum effort to write in a coding language and requires the least possible effort for the installation and configuration of environments, and training and implementation. With a rapidly growing number of companies, the use of low-code solutions can be a significant step forward in creating essential business applications. This paper describes the use of the Aurea BPM low-code platform for automating business processes in manufacturing.;Elsevier B.V.;Conference Proceeding;IFAC-PapersOnLine;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85075858242
291;Low-code platform for automating business processes in manufacturing;The low-code platform enables quick generation and delivery of business applications with minimum effort to write in a coding language and requires the least possible effort for the installation and configuration of environments, and training and implementation. With a rapidly growing number of companies, the use of low-code solutions can be a significant step forward in creating essential business applications. This paper describes the use of the Aurea BPM low-code platform for automating business processes in manufacturing.;Elsevier B.V.;Conference Proceeding;IFAC-PapersOnLine;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85075858242
292;Lowcomote: Training the next generation of experts in scalable low-code engineering platforms;Low-Code Development Platforms (LCDPs) are software development platforms on the Cloud, provided through a Platform-as-a-Service model, which allow users to build completely operational applications by interacting through dynamic graphical user interfaces, visual diagrams and declarative languages. Lowcomote will train a generation of experts that will upgrade the current trend of LCDP to a new paradigm, Low-Code Engineering Platform. This will be achieved by injecting in LCDPs the theoretical and technical framework defined by recent research in Model Driven Engineering, augmented with Cloud Computing and Machine Learning techniques.;CEUR-WSceurws@sunsite.informatik.rwth-aachen.de;Conference Proceeding;CEUR Workshop Proceedings;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85069741151
293;Machine Learning based Digital Twin Framework for Production Optimization in Petrochemical Industry;"Digital twins, along with the internet of things (IoT), data mining, and machine learning technologies, offer great potential in the transformation of today's manufacturing paradigm toward intelligent manufacturing. Production control in petrochemical industry involves complex circumstances and a high demand for timeliness; therefore, agile and smart controls are important components of intelligent manufacturing in the petrochemical industry. This paper proposes a framework and approaches for constructing a digital twin based on the petrochemical industrial IoT, machine learning and a practice loop for information exchange between the physical factory and a virtual digital twin model to realize production control optimization. Unlike traditional production control approaches, this novel approach integrates machine learning and real-time industrial big data to train and optimize digital twin models. It can support petrochemical and other process manufacturing industries to dynamically adapt to the changing environment, respond in a timely manner to changes in the market due to production optimization, and improve economic benefits. Accounting for environmental characteristics, this paper provides concrete solutions for machine learning difficulties in the petrochemical industry, e.g., high data dimensions, time lags and alignment between time series data, and high demand for immediacy. The approaches were evaluated by applying them in the production unit of a petrochemical factory, and a model was trained via industrial IoT data and used to realize intelligent production control based on real-time data. A case study shows the effectiveness of this approach in the petrochemical industry.";Elsevier Ltd;Journal;International Journal of Information Management;2019-12-01;https://api.elsevier.com/content/abstract/scopus_id/85066307148
294;Highly available distributed data collection model based on an industrial message-oriented middleware 分布式高可用工业消息中间件数据采集模型;To solve the problem of data collection in heterogeneous devices with multiple protocols and large-scale clustered devices, as well as the problem of high availability of data collection for the high-value data, the highly a-vailable distributed data collection model based on an industrial message-oriented middleware was proposed. The Industrial data collection Message Queue (IdcMQ) was used as the carrier of the industrial message-oriented middleware in this method to define the architecture of IdcMQ and the running mode of the distributed cluster of IdcMQ for achieving high availability of data collection. According to the definition, the architecture composed of protocol adaptation, data processing and service providing, and the process of connecting and data collection of heterogeneous devices with multiple protocols was illustrated. The running mode composed of data synchronization rules, data synchronization level and data synchronization process, and the implementation principle of high availability of data collection was described. Based on the model, the industrial data collection message-oriented middleware software named IdcSentry was developed. The performance of IdcSentry was tested and two application cases were given to prove the effectiveness of the model.;CIMS;Journal;Jisuanji Jicheng Zhizao Xitong/Computer Integrated Manufacturing Systems, CIMS;2023-02-28;https://api.elsevier.com/content/abstract/scopus_id/85151558473
295;Influence of different nano/micro-carriers on the bioavailability of iron: Focus on in vitro–in vivo studies;Anemia resulting from iron (Fe) deficiency is a global public health problem. The deficiency of Fe is usually due to insufficient dietary intake of iron, interaction of Fe with other food components, and thus low bioaccessibility/bioavailability. Fe encapsulation has the potential to tackle some major challenges in iron fortification of foods. Various nano/micro-carriers have been developed for encapsulation of Fe, including emulsions, liposomes, hydrogels, and spray-dried microcapsules. They could reduce the interactions of Fe with food components, increase iron tolerance and intestinal uptake, and decrease adverse effects. This article review covers the factors affecting the bioavailability of Fe along with emerging carriers that can be used as a solution of this issue. The application of Fe-loaded carriers in food supplements and products is also described. The advantages and limitations associated with the delivery efficiency of each carrier for Fe are highlighted.;Elsevier B.V.;Journal;Advances in Colloid and Interface Science;2023-08-01;https://api.elsevier.com/content/abstract/scopus_id/85162144836
296;Creating Business Applications with Microsoft 365: Techniques in Power Apps, Power BI, SharePoint, and Power Automate;"Learn how to automate processes, visualize your data, and improve productivity using Power Apps, Power Automate, Power BI, SharePoint, Forms, Teams, and more. This book will help you build complete solutions that often involve storing data in SharePoint, creating a front-end application in Power Apps or Forms, adding additional functionality with Power Automate, and effective reports and dashboards in Power BI. This new edition greatly expands the focus on Power Apps, Power BI, Power Automate, and Teams, along with SharePoint and Microsoft Forms. It starts with the basics of programming and shows how to build a simple email application in .NET, HTML/JavaScript, Power Apps on its own, and Power Apps and Power Automate in combination. It then covers how to connect Power Apps to SharePoint, create an approval process in Power Automate, visualize surveys in Power BI, and create your own survey solution with the combination of a number of Microsoft 365 tools. You'll work with an extended example that shows how to use Power Apps and SharePoint together to create your own help ticketing system. This book offers a deep dive into Power BI, including working with JSON, XML, and Yes/No data, as well as visualizing learning data and using it to detect inconsistencies between Excel files. You'll also see how to connect to Remedy and to the help system you will have created. Under author Jeffrey Rhodes's guidance, you'll delve into the Power Apps collection to learn how to avoid dreaded ""delegation"" issues with larger data sets. Back on applications, you will create a training class sign-up solution to only allow users to choose classes with available seats. Digging deeper into Teams, you'll learn how to send chats, posts, and ""adaptive cards"" from Power Automate. Rounding things out, you'll save Forms attachments to SharePoint with Power Automate, create your own ""Employee Recognition"" app with all of the Power Platform and Teams, add or edit weekly status reports, and learn how to create reservation and scoring applications. After reading the book, you will be able to build powerful applications using Power Apps, Power Automate, Power BI, SharePoint, Forms, and Teams.";Apress Media LLC;Book;Creating Business Applications with Microsoft 365: Techniques in Power Apps, Power BI, SharePoint, and Power Automate;2022-11-15;https://api.elsevier.com/content/abstract/scopus_id/85166089939
297;Mobile Cyber Physical Systems: Current Challenges and Future Networking Applications;Mobile cyber-physical systems (CPS) that take the advantages and extend the application domains of CPS have become increasingly popular in recent years. For example, mobile CPS could be a kind of foundational techniques to support the development of vehicular networking systems, thereby improving security and privacy of users in the dynamic environments of vehicular networks. In this paper, we first distinguish mobile CPS from traditional CPS. Then, we introduce their three emerging application areas, i.e., vehicular networking systems, healthcare systems, and mobile education. After that, we discuss four main research challenges of mobile CPS regarding security, energy consumption, mobile dynamic environment, and system stability. Also, we consider the corresponding techniques, which may address these challenges, and analyze the inter-relations among them. Finally, we outline the possible research directions and applications of mobile CPS in the future.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2017-12-12;https://api.elsevier.com/content/abstract/scopus_id/85038845465
298;Model driven architecture approach to logic controller design;The paper is concerned with the application of MDD approach in logic controller design process. We propose to divide traditional design process of a digital circuit into architectural layers and models defined by OMG MDA standard. Such arranged design process basically consists of transformations of models. As PIM we use UML state machine, as a PSM we propose own refined state machine models and target platform are HDL code model and mathematical model of Transition System.;American Institute of Physics Inc.subs@aip.org;Conference Proceeding;AIP Conference Proceedings;2018-11-30;https://api.elsevier.com/content/abstract/scopus_id/85058664323
299;Proposal of a module-driven architecture for building simulation models devoted to container terminals: dilemmas in applying generic, flexible, and modular principles;"Container terminals are complex systems where containerized cargo undergoes a set of processing and handling operations to be delivered to their outgoing modes. A pool of decision support methods and simulation models has been developed to assist planners and managers in making decisions about daily operations. Nevertheless, most are designed for a particular terminal and not generic types. Indeed, a generic model serves as a conceptual factory to create specific models which greatly reduces the time and efforts of development; however, building such a model is no mean feat. To this aim, the paper on hand discusses the complexity of applying genericity, flexibility, and modularity in system modeling and proposes a generic architecture to build modular and flexible simulation models for container terminals. This architecture is split into a set of smaller, manageable, well-connected, and generic modules that facilitate the creation of highly parametrized specific models. An illustrative example of the architecture usage is presented in a case study, the new container terminal of Stockholm, and the resulting models were validated by subject matter experts. Finally, to prove its efficiency, a numerical study fed with real data is conducted to investigate the handling capacity of the studied system under different handling and flow scenarios. The obtained results show that the terminal handling capacity can be increased by around 50% if three to four more straddle carriers are added to the existing fleet.";SAGE Publications Ltd;Journal;Simulation;2023-07-01;https://api.elsevier.com/content/abstract/scopus_id/85146338740
300;Model-Driven Development of a Digital Twin for Injection Molding;Digital Twins (DTs) of Cyber-Physical Production Systems (CPPSs) enable the smart automation of production processes, collection of data, and can thus reduce manual efforts for supervising and controlling CPPSs. Realizing DTs is challenging and requires significant efforts for their conception and integration with the represented CPPS. To mitigate this, we present an approach to systematically engineering DTs for injection molding that supports domain-specific customizations and automation of essential development activities based on a model-driven reference architecture. In this approach, reactive CPPS behavior is defined in terms of a Domain-Specific Language (DSL) for specifying events that occur in the physical system. The reference architecture connects to the CPPS through a novel DSL for representing OPC-UA bindings. We have evaluated this approach with a DT of an injection molding machine that controls the machine to optimize the Design of Experiment (DoE) parameters between experiment cycles before the products are molded. Through this, our reference implementation of the DT facilitates the time-consuming setup of a DT and the subsequent injection molding activities. Overall, this facilitates to systematically engineer digital twins with reactive behavior that help to optimize machine use.;Springer;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85086228557
301;Model order reduction a key technology for digital twins;An increasing number of disruptive innovations with high economic and social impact shape our digitalizing world. Speed and extending scope of these developments are limited by available tools and paradigms to master exploding complexities. Simulation technologies are key enablers of digitalization. They enable digital twins mirroring products and systems into the digital world. Digital twins require a paradigm shift. Instead of expert centric tools, engineering and operation require autonomous assist systems continuously interacting with its physical and digital environment through background simulations. Model order reduction (MOR) is a key technology to transfer highly detailed and complex simulation models to other domains and life cycle phases. Reducing the degree of freedom, i.e., increasing the speed of model execution while maintaining required accuracies and predictability, opens up new applications. Within this contribution, we address the advantages of model order reduction for model-based system engineering and real-time thermal control of electric motors.;Springer International Publishing;Book;Reduced-Order Modeling (ROM) for Simulation and Optimization: Powerful Algorithms as Key Enablers for Scientific Computing;2018-04-11;https://api.elsevier.com/content/abstract/scopus_id/85053527918
302;Model predictive control of a wind turbine modelled in Simpack;Wind turbines (WT) are steadily growing in size to increase their power production, which also causes increasing loads acting on the turbine's components. At the same time large structures, such as the blades and the tower get more flexible. To minimize this impact, the classical control loops for keeping the power production in an optimum state are more and more extended by load alleviation strategies. These additional control loops can be unified by a multiple-input multiple-output (MIMO) controller to achieve better balancing of tuning parameters. An example for MIMO control, which has been paid more attention to recently by wind industry, is Model Predictive Control (MPC). In a MPC framework a simplified model of the WT is used to predict its controlled outputs. Based on a user-defined cost function an online optimization calculates the optimal control sequence. Thereby MPC can intrinsically incorporate constraints e.g. of actuators. Turbine models used for calculation within the MPC are typically simplified. For testing and verification usually multi body simulations, such as FAST, BLADED or FLEX5 are used to model system dynamics, but they are still limited in the number of degrees of freedom (DOF). Detailed information about load distribution (e.g. inside the gearbox) cannot be provided by such models. In this paper a Model Predictive Controller is presented and tested in a co-simulation with SlMPACK, a multi body system (MBS) simulation framework used for detailed load analysis. The analysis are performed on the basis of the IME6.0 MBS WT model, described in this paper. It is based on the rotor of the NREL 5MW WT and consists of a detailed representation of the drive train. This takes into account a flexible main shaft and its main bearings with a planetary gearbox, where all components are modelled flexible, as well as a supporting flexible main frame. The wind loads are simulated using the NREL AERODYN v13 code which has been implemented as a routine to SlMPACK. This modeling approach allows to investigate the nonlinear behavior of wind loads and nonlinear drive train dynamics. Thereby the MPC's impact on specific loads and effects not covered by standard simulation tools can be assessed and investigated. Keywords. wind turbine simulation, model predictive control, multi body simulation, MIMO, load alleviation © Published under licence by IOP Publishing Ltd.;Institute of Physics Publishinghelen.craven@iop.org;Conference Proceeding;Journal of Physics: Conference Series;2014-01-01;https://api.elsevier.com/content/abstract/scopus_id/84903725725
303;Model-based fault diagnosis and prognosis of dynamic systems: A review;In maintenance of engineering systems, condition monitoring, fault diagnosis and fault prognosis constitute some of the principal tasks. With the increase of the number of machines within processing plants and their operational complexities, many engineers and researchers have started looking for automated solutions for these tasks. In most of the proposed solutions, these dynamic systems are modelled using tools like automata, Petri nets, bond graphs and Bayesian networks to diagnose and predict faults in those systems. This paper reviews these graphical model-based techniques related to fault diagnosis and prognosis and give suggestions for future research directions identifying research gaps in the field.;Elsevier B.V.;Conference Proceeding;Procedia Manufacturing;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85067299672
304;Model-based generation of run-time data collection systems exploiting AutomationML;Production system operators need support for collecting and pre-processing data on production systems consisting of several system components, as foundation for optimization and defect detection. Traditional approaches based on hard-coded programming of such run-time data collection systems take time and effort, and require both domain and technology knowledge. In this article, we introduce the AML-RTDC approach, which combines the strengths of AutomationML (AML) data modeling and model-driven engineering, to reduce the manual effort for realizing the run-time data collection (RTDC) system. We evaluate the feasibility of the AML-RTDC approach with a demonstration case about a lab-sized production system and a use case based on real-world requirements.;De Gruyter Oldenbourghbear@kams.or.kr;Journal;At-Automatisierungstechnik;2018-10-25;https://api.elsevier.com/content/abstract/scopus_id/85055572325
305;Model-based quantitative safety analysis of matlab simulink/stateflow models;In this paper we report on work in progress to extend the QuantUM approach to support the quantitative property analysis of Matlab Simulink/Stateflow models. We propose a translation of Simulink/Stateflow models to CTMCs which can be analyzed using the PRISM model checker inside the QuantUM tool. We also illustrate how the information needed to perform probabilistic analysis of dependability properties can be specified at the level of the Simulink/Stateflow model. We demonstrate the applicability of our approach using a case study taken from the MathWorks examples library.;fortiss GmbH;Conference Proceeding;Tagungsband - Dagstuhl-Workshop MBEES 2013: Modellbasierte Entwicklung Eingebetteter Systeme IX;2013-01-01;https://api.elsevier.com/content/abstract/scopus_id/85087608175
306;Model-Based Software Engineering at RWTH Aachen University;In this article, the Software Engineering Research Group of RWTH Aachen University presents its research aim, research topics and some research highlights that have been researched over the last ten years. Furthermore, the relevance of agile, generative and model-based software engineering methods for the special interest group Enterprise Modelling and Information Systems Architectures (SIG-EMISA) is discussed.;Gesellschaft fur Informatik (GI);Conference Proceeding;Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI);2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85127172570
307;Enabling Cross-Domain Modeling of Complex Autonomous Vehicles in System-of-Systems Architectures: A Model-Based System Specification for the Development of Complex Automotive Architectures;The engineering of vehicular systems is becoming increasingly difficult, mainly due to the ongoing integration of cyber-physical systems (CPS) aiming to automate difficult tasks or provide additional features to drivers. This automation potential leads to increasing complexity when engineering the vehicle itself or its subcomponents. In particular the development of a future-oriented kind of mobility, namely, connected autonomous vehicles (CAVs), is accompanied by new challenges, leading back to the different domains to be considered. To cope with this complexity and enable the mutual engineering of vehicular embedded systems, the Software Platform Embedded Systems (SPES) framework provides viewpoints and hierarchy layers in the shape of a matrix. However, to address all domains considered during the development of CAVs, the SPES methodology lacks specifications of how to model such vehicles across multiple domains, which impede its utilization in actual industrial projects. Thus, to deal with the mentioned issues, this article introduces an architecture framework enabling model-based systems engineering (MBSE) of CAVs across multiple domains. This includes a domain-specific reference architecture mapping, a particular development process, a detailed architecture definition, and a corresponding modeling approach. Subsequently, the resulting methodology is then evaluated for applicability using a real-world case study on the charging process of an electric vehicle (EV). The outcome of this article will thereby increase the usability of the SPES framework for industrial projects on the one hand and counteract the increasing complexity when engineering vehicular systems on the other hand.;SAE International;Journal;SAE International Journal of Connected and Automated Vehicles;2023-01-05;https://api.elsevier.com/content/abstract/scopus_id/85148102939
308;Model-based systems engineering: Motivation, current status, and research opportunities;As systems continue to grow in scale and complexity, the Systems Engineering community has turned to Model-Based Systems Engineering (MBSE) to manage complexity, maintain consistency, and assure traceability during system development. It is different from “engineering with models,” which has been a common practice in the engineering profession for decades. MBSE is a holistic, systems engineering approach centered on the evolving system model, which serves as the “sole source of truth” about the system. It comprises system specification, design, validation, and configuration management. Even though MBSE is beginning to see a fair amount of use in multiple industries, specific advances are needed on multiple fronts to realize its full benefits. This paper discusses the motivation for MBSE, and its current state of maturity. It presents systems modeling methodologies and the role of ontologies and metamodels in MBSE. It presents model-based verification and validation (V&V) as an example of MBSE use. An illustrative example of the use of MBSE for design synthesis is presented to demonstrate an important MBSE capability. The paper concludes with a discussion of challenges to widescale adoption and offers promising research directions to fully realize the potential benefits of MBSE.;John Wiley and Sons Inc.P.O.Box 18667NewarkNJ 07191-8667;Journal;Systems Engineering;2018-05-01;https://api.elsevier.com/content/abstract/scopus_id/85046694426
309;Model-Driven Development of a Digital Twin for Injection Molding;Digital Twins (DTs) of Cyber-Physical Production Systems (CPPSs) enable the smart automation of production processes, collection of data, and can thus reduce manual efforts for supervising and controlling CPPSs. Realizing DTs is challenging and requires significant efforts for their conception and integration with the represented CPPS. To mitigate this, we present an approach to systematically engineering DTs for injection molding that supports domain-specific customizations and automation of essential development activities based on a model-driven reference architecture. In this approach, reactive CPPS behavior is defined in terms of a Domain-Specific Language (DSL) for specifying events that occur in the physical system. The reference architecture connects to the CPPS through a novel DSL for representing OPC-UA bindings. We have evaluated this approach with a DT of an injection molding machine that controls the machine to optimize the Design of Experiment (DoE) parameters between experiment cycles before the products are molded. Through this, our reference implementation of the DT facilitates the time-consuming setup of a DT and the subsequent injection molding activities. Overall, this facilitates to systematically engineer digital twins with reactive behavior that help to optimize machine use.;Springer;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85086228557
310;Model-Driven Development of a Digital Twin for Injection Molding;Digital Twins (DTs) of Cyber-Physical Production Systems (CPPSs) enable the smart automation of production processes, collection of data, and can thus reduce manual efforts for supervising and controlling CPPSs. Realizing DTs is challenging and requires significant efforts for their conception and integration with the represented CPPS. To mitigate this, we present an approach to systematically engineering DTs for injection molding that supports domain-specific customizations and automation of essential development activities based on a model-driven reference architecture. In this approach, reactive CPPS behavior is defined in terms of a Domain-Specific Language (DSL) for specifying events that occur in the physical system. The reference architecture connects to the CPPS through a novel DSL for representing OPC-UA bindings. We have evaluated this approach with a DT of an injection molding machine that controls the machine to optimize the Design of Experiment (DoE) parameters between experiment cycles before the products are molded. Through this, our reference implementation of the DT facilitates the time-consuming setup of a DT and the subsequent injection molding activities. Overall, this facilitates to systematically engineer digital twins with reactive behavior that help to optimize machine use.;Springer;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85086228557
311;Model-Driven Development of a Digital Twin for Injection Molding;Digital Twins (DTs) of Cyber-Physical Production Systems (CPPSs) enable the smart automation of production processes, collection of data, and can thus reduce manual efforts for supervising and controlling CPPSs. Realizing DTs is challenging and requires significant efforts for their conception and integration with the represented CPPS. To mitigate this, we present an approach to systematically engineering DTs for injection molding that supports domain-specific customizations and automation of essential development activities based on a model-driven reference architecture. In this approach, reactive CPPS behavior is defined in terms of a Domain-Specific Language (DSL) for specifying events that occur in the physical system. The reference architecture connects to the CPPS through a novel DSL for representing OPC-UA bindings. We have evaluated this approach with a DT of an injection molding machine that controls the machine to optimize the Design of Experiment (DoE) parameters between experiment cycles before the products are molded. Through this, our reference implementation of the DT facilitates the time-consuming setup of a DT and the subsequent injection molding activities. Overall, this facilitates to systematically engineer digital twins with reactive behavior that help to optimize machine use.;Springer;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85086228557
312;Model-driven digital twin construction: Synthesizing the integration of cyber-physical systems with their information systems;Digital twins emerge in many disciplines to support engineering, monitoring, controlling, and optimizing cyber-physical systems, such as airplanes, cars, factories, medical devices, or ships. There is an increasing demand to create digital twins as representation of cyber-physical systems and their related models, data traces, aggregated data, and services. Despite a plethora of digital twin applications, there are very few systematic methods to facilitate the modeling of digital twins for a given cyber-physical system. Existing methods focus only on the construction of specific digital twin models and do not consider the integration of these models with the observed cyber-physical system. To mitigate this, we present a fully model-driven method to describe the software of the cyber-physical system, its digital twin information system, and their integration. The integration method relies on MontiArc models of the cyber-physical system's architecture and on UML/P class diagrams from which the digital twin information system is generated. We show the practical application and feasibility of our method on an IoT case study. Explicitly modeling the integration of digital twins and cyber-physical systems eliminates repetitive programming activities and can foster the systematic engineering of digital twins.;Association for Computing Machinery, Inc;Conference Proceeding;Proceedings - 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS 2020;2020-10-16;https://api.elsevier.com/content/abstract/scopus_id/85096992990
313;Model-driven digital twin construction: Synthesizing the integration of cyber-physical systems with their information systems;Digital twins emerge in many disciplines to support engineering, monitoring, controlling, and optimizing cyber-physical systems, such as airplanes, cars, factories, medical devices, or ships. There is an increasing demand to create digital twins as representation of cyber-physical systems and their related models, data traces, aggregated data, and services. Despite a plethora of digital twin applications, there are very few systematic methods to facilitate the modeling of digital twins for a given cyber-physical system. Existing methods focus only on the construction of specific digital twin models and do not consider the integration of these models with the observed cyber-physical system. To mitigate this, we present a fully model-driven method to describe the software of the cyber-physical system, its digital twin information system, and their integration. The integration method relies on MontiArc models of the cyber-physical system's architecture and on UML/P class diagrams from which the digital twin information system is generated. We show the practical application and feasibility of our method on an IoT case study. Explicitly modeling the integration of digital twins and cyber-physical systems eliminates repetitive programming activities and can foster the systematic engineering of digital twins.;Association for Computing Machinery, Inc;Conference Proceeding;Proceedings - 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS 2020;2020-10-16;https://api.elsevier.com/content/abstract/scopus_id/85096992990
314;Model-driven engineering for low-code ground support equipment configuration and automatic test procedures definition;Space domain systems must go through different types of ground testing. For system-level black-box functional testing, ground support equipment is built ad hoc, customized for each different mission. Building any of this specific equipment involves considerable engineering effort that can be diluted using techniques that allow reusing configurations of the test setup environment without recodification. These techniques can be merged into a hierarchical checking process based on independent filters to compare the received outputs with the expected ones. The hierarchical checking allows the separate definition of several layers or levels of validation, from the lowest protocol packet levels to the logical abstractions at the highest application level. This paper introduces a solution based on Model-Driven Engineering for Low-Code Ground Support Equipment. It uses the abovementioned mechanisms to reduce the effort to develop and customize ground support systems for different missions. This solution is integrated within an environment called MASSIVA, which allows the automatic configuration and definition of system-level test procedures. This environment has been used in the software verification and validation process of the Instrument Control Unit of the Energetic Particle Detector on board Solar Orbiter.;Elsevier Ltd;Journal;Acta Astronautica;2023-10-01;https://api.elsevier.com/content/abstract/scopus_id/85164275250
315;Model-driven engineering for mobile robotic systems: a systematic mapping study;Mobile robots operate in various environments (e.g. aquatic, aerial, or terrestrial), they come in many diverse shapes and they are increasingly becoming parts of our lives. The successful engineering of mobile robotics systems demands the interdisciplinary collaboration of experts from different domains, such as mechanical and electrical engineering, artificial intelligence, and systems engineering. Research and industry have tried to tackle this heterogeneity by proposing a multitude of model-driven solutions to engineer the software of mobile robotics systems. However, there is no systematic study of the state of the art in model-driven engineering (MDE) for mobile robotics systems that could guide research or practitioners in finding model-driven solutions and tools to efficiently engineer mobile robotics systems. The paper is contributing to this direction by providing a map of software engineering research in MDE that investigates (1) which types of robots are supported by existing MDE approaches, (2) the types and characteristics of MRSs that are engineered using MDE approaches, (3) a description of how MDE approaches support the engineering of MRSs, (4) how existing MDE approaches are validated, and (5) how tools support existing MDE approaches. We also provide a replication package to assess, extend, and/or replicate the study. The results of this work and the highlighted challenges can guide researchers and practitioners from robotics and software engineering through the research landscape.;Springer Science and Business Media Deutschland GmbH;Journal;Software and Systems Modeling;2022-02-01;https://api.elsevier.com/content/abstract/scopus_id/85112060247
316;Collaborative Model-Driven Software Engineering — A systematic survey of practices and needs in industry;The engineering of modern software-intensive systems is carried out in collaboration among stakeholders with specialized expertise. The complexity of such systems often also necessitates employing more rigorous approaches, such as Model-Driven Software Engineering (MDSE). Collaborative MDSE is the combination of the two disciplines, with its specific opportunities and challenges. The rapid expansion and maturation of the field started attracting tool builders from outside of academia. However, available systematic studies on collaborative MDSE focus exclusively on mapping academic research and fail to identify how academic research aligns with industry practices and needs. To address this shortcoming, we have carried out a mixed-method survey on the practices and needs concerning collaborative MDSE. First, we carried out a qualitative survey in two focus group sessions, interviewing seven industry experts. Second, based on the results of the interviews, we constructed a questionnaire and carried out a questionnaire survey with 41 industry expert participants. In this paper, we report the results of our study, investigate the alignment of academic research with the needs of practitioners, and suggest directions on research and development of the supporting techniques of collaborative MDSE.;Elsevier Inc.;Journal;Journal of Systems and Software;2023-05-01;https://api.elsevier.com/content/abstract/scopus_id/85147541731
317;Collaborative Model-Driven Software Engineering — A systematic survey of practices and needs in industry;The engineering of modern software-intensive systems is carried out in collaboration among stakeholders with specialized expertise. The complexity of such systems often also necessitates employing more rigorous approaches, such as Model-Driven Software Engineering (MDSE). Collaborative MDSE is the combination of the two disciplines, with its specific opportunities and challenges. The rapid expansion and maturation of the field started attracting tool builders from outside of academia. However, available systematic studies on collaborative MDSE focus exclusively on mapping academic research and fail to identify how academic research aligns with industry practices and needs. To address this shortcoming, we have carried out a mixed-method survey on the practices and needs concerning collaborative MDSE. First, we carried out a qualitative survey in two focus group sessions, interviewing seven industry experts. Second, based on the results of the interviews, we constructed a questionnaire and carried out a questionnaire survey with 41 industry expert participants. In this paper, we report the results of our study, investigate the alignment of academic research with the needs of practitioners, and suggest directions on research and development of the supporting techniques of collaborative MDSE.;Elsevier Inc.;Journal;Journal of Systems and Software;2023-05-01;https://api.elsevier.com/content/abstract/scopus_id/85147541731
318;Modeling and Analyzing MAPE-K Feedback Loops for Self-Adaptation;The MAPE-K (Monitor-Analyze-Plan-Execute over a shared Knowledge) feedback loop is the most influential reference control model for autonomic and self-adaptive systems. This paper presents a conceptual and methodological framework for formal modeling, validating, and verifying distributed self-adaptive systems. We show how MAPE-K loops for self adaptation can be naturally specified in an abstract stateful language like Abstract State Machines. In particular, we exploit the concept of multi-agent Abstract State Machines to specify decentralized adaptation control by using MAPE computations. We support techniques for validating and verifying adaptation scenarios, and getting feedback of the correctness of the adaptation logic as implemented by the MAPE-K loops. In particular, a verification technique based on meta-properties is proposed to allow discovering unwanted interferences between MAPE-K loops at the early stages of the system design. As a proof-of concepts, we model and analyze a traffic monitoring system.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 10th International Symposium on Software Engineering for Adaptive and Self-Managing Systems, SEAMS 2015;2015-08-12;https://api.elsevier.com/content/abstract/scopus_id/84953309690
319;Modeling language variability with reusable language components;Proliferation of modeling languages has produced a great variety of similar languages whose individual maintenance is challenging and costly. Reusing the syntax and semantics of modeling languages and their heterogeneous constituents, however, is rarely systematic. Current research on modeling language reuse focuses on reusing abstract syntax in form of metamodel parts. Systematic reuse of static and dynamic semantics is yet to be achieved. We present an approach to compose syntax and semantics of independently developed modeling languages through language product lines and derive new stand-alone language products. Using the MontiCore language workbench, we implemented a mechanism to compose language syntaxes and the realization of their semantics in form of template-based code generators according to language product line configurations. Leveraging variability of product lines greatly facilitates reusing modeling language and alleviates their proliferation.;Association for Computing Machineryacmhelp@acm.org;Conference Proceeding;ACM International Conference Proceeding Series;2018-08-20;https://api.elsevier.com/content/abstract/scopus_id/85055591621
320;Modeling mechanical functional architectures in SysML;Innovations in Cyber-Physical System (CPS) are driven by functionalities and features. Mechanical Engineering, on the other hand, is mainly concerned with the physical product architecture, i.e., the hierarchical arrangement of physical components and assemblies that forms the product, which is not explicitly linked to these functions. A holistic model-driven engineering approach for CPS, therefore, needs to bridge the gap between functions and the physical product architecture to enable agile development driven by automation. In the theoretical field of mechanical design methodology, functional architectures describe the functionality of the system under development as a hierarchical structure. However, in practice, these are typically not considered let alone modeled. Existing approaches utilizing mechanical functional architectures, however, do not formalize the relation between the functional architecture and the geometric design. Therefore, we conceived a meta-model that defines modeling-languages for modeling functional architectures of mechanical systems and physical solutions, i.e., interconnections of physical effects and geometries, as refinements of the functional components. We have encoded the meta-model as a SysML profile and applied it within an interdisciplinary, industrial project to model an automotive coolant pump. Our contribution signposts the potential of functional structures to not only bridge the gap between function and geometry in mechanics but also to integrate the heterogeneous domains participating in CPS engineering.;Association for Computing Machinery, Inc;Conference Proceeding;Proceedings - 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS 2020;2020-10-16;https://api.elsevier.com/content/abstract/scopus_id/85096973676
321;Assessing the specification of modelling language semantics: a study on UML PSSM;Modelling languages play a central role in developing complex, critical systems. A precise, comprehensible, and high-quality modelling language specification is essential to all stakeholders using, implementing, or extending the language. Many good practices can be found that improve the understandability or consistency of the languages’ semantics. However, designing a modelling language intended for a large audience is still challenging. In this paper, we investigate the challenges and typical issues with assessing the specifications of behavioural modelling language semantics. Our key insight is that the various stakeholder’s understandings of the language’s semantics are often misaligned, and the semantics defined in various artefacts (simulators, test suites) are inconsistent. Therefore assessment of semantics should focus on identifying and resolving these inconsistencies. To illustrate these challenges and techniques, we assessed parts of a state-of-the-art specification for a general-purpose modelling language, the Precise Semantics of UML State Machines (PSSM). We reviewed the text of the specification, analysed and executed PSSM’s conformance test suite, and categorised our experiences according to questions generally relevant to modelling languages. Finally, we made recommendations for improving the development of future modelling languages by representing the semantic domain and traces more explicitly, applying diverse test design techniques to obtain conformance test suites, and using various tools to support early-phase language design.;Springer;Journal;Software Quality Journal;2023-06-01;https://api.elsevier.com/content/abstract/scopus_id/85149045787
322;Monitoring CPS at runtime - A case study in the UAV domain;Unmanned aerial vehicles (UAVs) are becoming increasingly pervasive in everyday life, supporting diverse use cases such as aerial photography, delivery of goods, or disaster reconnaissance and management. UAVs are cyber-physical systems (CPS): they integrate computation (embedded software and control systems) with physical components (the UAVs flying in the physical world). UAVs in particular and CPS in general require monitoring capabilities to detect and possibly mitigate erroneous and safety-critical behavior at runtime. Existing monitoring approaches mostly do not adequately address UAV CPS characteristics such as the high number of dynamically instantiated components, the tight int elements, and the massive amounts of data that need to be processed. In this paper we report results of a case study on monitoring in UAVs. We discuss CPS-specific monitoring challenges and present a prototype we implemented by extending \reminds, a framework for software monitoring so far mainly used in the domain of metallurgical plants. Additionally, we demonstrate the applicability and scalability of our approach by monitoring a real control and management system for UAVs in simulations with up to 30 drones flying in an urban area.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 44th Euromicro Conference on Software Engineering and Advanced Applications, SEAA 2018;2018-10-18;https://api.elsevier.com/content/abstract/scopus_id/85056510669
323;MTComm based virtualization and integration of physical machine operations with digital-twins in cyber-physical manufacturing cloud;Digital-Twins simulate physical world objects by creating 'as-is' virtual images in a cyberspace. In order to create a well synchronized digital-twin simulator in manufacturing, information and activities of a physical machine need to be virtualized. Many existing digital-twins stream read-only data of machine sensors and do not incorporate operations of manufacturing machines through Internet. In this paper, a new method of virtualization is proposed to integrate machining data and operations into the digital-twins using Internet scale machine tool communication method. A fully functional digital-twin is implemented in CPMC testbed using MTComm and several manufacturing application scenarios are developed to evaluate the proposed method and system. Performance analysis shows that it is capable of providing data-driven visual monitoring of a manufacturing process and performing manufacturing operations through digital twins over the Internet. Results of the experiments also shows that the MTComm based digital twins have an excellent efficiency.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 5th IEEE International Conference on Cyber Security and Cloud Computing and 4th IEEE International Conference on Edge Computing and Scalable Cloud, CSCloud/EdgeCom 2018;2018-07-27;https://api.elsevier.com/content/abstract/scopus_id/85051552529
324;Multi-paradigm modelling for cyber–physical systems: a descriptive framework;The complexity of cyber–physical systems (CPSs) is commonly addressed through complex workflows, involving models in a plethora of different formalisms, each with their own methods, techniques, and tools. Some workflow patterns, combined with particular types of formalisms and operations on models in these formalisms, are used successfully in engineering practice. To identify and reuse them, we refer to these combinations of workflow and formalism patterns as modelling paradigms. This paper proposes a unifying (Descriptive) Framework to describe these paradigms, as well as their combinations. This work is set in the context of Multi-Paradigm Modelling (MPM), which is based on the principle to model every part and aspect of a system explicitly, at the most appropriate level(s) of abstraction, using the most appropriate modelling formalism(s) and workflows. The purpose of the Descriptive Framework presented in this paper is to serve as a basis to reason about these formalisms, workflows, and their combinations. One crucial part of the framework is the ability to capture the structural essence of a paradigm through the concept of a paradigmatic structure. This is illustrated informally by means of two example paradigms commonly used in CPS: Discrete Event Dynamic Systems and Synchronous Data Flow. The presented framework also identifies the need to establish whether a paradigm candidate follows, or qualifies as, a (given) paradigm. To illustrate the ability of the framework to support combining paradigms, the paper shows examples of both workflow and formalism combinations. The presented framework is intended as a basis for characterisation and classification of paradigms, as a starting point for a rigorous formalisation of the framework (allowing formal analyses), and as a foundation for MPM tool development.;Springer Science and Business Media Deutschland GmbH;Journal;Software and Systems Modeling;2021-06-01;https://api.elsevier.com/content/abstract/scopus_id/85107508780
325;Multisource Model-Driven Digital Twin System of Robotic Assembly;"The digital twin technology effectively fuels improvements in the quality and efficiency of robotic assembly, especially for sophisticated processes. High-quality digitalization requires a comprehensive description and real-time rendering of system, which are challenging. This article aims to demonstrate a novel multisource model-driven digital twin system, which is based on the geometric, physics, and sequential rule descriptions for producing a precise and real-time simulation of a robotic assembly system. In our system, the digital counterpart rendered with virtual reality technology is created and updated by the real environment information. A 3-D graphic model is reconstructed first using the geometric information of surroundings captured by the depth sensor. During interaction, a fast and efficient approach is proposed to generate the contact force and render the object deformation in the virtual environment. The virtual space also provides the sequential rule that is based on the danger field, which helps to constrain the operation of digital twin. At last, the experimental platform is established in which the virtual space is at an update rate of 100 Hz, while the automatic sorting task is performed and verified; the results show the effectiveness and applicability of the method to digital twin system.";Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Systems Journal;2021-03-01;https://api.elsevier.com/content/abstract/scopus_id/85102015160
326;Observe locally, infer globally: A space-time MRF for detecting abnormal activities with incremental updates;We propose a space-time Markov Random Field (MRF) model to detect abnormal activities in video. The nodes in the MRF graph correspond to a grid of local regions in the video frames, and neighboring nodes in both space and time are associated with links. To learn normal patterns of activity at each local node, we capture the distribution of its typical optical flow with a Mixture of Probabilistic Principal Component Analyzers. For any new optical flow patterns detected in incoming video clips, we use the learned model and MRF graph to compute a maximum a posteriori estimate of the degree of normality at each local node. Further, we show how to incrementally update the current model parameters as new video observations stream in, so that the model can efficiently adapt to visual context changes over a long period of time. Experimental results on surveillance videos show that our space-time MRF model robustly detects abnormal activities both in a local and global sense: not only does it accurately localize the atomic abnormal ac- tivities in a crowded video, but at the same time it captures the global-level abnormalities caused by irregular interactions between local activities. ©2009 IEEE.;IEEE Computer Society;Conference Proceeding;2009 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2009;2009-01-01;https://api.elsevier.com/content/abstract/scopus_id/70450169881
327;Ontology-Based Pattern for System Engineering;"System engineering is a multi-domain process that encompasses the design, realization, delivery, and management of complex systems or system of systems. The Model-Based System Engineering (MBSE) approach is commonly accepted by the system engineers community that depends up on the creation of centralized models to produce the expected deliverables. Standard metamodels such as UML, SysML, or NMM/NAF are typically used to describe the relevant concepts for these descriptive models. However, there is a need to also use domain specific languages (aka ontologies) to ease the communication between all the system engineering stakeholders. The author proposed an approach in previous works to reconcile the usage of complex but necessary predefined metamodels with dedicated ontologies. This solution speeds upthe creation of model-based documents. However, the implementation of such approach revealed that the modeling users are expecting a solution in-between the frozen metamodel andthe specific ontology approach; a set of predefined modeling features addressing recurrent engineering concerns completed by project specific concerns. Among the recurrent concerns there are the requirement elicitation, the functional analysis, the system interface definitions.... This paper shows how this balance can be addressed through ontology-based patterns developed as modular modeling features blocks. Since these blocks are applied in the context of model-based system engineering we also named them MBSE Enablers. The paper proposes a solution to a new issue raised by this pattern reuse expectations; a dynamic mapping is required between the building blocks and the existing models. The proposed method is based on the category theory which brings a theoretical foundation to ensure models are correctly managed. The global idea of the extended approach is to speed up again the modeling tool customizations letting the system engineers focusing as far as possible on the systems to be designed.";Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - ACM/IEEE 20th International Conference on Model Driven Engineering Languages and Systems, MODELS 2017;2017-11-07;https://api.elsevier.com/content/abstract/scopus_id/85040616641
328;Cybersecurity in Industrial Control Systems: An integration of information technology and operational technology;"The Industrial Control Systems (ICS) consists of supervisory control and data acquisition (SCADA) systems, distributed control systems (DCS), safety instrumented systems (SIS), and other control system configurations such as programmable logic controllers (PLC). These systems are vulnerable to cyber-attacks. Security against cyber-attacks is becoming more crucial for the ICS industries. The cyber-attacks could be carried out simultaneously at many SCADA, DCS, and SIS systems. The researcher deployed NIST.SP.800-61r2, NIST.SP.800-82r2, IEC 62443 series, and Purdue Enterprise Reference Architecture (PERA) as a guide to implementing cybersecurity approaches to protect them from these threats. The ten industrial plants used cases such as chemical processing, power generation, oil and gas processing, and petroleum processing have been investigated subject to the four main types of vulnerability in cyber security; network; operating system; human; and process vulnerabilities. This research approach is intended to lead to innovative, game-changing capabilities for an incident response plan (IRP) according to cybersecurity Spectrum Security SL2 and SL4 models for the critical ICS.";IEEE Computer Society;Conference Proceeding;IECON Proceedings (Industrial Electronics Conference);2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85143886882
329;Overview of Fault Diagnosis Methods based on Petri Net Models;Fault diagnosis of discrete-event systems has received a lot of attention in the literature since the early 90s. At the beginning, the problem has been approached using the framework of finite state automata and regular languages. Recently, the problem has been tackled within the Petri nets (PNs) framework. This paper overviews the main ideas behind the fault diagnosis approaches based on PNs.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2014 European Control Conference, ECC 2014;2014-07-22;https://api.elsevier.com/content/abstract/scopus_id/84911485987
330;Photovoltaics and wind status in the European Union after the Paris Agreement;Over the last decade, the utilisation of renewable energy in the electricity sector, especially from solar and wind sources, is growing at a much faster pace than the rest of the economy in Europe and world-wide. The significant cost reduction of solar PV and wind power during this time and their zero fuel cost volatility have increased their attractiveness. Between 2005 and 2015, the installed solar PV power in Europe as increased 50 fold to reach 95 GW and wind power has increased three and a half times to 142 GW at the end of 2015. The fact that the Paris Agreement went into force on 4 November 2016 will be another accelerating factor for the use of electricity from renewable energy sources. This paper shows the deployment of photovoltaics and wind power in the European Union and the policy drivers behind this development. So far, the European Union is the largest economy with a legally binding target to reach 27% of its energy consumption from renewable energy sources by 2030. The data used for this publication are collected on a regular basis from statistical offices, stock exchange filings, press releases, public and commercial studies. The results are cross checked with personal communications and on-site visits as well as meetings with government officials and policymakers. In order to provide a timely coverage of the dynamic increase of solar and wind power this use of grey data is necessary. In 2016 slightly more than 12% of the Union's electricity demand was covered by solar and wind, but in order to reach the 2030 target a tripling of this contribution is needed.;Elsevier Ltd;Journal;Renewable and Sustainable Energy Reviews;2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85021447290
331;Plant model-based fault detection during aircraft takeoff using non-deterministic finite-state automata;In this note, the application of a plant model-based fault detection method for nonlinear control systems on aircraft takeoff is introduced. This method utilizes non-deterministic finite-state automata, which approximate the fault-free dynamics of the plant. The aforementioned automaton is computed in a preliminary step while during evolution of the plant the automaton is continually evaluated to detect discrepancies between the actual and the nominal dynamics. In this way the fault detection module itself can be implemented on simpler hardware on board of the plant. Moreover, an implementation technique is presented that allows the use of the proposed fault detection method when the plant dynamics is given only by means of a graphical programming script. The great potential and practicality of the used method are demonstrated on a simulated takeoff manoeuvre of a battery-electrically driven aircraft.;MDPI Multidisciplinary Digital Publishing Instituterasetti@mdpi.com;Journal;Aerospace;2020-08-01;https://api.elsevier.com/content/abstract/scopus_id/85089848595
332;Pondering on the key functionality of model driven development tools: The case of mendix;Model Driven Architectures and Model Driven Development (MDD) have been used in information system (IS) development projects for almost a decade. While the methodological support for the MDD process is important, the success of a project taking the model driven approach to development also heavily depends on the tool. The tool simply needs to support a set of key functionalities, such as an appropriate level of model abstraction, the refinement of models and finally the execution of models. In this paper we analyze a new MDD tool, namely Mendix, with respect to a number of functionality areas needed to achieve success in a project and capitalize on the benefits of MDD. Our findings are that Mendix use a well selected set of models and that these models are well integrated and suitable for the construction of small systems. Based on the key functionality areas we also point out the weaknesses of the tool. © 2010 Springer-Verlag Berlin Heidelberg.;Springer Verlagservice@springer.de;Book Series;Lecture Notes in Business Information Processing;2010-01-01;https://api.elsevier.com/content/abstract/scopus_id/78349290761
333;Positioning of the low-code movement within the field of model-driven engineering;Low-code is being promoted as the key infrastructure for the digital transformation of our society. But is there something fundamentally new behind the low-code movement? How does it relate to other concepts like Model-Driven Engineering or Model-Driven development? And what are the implications for researchers in the modeling community?. This position paper tries to shed some light on these issues.;Association for Computing Machinery, Inc;Conference Proceeding;Proceedings - 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS-C 2020 - Companion Proceedings;2020-10-16;https://api.elsevier.com/content/abstract/scopus_id/85096807213
334;Positioning of the low-code movement within the field of model-driven engineering;Low-code is being promoted as the key infrastructure for the digital transformation of our society. But is there something fundamentally new behind the low-code movement? How does it relate to other concepts like Model-Driven Engineering or Model-Driven development? And what are the implications for researchers in the modeling community?. This position paper tries to shed some light on these issues.;Association for Computing Machinery, Inc;Conference Proceeding;Proceedings - 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS-C 2020 - Companion Proceedings;2020-10-16;https://api.elsevier.com/content/abstract/scopus_id/85096807213
335;Possibility of Digital Twins Technology for Improving Efficiency of the Branded Service System;Nowadays, the concept of digital economy along with market competition requires constant modification of current business models and logistic services. Since branded service companies directly interact with customers, the efficiency of the vehicle maintenance strongly influences on the company's level of service. Digital Twins helps to track data of failures throughout the whole transportation and to predict failures of each particular vehicle and plan the full capacity. By the example of the KAMAZ company we analyze the efficiency of such technology for the final customer. The comparison of the predicted number of failures, obtained from Digital Twin, shows a high level of flexibility that could be achieved with such a system, showing a potential towards leasing market.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2018 Global Smart Industry Conference, GloSIC 2018;2018-12-07;https://api.elsevier.com/content/abstract/scopus_id/85060671556
336;A machine learning digital twin approach for critical process parameter prediction in a catalyst manufacturing line;Digital twins (DTs) are rapidly changing how manufacturing companies leverage the large volumes of data they generate daily to gain a competitive advantage and optimize their supply chains. When coupled with recent developments in machine learning (ML), DTs have the potential to generate invaluable insights for process manufacturing companies to help them optimize their manufacturing processes. However, this potential has yet to be fully exploited due to the challenges that process manufacturing companies face in developing and implementing DTs in their organizations. Although DTs are receiving increasing attention in both industry and academia, there is limited literature on how to apply them in the process industry. To address this gap, this paper presents a framework for developing ML-based DTs to predict critical process parameters in real time. The proposed framework is tested through a case study at an international process manufacturing company in which it was used to collect and process plant data, build accurate predictive models for two critical process parameters, and develop a DT application to visualize the models’ predictions. The case study demonstrated the usefulness of the proposed DT–ML framework in the sense that it provided the company with more accurate predictions than the models it previously applied. The study provides insights into the value of applying ML-based DT in the process industry and sheds light on some of the challenges associated with the application of this technology.;Elsevier B.V.;Journal;Computers in Industry;2023-10-01;https://api.elsevier.com/content/abstract/scopus_id/85164238444
337;Process-aware digital twin cockpit synthesis from event logs;The engineering of digital twins and their user interaction parts with explicated processes, namely process-aware digital twin cockpits (PADTCs), is challenging due to the complexity of the systems and the need for information from different disciplines within the engineering process. Therefore, it is interesting to investigate how to facilitate their engineering by using already existing data, namely event logs, and reducing the number of manual steps for their engineering. Current research lacks systematic, automated approaches to derive process-aware digital twin cockpits even though some helpful techniques already exist in the areas of process mining and software engineering. Within this paper, we present a low-code development approach that reduces the amount of hand-written code needed and uses process mining techniques to derive PADTCs. We describe what models could be derived from event log data, which generative steps are needed for the engineering of PADTCs, and how process mining could be incorporated into the resulting application. This process is evaluated using the MIMIC III dataset for the creation of a PADTC prototype for an automated hospital transportation system. This approach can be used for early prototyping of PADTCs as it needs no hand-written code in the first place, but it still allows for the iterative evolvement of the application. This empowers domain experts to create their PADTC prototypes.;Elsevier Ltd;Journal;Journal of Computer Languages;2022-06-01;https://api.elsevier.com/content/abstract/scopus_id/85131671533
338;Product avatar as digital counterpart of a physical individual product: Literature review and implications in an aircraft;'Product Avatar' and 'Product Digital Twin' are the terms used currently to refer to the product digital counterpart of a physical product. Both terms derived from different perspectives and from different initial objectives. With a specific focus on the aerospace sector, this communication is a starting point and reviews the different topics involved in the creation of an aircraft digital counterpart, i.e. product identification, product lifecycle, product information, product configuration, product models, and software applications involved. Then, a specific section presents both approaches, 'product avatar' and 'product digital twin', together with the currently published related works. The paper ends with a discubion of the implications of creating an aircraft avatar with an industrialization-oriented perspective.;IOS Press BV;Conference Proceeding;Advances in Transdisciplinary Engineering;2015-01-01;https://api.elsevier.com/content/abstract/scopus_id/84975691204
339;Digital Twin-based Quality Management Method for the Assembly Process of Aerospace Products with the Grey-Markov Model and Apriori Algorithm;The assembly process of aerospace products such as satellites and rockets has the characteristics of single- or small-batch production, a long development period, high reliability, and frequent disturbances. How to predict and avoid quality abnormalities, quickly locate their causes, and improve product assembly quality and efficiency are urgent engineering issues. As the core technology to realize the integration of virtual and physical space, digital twin (DT) technology can make full use of the low cost, high efficiency, and predictable advantages of digital space to provide a feasible solution to such problems. Hence, a quality management method for the assembly process of aerospace products based on DT is proposed. Given that traditional quality control methods for the assembly process of aerospace products are mostly post-inspection, the Grey-Markov model and T-K control chart are used with a small sample of assembly quality data to predict the value of quality data and the status of an assembly system. The Apriori algorithm is applied to mine the strong association rules related to quality data anomalies and uncontrolled assembly systems so as to solve the issue that the causes of abnormal quality are complicated and difficult to trace. The implementation of the proposed approach is described, taking the collected centroid data of an aerospace product’s cabin, one of the key quality data in the assembly process of aerospace products, as an example. A DT-based quality management system for the assembly process of aerospace products is developed, which can effectively improve the efficiency of quality management for the assembly process of aerospace products and reduce quality abnormalities.;Springer;Journal;Chinese Journal of Mechanical Engineering (English Edition);2022-12-01;https://api.elsevier.com/content/abstract/scopus_id/85135783204
340;Reduced-order model based temperature control of induction brazing process;Accurate temperature control is an important part of an induction brazing process, because of a small difference between melting points of aluminum and soldering material. However, direct measurement of the local temperature at the spot of brazing is not possible in a production line. This temperature can be calculated from the results of indirect measurements and the physical model of the system. This paper shows a novel application of model order reduction in case of online temperature measurement. Three different controlling strategies are examined, the results proved that the more sophisticated, program controlled or mixed strategies need higher-order MOR models to accurately solve the problem. The presented, fourth degree meta-model provides sufficiently accurate results, which very fast and may be implemented into a micro-controller.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2019 Electric Power Quality and Supply Reliability Conference and 2019 Symposium on Electrical Engineering and Mechatronics, PQ and SEEM 2019;2019-06-01;https://api.elsevier.com/content/abstract/scopus_id/85072759835
341;Reliability Evaluation for Chain Routing Protocols in Wireless Sensor Networks Using Reliability Block Diagram;There are many different fields in which wireless sensor networks (WSNs) can be used such as environmental monitoring, healthcare, military, and security. Due to the vulnerability of WSNs, reliability is a critical concern. Evaluation of a WSN’s reliability is essential during the design process and when evaluating WSNs’ performance. Current research uses the reliability block diagram (RBD) technique, based on component functioning or failure state, to evaluate reliability. In this study, a new methodology-based RBD, to calculate the energy reliability of various proposed chain models in WSNs, is presented. A new method called D-Chain is proposed, to form the chain starting from the nearest node to the base station (BS) and to choose the chain head based on the minimum distance D, and Q-Chain is proposed, to form the chain starting from the farthest node from the BS and select the head based on the maximum weight, Q. Each chain has three different arrangements: single chain/single-hop, multi-chain/single-hop, and multi-chain/multi-hop. Moreover, we applied dynamic leader nodes to all of the models mentioned. The simulation results indicate that the multi Q-Chain/single-hop has the best performance, while the single D-Chain has the least reliability in all situations. In the grid scenario, multi Q-Chain/single-hop achieved better average reliability, 11.12 times greater than multi D-Chain/single-hop. On the other hand, multi Q-Chain/single-hop achieved 6.38 times better average reliability than multi D-Chain/single-hop, in a random scenario.;MDPI;Journal;Journal of Sensor and Actuator Networks;2023-04-01;https://api.elsevier.com/content/abstract/scopus_id/85153747793
342;ReMinds: A flexible runtime monitoring framework for systems of systems;Many software-intensive systems today can be characterized as systems of systems (SoS) comprising complex, interrelated, and heterogeneous systems. The behavior of SoS often only emerges at runtime due to complex interactions between the involved systems and their environment. It is thus necessary to determine unexpected behavior by monitoring SoS at runtime, i.e., collecting and analyzing events and data at different layers and levels of granularity. Existing monitoring approaches are often limited to individual systems, particular architectural styles, or technologies. In this paper we thus derive challenges for monitoring SoS based on an industrial case. We present a flexible framework adaptable to different system architectures and technologies. We discuss its capabilities for instrumenting systems, collecting and persisting events and data, checking constraints on events and data, and visualizing the systems' behavior to users. We demonstrate the framework's flexibility by tailoring and applying it to an industrial SoS and assessing its performance and scalability. Our results show that the framework is flexible and scalable for monitoring an industrial SoS with realistic event loads.;Elsevier Inc.usjcs@elsevier.com;Journal;Journal of Systems and Software;2016-02-01;https://api.elsevier.com/content/abstract/scopus_id/84937882015
343;Renewable energy emulation concepts for microgrids;This paper reviews the renewable energy systems emulators proposals for microgrid laboratory testing platforms. Four emulation conceptual levels are identified based on the literature analysis performed. Each of these levels is explained through a microgrid example, detailing its features and possibilities. Finally, an experimental microgrid, built based on emulators, is presented to exemplify the system performance.;Elsevier Ltd;Journal;Renewable and Sustainable Energy Reviews;2015-05-27;https://api.elsevier.com/content/abstract/scopus_id/84930200550
344;Representing Industrial Data Streams in Digital Twins using Semantic Labeling;Digital twins provide the opportunity to observe and simulate current and future behaviour of cyber-physical systems in a non-invasive way. At the same time, digital representations of real-world assets allow to compare multiple situations in parallel and to estimate effects of planned interventions. Such simulations can be used in cyper-physical systems to make predictions about the future and prevent failures. However, it is complex to build a model that accurately represents the real-world and connects real-world assets to technically-oriented data streams produced by these assets. In this paper, we present a novel approach to model socalled Industrial Data Streams. Such streams are produced by assets in the real world and are integrated on a messageoriented middleware. Streams are annotated using the concept of semantic labels, which allows to assign characteristics such as location or type of the underlying assets to data streams. Our contribution consists of a semantic schema representation that categorises similar data streams, allowing subscribers to consume similar data from multiple assets within a single data analytics pipeline. Therefore, our approach paves the way for a more intuitive management of digital twin representations from industrial assets.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2018 IEEE International Conference on Big Data, Big Data 2018;2019-01-22;https://api.elsevier.com/content/abstract/scopus_id/85062594541
345;Research on the virtual reality synchronization of workshop digital twin;Digital Twin (DT) has become the best link to connect the manufacturing physical world and the digital virtual world, and is an effective technical means to realize the interaction and integration between the physical world and the information world. Based on the intelligent workshop-based equipment, combined with the application of digital key technology, the workshop production line mainly performs virtual and real data synchronous communication and virtual and real mapping technology to realize the surreal virtual real-time digital simulation of the physical entity objects in the workshop. According to the actual application development, the virtual model of the intelligent workshop can be constructed internally, and a virtual model of the complete mapping can be constructed. At the same time, the various operating parameters and indicators of the product can be comprehensively supervised to realize the monitoring of the health status during the operation of the intelligent workshop.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings of 2019 IEEE 8th Joint International Information Technology and Artificial Intelligence Conference, ITAIC 2019;2019-05-01;https://api.elsevier.com/content/abstract/scopus_id/85071103625
346;Reshaping the Landscape of the Future: Software-Defined Manufacturing;We describe the concept of software-defined manufacturing, which divides the manufacturing ecosystem into software definition and physical manufacturing layers. Software-defined manufacturing allows better resource sharing and collaboration, and it has the potential to transform the existing manufacturing sector.;IEEE Computer Society;Trade Journal;Computer;2021-07-01;https://api.elsevier.com/content/abstract/scopus_id/85112695498
347;RESTful Industrial Communication with OPC UA;Representational state transfer (REST) is a wide-spread architecture style for decentralized applications. REST proposes the use of a fixed set of service interfaces to transfer heterogeneous resource representations instead of defining custom interfaces for individual applications. This paper explores the advantages of RESTful architectures, i.e., service-oriented software architectures comprised RESTful services, in industrial settings. These include communication advantages such as reduced communication overhead and the possibility to introduce caching layers, and system design advantages including stable service interfaces across applications and the use of resource-oriented information models in cyber-physical systems. Additionally, a RESTful extension to the open platform communications (OPC) unified architecture (OPC UA) binary protocol is proposed in order to leverage these advantages. It requires only minimal modifications to the existing OPC UA stacks and is fully backward compatible with the standard protocol. Performance benchmarks on industrial hardware show a throughput increase up to a factor of eight for short-lived interactions. This reduction of overhead is especially relevant for the use of OPC UA in the emerging Industrial Internet of Things.;IEEE Computer Societyhelp@computer.org;Journal;IEEE Transactions on Industrial Informatics;2016-10-01;https://api.elsevier.com/content/abstract/scopus_id/85012057836
348;Rigorous design of cyber-physical systems: Linking physicality and computation;"Cyber-physical systems have developed into a very active research field, with a broad range of challenges and research directions going from requirements, to implementation and simulation, as well as validation and verification to guarantee essential properties. In this survey paper, we focus exclusively on the following fundamental issue: how to link physicality and computation, continuous time-space dynamics with discrete untimed ones? We consider that cyber-physical system design flow involves the following three main steps: (1) cyber-physical systems modeling; (2) discretization for executability; and (3) simulation and implementation. We review—and strive to provide insight into possible approaches for addressing—the key issues, for each of these three steps.";Springer Verlagservice@springer.de;Journal;Software and Systems Modeling;2019-06-01;https://api.elsevier.com/content/abstract/scopus_id/85038123992
349;Robot online learning through digital twin experiments: A weightlifting project;This paper proposes and explores an approach in which robotics projects of novice engineering students focus on development of learning robots. We implemented a reinforcement learning scenario in which a humanoid robot learns to lift a weight of unknown mass through autonomous trial-and-error search. To expedite the process, trials of the physical robot are substituted by simulations with its virtual twin. The optimal parameters of the robot posture for executing the weightlifting task, found by analysis of the virtual trials, are transmitted to the robot through internet communication. The approach exposes students to the concepts and technologies of machine learning, parametric design, digital prototyping and simulation, connectivity and internet of things. Pilot implementation of the approach indicates its potential for teaching freshman and HS students, and for teacher education.;Springer;Book Series;Lecture Notes in Networks and Systems;2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85050462497
350;OpenRoACH: A durable open-source hexapedal platform with onboard robot operating system (ROS);OpenRoACH is a 15-cm 200-gram self-contained hexapedal robot with an onboard single-board computer. To our knowledge, it is the smallest legged robot with the capability of running the Robot Operating System (ROS) onboard. The robot is fully open sourced, uses accessible materials and off-the-shelf electronic components, can be fabricated with benchtop fast-prototyping machines such as a laser cutter and a 3D printer, and can be assembled by one person within two hours. Its sensory capacity has been tested with gyroscopes, accelerometers, Beacon sensors, color vision sensors, linescan sensors and cameras. It is low-cost within 150 including structure materials, motors, electronics, and a battery. The capabilities of OpenRoACH are demonstrated with multi-surface walking and running, 24-hour continuous walking burn-ins, carrying 200-gram dynamic payloads and 800-gram static payloads, and ROS control of steering based on camera feedback. Information and files related to mechanical design, fabrication, assembly, electronics, and control algorithms are all publicly available on https://wiki.eecs.berkeley.edu/biomimetics/Main/OpenRoACH.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - IEEE International Conference on Robotics and Automation;2019-05-01;https://api.elsevier.com/content/abstract/scopus_id/85071496807
351;Salesforce Platform Governance Method: A Guide to Governing Changes, Development, and Enhancements on the Salesforce Platform;Accelerate your Salesforce implementation to provide benefits to your business more rapidly while maintaining control and improving quality. Salesforce has become one of the most influential business tools in our modern age. What started as the world's most comprehensive customer relationship management (CRM) system available in the market place has now morphed over the years into an ecosystem of tools and services that enable you to run your entire business platform. This book gives you a method (a set of governance processes) that provides a complete view of how to govern and manage any Salesforce implementation. It breaks the architectural components of the Salesforce platform into manageable sections, allowing you to navigate and understand how to govern your Salesforce implementation in a consistent manner with an approach that is structured, repeatable, and clearly defined. Salesforce Platform Governance Method is divided into nine distinct phases which have been chosen based on how the Salesforce platform is architected. This is relevant today because every organization that implements Salesforce will face the same issues around governance, integration, development, and security and the majority of organizations will find, through trial and error, a solution to govern these components. This book will help Salesforce professionals and enterprise organizations as well as small and mid-sized businesses (SMBs) navigate these topics and ultimately have a successful and fully integrated, secure Salesforce implementation. What You Will Learn Govern the application architecture on the Salesforce platform, including general architecture, localization and global deployments, workflow and process, formulas and files, and social Govern the data architecture, including design and data optimization, performance, predictive and actual data volumes, and data movement Govern the identity and access management aspects of the application and Salesforce platform Govern the low-level platform capabilities delivered through Lightning, Visualforce, and Apex Handle community implementations that bring specific features into the Salesforce platform for consideration and governance Create checklists for the governance steps, laid out in the method, and for any tooling recommendations that can help simplify the process of governance Who This Book Is For People responsible for maintaining a Salesforce SaaS instance or developing changes for that Salesforce instance. Readers should have a basic understanding of the Salesforce platform and a desire to introduce a level of control around the changes being made, reduce issues on their Salesforce instance, and improve quality while increasing the throughput of changes they want to introduce into the platform.;Apress Media LLC;Book;Salesforce Platform Governance Method: a Guide to Governing Changes, Development, and Enhancements on the Salesforce Platform;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85166056695
352;Sars‐cov‐2 spread forecast dynamic model validation thorough digital twin approach, catalonia case study;The spread of the SARS‐CoV‐2 modeling is a challenging problem because of its complex nature and lack of information regarding certain aspects. In this paper, we explore a Digital Twin approach to model the pandemic situation in Catalonia. The Digital Twin is composed of three different dynamic models used to perform the validations by a Model Comparison approach. We detail how we use this approach to obtain knowledge regarding the effects of the nonpharmaceutical interventions and the problems we faced during the modeling process. We use Specification and Description Language (SDL) to represent the compartmental forecasting model for the SARS‐CoV‐2. Its graphical notation simplifies the different specialists’ understanding of the model hypotheses, which must be validated continuously following a Solution Validation approach. This model allows the successful forecasting of different scenarios for Catalonia. We present some formalization de-tails, discuss the validation process and present some results obtained from the validation model discussion, which becomes a digital twin of the pandemic in Catalonia.;MDPI AG;Journal;Mathematics;2021-07-02;https://api.elsevier.com/content/abstract/scopus_id/85111080660
353;Self-Adaptive Manufacturing with Digital Twins;Digital Twins are part of the vision of Industry 4.0 to represent, control, predict, and optimize the behavior of Cyber-Physical Production Systems (CPPSs). These CPPSs are long-living complex systems deployed to and configured for diverse environments. Due to specific deployment, configuration, wear and tear, or other environmental effects, their behavior might diverge from the intended behavior over time. Properly adapting the configuration of CPPSs then relies on the expertise of human operators. Digital Twins (DTs) that reify this expertise and learn from it to address unforeseen challenges can significantly facilitate self-adaptive manufacturing where experience is very specific and, hence, insufficient to employ deep learning techniques. We leverage the explicit modeling of domain expertise through case-based reasoning to improve the capabilities of Digital Twins for adapting to such situations. To this effect, we present a modeling framework for self-adaptive manufacturing that supports modeling domain-specific cases, describing rules for case similarity and case-based reasoning within a modular Digital Twin. Automatically configuring Digital Twins based on explicitly modeled domain expertise can improve manufacturing times, reduce wastage, and, ultimately, contribute to better sustainable manufacturing.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2021 International Symposium on Software Engineering for Adaptive and Self-Managing Systems, SEAMS 2021;2021-05-01;https://api.elsevier.com/content/abstract/scopus_id/85113473628
354;Semantics for I4.0 Smart Manufacturing;In the realm of ‚Smart Manufacturing‘[IEC20a] the ‚SemNorm‘Project [DKE20a] addresses the question of how to at derive an executable Digital Twin (DT) [DTC20] from standards. A Digital Twin is a virtual representation that embodies an asset of any type [IOSB18]. In that sense a DT is compared to the Asset Administration Shell (AAS). Smart Manufacturing is a real thing of a factory represented by its structure and behavior of inter-connected things that generate real-time data [IOSB18]. By combining Smart Manufacturing processes with a Digital Twin it is intended to validate operations of a production systems in real-time. In general the properties of inter-operating things respectively systems, and especially the properties of energy transportation between systems are considered to be the ‚Prove of Concepts‘(PoC) of semantics. When The Information Technology (IT) that processes data and up to some extend information, is compared to the technology that enables communication among things or objects then the technology is called Operation Technology (OT). Whereas the semantics of IT is straight-forward, namely the interpretation of data objects in different contexts of a sending and a receiving environment, the semantics of OT is achieved on two levels. The the first (informal) level explains semantics as a narrative of how things are processed in a smart manufacturing plant, whereas the second (formal) level defines semantics more formally, i.e. by means of graph manipulations. Graph Manipulations represent sequences of events that are related to the narrative of talking about inter-operations among things. At same time a graph is a computational representation (cp. [IOSB18]) in terms of sequences of events (so-called runs) that are executable by appropriate tools from the shelve. Thus graph computations and told narratives are said to be ‚similar‘, respectively ‚comparable‘since they are related to each other by a morphism i.e. the formal relationship between artifacts of graphs, artifacts from the standard ontology and artifacts of the technical asset domain. The OT narration validated by a graph semantics analysis is finally to be transformed into a standard’s document which is then called to be a Semantic Standard. This process is a backward transformation of interoperation properties from a semantic representation into an English text that describes the requirements of these properties. In a forward transformation it is started with the textual standards together with the derived guidelines to transform the standard into a semantic representation respectively a Digital Twin.;Gesellschaft fur Informatik (GI);Conference Proceeding;Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI);2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85127309160
355;Sensor Data and Information Fusion to Construct Digital-twins Virtual Machine Tools for Cyber-physical Manufacturing;This paper presents sensor data integration and information fusion to build “digital-twins” virtual machine tools for cyber-physical manufacturing. Virtual machine tools are useful for simulating machine tools’ capabilities in a safe and cost-effective way, but it is challenging to accurately emulate the behavior of the physical tools. When a physical machine tool breaks down or malfunctions, engineers can always go back to check the digital traces of the “digital-twins” virtual machine for diagnosis and prognosis. This paper presents an integration of manufacturing data and sensory data into developing “digital-twins” virtual machine tools to improve their accountability and capabilities for cyber-physical manufacturing. The sensory data are used to extract the machining characteristics profiles of a digital-twins machine tool, with which the tool can better reflect the actual status of its physical counterpart in its various applications. In this paper, techniques are discussed for deploying sensors to capture machine-specific features, and analytical techniques of data and information fusion are presented for modeling and developing “digital-twins” virtual machine tools. Example of developing the digital-twins of a 3-axis vertical milling machine is presented to demonstrate the concept of modeling and building a digital-twins virtual machine tool for cyber-physical manufacturing. The presented technique can be used as a building block for cyber-physic manufacturing development.;Elsevier B.V.;Conference Proceeding;Procedia Manufacturing;2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/85023642484
356;Shaping the digital twin for design and production engineering;The digitalization of manufacturing fuels the application of sophisticated virtual product models, which are referred to as digital twins, throughout all stages of product realization. Particularly, more realistic virtual models of manufactured products are essential to bridge the gap between design and manufacturing and to mirror the real and virtual worlds. In this paper, we propose a comprehensive reference model based on the concept of Skin Model Shapes, which serves as a digital twin of the physical product in design and manufacturing. In this regard, model conceptualization, representation, and implementation as well as applications along the product life-cycle are addressed.;Elsevier USA;Journal;CIRP Annals - Manufacturing Technology;2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/85018723536
357;Smart City Platform Enabling Digital Twin;Visual 3D models are being deployed in smart cities around the world. While earlier the motivation was mostly to visualize the buildings, the latest developments will turn the 3D models into a rich source of information related to the urban landscape and built environment. The models can be used to compare the energy consumption between similar buildings or to display the potential solar panels had if mounted on certain district. The models have soon become elemental in not only managing a smart city but also as a platform for co-design and development together with the citizens.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;9th International Conference on Intelligent Systems 2018: Theory, Research and Innovation in Applications, IS 2018 - Proceedings;2018-07-02;https://api.elsevier.com/content/abstract/scopus_id/85065998561
358;Smart factories in Industry 4.0: A review of the concept and of energy management approached in production based on the Internet of Things paradigm;The real and the virtual worlds are growing speedily and closely to form the Internet of Things (IoT). In fact, IoT has stimulated the factories and the governments to launch an evolutionary journey toward the fourth industrial revolution called Industry 4.0. Industrial production of the new era will be highly flexible in production volume and customization, extensive integration between customers, companies, and suppliers, and above all sustainable. Reviewing and analyzing the current initiatives and related studies of the smart factories/Industry 4.0, this paper presents a reference architecture for IoT-based smart factories, defines the main characteristics of such factories with a focus on the sustainability perspectives. And then it proposes an approach for energy management in smart factories based on the IoT paradigm: a guideline and expected benefits are discussed and presented.;IEEE Computer Societyhelp@computer.org;Conference Proceeding;IEEE International Conference on Industrial Engineering and Engineering Management;2014-01-01;https://api.elsevier.com/content/abstract/scopus_id/84988221092
359;Smart suit for body area network;This paper presents 'Smart suit' for body area network. Body communication network need to be prepared for firefighters, astronauts and soldiers to transmit vital data, location and other information to a base and to receive instructions. Corrected data by on/in body sensors are transmitted to an antenna through cables in conventional suits. For easy sensor location and no physical connection with cables, this paper presents a sheet-like waveguide and a transmission line with non-contact antenna feed. It consists of conductive fabric or paper to easily embed in the suit. This transmission line is a series of microstrip band path filter which provides non-contact electromagnetic coupling with any antennas placed above. This paper describes this novel transmission line and how to embed in the smart suit.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2016 IEEE Asia-Pacific Conference on Applied Electromagnetics, APACE 2016;2016-01-01;https://api.elsevier.com/content/abstract/scopus_id/85020264593
360;An SOA design patterns recommendation system based on ontology;Service-Oriented Architecture is an architectural style for building systems based on interacting services. For more performance, Service-oriented architectures (SOA) systems must have some quality requirements (e.g., reliability, availability, and performance). SOA design patterns are proven solutions to specific problems in this context. Given the benefits they offer for software development, the SOA design patterns use is in an increasing expansion. Nonetheless, without assistance, any inexperienced designer may not take advantage of SOA design patterns due to their overwhelming number. In this paper, we propose a new approach that recommends the SOA design pattern that is adequate to the designer’s modeling context. For this purpose, a new ontology created to classify the different SOA patterns problems and their corresponding solutions. Then this ontology will be interrogated by SPARQL to search for the adequate pattern in the repository of SOA patterns and present the appropriate solution.;Springer Verlagservice@springer.de;Book Series;Advances in Intelligent Systems and Computing;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85066306792
361;Specification-based monitoring of cyber-physical systems: A survey on theory, tools and applications;The term Cyber-Physical Systems (CPS) typically refers to engineered, physical and biological systems monitored and/or controlled by an embedded computational core. The behaviour of a CPS over time is generally characterised by the evolution of physical quantities, and discrete software and hardware states. In general, these can be mathematically modelled by the evolution of continuous state variables for the physical components interleaved with discrete events. Despite large effort and progress in the exhaustive verification of such hybrid systems, the complexity of CPS models limits formal verification of safety of their behaviour only to small instances. An alternative approach, closer to the practice of simulation and testing, is to monitor and to predict CPS behaviours at simulation-time or at runtime. In this chapter, we summarise the state-of-the-art techniques for qualitative and quantitative monitoring of CPS behaviours. We present an overview of some of the important applications and, finally, we describe the tools supporting CPS monitoring and compare their main features.;Springer Verlagservice@springer.de;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85042072854
362;Dynamic reliability model for subsea pipeline risk assessment due to third-party interference;The accidents of subsea pipelines due to third-party interference often result in catastrophic impacts, therefore, risk assessment has progressively become substantial to ensure the safety and reliability of the systems. However, the current risk analysis approaches are unable to minimize the uncertainties in the analysis due to the high demands of the qualitative inputs. The Bayesian network approach is believed to be able to provide answers to such a problem. The main advantage of this technique is that it allows the inference model and predictive analysis for constructing the current and future performance of the system based on the observed evidence. These can be achieved by introducing the subsea pipeline's accident history and operational data in the model for developing the conditional probability distribution of each variable in the analysis. This paper proposes a dynamic reliability model for subsea pipeline risk assessment due to third-party interference based on the Bayesian approach. This technique is combined with fault tree and the finite element models for producing a reliable risk assessment framework for subsea pipelines. It is expected that the proposed model will be able to minimize the number of qualitative inputs in the analysis and also provides dynamic results for estimating the risk level of the subsea pipeline throughout its service life.;KeAi Communications Co.;Journal;Journal of Pipeline Science and Engineering;2021-09-01;https://api.elsevier.com/content/abstract/scopus_id/85127508735
363;Supporting semi-automatic co-evolution of architecture and fault tree models;"In this work, we report about recent research results on ""Supporting Semi-Automatic Co-Evolution of Architecture and Fault Tree Models"", published in [Gel8]. During the whole life-cycle of software-intensive systems in safety-critical domains, system models must consistently co-evolve with quality evaluation models. However, performing the necessary synchronization steps is a cumbersome and often manual task prone to errors. To understand this problem in detail, we have analyzed the evolution of two representatives of system models and quality evaluation models, namely architecture and fault tree models, for a set of evolution scenarios of a factory automation system called Pick and Place Unit. We designed a set of intra- and inter-model transformation rules which fully cover the evolution scenarios of the case study and which offer the potential to semi-automate the co-evolution process. In particular, we validated these rules with respect to completeness and evaluated them by a comparison to typical visual editor operations. Our results show a significant reduction of the amount of required user interactions in order to realize the co-evolution.";Gesellschaft fur Informatik (GI)gs@gi-ev.de;Conference Proceeding;Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI);2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85072128278
364;Synchronizing physical factory and its digital twin throughan iiot middleware: A case study Füüsiline tehas ja selle digitaalse kaksiku sünkroonimine tööstusliku nutistu vahevara kaudu: Juhtumi uuring;Digital twin (DT) is the virtual clone of a factory representing its static and dynamic aspects (e.g., processes, systems, products, etc.) in detail. Among the significant challenges that manufacturing company has to face to implement the DT, one of the most demanding is applying an appropriate software infrastructure, which would enable synchronization of the physical factory with its DT. In this case, it was possible to exploit wide range of capabilities of DT in its full potential. In particular, the DT was used in different conditions to enable various operations within the shop floor, to simulate and assess the factory’s performance. To support companies in addressing this challenge, this paper presents a potential solution, based on the Industrial Internet of Things (IIoT) middleware, that implements a fully dual-way synchronization between the real and virtual worlds. A case study was carried out to investigate the possibilities to implement the solution. To demonstrate correctness and validity of the approach, tests were carried out in the laboratories of Flexible Manufacturing Systems, Robotics Demo Centre and ProtoLab of Tallinn University of Technology (TalTech).;Estonian Academy PublishersKohtu 6Tallinn10130niine@kirj.ee;Journal;Proceedings of the Estonian Academy of Sciences;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85074654014
365;SysML behaviour models for description of virtual reality environments for early evaluation of a product;Virtual Reality (VR) can help designers to realise later life phase situations of a product in presence of a specific actor (or actors) in a specific environment by building product use-cases in VR, thus facilitating an early evaluation of a design. In this paper, we present a model-based approach that uses SysML behaviour models to describe and control VR environments. The behaviour modelling process with SysML and the simulation results obtained using these behaviour models are discussed. An overview over simulation processes is provided by constructing an example product use-case in VR.;Faculty of Mechanical Engineering and Naval Architecture;Conference Proceeding;Proceedings of International Design Conference, DESIGN;2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85054904003
366;Architecting a BIM-Based Digital Twin Platform for Airport Asset Management: A Model-Based System Engineering with SysML Approach;"Airports play an essential role within the transportation and infrastructure sectors. As modernizing and expanding airport infrastructures receive a higher priority, addressing inefficiencies in capital expenditures (CapEx) and operational expenses (OpEx) through transformative digital ecosystems is gaining an increasing level of interest. Building information modeling (BIM) can form a basis to enable an end-to-end digital delivery platform, where airport life cycle data can be utilized for actionable insights. This study proposes a scalable, novel BIM-based modularized platform architecture based on model-based system engineering (MBSE) principles with systems modeling language (SysML) for optimal collection, integration, management, and utilization of airport critical asset data. This platform architecture aims at acting as a metaframework that enables an airport digital twin through cohesive and structured view of asset life cycle information for insightful actions by major airport stakeholders. Research methodology features an online survey and focus group discussions for data collection; mixed method analysis for data analysis; MBSE with SysML for data mapping; and prototype demonstration and an expert opinion survey for validation. Adopting a scalable BIM-based digital platform is anticipated to result in boosts in business value of airport infrastructures by sustaining value generation in operations and decreasing upfront costs for technology implementation.";American Society of Civil Engineers (ASCE);Journal;Journal of Construction Engineering and Management;2022-05-01;https://api.elsevier.com/content/abstract/scopus_id/85127072020
367;Systematic analysis and evaluation of visual conceptual modeling language notations;In systems analysis and design it is common to refer to some widely used de-facto industry standards like Unified Modeling Language (UML) and Business Process Model and Notation (BPMN). Albeit the wide adoption of such standard modeling languages, only limited research focuses on the techniques in which these standards are specified and the quality they provide. Most research focuses on case studies of applying standards, ways of extending standards to domain-specific requirements, e.g., by means of profiling, or evaluations of single modeling languages, e.g., using questionnaires or semiotic theories. By contrast, this paper critically reflects on the current state of modeling standards with a focus on their graphical representation (notation). The contribution of this paper is threefold: First, a systematic analysis is performed thereby investigating how different modeling standards specify notational aspects. Second, an evaluation is performed by applying Moody's Physics of Notation theory to the identified standards. Third, based on the findings, recommendations are given to improve modeling standard specifications in the future w.r.t. their notational aspects.;IEEE Computer Societyhelp@computer.org;Conference Proceeding;Proceedings - International Conference on Research Challenges in Information Science;2018-07-06;https://api.elsevier.com/content/abstract/scopus_id/85050851769
368;Systematic composition of independent language features;Systematic reuse is crucial to efficiently engineer and deploy software languages to software experts and domain experts alike. But “software languages are software too” and hence their engineering, customization, and reuse are subject to similar challenges. To this effect, we propose an approach for composing independent, grammar-based language syntax modules in a structured way that realizes a separation of concerns among the participants in the life cycle of the languages. We present a refined concept of systematic and controlled syntactic variability of extensible software language product lines through identification of syntax variation points and derivation of variants from independently developed features. This facilitates reuse of software languages and reduces the efforts of engineering and customizing languages for specific domains. We realized our concept with the MontiCore language workbench and assessed it through a case study on architecture description languages. Ultimately, systematic and controlled software language reuse reduces the effort of software language engineering and fosters the applicability of software languages.;Elsevier Inc.usjcs@elsevier.com;Journal;Journal of Systems and Software;2019-06-01;https://api.elsevier.com/content/abstract/scopus_id/85062348521
369;Systematic language extension mechanisms for the montiarc architecture description language;Architecture description languages (ADLs) combine the benefits of component-based software engineering and model-driven development. Extending an ADL to domain-specific requirements is a major challenge for its successful application. Most ADLs focus on fixed features and do not consider domain-specific language extension. ADLs focusing on extensibility focus on syntactic augmentation only and neither consider semantics, nor the ADL’s tooling. We present a systematic extension method for the MontiArc component and connector ADL that enables extending its syntax and infrastructure. The MontiArc ADL is built on top of the MontiCore workbench for compositional modeling languages and leverages its powerful language integration facilities. Based on these, we conceived systematic extension activities and present their application to customizing MontiArc for three different domains. This application of software language engineering to ADLs reduces effort for their extension and the presented method guides developers in applying it to their domain. This ultimately fosters the application of ADLs to real-world domain-specific challenges.;Springer Verlagservice@springer.de;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/85025126026
370;The AutomationML Component Description in the context of the Asset Administration Shell;One of the key ideas of Industry 4.0 is the availability of a digital representation of each industrial asset within an Industry 4.0 network, the 'Asset Administration Shell' (AAS). The AAS combines data related to an asset and software interfaces which provide access and explorability of the asset data in the network. Because an accepted standard is missing, component manufacturers are currently not able to economically release basic asset models for their products. This creates a deadlock situation for the widespread introduction of Industry 4.0 driven smart factory concepts. This paper describes and compares the most promising approaches to model the asset administration shell: the AAS model of the Platform I4.0, and the AutomationML component description of the AutomationML e.V. The technical concepts are comparatively analyzed for strengths and weaknesses and a useful combination of both model worlds is proposed.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;IEEE International Conference on Emerging Technologies and Factory Automation, ETFA;2019-09-01;https://api.elsevier.com/content/abstract/scopus_id/85074214979
371;The challenge of integrating Industry 4.0 in the degree of Mechanical Engineering;Industry is facing a historic turning point [1]. In industry 4.0, people, machines and products communicate with one another via the internet. This means the convergence of industry and Internet technology. Modern machines allow companies to exploit the potential of digitalization in their production facilities and to unlock new business fields. The mechanical engineering sector have to know how new technologies can be successfully integrated for the benefit of the customer. Production processes and supply chains will become more efficient, with advances in productivity and huge savings in material and energy. Digitalization goes hand in hand with the growing importance of platforms for data exchange, customer contact and services. Online platforms facilitate market access, reduce transaction costs and enable innovation through new business models. Machines are connected around the world, so Industry 4.0 would not be possible without networks and data traffic.;Elsevier B.V.;Journal;Procedia Manufacturing;2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/85030841151
372;The dawn of the new age of the industrial internet and how it can radically transform the offshore oil and gas industry;Rapid advancements in big data management, digital connectivity, low-cost sensor technologies and high-performance computing, are ushering in the fourth industrial revolution: the Industrial Internet. This paper provides an overview of the Industrial Internet and the infrastructure implementation challenges for the offshore oil and gas industry. The application of the Digital Twin for Asset Performance Management and Real-time Facility Risk Management is described in the paper. The Nauticus Twinity use case for performance management of a supply vessel demonstrates the benefits of a digital twin. Finally, the paper elucidates the challenges of implementing machine learning models in operations to improve asset performance.;Offshore Technology Conferenceservice@otcnet.org;Conference Proceeding;Proceedings of the Annual Offshore Technology Conference;2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/85030721863
373;Architectural Reply for Smart Building Design Concepts Based on Artificial Intelligence Simulation Models and Digital Twins;Artificial Intelligence (AI) simulation models and digital twins (DT) are used in designing and treating the activities, layout, and functions for the new generation of buildings to enhance user experience and optimize building performance. These models use data about a building’s use, configuration, functions, and environment to simulate different design options and predict their effects on house function efficiency, comfort, and safety. On the one hand, AI algorithms are used to analyze this data and find patterns and trends that can guide the design process. On the other hand, DTs are digital recreations of actual structures that can replicate building performance in real time. These models would evaluate alternative design options, the performance of the building, and ways to improve user comfort and building efficiency. This study examined the important role of intelligent building design aspects, such as activities using multi-layout and the creation of particular functions based on AI simulation models, in developing DT-based smart building systems. The empirical data came from a study of architecture and engineering firms throughout the globe using a CSAQ (computer-administered, self-completed survey). For this purpose, the study employed structural equation modeling (SEM) to examine the hypotheses and build the relationship model. The research verifies the relevance of AI-based simulation models supporting the creation of intelligent building design features (activities, layout, functionalities), enabling the construction of DT-based smart building systems. Furthermore, this study highlights the need for further exploration of AI-based simulation models’ role and integration with DT in smart building design.;MDPI;Journal;Sustainability (Switzerland);2023-03-01;https://api.elsevier.com/content/abstract/scopus_id/85151519691
374;The Digital Twin: Realizing the Cyber-Physical Production System for Industry 4.0;Concerning current approaches to planning of manufacturing processes, the acquisition of a sufficient data basis of the relevant process information and subsequent development of feasible layout options requires 74% of the overall time-consumption. However, the application of fully automated techniques within planning processes is not yet common practice. Deficits are to be observed in the course of the use of a fully automated data acquisition of the underlying process data, a key element of Industry 4.0, as well as the evaluation and quantification and analysis of the gathered data. As the majority of the planning operations are conducted manually, the lack of any theoretical evaluation renders a benchmarking of the results difficult. Current planning processes analyze the manually achieved results with the aid of simulation. Evaluation and quantification of the planning procedure are limited by complexity that defies manual controllability. Research is therefore required with regard to automated data acquisition and selection, as the near real-time evaluation and analysis of a highly complex production systems relies on a real-time generated database. The paper presents practically feasible approaches to a multi-modal data acquisition approach, its requirements and limitations. The further concept of the Digital Twin for a production process enables a coupling of the production system with its digital equivalent as a base for an optimization with a minimized delay between the time of data acquisition and the creation of the Digital Twin. Therefore a digital data acquisition approach is necessary. As a consequence a cyber-physical production system can be generated, that opens up powerful applications. To ensure a maximum concordance of the cyber-physical process with its real-life model a multimodal data acquisition and evaluation has to be conducted. The paper therefore presents a concept for the composition of a database and proposes guidelines for the implementation of the Digital Twin in production systems in small and medium-sized enterprises.;Elsevier B.V.;Conference Proceeding;Procedia CIRP;2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/85019987476
375;The Digital Twin: Realizing the Cyber-Physical Production System for Industry 4.0;Concerning current approaches to planning of manufacturing processes, the acquisition of a sufficient data basis of the relevant process information and subsequent development of feasible layout options requires 74% of the overall time-consumption. However, the application of fully automated techniques within planning processes is not yet common practice. Deficits are to be observed in the course of the use of a fully automated data acquisition of the underlying process data, a key element of Industry 4.0, as well as the evaluation and quantification and analysis of the gathered data. As the majority of the planning operations are conducted manually, the lack of any theoretical evaluation renders a benchmarking of the results difficult. Current planning processes analyze the manually achieved results with the aid of simulation. Evaluation and quantification of the planning procedure are limited by complexity that defies manual controllability. Research is therefore required with regard to automated data acquisition and selection, as the near real-time evaluation and analysis of a highly complex production systems relies on a real-time generated database. The paper presents practically feasible approaches to a multi-modal data acquisition approach, its requirements and limitations. The further concept of the Digital Twin for a production process enables a coupling of the production system with its digital equivalent as a base for an optimization with a minimized delay between the time of data acquisition and the creation of the Digital Twin. Therefore a digital data acquisition approach is necessary. As a consequence a cyber-physical production system can be generated, that opens up powerful applications. To ensure a maximum concordance of the cyber-physical process with its real-life model a multimodal data acquisition and evaluation has to be conducted. The paper therefore presents a concept for the composition of a database and proposes guidelines for the implementation of the Digital Twin in production systems in small and medium-sized enterprises.;Elsevier B.V.;Conference Proceeding;Procedia CIRP;2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/85019987476
376;The model transformation language of the VIATRA2 framework;We present the model transformation language of the VIATRA2 framework, which provides a rule- and pattern-based transformation language for manipulating graph models by combining graph transformation and abstract state machines into a single specification paradigm. This language offers advanced constructs for querying (e.g. recursive graph patterns) and manipulating models (e.g. generic transformation and meta-transformation rules) in unidirectional model transformations frequently used in formal model analysis to carry out powerful abstractions. © 2007 Elsevier B.V. All rights reserved.;Elsevier;Journal;Science of Computer Programming;2007-10-01;https://api.elsevier.com/content/abstract/scopus_id/34548501253
377;The role of the Industry 4.0 asset administration shell and the digital twin during the life cycle of a plant;Industry 4.0 has come up with an impressive number of additional terms and definitions e.g. Asset Administration Shell or Digital Twin. Those terms stand for Industry 4.0 coreparadigms, but their meaning is not harmonized even among experts. This is a source of misunderstanding and confusion. In this paper, the mentioned terms are discussed along the life cycle of a plant. A plant's life cycle comprises the whole process from its idea to its destruction. During the discussion of the terms not only the concepts, but also the visions of Industry 4.0 are clarified. Goal of this paper is not to define additional terms, but to explain and substantiate existing ones and to solve apparent contradictions. Additional outcome of the discussion are architectural recommendations for an upcoming Industry 4.0 architecture. Moreover, suggestions for device manufacturers, system integrators, plant owners and Industry 4.0 architects are given.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;IEEE International Conference on Emerging Technologies and Factory Automation, ETFA;2017-06-28;https://api.elsevier.com/content/abstract/scopus_id/85044475829
378;Application of systems modeling language (SysML) and discrete event simulation to address patient waiting time issues in healthcare;A robust health care system is crucial to reducing patient stress and contributing to economic growth. The future of the health care industry depends upon a reliable and efficient system to deal with the increasing number of patients. However, in today's healthcare system, patients face negative experiences as a result of long wait times. Now the pressing question is how to develop an effective healthcare system? To address this issue, this study uses Systems Modeling Language (SysML) coupled with a simulation approach to assess the performance of the healthcare system, identify the problem, and offer recommended alternatives. To elaborate, a systemic magic-grid methodology will be used to model and analyze the blood laboratory by using four pillars (structural, behavioral, requirement, and parametric) of SysML. To represent these pillars, a set of SysML diagrams will be used to visualize the layered system architecture, interactions, and activity between its different components. Furthermore, Discrete Event Simulation (DES) is utilized through Flexsim simulation software for the analysis of the parametric aspect of the system of interest. A blood laboratory within an outpatient clinic located at southern US State is considered a testing bed. The detailed architecture of the system of interest is studied, and required data are collected for modeling and simulation. The simulation results indicate that the combination of 50% Type I routes and 50% Type II routes resulted in the shortest wait times in the system of 22 min, the shortest wait times in the phlebotomist queue of 2 min, and the highest system throughput of 11369 patients per nine months. This article will provide a reference point for practitioners who want to apply the SysML approach to address health sector-related issues. More importantly, with this comprehensive approach, stakeholders of the blood laboratory system can utilize the hospital infrastructure in a more effective and optimized manner.;Elsevier B.V.;Journal;Smart Health;2023-09-01;https://api.elsevier.com/content/abstract/scopus_id/85163703822
379;The autonomic cloud: A vision of voluntary, Peer-2-Peer cloud computing;Autonomic computing - that is, the development of software and hardware systems featuring a certain degree of self-awareness and self-adaptability - is a field with many application areas and many technical difficulties. In this paper, we explore the idea of an autonomic cloud in the form of a platform-as-a-service computing infrastructure which, contrary to the usual practice, does not consist of a well-maintained set of reliable high-performance computers, but instead is formed by a loose collection of voluntarily provided heterogeneous nodes which are connected in a peer-to-peer manner. Such an infrastructure must deal with network resilience, data redundancy, and failover mechanisms for executing applications. We discuss possible solutions and methods which help developing such (and similar) systems. The described approaches are developed in the EU project ASCENS. © 2013 IEEE.;IEEE Computer Societyhelp@computer.org;Conference Proceeding;Proceedings - IEEE 7th International Conference on Self-Adaptation and Self-Organizing Systems Workshops, SASOW 2013;2013-01-01;https://api.elsevier.com/content/abstract/scopus_id/84901202096
380;ThingML: A language and code generation framework for heterogeneous targets;One of the selling points of Model-Driven Software Engineering (MDSE) is the increase in productivity offered by automatically generating code from models. However, the practical adoption of code generation remains relatively slow and limited to niche applications. Tooling issues are often pointed out but more fundamentally, experience shows that: (i) models and modeling languages used for other purposes are not necessarily well suited for code generation and (ii) code generators are often seen as black-boxes which are not easy to trust and produce sub-optimal code. This paper presents and discusses our experiences applying the ThingML approach to different domains. ThingML includes a modeling language and tool designed for supporting code generation and a highly customizable multi-platform code generation framework. The approach is implemented in an open-source tool providing a family of code generators targeting heterogeneous platforms. It has been evaluated through several case studies and is being used for in the development of a commercial ambient assisted living system.;Association for Computing Machinery, Incacmhelp@acm.org;Conference Proceeding;Proceedings - 19th ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS 2016;2016-10-02;https://api.elsevier.com/content/abstract/scopus_id/85008457888
381;Thirteen years of SysML: a systematic mapping study;"The OMG standard Systems Modeling Language (SysML) has been on the market for about thirteen years. This standard is an extended subset of UML providing a graphical modeling language for designing complex systems by considering software as well as hardware parts. Over the period of thirteen years, many publications have covered various aspects of SysML in different research fields. The aim of this paper is to conduct a systematic mapping study about SysML to identify the different categories of papers, (i) to get an overview of existing research topics and groups, (ii) to identify whether there are any publication trends, and (iii) to uncover possible missing links. We followed the guidelines for conducting a systematic mapping study by Petersen et al. (Inf Softw Technol 64:1–18, 2015) to analyze SysML publications from 2005 to 2017. Our analysis revealed the following main findings: (i) there is a growing scientific interest in SysML in the last years particularly in the research field of Software Engineering, (ii) SysML is mostly used in the design or validation phase, rather than in the implementation phase, (iii) the most commonly used diagram types are the SysML-specific requirement diagram, parametric diagram, and block diagram, together with the activity diagram and state machine diagram known from UML, (iv) SysML is a specific UML profile mostly used in systems engineering; however, the language has to be customized to accommodate domain-specific aspects, (v) related to collaborations for SysML research over the world, there are more individual research groups than large international networks. This study provides a solid basis for classifying existing approaches for SysML. Researchers can use our results (i) for identifying open research issues, (ii) for a better understanding of the state of the art, and (iii) as a reference for finding specific approaches about SysML.";Springer;Journal;Software and Systems Modeling;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85065723254
382;CitcomSVE: A Three-Dimensional Finite Element Software Package for Modeling Planetary Mantle’s Viscoelastic Deformation in Response to Surface and Tidal Loads;This article presents a comprehensive benchmark study for the newly updated and publicly available finite element code CitcomSVE for modeling dynamic deformation of a viscoelastic and incompressible planetary mantle in response to surface and tidal loading. A complete description of CitcomSVE’s finite element formulation including calculations of the sea-level change, polar wander, apparent center of mass motion, and removal of mantle net rotation is presented. The 3-D displacements and displacement rates and the gravitational potential anomalies are solved with CitcomSVE for three benchmark problems using different spatial and temporal resolutions: (a) surface loading of single harmonics, (b) degree-2 tidal loading, and (c) the ICE-6G GIA model. The solutions are compared with semi-analytical solutions for error analyses. The benchmark calculations demonstrate the accuracy and efficiency of CitcomSVE. For example, for a typical ICE-6G GIA calculation with a 122-ky glaciation-deglaciation history, time increment of 100 years, and ∼50 km (or ∼0.5°) surface horizontal resolution, it takes ∼4.5 hr on 96 CPU cores to complete with about 1% and 5% errors for displacements and displacement rates, respectively. Error analyses shows that CitcomSVE achieves a second order accuracy, but the errors are insensitive to temporal resolution. CitcomSVE achieves the parallel computational efficiency >75% for using up to 6,144 CPU cores on a parallel supercomputer. With its accuracy, computational efficiency and its open-source public availability, CitcomSVE provides a powerful tool for modeling viscoelastic deformation of a planetary mantle with 3-D mantle viscous and elastic structures in response to surface and tidal loading problems.;John Wiley and Sons Inc;Journal;Geochemistry, Geophysics, Geosystems;2022-10-01;https://api.elsevier.com/content/abstract/scopus_id/85142373469
383;Toward a Digital Twin for real-time geometry assurance in individualized production;Simulations of products and production processes are extensively used in the engineering phase. To secure good geometrical quality in the final product, tolerances, locator positions, clamping strategies, welding sequence, etc. are optimized during design and pre-production. Faster optimization algorithms, increased computer power and amount of available data, can leverage the area of simulation toward real-time control and optimization of products and production systems – a concept often referred to as a Digital Twin. This paper specifies and highlights functionality and data models necessary for real-time geometry assurance and how this concept allows moving from mass production to more individualized production.;Elsevier USA;Journal;CIRP Annals - Manufacturing Technology;2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/85018779245
384;Toward a new definition of FMECA approach;It is well known that Failure Mode Effect Analysis methodology (FMEA) allows to reduce, and if it possible eliminate, the effects of potential failure modes starting from the first stage of the product design. By means of the Criticality Analysis (CA), implemented in FMECA, it is possible to select by means of risk indexes the most potential critical failures. In this paper the authors present the pros and cons of FMECA along the product development cycle based on the existing standards, recommending the most appropriate standard for each development stage. Additionally, the concept of fault mechanisms is introduced through a new hybrid approach to avoid drawbacks of current FMECA. In this way, it will be possible to observe the evolution of the Remaining Useful Life (RUL) of the system and define the maintenance strategy using the information provided by the suitable monitoring activity.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Conference Record - IEEE Instrumentation and Measurement Technology Conference;2015-07-06;https://api.elsevier.com/content/abstract/scopus_id/84938842449
385;Toward an experiential design language: Augmenting Model-Based Systems Engineering with technical storytelling in virtual worlds;"Systems engineering has made significant strides over the last decade with the advent of Model Based Systems Engineering (MBSE) and the Systems Engineering Markup Language (SysML). These advances have made it possible for collaborative engineering teams to communicate using a common language and share information in the form of digital models rather than hard-to-maintain paper documents. One major advance that needs to occur next is enhancing systems engineering languages to address the needs of all stakeholders especially non-engineers. In this paper, we advance the proposition that recent advances in systems modeling, virtual world building, and technical storytelling are the key enablers of next generation systems engineering and systems engineering languages. To this end, this paper presents an innovative approach for developing an experiential design language that augments existing systems engineering language (i.e., SysML) with new perspectives informed by exploration and storytelling in virtual worlds. This language is intended to allow all stakeholders to understand and collaborate on system designs without having to learn engineering notation, and bring to bear their unique perspectives during collaborative system design. Furthermore, immersive experiences made possible by storytelling in the virtual world can potentially illuminate key system interactions and behaviors, allowing all stakholders to make meaningful contibuions in upfront systems engineering. The benefits an payofs of the experimental design language are increased participation of all stakeholders in upfront systems engineering; supeior collaboration among stakeholders by allowing them to focus on different system levels and perspectives; and elegent system design by getting the architecture right the first time minimum structural complexity. © 2014 The Authors. Published by Elsevier B.V.";Elsevier B.V.;Conference Proceeding;Procedia Computer Science;2014-01-01;https://api.elsevier.com/content/abstract/scopus_id/84897978831
386;Toward self-reconfiguration of manufacturing systems using automation agents;"The reconfiguration of control software is regarded as an important ability to enhance the effectiveness and efficiency in future manufacturing systems. Agent technology is considered as a promising approach to provide reconfiguration abilities, but existing work has been focused mainly on the reconfiguration of higher layers concerned with production scheduling and planning. In this paper, we present an automation agent architecture for controlling physical components that integrates ""on the fly"" reconfiguration abilities on the low-level layer. Our approach is combined with an ontological representation of the low-level functionality at the highlevel control layer, which is able to reason and initiate reconfiguration processes to modify the low-level control (LLC). As current control systems are mostly based on standards and principles that do not support reconfiguration, leading to rigid control software architectures, we base our approach on the promising Standard IEC 61499 for the LLC, extended by an innovative reconfiguration infrastructure.We demonstrate this approach with a case study of a reconfiguration process that modifies the LLC functionality provided by the automation agent of a physical component. Thereby, we obtain the ability to support numerous different LLC configurations without increasing the LLC's complexity. By applying our automation agent architecture, we enhance not only the flexibility of each component's control software, but also achieve the precondition for reconfiguring the entire manufacturing system. © 2010 IEEE.";Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Transactions on Systems, Man and Cybernetics Part C: Applications and Reviews;2011-01-01;https://api.elsevier.com/content/abstract/scopus_id/80051783421
387;Towards a domain-specific approach enabling tool-supported model-based systems engineering of complex industrial internet-of-things applications;Contemporary manufacturing systems are undergoing a major change promoted by emerging technologies such as Cyber-physical Systems (CPS) or the Internet of Things (IoT). This trend, nowadays widely known by the term “Industry 4.0”, leads to a new kind of automated production. However, the rising number of dynamically interconnected elements in industrial production lines results in such a system being transformed into a complex System of Systems (SoS). Due to the increasing complexity and the challenges accompanied by this change, conventional engineering methods using generic principles reach their limits when developing this type of systems. With varying approaches only trying to find a solution for small-scaled areas of this problem statement, the need for a holistic methodology becomes more and more obvious. Having recognized this issue, one of the most promising approaches has been introduced with the Reference Architecture Model Industry 4.0 (RAMI 4.0). However, in the current point of view, this domain-specific architecture framework is missing specifications to address all aspects of such a critical infrastructure. Thus, this paper introduces a comprehensive modeling approach utilizing methods applied in Model-Based Systems Engineering (MBSE) and including domain-specific particularities as well as architectural concepts with the goal to enable mutual engineering of current and future industrial systems. The resulting artifacts, a domain-specific language (DSL), an architecture definition and a development process, are thereby consolidated in a ready to use software framework, whose applicability was evaluated by a real-world case study.;MDPI AG;Journal;Systems;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85105520708
388;Towards a Model-Driven Architecture for Interactive Digital Twin Cockpits;Digital twins promise tremendous potential to reduce time and cost in the smart manufacturing of Industry 4.0. Engineering and monitoring interactive digital twins currently demands integrating different piecemeal technologies that effectively hinders their application and deployment. Current research on digital twins focuses on specific implementations or abstract models on how digital twins could be conceived. We propose model-driven software engineering to realize interactive digital twins and user-specific cockpits to interact with the digital twin by generating the infrastructure from common data structure models. To this end, we present a model-driven architecture for digital twins, its integration with an interactive cockpit, and a systematic method of realizing both. Through this, modeling, deploying, and monitoring interactive digital twins becomes more feasible and fosters their successful application in smart manufacturing.;Springer Science and Business Media Deutschland GmbH;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85097375593
389;Towards a Model-Based DevOps for Cyber-Physical Systems;The emerging field of Cyber-Physical Systems (CPS) calls for new scenarios of the use of models. In particular, CPS require to support both the integration of physical and cyber parts in innovative complex systems or production chains, together with the management of the data gathered from the environment to drive dynamic reconfiguration at runtime or finding improved designs. In such a context, the engineering of CPS must rely on models to uniformly reason about various heterogeneous concerns all along the system life cycle. In the last decades, the use of models has been intensively investigated both at design time for driving the development of complex systems, and at runtime as a reasoning layer to support deployment, monitoring and runtime adaptations. However, the approaches remain mostly independent. With the advent of DevOps principles, the engineering of CPS would benefit from supporting a smooth continuum of models from design to runtime, and vice versa. In this vision paper, we introduce a vision for supporting model-based DevOps practices, and we infer the corresponding research roadmap for the modeling community to address this vision by discussing a CPS demonstrator.;Springer;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85079099244
390;Towards a Model-Driven Architecture for Interactive Digital Twin Cockpits;Digital twins promise tremendous potential to reduce time and cost in the smart manufacturing of Industry 4.0. Engineering and monitoring interactive digital twins currently demands integrating different piecemeal technologies that effectively hinders their application and deployment. Current research on digital twins focuses on specific implementations or abstract models on how digital twins could be conceived. We propose model-driven software engineering to realize interactive digital twins and user-specific cockpits to interact with the digital twin by generating the infrastructure from common data structure models. To this end, we present a model-driven architecture for digital twins, its integration with an interactive cockpit, and a systematic method of realizing both. Through this, modeling, deploying, and monitoring interactive digital twins becomes more feasible and fosters their successful application in smart manufacturing.;Springer Science and Business Media Deutschland GmbH;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85097375593
391;Towards a Model-Driven Architecture for Interactive Digital Twin Cockpits;Digital twins promise tremendous potential to reduce time and cost in the smart manufacturing of Industry 4.0. Engineering and monitoring interactive digital twins currently demands integrating different piecemeal technologies that effectively hinders their application and deployment. Current research on digital twins focuses on specific implementations or abstract models on how digital twins could be conceived. We propose model-driven software engineering to realize interactive digital twins and user-specific cockpits to interact with the digital twin by generating the infrastructure from common data structure models. To this end, we present a model-driven architecture for digital twins, its integration with an interactive cockpit, and a systematic method of realizing both. Through this, modeling, deploying, and monitoring interactive digital twins becomes more feasible and fosters their successful application in smart manufacturing.;Springer Science and Business Media Deutschland GmbH;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85097375593
392;Towards a Model-Integrated Runtime Monitoring Infrastructure for Cyber-Physical Systems;Runtime monitoring is essential for ensuring the safe operation and enabling self-adaptive behavior of Cyber-Physical Systems (CPS). It requires the creation of system monitors, instrumentation for data collection, and the definition of constraints. All of these aspects need to evolve to accommodate changes in the system. However, most existing approaches lack support for the automated generation and setup of monitors and constraints for diverse technologies and do not provide adequate support for evolving the monitoring infrastructure. Without this support, constraints and monitors can become stale and become less effective in long-running, rapidly changing CPS. In this 'new and emerging results' paper we propose a novel framework for model-integrated runtime monitoring. We combine model-driven techniques and runtime monitoring to automatically generate large parts of the monitoring framework and to reduce the maintenance effort necessary when parts of the monitored system change. We build a prototype and evaluate our approach against a system for controlling the flights of unmanned aerial vehicles.;IEEE Computer Society;Conference Proceeding;Proceedings - International Conference on Software Engineering;2021-05-01;https://api.elsevier.com/content/abstract/scopus_id/85115603171
393;Towards a Reference Architecture for Leveraging Model Repositories for Digital Twins;"In the area of Cyber-Physical Systems (CPS), the degree of complexity continuously increases mainly due to new key-enabling technologies supporting those systems. One way to deal with this increasing complexity is to create a digital representation of such systems, a so-called Digital Twin (DT), which virtually acts in parallel ideally across the entire life-cycle of a CPS. For this purpose, the DT uses simulated or real-time data to mimic operations, control, and may modify the CPS's behaviour at runtime. However, building such DTs from scratch is not trivial, mainly due to the integration needed to deal with heterogeneous systems residing in different technological spaces. In order to tackle this challenge, Model-Driven Engineering (MDE) allows to logically model a CPS with its physical components. Usually, in MDE such ""logical models""are created at design time which keep them detached from the deployed system during runtime. Instead of building bilateral solutions between each runtime environment and every engineering tool, a dedicated integration layer is needed which can deal with both, design and runtime aspects. Therefore, we present a reference architecture that allows on the one side to query data from model repositories to enrich the running system with design-time knowledge, and on the other side, to be able to reasoning about system states at runtime in design-time models. We introduce a model repository query and management engine as mediator and show its feasibility by a demonstration case.";Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;IEEE International Conference on Emerging Technologies and Factory Automation, ETFA;2020-09-01;https://api.elsevier.com/content/abstract/scopus_id/85093356602
394;Towards creation of a reference architecture for trust-based digital ecosystems;With progressing digitalization and the trend towards autonomous computing, systems tend to form digital ecosystems, where each autonomous system aims at achieving its own goals. Within a highway ecosystem, for example, autonomous vehicles could deploy smart agents in the form of software applications. This would enable cooperative driving and ultimately formation of vehicle platoons that reduce air friction and fuel consumption. In the smart grid domain, software-defined virtual power plants could be established to enable remote and autonomous collaboration of various units, such as smart meters, data concentrators, and distributed energy resources, in order to optimize power generation, demand-side energy and power storage. Effective collaboration within these emerging digital ecosystems strongly relies on the assumption that all components of the ecosystem operate as expected, and a level of trust among them is established based on that. In this paper, we present the idea of trust-based digital ecosystems, built upon the concept of a digital twin of this ecosystem, as a machine readable representation of the system and a representation of goals and trust at runtime. This creates demand for introducing a reference architecture for trust-based digital ecosystems that would capture their main concepts and relationships. By modeling the goals of the actors and systems, a reference architecture can provide a basis for analyzing competitive forces that influence the health of an ecosystem.;Association for Computing Machinery;Conference Proceeding;ACM International Conference Proceeding Series;2019-09-09;https://api.elsevier.com/content/abstract/scopus_id/85081952519
395;Towards Development Platforms for Digital Twins: A Model-Driven Low-Code Approach;Digital Twins in smart manufacturing must be highly adaptable for different challenges, environments, and system states. In practice, there is a need for enabling the configuration of Digital Twins by domain experts. Low-code approaches seem to be a meaningful solution for configuration purposes but often lack extension options. We propose a model-driven low-code approach for the configuration and reconfiguration of Digital Twins using language plugins. This approach uses model-driven software engineering and software language engineering methods to derive a configurable digital twin implementation. Moreover, we discuss some remaining challenges such as interoperability, language modularity, evolution, integration of assistive services, collaborative development, and web-based debugging.;Springer Science and Business Media Deutschland GmbH;Book Series;IFIP Advances in Information and Communication Technology;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85115225554
396;Towards digital twins cloud platform: Microservices and computational workflows to rule a smart factory;The concept of “Industry 4.0” considers smart factories as data-driven and knowledge enabled enterprise intelligence. In such kind of factory, manufacturing processes and final products are accompanied by virtual models – Digital Twins. To support Digital Twins concept, a simulation model for each process or system should be implemented as independent computational service. The only way to implement an orchestration of a set of independent services and provide scalability for simulation is to use a cloud computing platform as a provider of the computing infrastructure. In this paper, we describe a Digital Twin-as-a-Service (DTaaS) model for simulation and prediction of industrial processes using Digital Twins.;Association for Computing Machinery, Incacmhelp@acm.org;Conference Proceeding;UCC 2017 - Proceedings of the10th International Conference on Utility and Cloud Computing;2017-12-05;https://api.elsevier.com/content/abstract/scopus_id/85058345420
397;Towards Domain-Specific Modelling Environments Based on Augmented Reality;Models are pervasive in many disciplines, like software and systems engineering. Modelling by the use of domain-specific languages (DSLs) has lowered the entry barrier to this activity to domain experts and citizen developers. At the same time, we are witnessing constant improvements in the capabilities of mobile devices, like augmented reality (AR) based on their camera. AR could be exploited in modelling scenarios that require locating virtual objects in the surrounding physical space. In this vision paper, we explore the use of DSLs with AR syntax, and propose the automated synthesis of mobile modelling environments for them. This opens the door to novel scenarios for domain-specific modelling in areas like interior design, Industry 4.0, domotics, tourism and transportation, among others. We propose a design process founded on Software Language Engineering principles, provide prototype tool support, and identify open challenges for the community.;IEEE Computer Society;Conference Proceeding;Proceedings - International Conference on Software Engineering;2021-05-01;https://api.elsevier.com/content/abstract/scopus_id/85109145833
398;Towards Model-Driven Digital Twin Engineering: Current Opportunities and Future Challenges;Digital Twins have emerged since the beginning of this millennium to better support the management of systems based on (real-time) data collected in different parts of the operating systems. Digital Twins have been successfully used in many application domains, and thus, are considered as an important aspect of Model-Based Systems Engineering (MBSE). However, their development, maintenance, and evolution still face major challenges, in particular: (i) the management of heterogeneous models from different disciplines, (ii) the bi-directional synchronization of digital twins and the actual systems, and (iii) the support for collaborative development throughout the complete life-cycle. In the last decades, the Model-Driven Engineering (MDE) community has investigated these challenges in the context of software systems. Now the question arises, which results may be applicable for digital twin engineering as well. In this paper, we identify various MDE techniques and technologies which may contribute to tackle the three mentioned digital twin challenges as well as outline a set of open MDE research challenges that need to be addressed in order to move towards a digital twin engineering discipline.;Springer Science and Business Media Deutschland GmbHinfo@springer-sbm.com;Book Series;Communications in Computer and Information Science;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85094117399
399;Towards Model-Driven Digital Twin Engineering: Current Opportunities and Future Challenges;Digital Twins have emerged since the beginning of this millennium to better support the management of systems based on (real-time) data collected in different parts of the operating systems. Digital Twins have been successfully used in many application domains, and thus, are considered as an important aspect of Model-Based Systems Engineering (MBSE). However, their development, maintenance, and evolution still face major challenges, in particular: (i) the management of heterogeneous models from different disciplines, (ii) the bi-directional synchronization of digital twins and the actual systems, and (iii) the support for collaborative development throughout the complete life-cycle. In the last decades, the Model-Driven Engineering (MDE) community has investigated these challenges in the context of software systems. Now the question arises, which results may be applicable for digital twin engineering as well. In this paper, we identify various MDE techniques and technologies which may contribute to tackle the three mentioned digital twin challenges as well as outline a set of open MDE research challenges that need to be addressed in order to move towards a digital twin engineering discipline.;Springer Science and Business Media Deutschland GmbHinfo@springer-sbm.com;Book Series;Communications in Computer and Information Science;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85094117399
400;Towards Model-Driven Digital Twin Engineering: Current Opportunities and Future Challenges;Digital Twins have emerged since the beginning of this millennium to better support the management of systems based on (real-time) data collected in different parts of the operating systems. Digital Twins have been successfully used in many application domains, and thus, are considered as an important aspect of Model-Based Systems Engineering (MBSE). However, their development, maintenance, and evolution still face major challenges, in particular: (i) the management of heterogeneous models from different disciplines, (ii) the bi-directional synchronization of digital twins and the actual systems, and (iii) the support for collaborative development throughout the complete life-cycle. In the last decades, the Model-Driven Engineering (MDE) community has investigated these challenges in the context of software systems. Now the question arises, which results may be applicable for digital twin engineering as well. In this paper, we identify various MDE techniques and technologies which may contribute to tackle the three mentioned digital twin challenges as well as outline a set of open MDE research challenges that need to be addressed in order to move towards a digital twin engineering discipline.;Springer Science and Business Media Deutschland GmbHinfo@springer-sbm.com;Book Series;Communications in Computer and Information Science;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85094117399
401;Towards Model-Driven Digital Twin Engineering: Current Opportunities and Future Challenges;Digital Twins have emerged since the beginning of this millennium to better support the management of systems based on (real-time) data collected in different parts of the operating systems. Digital Twins have been successfully used in many application domains, and thus, are considered as an important aspect of Model-Based Systems Engineering (MBSE). However, their development, maintenance, and evolution still face major challenges, in particular: (i) the management of heterogeneous models from different disciplines, (ii) the bi-directional synchronization of digital twins and the actual systems, and (iii) the support for collaborative development throughout the complete life-cycle. In the last decades, the Model-Driven Engineering (MDE) community has investigated these challenges in the context of software systems. Now the question arises, which results may be applicable for digital twin engineering as well. In this paper, we identify various MDE techniques and technologies which may contribute to tackle the three mentioned digital twin challenges as well as outline a set of open MDE research challenges that need to be addressed in order to move towards a digital twin engineering discipline.;Springer Science and Business Media Deutschland GmbHinfo@springer-sbm.com;Book Series;Communications in Computer and Information Science;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85094117399
402;Towards privacy-preserving IoT systems using model driven engineering;Considering the Internet of Things in production processes, the human factor and aspects such as data protection and data transparency are often ignored. However, collecting, storing and processing data is going to be a standard procedure in this domain. This includes data from sensors, machines, and processes as well as individual data about people. Recent approaches such as assistive systems for human-computer and human-machine interaction need more personal data than ever before to provide purposeful, tailored support. For MDE approaches it is important to consider privacy already on model level. This paper discusses a way to create privacy-preserving IoT systems using an MDE approach to support privacy and data transparency. We show the relevance and application on a use case from industrial production processes. Additionally, we discuss abilities for practical realization and its limitation.;CEUR-WSceurws@sunsite.informatik.rwth-aachen.de;Conference Proceeding;CEUR Workshop Proceedings;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85072779130
403;Towards privacy-preserving IoT systems using model driven engineering;Considering the Internet of Things in production processes, the human factor and aspects such as data protection and data transparency are often ignored. However, collecting, storing and processing data is going to be a standard procedure in this domain. This includes data from sensors, machines, and processes as well as individual data about people. Recent approaches such as assistive systems for human-computer and human-machine interaction need more personal data than ever before to provide purposeful, tailored support. For MDE approaches it is important to consider privacy already on model level. This paper discusses a way to create privacy-preserving IoT systems using an MDE approach to support privacy and data transparency. We show the relevance and application on a use case from industrial production processes. Additionally, we discuss abilities for practical realization and its limitation.;CEUR-WSceurws@sunsite.informatik.rwth-aachen.de;Conference Proceeding;CEUR Workshop Proceedings;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85072779130
404;TwinOps - DevOps meets model-based engineering and digital twins for the engineering of CPS;The engineering of Cyber-Physical Systems (CPS) requires a large set of expertise to capture the system requirements and to derive a correct solution. Model-based Engineering and DevOps aim to efficiently deliver software with increased quality. Model-based Engineering relies on models as first-class artifacts to analyze, simulate, and ultimately generate parts of a system. DevOps focuses on software engineering activities, from early development to integration, and then improvement through the monitoring of the system at run-time. We claim these can be efficiently combined to improve the engineering process of CPS. In this paper, we present TwinOps, a process that unifies Model-based Engineering, Digital Twins, and DevOps practice in a uniform workflow. TwinOps illustrates how to leverage several best practices in MBE and DevOps for the engineering Cyber-Physical systems. We illustrate our contribution using a Digital Twins case study to illustrate TwinOps benefits, combining AADL and Modelica models, and an IoT platform.;Association for Computing Machinery, Inc;Conference Proceeding;Proceedings - 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS-C 2020 - Companion Proceedings;2020-10-16;https://api.elsevier.com/content/abstract/scopus_id/85096747019
405;Unity 3D production and environmental perception vehicle simulation platform;This paper uses the software package, Unity, to create a virtual reality system. After virtual structures of automobile bodies, streets, and background were created, various weather conditions such as sunny, rainy, and snowy along with artificial variables such as sudden crossings by pedestrians, roadblocks, vehicle and scooter blind spots, and other emergency events that can easily occur while driving were taken into account when establishing the system. The virtual reality model that simulates the operation of real cars and Unity 3D are used to integrate the driver into the test scenario while the driver's movements and gaze angle can serve as a research basis. Different driving scenarios were used to examine how the depth sensors react to enhance accuracy of the depth sensors when they are applied to real situations during the development process and when they are used to verify the effects of environmental factors on the scenes.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings of the IEEE International Conference on Advanced Materials for Science and Engineering: Innovation, Science and Engineering, IEEE-ICAMSE 2016;2017-02-02;https://api.elsevier.com/content/abstract/scopus_id/85015155426
406;Updated case study: The pursuit of an ultra-low manned platform pays dividends in the North Sea;The use of a unique, data-driven approach to remote condition monitoring of equipment maintenance has enabled a major offshore E&P producer to build and operate a a low-manned platform - a key step in its strategic goal to reduce per-barrel production costs to below $7. The field is 112 miles (180 km) off Norway's coast, with the platform drawing first oil in December 2016. In January 2019 - after operating identical offshore and onshore platform control rooms - the company started conducting remote condition monitoring of platform machinery exclusively from its control room onshore in Trondheim, Norway, 620 miles (1,000 km) away. With the remote equipment condition monitoring done onshore, the operator is better able to optimize maintenance work and schedules. At the same time, it has contributed to a big reduction in the number of offshore personnel otherwise required, reducing operating costs and personnel risks substantially. In May 2018, Siemens entered into a long-term partnership with the operator to continue developing digital solutions in a closed-loop lifecycle approach, utilizing the digital twin concept from pre-FEED and FEED stages through construction, commissioning, and operations, with operations expected to continue for a minimum of 20-years. This paper will provide an update to a 2018 OTC conference presentation when this use case was introduced. Last year's paper was based on operations and observations during 2017, the platform's first full year of operation.;Offshore Technology Conferenceservice@otcnet.org;Conference Proceeding;Proceedings of the Annual Offshore Technology Conference;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85066633465
407;Using automationml and graph-based design languages for automatic generation of digital twins of cyber-physical systems;The interdisciplinary development of smart factories and cyber-physical systems CPS shows the weaknesses of classical development methods. For example, the communication of the interdisciplinary participants in the development process of CPS is difficult due to a lack of cross-domain language comprehension. At the same time, the functional complexity of the systems to be developed increases and they act operationally as independent CPSs. And it is not only the product that needs to be developed, but also the manufacturing processes are complex. The use of graph-based design languages offers a technical solution to these challenges. The UML-based structures offer a cross-domain language understanding for all those involved in the interdisciplinary development process. Simulations are required for the rapid and successful development of new products. Depending on the functional scope, graphical simulations of the production equipment are used to simulate the manufacturing processes as a digital factory or a virtual commissioning simulation. Due to the high number of functional changes during the development process, it makes sense to automatically generate the simulation modelling as digital twins of the products or means of production from the graph-based design languages. The paper describes how digital twins are automatically generated using AutomationML according to the Reference Architecture Model Industry 4.0 (RAMI 4.0) or the Industrial Internet Reference Architecture (IIRA).;IOS Press BVsales@iospress.com;Conference Proceeding;Advances in Transdisciplinary Engineering;2020-09-25;https://api.elsevier.com/content/abstract/scopus_id/85092761645
408;NU SAFE Faculty: A Microsoft PowerApps Application for Health Monitoring in National University Philippines;In the early stages of the COVID-19 pandemic, everyone is affected with changes in their lifestyle due to the enforcement of minimum public health standards and lockdowns. This study presents a web and mobile application with Microsoft PowerApps that will allow users in their health monitoring needs amidst the pandemic. The proposed web and mobile application will allow students and employees input their health declaration before entering the campus. The proposed system will also cover users to input their vaccination details and personal information for monitoring. Contact tracing through the mobile application is also proposed to assist the administrators in the early detection of confirmed positive cases.;IEEE Computer Society;Conference Proceeding;International Conference on ICT Convergence;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85143252961
409;Using UML and OCL Models to Realize High-Level Digital Twins;Digital twins constitute virtual representations of physically existing systems. However, their inherent complexity makes them difficult to develop and prove correct. In this paper we explore the use of UML and OCL, complemented with an executable language, SOIL, to build and test digital twins at a high level of abstraction. We also show how to realize the bidirectional connection between the UML models of the digital twin in the USE tool with the physical twin, using an architectural framework centered on a data lake. We have built a prototype of the framework to demonstrate our ideas, and validated it by developing a digital twin of a Lego Mindstorms car. The results allow us to show some interesting advantages of using high-level UML models to specify virtual twins, such as simulation, property checking and some other types of tests.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Companion Proceedings - 24th International Conference on Model-Driven Engineering Languages and Systems, MODELS-C 2021;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85123990225
410;Verification and validation in systems engineering: Assessing UML/SysML design models;Verification and validation represents an important process used for the quality assessment of engineered systems and their compliance with the requirements established at the beginning of or during the development cycle. Debbabi and his coauthors investigate methodologies and techniques that can be employed for the automatic verification and validation of systems engineering design models expressed in standardized modeling languages. Their presentation includes a bird's eye view of the most prominent modeling languages for software and systems engineering, namely the Unified Modeling Language (UML) and the more recent Systems Modeling Language (SysML). Moreover, it elaborates on a number of quantitative and qualitative techniques that synergistically combine automatic verification techniques, program analysis, and software engineering quantitative methods applicable to design models described in these modeling languages. Each of these techniques is additionally explained using a case study highlighting the process, its results, and resulting changes in the system design. Researchers in academia and industry as well as students specializing in software and systems engineering will find here an overview of state-of-the-art validation and verification techniques. Due to their close association with the UML standard, the presented approaches are also applicable to industrial software development. © Springer-Verlag Berlin Heidelberg 2010. All rights are reserved.;Springer Berlin Heidelberg;Book;Verification and Validation in Systems Engineering: Assessing UML/SysML Design Models;2010-12-01;https://api.elsevier.com/content/abstract/scopus_id/84891475935
411;A Continuous Process for Validation, Verification, and Accreditation of Simulation Models;A simulation model, and more generically, a model, is founded on its assumptions. Assurance of the model’s correctness and correct use is needed to achieve accreditation. Often the exercise of working with a specific code misunderstands the overall process, focusing the resources on the model coding and forgetting the needed resources to ensure the validation of every step of the model definition and coding. The goal of this work is to present a methodology to help in the definition and use of the assumptions in the modeling process. To do so, we present a process to conduct a simulation project, an assumptions taxonomy, and a method that simplifies working with those assumptions. We propose to extend the traditional Validation, Verification, and Accreditation processes to a process composed of eight Validation, Verification, and Accreditation phases that cover the overall life cycle of a model. Although this paper is focused on a simulation model, we can extend the proposed method to a more general modeling approach.;MDPI;Journal;Mathematics;2023-02-01;https://api.elsevier.com/content/abstract/scopus_id/85148955919
412;Visualising the digital twin using web services and augmented reality;As the number of network connected devices in an industrial system increases, the management and handling of all the information generated become a challenge. In this work we explore concepts of Cyber-Physical System model the virtual part of industrial devices (sensor, machines, CLPs) using the Digital Twin concept and propose an architecture based on web services for accessing their data. We present a case study where an Augmented Reality system access the Twin Model data via web services and display real-time information to the user. Moreover, we present a review of how the involved concepts, which have a strong computational background, relate to industrial applications and how they can expand the possibility of services and business models.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;IEEE International Conference on Industrial Informatics (INDIN);2016-07-02;https://api.elsevier.com/content/abstract/scopus_id/85012932205
413;Visualization support for requirements monitoring in systems of systems;Industrial software systems are often systems of systems (SoS) whose full behavior only emerges at runtime. The systems and their interactions thus need to be continuously monitored and checked during operation to determine compliance with requirements. Many requirements monitoring approaches have been proposed. However, only few of these come with tools that present and visualize monitoring results and details on requirements violations to end users such as industrial engineers. In this tool demo paper we present visualization capabilities we have been developing motivated by industrial scenarios. Our tool complements ReMinds, an existing requirements monitoring framework, which supports collecting, aggregating, and analyzing events and event data in architecturally heterogeneous SoS. Our visualizations support a 'drill-down' scenario for monitoring and diagnosis: starting from a graphical status overview of the monitored systems and their relations, engineers can view trends and statistics about performed analyses and diagnose the root cause of problems by inspecting the events and event data that led to a specific violation. Initial industry feedback we received confirms the usefulness of our tool support. Demo video: https://youtu.be/iv7kWzeNkdk.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;ASE 2017 - Proceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering;2017-11-20;https://api.elsevier.com/content/abstract/scopus_id/85041444205
414;Stochastic optimization – based economic design for a hybrid sustainable system of wind turbine, combined heat, and power generation, and electric and thermal storages considering uncertainty: A case study of Espoo, Finland;This work-study deals with the economic planning of an island sustainable system that consists of a wind turbine, battery, combined heat and power system, and thermal storage to meet electrical and thermal loads at the same time. The approach attempts to find minimum capital cost, repair and maintenance cost, and operating cost, as well as minimize the pollution of these elements. It is also constrained by the operation-planning model of the mentioned resources and storage, provided that a wind turbine and combined heat and power system have priority in electrical load supply, a combined system of heat and power has priority in thermal load supply, and batteries and storage devices have the task of filling the gap between supply and demand profiles. Uncertainty parameters of the scheme include electrical and thermal load and power output of the wind system. The scheme adopts the unscented transformation method to provide proper modeling of the mentioned uncertainties. Moreover, the essence of the problem is integer nonlinear programming, which uses the combined gray wolf optimization and honey bee mating optimization algorithm to achieve the desired solution. Simultaneous supply of electrical and thermal loads, modeling of uncertainties, and adoption of a combined solver in the proposed scheme are among the contributions. Finally, by implementing this scheme on data from the city of Espoo, Finland, the numerical results indicate a reduction of 10%–11% in the planning cost of the proposed scheme compared to a design that only supplies electricity.;Elsevier Ltd;Journal;Renewable and Sustainable Energy Reviews;2023-09-01;https://api.elsevier.com/content/abstract/scopus_id/85164517559
415;Xatkit: a Multimodal Low-Code Chatbot Development Framework;Chatbot (and voicebot) applications are increasingly adopted in various domains such as e-commerce or customer services as a direct communication channel between companies and end-users. Multiple frameworks have been developed to ease their definition and deployment. While these frameworks are efficient to design simple chatbot applications, they still require advanced technical knowledge to define complex interactions and are difficult to evolve along with the company needs (e.g. it is typically impossible to change the NL engine provider). In addition, the deployment of a chatbot application usually requires a deep understanding of the targeted platforms, especially back-end connections, increasing the development and maintenance costs. In this paper, we introduce the Xatkit framework. Xatkit tackles these issues by providing a set of Domain Specific Languages to define chatbots (and voicebots and bots in general) in a platform-independent way. Xatkit also comes with a runtime engine that automatically deploys the chatbot application and manages the defined conversation logic over the platforms of choice. Xatkit's modular architecture facilitates the separate evolution of any of its components. Xatkit is open source and fully available online.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85079821080
416;An approach for leveraging Digital Twins in agent-based production systems Ein Ansatz zur effizienten Erstellung agentenbasierter Produktionssysteme mittels Digitaler Zwillinge;To cope with individualization and the high costs of downtimes, modern production systems should be flexible, adaptable, and resilient. Multi-Agent Systems are suitable to address these requirements by decentralizing production systems. However, the agent paradigm is still not widely applied. One of the key reasons is that the agents' knowledge bases had to be created manually, which is cumbersome, error-prone, and insufficiently standardized. Digital Twins have the potential to solve this issue, as they describe relevant information in a standardized way. This paper presents an approach to leveraging Digital Twins, i. e., the Asset Administration Shell, to realize Multi-Agent Systems in the production context. For this, a parser automatically extracts relevant information from the Digital Twins and initializes the individual agents in a Multi-Agent System, i. e., PADE.;De Gruyter Oldenbourg;Journal;At-Automatisierungstechnik;2021-12-20;https://api.elsevier.com/content/abstract/scopus_id/85120747374
417;Autonomous Digital Twin of Enterprise: Method and Toolset for Knowledge-Based Multi-Agent Adaptive Management of Tasks and Resources in Real Time;Digital twins of complex technical objects are widely applied for various domains, rapidly becoming smart, cognitive and autonomous. However, the problem of digital twins for autonomous management of enterprise resources is still not fully researched. In this paper, an autonomous digital twin of enterprise is introduced to provide knowledge-based multi-agent adaptive allocation, scheduling, optimization, monitoring and control of tasks and resources in real time, synchronized with employees’ plans, preferences and competencies via mobile devices. The main requirements for adaptive resource management are analyzed. The authors propose formalized ontological and multi-agent models for developing the autonomous digital twin of enterprise. A method and software toolset for designing the autonomous digital twin of enterprise, applicable for both operational management of tasks and resources and what-if simulations, are developed. The validation of developed methods and toolsets for IT service desk has proved increase in efficiency, as well as savings in time and costs of deliveries for various applications. The paper also outlines a plan for future research, as well as a number of new potential business applications.;MDPI;Journal;Mathematics;2022-05-01;https://api.elsevier.com/content/abstract/scopus_id/85130349601
418;Architecting Digital Twins Using a Domain-Driven Design-Based Approach*;The Digital Twin (DT) concept has overcome its initial definition based on a purely descriptive approach focusing on modelling physical objects, often using CAD. Today DT often describes a behavioural approach that can simulate an object's dynamics, monitor its state, and control or predict its behaviour. Although DTs are attracting significant attention and offer many advantages in the design of especially cyber-physical systems, most proposals have focused on developing DTs for a specific use case or need without providing a more holistic approach to its design. We aim to propose a domain-agnostic approach for architecting DTs. Here, DTs are directly supported by Domain-Driven Design's notion of Bounded Contexts (BCs), hiding all the domain-inherent specifications behind BC boundaries. These BCs are also the central abstraction in many microservice architectures and can be used to describe DTs. A Wind Turbine DT architecture is used as a running example to describe how every relevant DT property can be satisfied following our proposal for architecting digital twins. A qualitative evaluation of this case by five external practitioners shows that our DDD-based proposal consistently outperforms the 5-dimension model used as the reference approach.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - IEEE 20th International Conference on Software Architecture, ICSA 2023;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85159152753
419;A Computer Science Perspective on Digital Transformation in Production;"The Industrial Internet-of-Things (IIoT) promises significant improvements for the manufacturing industry by facilitating the integration of manufacturing systems by Digital Twins. However, ecological and economic demands also require a cross-domain linkage of multiple scientific perspectives from material sciences, engineering, operations, business, and ergonomics, as optimization opportunities can be derived from any of these perspectives. To extend the IIoT to a true Internet of Production, two concepts are required: first, a complex, interrelated network of Digital Shadows which combine domain-specific models with data-driven AI methods; and second, the integration of a large number of research labs, engineering, and production sites as a World Wide Lab which offers controlled exchange of selected, innovation-relevant data even across company boundaries. In this article, we define the underlying Computer Science challenges implied by these novel concepts in four layers: Smart human interfaces provide access to information that has been generated by model-integrated AI. Given the large variety of manufacturing data, new data modeling techniques should enable efficient management of Digital Shadows, which is supported by an interconnected infrastructure. Based on a detailed analysis of these challenges, we derive a systematized research roadmap to make the vision of the Internet of Production a reality.";Association for Computing Machinery;Journal;ACM Transactions on Internet of Things;2022-05-01;https://api.elsevier.com/content/abstract/scopus_id/85121783951
420;A Conceptual Model for Digital Shadows in Industry and Its Application;Smart manufacturing demands to process data in domain-specific real-time. Engineering models created for constructing, commissioning, planning, or simulating manufacturing systems can facilitate aggregating and abstracting the wealth of manufacturing data to faster processable data structures for more timely decision making. Current research lacks conceptual foundations for how data and engineering models can be exploited in an integrated way to achieve this. Such research demands expertise from different smart manufacturing domains to harmonize the notion space. We propose a conceptual model to describe digital shadows, data structures tailored to exploit models and data in smart manufacturing, through a metamodel and its notion space. This conceptual model was established through interdisciplinary research in the German excellence cluster “Internet of Production” and evaluated in various real-world manufacturing scenarios. This foundation for an understanding helps to manage complexity, automated analyses, and syntheses, and, ultimately, facilitates cross-domain collaboration.;Springer Science and Business Media Deutschland GmbH;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85118142665
421;Generating customized low-code development platforms for digital twins;A digital twin improves our use of a cyber–physical system and understanding of its emerging behavior. To this effect, a digital twin is to be developed and configured and potentially also operated by domain experts, who rarely have a professional software engineering background and for whom easy access and support, e.g., in form of low-code platforms are missing. In this paper, we report on an integrated method for the model-driven engineering of low-code development platforms for digital twins that enables domain experts to create and operate digital twins for cyber–physical systems using the most appropriate modeling languages. The foundation of this method is (1) a code generation infrastructure for information systems combined with (2) an extensible base architecture for self-adaptive digital twins and (3) reusable language components for their configuration. Using this method, software engineers first configure the information system with the required modeling languages to generate the low-code development platform for digital twins before domain experts leverage the generated platform to create digital twins. This two-step method facilitates creating tailored low-code development platforms as well as creating and operating customized digital twins for a variety of applications.;Elsevier Ltd;Journal;Journal of Computer Languages;2022-06-01;https://api.elsevier.com/content/abstract/scopus_id/85129984615
422;A machine learning digital twin approach for critical process parameter prediction in a catalyst manufacturing line;Digital twins (DTs) are rapidly changing how manufacturing companies leverage the large volumes of data they generate daily to gain a competitive advantage and optimize their supply chains. When coupled with recent developments in machine learning (ML), DTs have the potential to generate invaluable insights for process manufacturing companies to help them optimize their manufacturing processes. However, this potential has yet to be fully exploited due to the challenges that process manufacturing companies face in developing and implementing DTs in their organizations. Although DTs are receiving increasing attention in both industry and academia, there is limited literature on how to apply them in the process industry. To address this gap, this paper presents a framework for developing ML-based DTs to predict critical process parameters in real time. The proposed framework is tested through a case study at an international process manufacturing company in which it was used to collect and process plant data, build accurate predictive models for two critical process parameters, and develop a DT application to visualize the models’ predictions. The case study demonstrated the usefulness of the proposed DT–ML framework in the sense that it provided the company with more accurate predictions than the models it previously applied. The study provides insights into the value of applying ML-based DT in the process industry and sheds light on some of the challenges associated with the application of this technology.;Elsevier B.V.;Journal;Computers in Industry;2023-10-01;https://api.elsevier.com/content/abstract/scopus_id/85164238444
423;Self-Adaptive Manufacturing with Digital Twins;Digital Twins are part of the vision of Industry 4.0 to represent, control, predict, and optimize the behavior of Cyber-Physical Production Systems (CPPSs). These CPPSs are long-living complex systems deployed to and configured for diverse environments. Due to specific deployment, configuration, wear and tear, or other environmental effects, their behavior might diverge from the intended behavior over time. Properly adapting the configuration of CPPSs then relies on the expertise of human operators. Digital Twins (DTs) that reify this expertise and learn from it to address unforeseen challenges can significantly facilitate self-adaptive manufacturing where experience is very specific and, hence, insufficient to employ deep learning techniques. We leverage the explicit modeling of domain expertise through case-based reasoning to improve the capabilities of Digital Twins for adapting to such situations. To this effect, we present a modeling framework for self-adaptive manufacturing that supports modeling domain-specific cases, describing rules for case similarity and case-based reasoning within a modular Digital Twin. Automatically configuring Digital Twins based on explicitly modeled domain expertise can improve manufacturing times, reduce wastage, and, ultimately, contribute to better sustainable manufacturing.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2021 International Symposium on Software Engineering for Adaptive and Self-Managing Systems, SEAMS 2021;2021-05-01;https://api.elsevier.com/content/abstract/scopus_id/85113473628
424;Process-aware digital twin cockpit synthesis from event logs;The engineering of digital twins and their user interaction parts with explicated processes, namely process-aware digital twin cockpits (PADTCs), is challenging due to the complexity of the systems and the need for information from different disciplines within the engineering process. Therefore, it is interesting to investigate how to facilitate their engineering by using already existing data, namely event logs, and reducing the number of manual steps for their engineering. Current research lacks systematic, automated approaches to derive process-aware digital twin cockpits even though some helpful techniques already exist in the areas of process mining and software engineering. Within this paper, we present a low-code development approach that reduces the amount of hand-written code needed and uses process mining techniques to derive PADTCs. We describe what models could be derived from event log data, which generative steps are needed for the engineering of PADTCs, and how process mining could be incorporated into the resulting application. This process is evaluated using the MIMIC III dataset for the creation of a PADTC prototype for an automated hospital transportation system. This approach can be used for early prototyping of PADTCs as it needs no hand-written code in the first place, but it still allows for the iterative evolvement of the application. This empowers domain experts to create their PADTC prototypes.;Elsevier Ltd;Journal;Journal of Computer Languages;2022-06-01;https://api.elsevier.com/content/abstract/scopus_id/85131671533
425;Using UML and OCL Models to Realize High-Level Digital Twins;Digital twins constitute virtual representations of physically existing systems. However, their inherent complexity makes them difficult to develop and prove correct. In this paper we explore the use of UML and OCL, complemented with an executable language, SOIL, to build and test digital twins at a high level of abstraction. We also show how to realize the bidirectional connection between the UML models of the digital twin in the USE tool with the physical twin, using an architectural framework centered on a data lake. We have built a prototype of the framework to demonstrate our ideas, and validated it by developing a digital twin of a Lego Mindstorms car. The results allow us to show some interesting advantages of using high-level UML models to specify virtual twins, such as simulation, property checking and some other types of tests.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Companion Proceedings - 24th International Conference on Model-Driven Engineering Languages and Systems, MODELS-C 2021;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85123990225
426;Digital Twin applications toward Industry 4.0: A Review;Digital Twin is a virtual representation of objects, processes, and systems that exist in real-time. While Digital Twin can represent digital objects, they are often used to connect the physical and digital worlds. This technology plays a vital role in fulfilling various requirements of Industry 4.0. It gives a digital image of a factory's operations, a communications network's activities, or the movement of items through a logistics system. This paper studies Digital Twin and its need in Industry 4.0. Then the process and supportive features of Digital Twin for Industry 4.0 are diagrammatically discussed, and finally, the major applications of Digital Twin for Industry 4.0 are identified. Digital Twin sophistication depends on the process or product represented and the data available. Manufacturers can learn how assets will behave in real-time, in the physical world, by putting sensors on particular assets, gathering data, creating digital duplicates, and employing machine intelligence. They can confidently make wise judgments, which helps improve company performance. Digital Twin assesses material usage to save costs, discover inefficiencies, replicate tool tracking systems, and do other things. Manufacturers construct a digital clone for specific equipment and tools, exclusive products or systems, entire procedures, or anything else they want to improve on the factory floor. Sensors and other equipment that collect real-time data on the state of the process or product collect this information, which on the other hand, must be handled and processed appropriately. It is made feasible by IoT sensors, which collect data from the physical environment and transmit it to be virtually recreated. This information comprises design and engineering details that explain the asset's shape, materials, components, and behaviour or performance.;KeAi Communications Co.;Journal;Cognitive Robotics;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85152954260
427;Integration Challenges for Digital Twin Systems-of-Systems;Research and industry leverage digital twins to monitor and control (cyber-physical) systems in various domains. For their efficient engineering, these twins need to become Systems-of-Systems (SoS), in which digital twins of smaller systems (e.g., a production machine) become parts of digital twins of larger systems (e.g., a factory). Yet, research on digital twins as SoS largely ignores reusing digital twins in SoS. Based on our experience in engineering digital twins with experts from various domains related to production systems engineering, we present insights on the challenges of composing and integrating that need to be addressed for efficient engineering of digital twins as SoS. These insights may guide future research on engineering digital twins as well as practitioners considering the challenges in building and composing digital twin systems-of-systems.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 10th IEEE/ACM International Workshop on Software Engineering for Systems-of-Systems and Software Ecosystems, SESoS 2022;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85135174156
428;Generating Digital Twin Cockpits for Parameter Management in the Engineering of Wind Turbines;The complexity of wind energy systems combined with an increased trend towards mass customization require the collaboration of many experts to achieve high quality products. Currently, a major issue arises from the lack of data integration among the different tools used during the engineering process which may cause system failures eventually. Existing tools largely do not support automatic detection and indication of erroneous or contradictory parameter values between artifacts of different tools. Employing a model-driven and functional engineering approach enables to establish an integrated toolchain for the management and visualization of engineering artifacts that consume and produce the data. Within this paper, we present an automatic approach to derive an engineering digital twin for the cooperative development and management of engineering artifacts from functional models of the system under development. We evaluate our approach on the example of a hydraulic pump within the cooling system of a wind turbine. The prototype can be coupled with an existing engineering tool ecosystem. The approach enables to exchange the data produced by engineering artifacts according to a functional system model which facilitates the cooperation between different stakeholders throughout the development process.;Gesellschaft fur Informatik (GI);Conference Proceeding;Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI);2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85138312179
429;Towards Development Platforms for Digital Twins: A Model-Driven Low-Code Approach;Digital Twins in smart manufacturing must be highly adaptable for different challenges, environments, and system states. In practice, there is a need for enabling the configuration of Digital Twins by domain experts. Low-code approaches seem to be a meaningful solution for configuration purposes but often lack extension options. We propose a model-driven low-code approach for the configuration and reconfiguration of Digital Twins using language plugins. This approach uses model-driven software engineering and software language engineering methods to derive a configurable digital twin implementation. Moreover, we discuss some remaining challenges such as interoperability, language modularity, evolution, integration of assistive services, collaborative development, and web-based debugging.;Springer Science and Business Media Deutschland GmbH;Book Series;IFIP Advances in Information and Communication Technology;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85115225554
430;Air Quality Management: An Exemplar for Model-Driven Digital Twin Engineering;Since its first mentioning in the literature, the concept of Digital Twin has gained traction in both industry and academia. However, there are still many open challenges when applying Digital Twins to industry-scale use cases. Applying Model-Driven Engineering techniques to the creation and maintenance of Digital Twins (also referred to as Model-Driven Digital Twin Engineering) promises automation and consistency throughout the life cycle of a Digital Twin. The exemplar provided in this paper can be used to identify open challenges when it comes to Model-Driven Digital Twin Engineering, and to demonstrate how approaches can solve them. This exemplar applies Digital Twins to an indoor air quality management use case, where CO2, temperature, and humidity values of rooms within a building are measured. These values can be used to derive actions to improve work productivity and reduce the risk for virus infections. We describe three applications that make use of this Digital Twin (i.e., runtime visualization, physical simulation, and ML-based predictions), and provide an online repository with the artefacts of this exemplar.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Companion Proceedings - 24th International Conference on Model-Driven Engineering Languages and Systems, MODELS-C 2021;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85124047367
431;Properties and Characteristics of Digital Twins: Review of Industrial Definitions;As digital twin configurations depend on their use case, there is a need for research on how companies can select the capabilities and appropriate level of sophistication to deploy digital twins in practice successfully. This study investigated the properties and characteristics of digital twins described in academic literature. It summarized them in a taxonomy, which was subsequently used to code and examine 90 definitions of companies. For the analysis, both supervised and unsupervised methods were applied. The results show that researchers focus more on technological requirements when defining digital twins, while companies use more value-based properties that are not included or not precisely delineated in academic reviews. Therefore, an application-oriented definition is proposed to bridge this gap and complement the taxonomy. This study thus contributes to the discussion and forming of an application-oriented and shared understanding of the digital twin concept in research and practice.;Springer;Journal;SN Computer Science;2023-09-01;https://api.elsevier.com/content/abstract/scopus_id/85163108717
432;Towards a Digital Twin Modelling Notation;Digital Twins (DTs) constitute a growing and promising trend recognised by academia and industry. They are virtual replicas of distinctive objects, processes, buildings, or humans. DTs are used to reason about their physical counterparts' functionalities, interactions, behaviours, and overall to plan optimal actions that they can perform or be subjected to. Given their intrinsic complexity, no standard definition nor a unified solution is yet available for designing and developing DTs. Intending to shed light on such a complex topic, we analysed the literature and derived a list of twelve pivotal characteristics of DTs. Such characteristics will be used as requirements for defining a Digital Twin Modelling Notation that will enable reasoning about the design of DT solutions.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings of the 2022 IEEE International Conference on Dependable, Autonomic and Secure Computing, International Conference on Pervasive Intelligence and Computing, International Conference on Cloud and Big Data Computing, International Conference on Cyber Science and Technology Congress, DASC/PiCom/CBDCom/CyberSciTech 2022;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85145346103
433;Agile Generator-Based GUI Modeling for Information Systems;We use two code generators for the model-based continuous development of information systems including its graphical user interfaces (GUIs). As our goal is to develop full-size real-world systems for different domains, the continuous and iterative model-based engineering of their GUIs comes along with challenges regarding their extension and modification. These challenges concern models, the languages they are written in and hand-written code. In this work we present four complementary approaches to allow extensions for GUIs that we encounter with the generator-based framework MontiGem to tackle these challenges. We discuss the four approaches in detail and present extensions of the framework in the grammar of the language, via atomic components, via hand-written amendments of generated models and by generating connections between the GUI and data structure models. These techniques can be used to create a flexible DSL for engineering information systems, adaptable for different domains and rapidly changing requirements.;Springer Science and Business Media Deutschland GmbH;Book Series;Communications in Computer and Information Science;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85107450806
434;Goal Modeling and MDSE for Behavior Assistance;Systems providing their end-users behavior assistance must be customized to meet those users' needs and behavior goals. We investigate how it is possible to improve the engineering process of such systems and provide humans better support by using human behavior goals not only for analysis but also in the design and run-time of a system. Current research focuses either on the analysis phase of a system or uses goals at the run-time of an application. They do not consider the mapping of human behavior goals from one phase to the other one needed for generative approaches. Within this paper, we present our vision towards the use of goals and goal modeling for human behavior assistance in generated systems. We show its application by adding assistive functionalities to an existing, full-size real-world information system. For the engineering of this system, we follow a model-driven, generative software engineering approach. Our prototypical implementation towards the vision of using goal models for human behavior assistance shows the feasibility of the approach and provides first insights into how it could improve the assistive abilities of systems towards end-user goals.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Companion Proceedings - 24th International Conference on Model-Driven Engineering Languages and Systems, MODELS-C 2021;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85123982473
435;A Catalog of Design Patterns for Compositional Language Engineering;When composing a domain-specific language from several language components, it is also necessary to compose analysis and synthesis techniques, which are individually defined on these components in an efficient, ideally black-box form. An effective way of allowing such compositions is to use specific design patterns, which are partly reflected in the tooling code, partly reflected in the language, but also partly reflected in the language workbench (one meta-level higher), and the generated/synthesized product code (one meta-level downward). Based on the experiences gained in compositional language development using the language workbench MontiCore, we in detail discuss several of those design patterns, namely the Mill, the RealThis object composition, the Template/Hook, and the TOP-Generator Patterns, and the hidden complexity of an extended visitor infrastructure coping with the above patterns. The patterns are recorded and described in a reusable way, as usual, allowing readers to participate from the gained insights and possible solutions.;Association Internationale pour les Technologies Objets;Journal;Journal of Object Technology;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85141747625
436;Engineering Digital Twins and Digital Shadows as Key Enablers for Industry 4.0;Industry 4.0 opens up new potentials for the automation and improvement of production processes, but the associated digitization also increases the complexity of this development. Monitoring and maintenance activities in production processes still require high manual effort and are only partially automated due to immature data aggregation and analysis, resulting in expensive downtimes, inefficient use of machines, and too much production of waste. To maintain control over the growing complexity and to provide insight into the production, concepts such as Digital Twins, Digital Shadows, and modelbased systems engineering for Industry 4.0 emerge. Digital Shadows consist of data traces of an observed Cyber-Physical Production System. Digital Twins operate on Digital Shadows to enable novel analysis, monitoring, and optimization.We present a general overview of the concepts of Digital Twins, Digital Shadows, their usage and realization in Data Lakes, their development based on engineering models, and corresponding engineering challenges. This provides a foundation for implementing Digital Twins, which constitute a main driver for future innovations in Industry 4.0 digitization.;Springer Berlin Heidelberg;Book;Digital Transformation: Core Technologies and Emerging Topics from a Computer Science Perspective;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85161813629
437;DTMN a Modelling Notation for Digital Twins;Modelling and developing digital twin solutions is a growing and promising trend followed by enterprises with the ambition to improve decision-making and accelerate risk assessment and production time. However, as a current emerging trend, there is no recognised standard nor a unique solution that provides support for all the characteristics of a digital twin. This article builds upon the result of a literature review that we conducted to extract the main characteristics attributed to Digital Twins. The identified characteristics guided the proposal of a Digital Twin Modelling Notation (DTMN). In this work we present the DTMN meta-model supported by a graphical modelling notation. This modelling notation can be used as a starting point to design and reason about Digital Twin solutions.;Springer Science and Business Media Deutschland GmbH;Book Series;Lecture Notes in Business Information Processing;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85149833934
438;Model-Driven Engineering of Process-Aware Information Systems;Enterprise information systems created with model-driven software engineering methods need to handle not only data but also business processes in an automated way. This paper shows how to engineer process-aware information systems following the model-driven and generative software engineering paradigms. Existing approaches realize either the generation of automated or manual activities but do not employ model-driven engineering of all system aspects through systematic language composition. A generative approach that additionally uses process modeling languages allows developers to evolve generated data-centric information systems into process-aware information systems. To be usable within our generation process, we have developed a textual BPMN version and a corresponding language tooling to check the soundness of the models. We have included these process models into the generation process of an information system together with other domain-specific modeling languages, e.g., for data structures, and generate an extendable, process-aware information system that is open for continuous regeneration and hand-written additions. This approach allows us to lift a generated data-centric information system to a process-aware information system. Agile development enabled through the opportunity to validate assumptions automatically and adapt changes efficiently, enhances the engineering process as well as the generated systems themselves.;Springer;Journal;SN Computer Science;2022-11-01;https://api.elsevier.com/content/abstract/scopus_id/85139200076
439;DTMN a Modelling Notation for Digital Twins;Modelling and developing digital twin solutions is a growing and promising trend followed by enterprises with the ambition to improve decision-making and accelerate risk assessment and production time. However, as a current emerging trend, there is no recognised standard nor a unique solution that provides support for all the characteristics of a digital twin. This article builds upon the result of a literature review that we conducted to extract the main characteristics attributed to Digital Twins. The identified characteristics guided the proposal of a Digital Twin Modelling Notation (DTMN). In this work we present the DTMN meta-model supported by a graphical modelling notation. This modelling notation can be used as a starting point to design and reason about Digital Twin solutions.;Springer Science and Business Media Deutschland GmbH;Book Series;Lecture Notes in Business Information Processing;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85149833934
440;Supporting the Implementation of Digital Twins for IoT-Enhanced BPs;IoT-Enhanced Business Processes make use of Internet of Things technology to integrate physical devices into the process as digital actors. Closely related to this topic arises the concept of Digital Twin, which is a virtual representation of real-world entities and processes that connect to the physical counterpart to represent, simulate, or predict changes in the physical system. There are many works that focus on supporting the high-fidelity implementation of Digital Twins for specific physical devices. However, few of them consider the process as a real-world entity to be integrated into the Digital Twin. In this work, we present a microservice architecture to support the implementation of Digital Twins for IoT-Enhanced Business Processes, considering not only the physical devices but also the process itself and the relationship among them. This architectural solution is supported by a model-driven development approach, which proposes (1) the construction of a BPMN model to represent an IoT-enhanced Business Process and (2) the application of model transformation to automatically generate both Digital Twin Definition Language (DTDL) models and microservice Java code templates. DTDL models are used in the implementation of the Digital Twins for the IoT-Enhanced Business Process. Java code templates are used to facilitate the implementation of the microservices required to deploy the IoT-enhanced Business Process and its Digital Twins into the proposed architecture and maintain the digital and physical parts synchronised.;Springer Science and Business Media Deutschland GmbH;Book Series;Lecture Notes in Business Information Processing;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85163280406
441;Measuring the fidelity of digital twin systems;A digital twin is a virtual replica of a system at a certain level of fidelity, synchronized at a specific frequency. Digital twins often replicate physical systems whose simulations are usually computationally costly. One of the solutions to this problem proposed in the literature is to define a hierarchy of multi-fidelity digital twins, where we use one twin or another depending on the specific purpose. However, one of the challenges of this proposal is the need to determine whether the different twins are equivalent to each other and the physical system. In this thesis, we explore different methods to measure this equivalence by analyzing the state and behavior of the twins with the aid of high-level software models.;Association for Computing Machinery, Inc;Conference Proceeding;Proceedings - ACM/IEEE 25th International Conference on Model Driven Engineering Languages and Systems, MODELS 2022: Companion Proceedings;2022-10-23;https://api.elsevier.com/content/abstract/scopus_id/85142936449
442;CPSAML: A Language and Code Generation Framework for Digital Twin based Monitoring of Mobile Cyber-Physical Systems;Cyber-physical systems (CPS) are finding increasing use, whether in factories, autonomous vehicles, or smart buildings. Monitoring the execution of CPSs is crucial since CPSs directly influence their physical environment. Like the actual system, the monitoring application must be designed, developed, and tested. Mobile CPSs, in contrast to stationary CPSs, bring the additional requirement that instances can dynamically join, leave, or fail during execution time. This dynamic behavior must also be considered in the monitoring application. This paper presents CPSAML, a language and code generation framework for the model-driven development of mobile CPS systems, including a cockpit application for monitoring and interacting with such a system. The pipeline starts with the formulation of the system and the CPSs it contains at an abstract level by the system architect using a domain-specific modeling language. Next, this model is transformed into SysML 2 for further extension and richer specificity by system engineers on a more technical level. In the last step of the pipeline, the SysML 2 model is used to generate code for the CPS devices, a system-wide digital twin, and the cockpit application mentioned above. This cockpit enables the operator to configure and apply the monitoring and interaction with the system during runtime. We evaluate our CPSAML language and code generation framework on an Indoor Transport System case study with Roomba vacuum cleaner robots.;Association for Computing Machinery, Inc;Conference Proceeding;Proceedings - ACM/IEEE 25th International Conference on Model Driven Engineering Languages and Systems, MODELS 2022: Companion Proceedings;2022-10-23;https://api.elsevier.com/content/abstract/scopus_id/85142923460
443;Cognitive neuroscience and robotics: Advancements and future research directions;In recent years, brain-based technologies that capitalise on human abilities to facilitate human–system/robot interactions have been actively explored, especially in brain robotics. Brain–computer interfaces, as applications of this conception, have set a path to convert neural activities recorded by sensors from the human scalp via electroencephalography into valid commands for robot control and task execution. Thanks to the advancement of sensor technologies, non-invasive and invasive sensor headsets have been designed and developed to achieve stable recording of brainwave signals. However, robust and accurate extraction and interpretation of brain signals in brain robotics are critical to reliable task-oriented and opportunistic applications such as brainwave-controlled robotic interactions. In response to this need, pervasive technologies and advanced analytical approaches to translating and merging critical brain functions, behaviours, tasks, and environmental information have been a focus in brain-controlled robotic applications. These methods are composed of signal processing, feature extraction, representation of neural activities, command conversion and robot control. Artificial intelligence algorithms, especially deep learning, are used for the classification, recognition, and identification of patterns and intent underlying brainwaves as a form of electroencephalography. Within the context, this paper provides a comprehensive review of the past and the current status at the intersection of robotics, neuroscience, and artificial intelligence and highlights future research directions.;Elsevier Ltd;Journal;Robotics and Computer-Integrated Manufacturing;2024-02-01;https://api.elsevier.com/content/abstract/scopus_id/85165534271
444;CDMerge: Semantically Sound Merging of Class Diagrams for Software Component Integration;Abstraction, refinement and (de-)composition are fundamental techniques for engineering large software systems. In the context of Model Driven Development (MDD), these techniques are primarily applied to models. Our goal is to integrate automated composition of data models into the development process. We focus primarily on Class Diagrams (CDs) which are widely used to model object-oriented systems. In particular, we consider the variant of UML/P CDs which are equipped with a formal semantics for both the closed-world and open-world assumptions and allow for underspecified associations. A sound merge of CDs must include precisely the information of its components and preserve their semantic implications. In this paper we introduce a merge operator for CDs that considers both formal and implementation-oriented soundness requirements. The operator is able to support a divide-and-conquer approach for modeling and code-generation of large object-oriented software systems. We clarify why we deem an open-world approach necessary and outline merge conflicts and variants. Finally, we discuss integration of automated merging into the development process and provide an outlook on run-time data integration.;Association Internationale pour les Technologies Objets;Journal;Journal of Object Technology;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85166967265
445;A Conceptual Model for Digital Shadows in Industry and Its Application;Smart manufacturing demands to process data in domain-specific real-time. Engineering models created for constructing, commissioning, planning, or simulating manufacturing systems can facilitate aggregating and abstracting the wealth of manufacturing data to faster processable data structures for more timely decision making. Current research lacks conceptual foundations for how data and engineering models can be exploited in an integrated way to achieve this. Such research demands expertise from different smart manufacturing domains to harmonize the notion space. We propose a conceptual model to describe digital shadows, data structures tailored to exploit models and data in smart manufacturing, through a metamodel and its notion space. This conceptual model was established through interdisciplinary research in the German excellence cluster “Internet of Production” and evaluated in various real-world manufacturing scenarios. This foundation for an understanding helps to manage complexity, automated analyses, and syntheses, and, ultimately, facilitates cross-domain collaboration.;Springer Science and Business Media Deutschland GmbH;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85118142665
446;Towards a Product Line Architecture for Digital Twins;Digital twins are a new kind of software systems for which corresponding architectures in different engineering domains have emerged for enabling the efficient interaction of software systems with physical systems to realize cyber-physical systems (CPS). To facilitate the development of digital twins, various software platforms emerged in recent years, which often come with a certain architecture for the developed systems together with a set of domain-specific languages (DSLs) that help domain experts to configure the platform and implement the digital twins. This results in a set of architectures and DSLs which are currently used to realize the various concerns of digital twins. Thus, creating a comprehensive digital twin for a given system requires the combination of several architectures and DSLs, which is challenging as (i) the components of the different architectures have to be combined on a technological level, and (ii) the concerns specified with the different DSLs are developed in isolation which potentially leads to inconsistencies, especially during the evolution of digital twins.To tackle these challenges, we outline our vision of a product line architecture that explicitly specifies the different concerns of digital twins and their alignment on both, the technological level considering the different architectural elements as well as on the language level considering the different language elements. As a result, glue code that is currently required to compose the individual features together into particular digital twin systems is automatically generated. We demonstrate the applicability of this approach by (i) specifying an example product line architecture for selected structural and behavioral concerns of digital twins, and (ii) configuring an existing digital twin based architecture for self-adaptive systems based on this product line architecture by (iii) applying the selected platforms realizing these concerns to a smart room use case. Finally, we discuss expected benefits of the presented approach, such as plug-&-play of digital twin modules, as well as sketch out future work to realize the presented vision.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - IEEE 20th International Conference on Software Architecture Companion, ICSA-C 2023;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85159120968
447;Agents and Digital Twins for the engineering of Cyber-Physical Systems: opportunities, and challenges;Digital Twins (DTs) are emerging as a fundamental brick of engineering Cyber-Physical Systems (CPSs), but their notion is still mostly bound to specific business domains (e.g. manufacturing), goals (e.g. product design), or applications (e.g. the Internet of Things). As such, their value as general purpose engineering abstractions is yet to be fully revealed. In this paper, we relate DTs with agents and multiagent systems, as the latter are arguably the most rich abstractions available for the engineering of complex socio-technical and CPSs, and the former could both fill in some gaps in agent-oriented software engineering and benefit from an agent-oriented interpretation—in a cross-fertilisation journey.;Springer Science and Business Media Deutschland GmbH;Journal;Annals of Mathematics and Artificial Intelligence;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85165304975
448;Model-driven Self-adaptive Deployment of Internet of Things Applications with Automated Modification Proposals;Today's Internet of Things (IoT) applications are mostly developed as a bundle of hardware and associated software. Future cross-manufacturer app stores for IoT applications will require that the strong coupling of hardware and software is loosened. In the resulting IoT applications, a quintessential challenge is the effective and efficient deployment of IoT software components across variable networks of heterogeneous devices. Current research focuses on computing whether deployment requirements fit the intended target devices instead of assisting users in successfully deploying IoT applications by suggesting deployment requirement relaxations or hardware alternatives. This can make successfully deploying large-scale IoT applications a costly trial-and-error endeavor. To mitigate this, we have devised a method for providing such deployment suggestions based on search and backtracking. This can make deploying IoT applications more effective and more efficient, which, ultimately, eases reducing the complexity of deploying the software surrounding us.;Association for Computing Machinery;Journal;ACM Transactions on Internet of Things;2022-09-06;https://api.elsevier.com/content/abstract/scopus_id/85141044295
449;FastSlowMo: Federated Learning With Combined Worker and Aggregator Momenta;"In this paper, we propose and analyze FastSlowMo, a combined Nesterov accelerated gradient (NAG) style worker momentum and aggregator momentum algorithm for Federated Learning (FL). Existing NAG momentum-based FL algorithms depend on either worker momentum only or aggregator momentum only, which may be inefficient due to infrequent usage of momentum, data heterogeneity, and out-of-date momentum. FastSlowMo combines the advantages of worker momentum and aggregator momentum to address these issues. We then provide mathematical proof for the convergence of FastSlowMo. Finally, extensive experiments based on real-world datasets and trace-driven simulation are conducted, verifying that FastSlowMo decreases the total training time by 3&#x2013;61&#x0025;, and outperforms existing mainstream benchmarks under a wide range of settings.";Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Transactions on Artificial Intelligence;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85133764608
450;Out-of-Things Debugging: A Live Debugging Approach for Internet of Things;Context Internet of Things (IoT) has become an important kind of distributed systems thanks to the wide-spread of cheap embedded devices equipped with different networking technologies. Although ubiquitous, developing IoT systems remains challenging. Inquiry A recent field study with 194 IoT developers identifies debugging as one of the main challenges faced when developing IoT systems. This comes from the lack of debugging tools taking into account the unique properties of IoT systems such as non-deterministic data, and hardware restricted devices. On the one hand, offline debuggers allow developers to analyse post-failure recorded program information, but impose too much overhead on the devices while generating such information. Furthermore, the analysis process is also time-consuming and might miss contextual information relevant to find the root cause of bugs. On the other hand, online debuggers do allow debugging a program upon a failure while providing contextual information (e.g., stack trace). In particular, remote online debuggers enable debugging of devices without physical access to them. However, they experience debugging interference due to network delays which complicates bug reproducibility, and have limited support for dynamic software updates on remote devices. Approach This paper proposes out-of-things debugging, an online debugging approach especially designed for IoT systems. The debugger is always-on as it ensures constant availability to for instance debug post-deployment situations. Upon a failure or breakpoint, out-of-things debugging moves the state of a deployed application to the developer’s machine. Developers can then debug the application locally by applying operations (e.g., step commands) to the retrieved state. Once debugging is finished, developers can commit bug fixes to the device through live update capabilities. Finally, by means of a fine-grained flexible interface for accessing remote resources, developers have full control over the debugging overhead imposed on the device, and the access to device hardware resources (e.g., sensors) needed during local debugging. Knowledge Out-of-things debugging maintains good properties of remote debugging as it does not require physical access to the device to debug it, while reducing debugging interference since there are no network delays on operations (e.g., stepping) issued on the debugger since those happen locally. Furthermore, device resources are only accessed when requested by the user which further mitigates overhead and opens avenues for mocking or simulation of non-accessed resources. Grounding We implemented an out-of-things debugger as an extension to a WebAssembly Virtual Machine and benchmarked its suitability for IoT. In particular, we compared our solution to remote debugging alternatives based on metrics such as network overhead, memory usage, scalability, and usability in production settings. From the benchmarks, we conclude that our debugger exhibits competitive performance in addition to confining overhead without sacrificing debugging convenience and flexibility. Importance Out-of-things debugging enables debugging of IoT systems by means of classical online operations (e.g., stepwise execution) while addressing IoT-specific concerns (e.g., hardware limitations). We show that having the debugger always-on does not have to come at cost of performance loss or increased overhead but instead can enforce a smooth-going and flexible debugging experience of IoT systems.;AOSA Inc.;Journal;Art, Science, and Engineering of Programming;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85142781724
451;Hierarchical Federated Learning with Momentum Acceleration in Multi-Tier Networks;"In this paper, we propose Hierarchical Federated Learning with Momentum Acceleration (HierMo), a three-tier worker-edge-cloud federated learning algorithm that applies momentum for training acceleration. Momentum is calculated and aggregated in the three tiers. We provide convergence analysis for HierMo, showing a convergence rate of <inline-formula><tex-math notation=""LaTeX"">$\mathcal {O}(\frac{1}{T})$</tex-math></inline-formula>. In the analysis, we develop a new approach to characterize model aggregation, momentum aggregation, and their interactions. Based on this result, we prove that HierMo achieves a tighter convergence upper bound compared with HierFAVG without momentum. We also propose HierOPT, which optimizes the aggregation periods (worker-edge and edge-cloud aggregation periods) to minimize the loss given a limited training time. By conducting the experiment, we verify that HierMo outperforms existing mainstream benchmarks under a wide range of settings. In addition, HierOPT can achieve a near-optimal performance when we test HierMo under different aggregation periods.";IEEE Computer Society;Journal;IEEE Transactions on Parallel and Distributed Systems;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85164663092
452;Federated Learning With Nesterov Accelerated Gradient;Federated learning (FL) is a fast-developing technique that allows multiple workers to train a global model based on a distributed dataset. Conventional FL (FedAvg) employs gradient descent algorithm, which may not be efficient enough. Momentum is able to improve the situation by adding an additional momentum step to accelerate the convergence and has demonstrated its benefits in both centralized and FL environments. It is well-known that Nesterov Accelerated Gradient (NAG) is a more advantageous form of momentum, but it is not clear how to quantify the benefits of NAG in FL so far. This motives us to propose FedNAG, which employs NAG in each worker as well as NAG momentum and model aggregation in the aggregator. We provide a detailed convergence analysis of FedNAG and compare it with FedAvg. Extensive experiments based on real-world datasets and trace-driven simulation are conducted, demonstrating that FedNAG increases the learning accuracy by 3-24% and decreases the total training time by 11-70% compared with the benchmarks under a wide range of settings.;IEEE Computer Society;Journal;IEEE Transactions on Parallel and Distributed Systems;2022-12-01;https://api.elsevier.com/content/abstract/scopus_id/85139407013
453;Web-Based Tracing for Model-Driven Applications;Logging still is a core functionality used to understand the behavior of programs and executable models. Yet, modeling languages rarely consider logging as a first-level activity that is manifested in the language through modeling elements or their behavior. When logging is part of the code generated for the respective models or the corresponding runtime environment only, it must be generic, as the modeler cannot influence, through the models, what and when logging takes place. To enable modelers to log model behavior, we devised a method based on language extension and smart code generation that can integrate logging into arbitrary textual modeling languages. Based on this method, log entries can be produced, traced, and presented through a web application. This method and its infrastructure can facilitate lifting logging to the model level and, hence, improve the understanding of executable models.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 48th Euromicro Conference on Software Engineering and Advanced Applications, SEAA 2022;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85147714086
454;Generating customized low-code development platforms for digital twins;A digital twin improves our use of a cyber–physical system and understanding of its emerging behavior. To this effect, a digital twin is to be developed and configured and potentially also operated by domain experts, who rarely have a professional software engineering background and for whom easy access and support, e.g., in form of low-code platforms are missing. In this paper, we report on an integrated method for the model-driven engineering of low-code development platforms for digital twins that enables domain experts to create and operate digital twins for cyber–physical systems using the most appropriate modeling languages. The foundation of this method is (1) a code generation infrastructure for information systems combined with (2) an extensible base architecture for self-adaptive digital twins and (3) reusable language components for their configuration. Using this method, software engineers first configure the information system with the required modeling languages to generate the low-code development platform for digital twins before domain experts leverage the generated platform to create digital twins. This two-step method facilitates creating tailored low-code development platforms as well as creating and operating customized digital twins for a variety of applications.;Elsevier Ltd;Journal;Journal of Computer Languages;2022-06-01;https://api.elsevier.com/content/abstract/scopus_id/85129984615
455;Digital Twins in Healthcare: an architectural proposal and its application in a social distancing case study;"The digital transformation process fostered by the development of Industry 4.0 technologies has largely affected the health sector, increasing diagnostic capabilities and improving drug effectiveness and treatment delivery. The Digital Twin (DT) technology, based on the virtualization of physical assets/processes and on a bidirectional communication between the digital and physical space for data exchange, is considered a game changer in modern health systems. Digital Twin applications in healthcare are various, ranging from virtualization of hospitals&#x0027; physical spaces/organizational processes to individuals&#x0027; physiological/genetic/lifestyle characteristics replication, and include the modeling of public health-related processes for monitoring, optimization and planning purposes. In this paper, motivated by the current COVID-19 pandemic, we focus on the application of the Digital Twin technology for virus containment on the workplace through social distancing. The contribution of this paper is three-fold: i) we review the existing literature on the adoption of the Digital Twin technology in the healthcare domain, and propose a classification of DT applications into four categories; ii) we propose a generalized Digital Twin architecture that can be used as reference to identify the main functional components of a Digital Twin system; iii) we present CanTwin, a real-life industrial case study developed by Hitachi and representing the Digital Twin of a canteen service serving 1100 workers, set up for social distancing monitoring, queue inspection, people counting and tracking, table occupancy supervision.";Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Journal of Biomedical and Health Informatics;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85137900898
456;Using trace alignments for measuring the similarity between a physical and its digital twin;A common problem in the development of digital twin systems is the validation that the behavior of both twins, the physical and the digital, is the same, or at least similar enough given the requirements of the digital twin system. In this paper, we propose a method for the alignment of the traces of both twins. Traces are sequences of snapshots that capture the progressive states of each entity. Our approach is based on a bioinformatic algorithm that we adapt and use for the alignment of snapshots. Additionally, we include a set of measures to evaluate the quality of these alignments and reason about the level of fidelity of the digital twin system. Two case studies are used to demonstrate our proposal and evaluate its accuracy and effectiveness.;Association for Computing Machinery, Inc;Conference Proceeding;Proceedings - ACM/IEEE 25th International Conference on Model Driven Engineering Languages and Systems, MODELS 2022: Companion Proceedings;2022-10-23;https://api.elsevier.com/content/abstract/scopus_id/85142936475
457;Digital twin solution architecture;A digital twin simulates the state and the behavior of a physical object in real time. This work focuses on primarily the digital twin solution architecture. The emphasis is on how the digital twin can be designed to deliver common use cases. From an architecture standpoint, a digital twin is a collection of several different software services, applications and data stores. In this chapter, we will first review how the physical object can be connected to the digital twin through the Internet of Things (IoT) and then see a layered view of the digital twin solution architecture. A description of the layered view and components in each layer will follow. An explanation of the data flow across digital twin components will show how various components work together. The digital twin solution architecture is explained through various viewpoints including data stores, user experience, integration with external applications, application programming interface (API), and cyber security. The solution architecture is presented at a conceptual level and is not tied to a framework, platform, or solution from a particular vendor. Concepts in the digital twin solution architecture are illustrated through examples from the world of discrete manufacturing.;wiley;Book;Digital Twin Technology: Fundamentals and Applications;2022-11-22;https://api.elsevier.com/content/abstract/scopus_id/85147836717
458;A pattern catalog for augmenting Digital Twin models with behavior Ein Musterkatalog zur Erweiterung von digitalen Zwillingsmodellen um Verhaltenssichten;Digital Twins are emerging as a solution to build and extend existing software systems to make better use of data produced by physical systems. For supporting the development of Digital Twins, several software vendors are offering dedicated tool support, often referred to as Digital Twin platforms. The modeling capabilities of these platforms are mostly concerned with structural viewpoints, i.e., providing an overview of available components including their current and historical sensor values. However, behavioral viewpoints did not yet receive much attention on these platforms. As behavioral models are often used during the design processes, e.g., for simulation and synthesis, it would be beneficial for having them included in Digital Twin platforms, e.g., for reasoning on the set of possible next actions or for checking the execution history to perform runtime validation. In this paper, we present a catalog of modeling patterns for augmenting Digital Twin models with behavioral models and their corresponding runtime information without requiring any extension of the code bases of Digital Twin platforms. We demonstrate the presented modeling patterns by applying them to the Digital Twin platform offered by Microsoft, in an additive manufacturing use case of a 3D printer in a production line.;De Gruyter Oldenbourg;Journal;At-Automatisierungstechnik;2023-06-01;https://api.elsevier.com/content/abstract/scopus_id/85161546216
459;Modeling and Synchronizing Digital Twin Environments;A digital twin is a virtual replica of a system defined at a certain level of fidelity and synchronized to a specific frequency. Digital twins are often used to replicate physical systems whose simulations are computationally expensive. If modeling the environment of any system is generally difficult, the problem is even harder in the case of digital twins, since the model of their environment must be synchronized with that of the physical system too. In this paper, we show how the environment of a digital twin can be effectively modeled and kept in sync with the real one, by adding digital proxies of the relevant elements of the environment to the models of the digital twin elements, and connecting them using the same synchronization mechanisms used by the twins. We demonstrate our approach with a case study of a smart room with sensors, using high-level software models.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings of the 2023 Annual Modeling and Simulation Conference, ANNSIM 2023;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85165506827
460;Measuring the fidelity of digital twin systems;A digital twin is a virtual replica of a system at a certain level of fidelity, synchronized at a specific frequency. Digital twins often replicate physical systems whose simulations are usually computationally costly. One of the solutions to this problem proposed in the literature is to define a hierarchy of multi-fidelity digital twins, where we use one twin or another depending on the specific purpose. However, one of the challenges of this proposal is the need to determine whether the different twins are equivalent to each other and the physical system. In this thesis, we explore different methods to measure this equivalence by analyzing the state and behavior of the twins with the aid of high-level software models.;Association for Computing Machinery, Inc;Conference Proceeding;Proceedings - ACM/IEEE 25th International Conference on Model Driven Engineering Languages and Systems, MODELS 2022: Companion Proceedings;2022-10-23;https://api.elsevier.com/content/abstract/scopus_id/85142936449
461;Categorization of approaches to extend and reuse OCL;Languages with a fixed set of data types and operations are very useful in formal verification and validation. However, the languages that are most relevant to industrial applications are those that provide extension mechanisms to define new capabilities. For example, Java libraries contribute essentially to the success of Java. In this paper we argue that OCL needs such extension capabilities across tooling boundaries. We describe different approaches of extending languages and elaborate on how such approaches can be applied to OCL. We sketch ideas of such approaches using a well-known OCL tool and suggest changes to the OCL standard to accommodate such approaches. In our opinion, the inclusion of such extension and reusability mechanisms will pave the way for better adoption of OCL in industrial settings and real-world projects.;Association for Computing Machinery, Inc;Conference Proceeding;Proceedings - ACM/IEEE 25th International Conference on Model Driven Engineering Languages and Systems, MODELS 2022: Companion Proceedings;2022-10-23;https://api.elsevier.com/content/abstract/scopus_id/85142926044
462;A survey on digital twin: Definitions, characteristics, applications, and design implications;When, in 1956, Artificial Intelligence (AI) was officially declared a research field, no one would have ever predicted the huge influence and impact its description, prediction, and prescription capabilities were going to have on our daily lives. In parallel to continuous advances in AI, the past decade has seen the spread of broadband and ubiquitous connectivity, (embedded) sensors collecting descriptive high dimensional data, and improvements in big data processing techniques and cloud computing. The joint usage of such technologies has led to the creation of digital twins, artificial intelligent virtual replicas of physical systems. Digital Twin (DT) technology is nowadays being developed and commercialized to optimize several manufacturing and aviation processes, while in the healthcare and medicine fields this technology is still at its early development stage. This paper presents the results of a study focused on the analysis of the state-of-the-art definitions of DT, the investigation of the main characteristics that a DT should possess, and the exploration of the domains in which DT applications are currently being developed. The design implications derived from the study are then presented: they focus on socio-technical design aspects and DT lifecycle. Open issues and challenges that require to be addressed in the future are finally discussed.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85076680404
463;An AAS Modeling Tool for Capability-Based Engineering of Flexible Production Lines;The future intelligent manufacturing systems should possess a high degree of autonomy, which is able to monitor the entire production process, quickly re-plan operations, and respond to various unforeseen situations in a secure and safe manner. This can achieve rapid response to customers and avoid costly machine downtime, which is crucial to maintaining business success and profitability. The Asset Administration Shell (AAS) is an emerging standard in the I4.0 (Industry 4.0) domain. Based on the concept of digital twins, it provides concepts for describing the digital representation of I4.0 assets including their capabilities and skills. The AAS provides also responses to the challenge of syntactic and semantic interoperability that the flexible and autonomous production lines are facing. In this article, we propose a capability-based operation and engineering approach for flexible production lines. Our approach is relying on the AAS standard which is a very wide and rich specification. Consequently, we describe the subset of AAS modelling concepts necessary for our approach, we clarify their semantics and we show their usage through a production cell use case. Furthermore, we demonstrate how these modelling concepts were tooled as an extension of the open source model-driven workbench Papyrus.;IEEE Computer Society;Conference Proceeding;IECON Proceedings (Industrial Electronics Conference);2021-10-13;https://api.elsevier.com/content/abstract/scopus_id/85119507003
464;Potential for combining semantics and data analysis in the context of digital twins;Modern production systems can benefit greatly from integrated and up-to-date digital representations. Their applications range from consistency checks during the design phase to smart manufacturing to maintenance support. Such digital twins not only require data, information and knowledge as inputs but can also be considered integrated models themselves. This paper provides an overview of data, information and knowledge typically available throughout the lifecycle of production systems and the variety of applications driven by data analysis, expert knowledge and knowledge-based systems. On this basis, we describe the potential for combining data analysis and knowledge-based systems in the context of production systems and describe two feasibility studies that demonstrate how knowledge-based systems can be created using data analysis. This article is part of the theme issue 'Towards symbiotic autonomous systems'.;Royal Society Publishing;Journal;Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences;2021-10-04;https://api.elsevier.com/content/abstract/scopus_id/85113289464
465;Interoperable digital twins in IIoT systems by transformation of information models: A case study with asset administration shell;By providing a consolidated access point to information of devices and systems, digital twins enable new, data-intensive use cases for the industrial internet of things (IIoT), like predictive plant and product design. However, the lack of interoperability between the digital twins of different companies hinders use cases that require information exchange between different organizations. Achieving interoperability among digital twins requires transforming the included information to other formats. In this paper, we present requirements and a solution to enable interoperable digital twins by transforming their information models in a flexible way. We illustrate how we applied our solution to a real-world application example in an industrial context by transforming ABB Ability™ digital twins to the Asset Administration Shell format. We show that our customizable transformation system paves the way for on demand interoperability and thereby enables advanced use cases in the IIoT.;Association for Computing Machinery;Conference Proceeding;ACM International Conference Proceeding Series;2019-10-22;https://api.elsevier.com/content/abstract/scopus_id/85076137292
466;The use of ontologies for effective knowledge modelling and information retrieval;The dramatic increase in the use of knowledge discovery applications requires end users to write complex database search requests to retrieve information. Such users are not only expected to grasp the structural complexity of complex databases but also the semantic relationships between data stored in databases. In order to overcome such difficulties, researchers have been focusing on knowledge representation and interactive query generation through ontologies, with particular emphasis on improving the interface between data and search requests in order to bring the result sets closer to users research requirements. This paper discusses ontology-based information retrieval approaches and techniques by taking into consideration the aspects of ontology modelling, processing and the translation of ontological knowledge into database search requests. It also extensively compares the existing ontology-to-database transformation and mapping approaches in terms of loss of data and semantics, structural mapping and domain knowledge applicability. The research outcomes, recommendations and future challenges presented in this paper can bridge the gap between ontology and relational models to generate precise search requests using ontologies. Moreover, the comparison presented between various ontology-based information retrieval, database-to-ontology transformations and ontology-to-database mappings approaches provides a reference for enhancing the searching capabilities of massively loaded information management systems.;Elsevier B.V.;Journal;Applied Computing and Informatics;2018-07-01;https://api.elsevier.com/content/abstract/scopus_id/85048925522
467;Enabling semantic interoperability of asset administration shells through an ontology-based modeling method;Digital twin technology establishes the future development vision for Industry 4.0, and is also an important exploration direction for the Model-Driven Engineering (MDE) paradigm. Because it builds a more flexible and communicative production system through models that spans life cycle, hierarchy and architecture. The standard proposed under the concept of Industry 4.0, the Asset Administration Shell (AAS), provides a syntactic interoperability interface for all assets involved in smart factories. However, there is still a need to fill the gap regarding semantic interoperability, in order to allow efficient interactions between Industry 4.0 components. Ontologies are a good candidate because they provide formal semantics expressed using a knowledge representation language, and in addition, there are many associated mature tools for reasoning and inference. Therefore, we propose a modeling approach that provides semantic interoperability for AAS-based digital twins using ontologies.;Association for Computing Machinery, Inc;Conference Proceeding;Proceedings - ACM/IEEE 25th International Conference on Model Driven Engineering Languages and Systems, MODELS 2022: Companion Proceedings;2022-10-23;https://api.elsevier.com/content/abstract/scopus_id/85142934810
468;AAS Capability-Based Operation and Engineering of Flexible Production Lines;"Lot-size-one systems as well as plug and produce concepts imply (1) producing increased variety of products in a highly flexible and timely manner, and (2) making commissioning and maintenance more flexible. The speed with which manufacturers, in particular SMEs, can reconfigure the production to a new run and thus respond to clients and avoid costly machine downtime is critical to maintaining commercial success and profit margins. The manufacturing systems of tomorrow must offer a high degree of autonomy, be quickly re-planned to other operations, and cope with a wide variety of unforeseen situations, in a secure and safe manner. In this context, the Asset Administration Shell (AAS) is an emergent standard that leverages the digital twin approach and provides concepts for describing capabilities and skills of I4.0 components in order to automate the reconfiguration process. This article proposes a capability-based operation and engineering approach to tackle the syntactic and semantic interoperability problems in flexible production lines. We demonstrate the implementation of the AAS standard in the open source model-driven workbench Papyrus; then we assess its usability for modeling a production cell use case in order to implement a capability-based reconfiguration approach for flexible production lines.";Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;IEEE International Conference on Emerging Technologies and Factory Automation, ETFA;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85122963448
469;Digital Twin-Driven Design: A Framework to Enhance System Interoperability in the Era of Industry 4.0;Product development and manufacturing is entering a digital era, thanks to the progress made in data science and virtual technologies. The digital twin (DT) is one of the key concepts associated with this transition to Industry 4.0. Yet, in the literature, the term is differently used in various communities. In addition, the DT implementation in the product development process (PDP) lacks a conceptual ground, which hinders the proper use and wider application of this technology in engineering design and product life cycle management. This paper proposes an interoperability framework for digital twin-driven product design, based on data integration at different stages of the respective life cycles of the product and its digital twin. Such a framework can greatly help companies optimize their PDP.;Springer Science and Business Media Deutschland GmbH;Conference Proceeding;Proceedings of the I-ESA Conferences;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85149692057
470;Semantics for I4.0 Smart Manufacturing;In the realm of ‚Smart Manufacturing‘[IEC20a] the ‚SemNorm‘Project [DKE20a] addresses the question of how to at derive an executable Digital Twin (DT) [DTC20] from standards. A Digital Twin is a virtual representation that embodies an asset of any type [IOSB18]. In that sense a DT is compared to the Asset Administration Shell (AAS). Smart Manufacturing is a real thing of a factory represented by its structure and behavior of inter-connected things that generate real-time data [IOSB18]. By combining Smart Manufacturing processes with a Digital Twin it is intended to validate operations of a production systems in real-time. In general the properties of inter-operating things respectively systems, and especially the properties of energy transportation between systems are considered to be the ‚Prove of Concepts‘(PoC) of semantics. When The Information Technology (IT) that processes data and up to some extend information, is compared to the technology that enables communication among things or objects then the technology is called Operation Technology (OT). Whereas the semantics of IT is straight-forward, namely the interpretation of data objects in different contexts of a sending and a receiving environment, the semantics of OT is achieved on two levels. The the first (informal) level explains semantics as a narrative of how things are processed in a smart manufacturing plant, whereas the second (formal) level defines semantics more formally, i.e. by means of graph manipulations. Graph Manipulations represent sequences of events that are related to the narrative of talking about inter-operations among things. At same time a graph is a computational representation (cp. [IOSB18]) in terms of sequences of events (so-called runs) that are executable by appropriate tools from the shelve. Thus graph computations and told narratives are said to be ‚similar‘, respectively ‚comparable‘since they are related to each other by a morphism i.e. the formal relationship between artifacts of graphs, artifacts from the standard ontology and artifacts of the technical asset domain. The OT narration validated by a graph semantics analysis is finally to be transformed into a standard’s document which is then called to be a Semantic Standard. This process is a backward transformation of interoperation properties from a semantic representation into an English text that describes the requirements of these properties. In a forward transformation it is started with the textual standards together with the derived guidelines to transform the standard into a semantic representation respectively a Digital Twin.;Gesellschaft fur Informatik (GI);Conference Proceeding;Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI);2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85127309160
471;Digital twin-enabled decision support services in industrial ecosystems;The goal of this paper is to further elaborate a new concept for value creation by decision support services in industrial service ecosystems using digital twins and to apply it to an extended case study. The aim of the original model was to design and integrate an architecture of digital twins derived from business needs that leveraged the potential of the synergies in the ecosystem. The conceptual framework presented in this paper extends the semantic ontology model for integrating the digital twins. For the original model, technical modeling approaches were developed and integrated into an ecosystem perspective based on a modeling of the ecosystem and the actors’ decision jobs. In a service ecosystem comprising several enterprises and a multitude of actors, decision making is based on the interlinkage of the digital twins of the equipment and the processes, which is achieved by the semantic ontology model further elaborated in this paper. The implementation of the digital twin architecture is shown in the example of a manufacturing SME (small and medium-sized enterprise) case that was introduced in. The mixed semantic modeling and model-based systems engineering for this implementation is discussed in further detail in this paper. The findings of this detailed study provide a theoretical concept for implementing digital twins on the level of service ecosystems and integrating digital twins based on a unified ontology. This provides a practical blueprint to companies for developing digital twin based services in their own operations and beyond in their ecosystem.;MDPI;Journal;Applied Sciences (Switzerland);2021-12-01;https://api.elsevier.com/content/abstract/scopus_id/85120790758
472;Capability matchmaking software for rapid production system design and reconfiguration planning;Traditionally, the production system design and reconfiguration planning are manual processes, which rely heavily on the designers' expertise and tacit knowledge to find feasible system configuration solutions. Rapid responsiveness of future production systems calls for new computer-aided intelligent design and planning solutions, that would reduce the time and effort put into system design, both in brownfield and greenfield scenarios. This paper describes the implementation of a capability matchmaking software, which automatizes the matchmaking between product requirements and resource capabilities. The interaction of the matchmaking system with external design and planning tools is explained and illustrated with a case example. The matchmaking approach supports production system design and reconfiguration planning by providing automatic means for checking if the existing system already fulfills the new product requirements, and for finding alternative resources and resource combinations to specific product requirements from large search spaces, e.g. from global resource catalogues.;Elsevier B.V.;Conference Proceeding;Procedia CIRP;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85100851587
473;Definition of modeling vs. programming languages;Modeling languages (like UML and SysML) are those used in model-based specification of software-intensive systems. Like programming languages, they are defined using their syntax and semantics. However, both kinds of languages are defined by different communities, and in response to different requirements, which makes their methodologies and tools different. In this paper, we highlight the main differences between the definition methodologies of modeling and programming languages. We also discuss the impact of these differences on language tool support. We illustrate our ideas using examples from known programming and modeling languages. We also present a case study, where we analyze the definition of a new modeling language called the Ontology Modeling Language (OML). We highlight the requirements that have driven OML definition and explain how they are different from those driving typical programming languages. Finally, we discuss how these differences are being abstracted away using new language definition tools.;Springer Verlagservice@springer.de;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85056487138
474;Web-based solution to automate capability matchmaking for rapid system design and reconfiguration;Modern manufacturing companies desire rapid responsiveness from their production systems, in order to operate efficiently in highly dynamic environments. There is a need for design tools, which can support production system design and reconfiguration by providing automatic matchmaking between product requirements and resource capabilities. Such matchmaking is currently time consuming and heavily dependent upon designer’s experience. This paper introduces a prototype of a web-based software service, which carries out this matchmaking task automatically, and how it is designed to meet the requirements of manufacturing industry. Software engineering process has been followed for the development. We also describe a case example, which illustrates how the production system designer can interact with matchmaking activity through its web service interface. We expect that web service-based approach to matchmaking will reduce the technical barrier for adoption by the manufacturing industry as existing planning and reconfiguration systems can utilize the service with small efforts.;Elsevier B.V.;Conference Proceeding;Procedia CIRP;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85068477095
475;From open business model to ecosystem business model: A processes view;A central and underexamined phenomenon in the growing literature on business models is: how firms pursuing platformization transform their open business models to create an ecosystem-based business model and ecosystem business model. While an open business model focuses mainly on searching and integrating external knowledge to address key aspects of a firm's value proposition and offerings, an ecosystem-based business model refers to how a firm adjusts the critical components of its business model according to its position, role, and links in the ecosystem. However, an ecosystem business model involves activities and offerings from ecosystem actors that should be aligned to materialize a general value proposition. This platformization requires a profound yet little understood view on how firms transform business models through cognitive and managerial processes. To address this research gap, we employ a multiple-case study approach in four large firms. This study identifies a new business model transformation process consisting of three phases: 1) broadening view, 2) integrating, and 3) orchestrating. Our findings contribute to the literature by demonstrating the unique cognitive and managerial processes related to shaping the emergence of the ecosystem business model while simultaneously transforming the firm's business model to operate in ecosystems.;Elsevier Inc.;Journal;Technological Forecasting and Social Change;2023-09-01;https://api.elsevier.com/content/abstract/scopus_id/85163554208
476;Developing Multi-Agent Based Micro-Grid Management System in JADE;This paper presents an implementation of a Multi-Agent based Energy Management System for a micro grid with JADE (Java Agent Development Framework). The MAS is applied for a micro grid consisting of different distributed energy sources such as solar PV system, wind power system, diesel generator system, storage system, and critical and noncritical loads. Different agents are developed on JADE framework and they are given responsibilities of relevant DES's (Distributed Energy Source) and loads. A runtime environment for Agents are created and a dynamic simulation model developed through JADE considering the intermittent qualities of renewable energy sources. The case studies presented on this paper are modeled on JADE platform. Developing MAS in JADE runtime environment using AOP (Agent-Oriented Programming) helps agents to operate with all their autonomous, rational, reactive, and proactive qualities. The use of MAS concept in micro grids improves its efficiency in various aspects. The MAS based micro grid management system implemented in JADE platform and can be used to carry out various simulations to study about agent behaviors in different environments and different system objectives. The main purpose of the paper is to prove the possibility of using multi-agent concept in micro grid energy management systems.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings of the 2019 2nd International Conference on Power and Embedded Drive Control, ICPEDC 2019;2019-08-01;https://api.elsevier.com/content/abstract/scopus_id/85082993306
477;An ASM semantics of token flow in UML 2 activity diagrams;The token flow semantics of UML 2 activity diagrams is formally defined using Abstract State Machines. Interruptible activity regions and multiplicity bounds for pins are considered for the first time in a comprehensive and rigorous way. The formalisation provides insight into problems with the UML specification, and their solutions. It also serves as a basis for an integrated environment supporting the simulation and debugging of activity diagrams. © Springer-Verlag Berlin Heidelberg 2007.;Springer Verlag;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2007-01-01;https://api.elsevier.com/content/abstract/scopus_id/38049134593
478;Model-driven engineering for design-runtime interaction in complex systems: Scientific challenges and roadmap: Report on the MDE@DeRun 2018 workshop;This paper reports on the first Workshop on Model-Driven Engineering for Design-Runtime Interaction in Complex Systems (also called MDE@DeRun 2018) that took place during the STAF 2018 week. It explains the main objectives, content and results of the event. Based on these, the paper also proposes initial directions to explore for further research in the workshop area.;Springer Verlagservice@springer.de;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85058512584
479;Scalable model views over heterogeneous modeling technologies and resources;When engineering complex systems, models are typically used to represent various systems aspects. These models are often heterogeneous in terms of modeling languages, provenance, number or scale. As a result, the information actually relevant to engineers is usually split into different kinds of interrelated models. To be useful in practice, these models need to be properly integrated to provide global views over the system. This has to be made possible even when those models are serialized or stored in different formats adapted to their respective nature and scalability needs. Model view approaches have been proposed to tackle this issue. They provide unification mechanisms to combine and query various different models in a transparent way. These views usually target specific engineering tasks such as system design, monitoring and evolution. In an industrial context, there can be many large-scale use cases where model views can be beneficial, in order to trace runtime and design-time data, for example. However, existing model view solutions are generally designed to work on top of one single modeling technology (even though model import/export capabilities are sometimes provided). Moreover, they mostly rely on in-memory constructs and low-level modeling APIs that have not been designed to scale in the context of large models stored in different kinds of data sources. This paper presents a general solution to efficiently support scalable model views over heterogeneous modeling resources possibly handled via different modeling technologies. To this intent, it describes our integration approach between a model view framework and various modeling technologies providing access to multiple types of modeling resources (e.g., in XML/XMI, CSV, databases). It also presents how queries on such model views can be executed efficiently by benefiting from the optimization of the different model technologies and underlying persistence backends. Our solution has been evaluated on a practical large-scale use case provided by the industry-driven European MegaM@Rt2 project that aims at implementing a runtime ↔ design time feedback loop. The corresponding EMF-based tooling support, modeling artifacts and reproducible benchmarks are all available online.;Springer;Journal;Software and Systems Modeling;2020-07-01;https://api.elsevier.com/content/abstract/scopus_id/85083396373
480;Blended modelling - What, why and how;Empirical studies indicate that user experience can significantly be improved in model-driven engineering. Blended modelling aims at mitigating this by enabling users to interact with a single model through different notations. Blended modelling contributes to various modelling qualities, including comprehensibility, analysability, and acceptability. In this paper, we define the notion of blended modelling and propose a set of dimensions that characterise blended modelling. The dimensions are grouped in two classes: user-oriented dimensions and realisation-oriented dimensions. Each dimension describes a facet that is relevant to blended modelling together with its domain (i.e., the range of values for that dimension). The dimensions offer a basic vocabulary to support tool developers with making well-informed design decisions as well as users to select appropriate tools and configure them according to the needs at hand. We illustrate how the dimensions apply to different cases relying on our experience with blended modelling. We discuss the impact of blended modelling on usability and user experience and sketch metrics to measure it. Finally, we outline a number of core research directions in this increasingly important modelling area.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2019 ACM/IEEE 22nd International Conference on Model Driven Engineering Languages and Systems Companion, MODELS-C 2019;2019-09-01;https://api.elsevier.com/content/abstract/scopus_id/85075926513
481;Recommendation patterns for Business Process imperative Modeling;With the wide acceptance of the Imperative Business Process Modeling, supporting this activity has becoming increasingly important. In this sense, the dificulties faced by modelers while mapping business concerns into correct process models is a key issue. This paper presents the idea of Imperative Modeling Recommendation Patterns in order to tackle this issue. Recommendation Patterns aim at supporting modelers to decide between modeling structure options while preserving both process and modeling concerns. By doing so, these patterns enable the achievement of correct modeling solutions without, however, forcing a unique solution. The application of the Recommendation Patterns is discussed in the context of a methodology for Business Process Imperative Modeling support.;Association for Computing Machineryacmhelp@acm.org;Conference Proceeding;Proceedings of the ACM Symposium on Applied Computing;2017-04-03;https://api.elsevier.com/content/abstract/scopus_id/85020898336
482;Linking data and BPMN processes to achieve executable models;We describe a formally well founded approach to link data and processes conceptually, based on adopting UML class diagrams to represent data, and BPMN to represent the process. The UML class diagram together with a set of additional process variables, called Artifact, form the information model of the process. All activities of the BPMN process refer to such an information model by means of OCL operation contracts. We show that the resulting semantics while abstract is fully executable. We also provide an implementation of the executor.;Springer Verlagservice@springer.de;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/85021236150
483;Towards a mapping from BPMN to agents;In industry, people who design business processes are often different from those designing the technical realization. Also, they generally use different languages, such as BPMN on the one hand and UML on the other. While agents are theoretically suitable for designing and implementing business ideas, multi-agent methodologies are generally not geared towards them. In this paper, we describe the first step of mapping business process diagrams to agent concepts. To this end, we present a graph based representation of BPMN together with structural and semantical analysis methods. These provide the necessary formal grounding for the mapping we have in mind. © Springer-Verlag Berlin Heidelberg 2007.;Springer Verlag;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2007-01-01;https://api.elsevier.com/content/abstract/scopus_id/38149060099
484;Smart recoating: A digital twin framework for optimisation and control of powder spreading in metal additive manufacturing;We present a new framework for learning novel operational strategies and dynamically controlling the layering process in metal additive manufacturing. Metal additive manufacturing technologies such as powder bed fusion (PBF) are generally constrained by a fixed action powder spreading process. At every layer, the print platform is lowered by a fixed amount, and the same recoating action is performed. Ideally this would lead to consistent layering and identical properties each time, but frequently process variability disrupts this procedure, leading to inconsistent layers. This can be mitigated by intelligently controlling the powder spreading process, which we achieve via a shift to digital methodologies that can reveal new process strategies and dynamically update the printer commands. We employ Bayesian optimisation as a method to build and train surrogate models for real-time control. We then demonstrate the utility of this Smart Recoating approach within an integrated simulation framework driven by realistic Discrete Element Method powder spreading simulations. Our results inform new strategies for controlling the recoater and print stage displacements, and demonstrate the potential of a digital twin control system to mitigate process variation and achieve consistent print quality in each layer.;Elsevier Ltd;Journal;Journal of Manufacturing Processes;2023-08-04;https://api.elsevier.com/content/abstract/scopus_id/85160564044
485;Microservices as agents in IoT systems;Developing robust monolith systems has achieved its limitations, since the implementation of changes in today’s large, complex, and fast evolving systems would be too slow and inefficient. As a response to these problems, microservice architecture emerged, and quickly became a widely used solution. Such modular architecture is appropriate for distributed environment of Internet of Things (IoT) solutions. In this paper we present a solution for service management on Machine-to-Machine (M2M) devices within IoT system by using collaborative microservices. Collaboration of distributed modules highly reminds of multi-agent systems where autonomous agents also cooperate to provide services to the end-user. Because of these similarities we consider microservices as modern agents that could improve systems in distributed environments, such as IoT.;Springer Science and Business Media Deutschland GmbHinfo@springer-sbm.com;Book Series;Smart Innovation, Systems and Technologies;2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85020401655
486;Web-based digital twin modeling and remote control of cyber-physical production systems;The rapid development new generation of information technologies facilitate the emergence of cyber-physical production system (CPPS) which could pave a way to exploring new smart manufacturing solutions. Digital twin (DT) is the technical core for establishing CPPS in the context of industry 4.0. Developing an easy-to-deploy and simple-to-use DT-based CPPS is a critical research gap. In this paper, a systemic framework is proposed to provide guidelines for rapid system configuration and easy runtime of DT-based CPPS by integrating CPS, DT modeling technologies, event-driven distributed cooperation mechanisms, and web technologies. The concept of CPS node (CPSN) for manufacturing resources is established by integrating semantic information model, 3D geometric model and function modules. Various CPSNs are orchestrated as an autonomous CPPS using dynamic resource registration and binding technologies. To achieve easy runtime of DT-based CPPS, event-driven distributed cooperation among CPSNs and web-based remote control of CPPS are proposed respectively. Finally, to verify the feasibility of the proposed framework, a prototype of DT-based CPPS is implemented, based on which an exemplary case is conducted.;Elsevier Ltd;Journal;Robotics and Computer-Integrated Manufacturing;2020-08-01;https://api.elsevier.com/content/abstract/scopus_id/85079532714
487;Heuristics for Robots-Humans Tasks Assignment in a Containers Loading Center;To improve working conditions at sorting centers and to reduce the burden, La Poste wants to automate a part of the container-handling process. This mainly concerns containers that belong to the destinations with highest traffic since they demand an important effort and time amount from the operators especially in critical times like truck-departure times, when the operators must quickly load the containers in carts to be transported in trucks so that no delay will occur to the delivery date of the mail items. In this paper, we give a mixed integer linear program to assign the tasks to the robots, in order to maximize the workload of the robots and minimize the effort made by the operators. In addition, a greedy heuristic is proposed. Experiments performed on realistic data confirm the performance of the greedy algorithm. In addition, a sensitivity analysis of the heuristic is given to test its robustness on noisy data.;Elsevier B.V.;Conference Proceeding;IFAC-PapersOnLine;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85075864039
488;The Digital Twin: Realizing the Cyber-Physical Production System for Industry 4.0;Concerning current approaches to planning of manufacturing processes, the acquisition of a sufficient data basis of the relevant process information and subsequent development of feasible layout options requires 74% of the overall time-consumption. However, the application of fully automated techniques within planning processes is not yet common practice. Deficits are to be observed in the course of the use of a fully automated data acquisition of the underlying process data, a key element of Industry 4.0, as well as the evaluation and quantification and analysis of the gathered data. As the majority of the planning operations are conducted manually, the lack of any theoretical evaluation renders a benchmarking of the results difficult. Current planning processes analyze the manually achieved results with the aid of simulation. Evaluation and quantification of the planning procedure are limited by complexity that defies manual controllability. Research is therefore required with regard to automated data acquisition and selection, as the near real-time evaluation and analysis of a highly complex production systems relies on a real-time generated database. The paper presents practically feasible approaches to a multi-modal data acquisition approach, its requirements and limitations. The further concept of the Digital Twin for a production process enables a coupling of the production system with its digital equivalent as a base for an optimization with a minimized delay between the time of data acquisition and the creation of the Digital Twin. Therefore a digital data acquisition approach is necessary. As a consequence a cyber-physical production system can be generated, that opens up powerful applications. To ensure a maximum concordance of the cyber-physical process with its real-life model a multimodal data acquisition and evaluation has to be conducted. The paper therefore presents a concept for the composition of a database and proposes guidelines for the implementation of the Digital Twin in production systems in small and medium-sized enterprises.;Elsevier B.V.;Conference Proceeding;Procedia CIRP;2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/85019987476
489;Complex behavior of individuals and collectives in a social system: An introduction to exploratory computational experimental methodology based on multi-agent modeling;Although the multi-agent model has been used to analyze several economic and management problems, and the research results are regarded more profoundly, they all rely on certain scenarios. Once the scenarios are shifted to an unknown one, the results cannot be matched. In this paper, a new research method named exploratory computational experiment is introduced to resolve the problems coming from the social complex system, where individual’s behaviors are irrational, diverse, and complex, and collective behavior is dynamical, complex, and critical. Firstly, the foundation of the computational experiment is introduced, then several important problems, how individuals make the decision under complex environment, how collective behavior have emerged when different conflicts co-exist, and how to evaluate collect behaviors, are analyzed. To specify this new method, two examples of how to design a scientific mechanism to make the traffic system more effective and how is the evolution law of giant components in scale-free networks if the parameters are changed continuously. The results show that multi-agent modeling based on irrational behaviors controlled by individual dynamical game radius and memory length limited can describe the social problem more accurately, the exploratory computational experiment can give us more profound conclusions.;Springer;Journal;Annals of Operations Research;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85160220072
490;Enterprise Information Systems in Academia and Practice: Lessons learned from a MBSE Project;The development of domain-specific information systems, especially web information systems, takes a certain amount of time, needs intensive testing to ensure a certain quality and lacks the consistency of front- and backend. Using model-based strategies for the creation of information systems helps to overcome these problems by fastening the development process, facilitating testing and ensuring consistency-by-construction. In practice, however, they are still rarely used. In this paper, we show that model-based engineering is beneficial for the creation of an enterprise information system and improves the quality of the resulting product. We present the basic functionalities of our Generator for Enterprise Management (MontiGEM) and discuss identified problems and lessons learned in a project in practice. The generator was developed simultaneously with and for an enterprise management system. Our research shows that the use of generative methods and MBSE improves the adaptability and reusability of parts of the application on the one hand but on the other hand, there are still obstacles that slow down its broad application in practice.;Gesellschaft fur Informatik (GI);Conference Proceeding;Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI);2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85115262972
491;Model-based generation of enterprise information systems;Thick clients of client/server-information systems include increasingly more logic which leads to several challenges in the development process: Resulting from the separate development of frontand backend, the risk for inconsistencies between components on the one hand, and communication overhead between developers on the other hand are high. We present an approach which helps to overcome these challenges by using model-driven engineering for the development of data-intensive enterprise information systems. WebDEx was developed as a generator for the creation of such systems. It uses UML/P inspired modelling languages, as models (1) build the base for communication among project members and (2) are used as input for the code generator which ensures consistency by construction. This work relies on an infrastructure created by the language workbench and code generation framework MontiCore. Moreover, this paper presents the practical application of this approach for the agile development of a multi user, adaptable web-application to be used by more than 400 chairs of RWTH Aachen University.;CEUR-WSceurws@sunsite.informatik.rwth-aachen.de;Conference Proceeding;CEUR Workshop Proceedings;2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85048362638
492;C2PS: A digital twin architecture reference model for the cloud-based cyber-physical systems;Cyber-physical system (CPS) is a new trend in the Internet-of-Things related research works, where physical systems act as the sensors to collect real-world information and communicate them to the computation modules (i.e. cyber layer), which further analyze and notify the findings to the corresponding physical systems through a feedback loop. Contemporary researchers recommend integrating cloud technologies in the CPS cyber layer to ensure the scalability of storage, computation, and cross domain communication capabilities. Though there exist a few descriptive models of the cloud-based CPS architecture, it is important to analytically describe the key CPS properties: computation, control, and communication. In this paper, we present a digital twin architecture reference model for the cloud-based CPS, C2PS, where we analytically describe the key properties of the C2PS. The model helps in identifying various degrees of basic and hybrid computation-interaction modes in this paradigm. We have designed C2PS smart interaction controller using a Bayesian belief network, so that the system dynamically considers current contexts. The composition of fuzzy rule base with the Bayes network further enables the system with reconfiguration capability. We also describe analytically, how C2PS subsystem communications can generate even more complex system-of-systems. Later, we present a telematics-based prototype driving assistance application for the vehicular domain of C2PS, VCPS, to demonstrate the efficacy of the architecture reference model.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/85015767302
493;Model-Driven Development of a Digital Twin for Injection Molding;Digital Twins (DTs) of Cyber-Physical Production Systems (CPPSs) enable the smart automation of production processes, collection of data, and can thus reduce manual efforts for supervising and controlling CPPSs. Realizing DTs is challenging and requires significant efforts for their conception and integration with the represented CPPS. To mitigate this, we present an approach to systematically engineering DTs for injection molding that supports domain-specific customizations and automation of essential development activities based on a model-driven reference architecture. In this approach, reactive CPPS behavior is defined in terms of a Domain-Specific Language (DSL) for specifying events that occur in the physical system. The reference architecture connects to the CPPS through a novel DSL for representing OPC-UA bindings. We have evaluated this approach with a DT of an injection molding machine that controls the machine to optimize the Design of Experiment (DoE) parameters between experiment cycles before the products are molded. Through this, our reference implementation of the DT facilitates the time-consuming setup of a DT and the subsequent injection molding activities. Overall, this facilitates to systematically engineer digital twins with reactive behavior that help to optimize machine use.;Springer;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85086228557
494;Systematic language extension mechanisms for the montiarc architecture description language;Architecture description languages (ADLs) combine the benefits of component-based software engineering and model-driven development. Extending an ADL to domain-specific requirements is a major challenge for its successful application. Most ADLs focus on fixed features and do not consider domain-specific language extension. ADLs focusing on extensibility focus on syntactic augmentation only and neither consider semantics, nor the ADL’s tooling. We present a systematic extension method for the MontiArc component and connector ADL that enables extending its syntax and infrastructure. The MontiArc ADL is built on top of the MontiCore workbench for compositional modeling languages and leverages its powerful language integration facilities. Based on these, we conceived systematic extension activities and present their application to customizing MontiArc for three different domains. This application of software language engineering to ADLs reduces effort for their extension and the presented method guides developers in applying it to their domain. This ultimately fosters the application of ADLs to real-world domain-specific challenges.;Springer Verlagservice@springer.de;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/85025126026
495;A distributed ledger approach to digital twin secure data sharing;The Digital Twin refers to a digital representation of any real-world counterpart allowing its management (from simple monitoring to autonomy). At the core of the concept lies the inclusion of the entire asset lifecycle. To enable all lifecycle parties to partake, the Digital Twin should provide a sharable data base. Thereby, integrity and confidentiality issues are pressing, turning security into a major requirement. However, given that the Digital Twin paradigm is still at an early stage, most works do not consider security yet. Distributed ledgers provide a novel technology for multi-party data sharing that emphasizes security features such as integrity. For this reason, we examine the applicability of distributed ledgers to secure Digital Twin data sharing. We contribute to current literature by identifying requirements for Digital Twin data sharing in order to overcome current infrastructural challenges. We furthermore propose a framework for secure Digital Twin data sharing based on Distributed Ledger Technology. A conclusive use case demonstrates requirements fulfillment and is followed by a critical discussion proposing avenues for future work.;Springer Verlagservice@springer.de;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85069511065
496;A hierarchical digital twin model framework for dynamic cyber-physical system design;Cyber-physical system (CPS) is a new trend in the complex system related research works, where network connectivity enhances computing power and systemic behavior emerges through the competition, interaction, collaboration and integration among individual interweaving, which consists of real-time monitoring, data management, physical feedback control. From this perspective, CPS is a dynamic entity with rich functions. However, designers may encounter a difficult situation, in which subsequent dynamic changes of the system are discussed and appropriate functionalities are added in the early design phase. Since the digital twin is the digital duplicate of the physical entity, it can dynamically evolve following the product life cycle. In this paper, we propose a hierarchical digital twin model framework for CPS design. In the light of digital twin concept, the hierarchical high-level models facilitate storage of information from the entire product life cycle. Finally, an industrial robot application is presented to demonstrate the efficacy of the model framework.;Association for Computing Machinery;Conference Proceeding;ACM International Conference Proceeding Series;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85065215650
497;A Digital Twin-Based Multi-modal UI Adaptation Framework for Assistance Systems in Industry 4.0;As a consequence of digital transformation many aspects related to the industrial manufacturing processes are facing changes. In terms of Human-Machine Interaction, the User Interface (UI) plays the most important role as a mediator between the human and certain assistance systems. In traditional industrial environments, the UIs are usually designed to handle a unimodal input command (via touch screen, keyboard or mouse) and to present a feedback in a visual way. However, due to the nature of the tasks there is a need for the human workers to easily shift tasks and acquire new skills. For this reason, in the UI adaptation process the personal abilities and preferences of the human workers should be taken into consideration. In this paper, we present a novel reference model for multi-modal adaptive UIs for assistance systems in manufacturing processes. Our approach provides a solution framework for adaptation of assistance systems in manufacturing processes not only based on the environmental conditions, but also based on the personal characteristics and abilities of the human workers, obtained by a personalized Digital Twin.;Springer Verlagservice@springer.de;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85069873204
498;Digital twins as a modern approach to design of industrial processes;The objective of the paper was to describe the concept of a virtual, digital equivalent to a physical process. The basic idea of the virtual counterpart for the process called a digital twin is described first. Following this the hybrid computer system dedicated to the design of the optimal manufacturing technology for thin steel strips is presented. The models used in the system and the database are described. Numerical tests showing capabilities of the system recapitulate the work.;Editorial Institution of Wrocaw Board of Scientificjerzy.jedrzejewski@pwr.edu.pl;Journal;Journal of Machine Engineering;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85064730379
499;Handbook of Metal Injection Molding;Metal injection molding combines the most useful characteristics of powder metallurgy and plastic injection molding to facilitate the production of small, complex-shaped metal components with outstanding mechanical properties. Handbook of Metal Injection Molding, Second Edition provides an authoritative guide to this important technology and its applications. Building upon the success of the first edition, this new edition includes the latest developments in the field and expands upon specific processing technologies. Part one discusses the fundamentals of the metal injection molding process with chapters on topics such as component design, important powder characteristics, compound manufacture, tooling design, molding optimization, debinding, and sintering. Part two provides a detailed review of quality issues, including feedstock characterisation, modeling and simulation, methods to qualify a MIM process, common defects and carbon content control. Special metal injection molding processes are the focus of part three, which provides comprehensive coverage of micro components, two material/two color structures, and porous metal techniques. Finally, part four explores metal injection molding of particular materials, and has been expanded to include super alloys and precious metals. With its distinguished editor and expert team of international contributors, the Handbook of Metal Injection Molding is an essential guide for all those involved in the high-volume manufacture of small precision parts, across a wide range of high-tech industries such as microelectronics, biomedical and aerospace engineering.;Elsevier;Book;Handbook of Metal Injection Molding;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85093925624
500;Visualising the digital twin using web services and augmented reality;As the number of network connected devices in an industrial system increases, the management and handling of all the information generated become a challenge. In this work we explore concepts of Cyber-Physical System model the virtual part of industrial devices (sensor, machines, CLPs) using the Digital Twin concept and propose an architecture based on web services for accessing their data. We present a case study where an Augmented Reality system access the Twin Model data via web services and display real-time information to the user. Moreover, we present a review of how the involved concepts, which have a strong computational background, relate to industrial applications and how they can expand the possibility of services and business models.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;IEEE International Conference on Industrial Informatics (INDIN);2016-07-02;https://api.elsevier.com/content/abstract/scopus_id/85012932205
501;Knowledge map and forecast of digital twin in the construction industry: State-of-the-art review using scientometric analysis;"With the advancement of Industry 4.0 and the development of science and technology, industries have seen the advantages of digital twin (DT) implementations and concepts. Although the construction industry is still in the early stage of DT development and implementation, it is urgent for the industry to have a DT agenda. This paper identifies 1158 related bibliographic records from the Web of Science and 745 records from the Derwent Patent Database and quantitatively analyzed them to describe patterns of publications. Two knowledge mapping tools were selected to visualize and analyze the literature in the relevant scientific domain. Then, we integrated clustering, knowledge mapping, and network analysis methods to show the current foci and future directions of DT-MT derived from the data of time distribution, journal areas, and subject distribution. The results indicate that DT is a cross-disciplinary information technology with great development potential, and its development in the construction industry is scattered with the leading advancement in the manufacturing of construction materials and components. The derived knowledge map shows three stages of construction DT, including (1) data collection and creation of DT framework and database; (2) implementation of planning and design modules in detail and control of construction sites; and (3) carrying out asset management and fault prediction in the operation and maintenance phase of projects. The novelty of this paper is the specific analysis of DT in the construction industry. This study adds value to the architecture, engineering, and construction industries by shedding light on the focus of DT practical applications and the formation of a development path of construction DT.";Elsevier Ltd;Journal;Journal of Cleaner Production;2023-01-10;https://api.elsevier.com/content/abstract/scopus_id/85143719809
502;Digital Twin Shop-Floor: A New Shop-Floor Paradigm Towards Smart Manufacturing;With the developments and applications of the new information technologies, such as cloud computing, Internet of Things, big data, and artificial intelligence, a smart manufacturing era is coming. At the same time, various national manufacturing development strategies have been put forward, such as Industry 4.0, Industrial Internet, manufacturing based on Cyber-Physical System, and Made in China 2025. However, one of specific challenges to achieve smart manufacturing with these strategies is how to converge the manufacturing physical world and the virtual world, so as to realize a series of smart operations in the manufacturing process, including smart interconnection, smart interaction, smart control and management, etc. In this context, as a basic unit of manufacturing, shop-floor is required to reach the interaction and convergence between physical and virtual spaces, which is not only the imperative demand of smart manufacturing, but also the evolving trend of itself. Accordingly, a novel concept of digital twin shop-floor (DTS) based on digital twin is explored and its four key components are discussed, including physical shop-floor, virtual shop-floor, shop-floor service system, and shop-floor digital twin data. What is more, the operation mechanisms and implementing methods for DTS are studied and key technologies as well as challenges ahead are investigated, respectively.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2017-09-24;https://api.elsevier.com/content/abstract/scopus_id/85030752762
503;Applying a model-driven approach to the development of power plant SCADA/EMS software;"In this paper, we propose and apply a model-driven approach to develop applications that compose a suite known as Energy Management System (EMS). EMS is an essential tool for the operation of electrical systems. Although models of cyber–physical phenomena are extensively used in planning, designing, and operating power systems, the development of EMS applications often uses such models only as support and documentation, while the main artifact throughout the software development process is source code. In other words, the models are used merely to document and communicate some aspects of a system. The evolution of such a system is expensive and error-prone, requiring specialized personnel, skilled in both software engineering and power systems. Some of the problems arising from this manual process include: (i) substantial implementation effort in interpreting models and manually translating them into programs; (ii) greater risk of introducing software defects; (iii) risk of leaving documentation outdated, or implementation inconsistent with the intended design. Model-Driven Engineering (MDE) is an approach to constructing computing systems in which models are used as primary engineering artifacts, while programs (and other products) are automatically generated from the models, thus addressing the above limitations. MDE approaches have been adopted in several industrial areas, including smart grid automation, in which specialized modeling languages and tools facilitate the production of executable software from high-level models. For SCADA/EMS software development, however, a dedicated approach is still absent. We address these issues by proposing D-SPADES: a Model-Driven Engineering approach tailored to the EMS domain. D-SPADES defines a domain-specific modeling language based on block diagram notation, called EMSML, specifically targeted to describe the behavior of EMS applications. It also defines the associated mapping strategies and harnesses a set of tools for automatically transforming models into source code of applications that can be integrated into existing SCADA platforms. We have applied D-SPADES to model and automatically generate source code for two different applications from the Itaipu power plant: a voltage and reactive power controller and a component for a system-wide special protection scheme. Both applications were validated using a power system simulator and performed satisfactorily. The special protection scheme was deployed to the production system. Hence we demonstrate that D-SPADES is a viable approach to developing mission-critical applications.";Elsevier Ltd;Journal;International Journal of Electrical Power and Energy Systems;2023-11-01;https://api.elsevier.com/content/abstract/scopus_id/85164229260
504;A Digital Twin-Based Approach for Designing and Multi-Objective Optimization of Hollow Glass Production Line;Various new national advanced manufacturing strategies, such as Industry 4.0, Industrial Internet, and Made in China 2025, are issued to achieve smart manufacturing, resulting in the increasing number of newly designed production lines in both developed and developing countries. Under the individualized designing demands, more realistic virtual models mirroring the real worlds of production lines are essential to bridge the gap between design and operation. This paper presents a digital twin-based approach for rapid individualized designing of the hollow glass production line. The digital twin merges physics-based system modeling and distributed real-time process data to generate an authoritative digital design of the system at pre-production phase. A digital twin-based analytical decoupling framework is also developed to provide engineering analysis capabilities and support the decision-making over the system designing and solution evaluation. Three key enabling techniques as well as a case study in hollow glass production line are addressed to validate the proposed approach.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2017-10-24;https://api.elsevier.com/content/abstract/scopus_id/85032451877
505;Digital twin-driven cyber-physical production system towards smart shop-floor;Smart manufacturing is the core in the 4th industrial revolution. Smart shop-floor is one of the basic units of smart manufacturing. With the development of the advanced technologies (e.g. cloud computing, internet of things, model-based definition, advanced simulation, artificial intelligence), a larger number of virtual shop-floors are being built. However, it is very important that how to realize the intelligent interconnection and interaction between physical shop-floors and virtual ones. Digital twin (DT) is one of the key technologies associated to the cyber-physical system. In this paper, we present our vision on the cyber-physical production system (CPPS) towards smart shop-floor at scale via DT. This paper firstly explores a product manufacturing digital twin (PMDT), which focuses on the production phase in smart shop-floor. The proposed PMDT consists of five models: Product Definition Model (PDM), Geometric and Shape Model (GSM), Manufacturing Attribute Model (MAM), Behavior and Rule Model (BRM) and Data Fusion Model (DFM). And then based on PMDT, this paper proposes a new architecture of CPPS, which is composed of five layers (physical layer, network layer, database layer, model layer, application layer). Finally, this paper addresses the opportunities to use DT for the CPPS to support job scheduling during normal operation. Furthermore, the related further work and suggestions are also discussed.;Springer Verlagservice@springer.de;Journal;Journal of Ambient Intelligence and Humanized Computing;2019-11-01;https://api.elsevier.com/content/abstract/scopus_id/85057330632
506;Multi-objective optimization in rule-based design space exploration;Design space exploration (DSE) aims to find optimal design candidates of a domain with respect to different objectives where design candidates are constrained by complex structural and numerical restrictions. Rule-based DSE [10,14,18] aims to find such candidates that are reachable from an initial model by applying a sequence of exploration rules. Solving a rule-based DSE problem is a difficult challenge due to the inherently dynamic nature of the problem. In the current paper, we propose to integrate multi-objective optimization techniques by using Non-dominated Sorting Genetic Algorithms (NSGA) to drive rule-based design space exploration. For this purpose, finite populations of the most promising design candidates are maintained wrt. different optimization criteria. In our context, individuals of a generation are defined as a sequence of rule applications leading from an initial model to a candidate model. Populations evolve by mutation and crossover operations which manipulate (change, extend or combine) rule execution sequences to yield new individuals. Our multi-objective optimization approach for rule-based DSE is domain independent and it is automated by tooling built on the Eclipse framework. The main added value is to seamlessly lift multi-objective optimization techniques to the exploration process preserving both domain independence and a high-level of abstraction. Design candidates will still be represented as models and the evolution of these models as rule execution sequences. Constraints are captured by model queries while objectives can be derived both from models or rule applications.;Association for Computing Machinery, Incacmhelp@acm.org;Conference Proceeding;ASE 2014 - Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering;2014-01-01;https://api.elsevier.com/content/abstract/scopus_id/84908611671
507;Modeling and Analyzing MAPE-K Feedback Loops for Self-Adaptation;The MAPE-K (Monitor-Analyze-Plan-Execute over a shared Knowledge) feedback loop is the most influential reference control model for autonomic and self-adaptive systems. This paper presents a conceptual and methodological framework for formal modeling, validating, and verifying distributed self-adaptive systems. We show how MAPE-K loops for self adaptation can be naturally specified in an abstract stateful language like Abstract State Machines. In particular, we exploit the concept of multi-agent Abstract State Machines to specify decentralized adaptation control by using MAPE computations. We support techniques for validating and verifying adaptation scenarios, and getting feedback of the correctness of the adaptation logic as implemented by the MAPE-K loops. In particular, a verification technique based on meta-properties is proposed to allow discovering unwanted interferences between MAPE-K loops at the early stages of the system design. As a proof-of concepts, we model and analyze a traffic monitoring system.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 10th International Symposium on Software Engineering for Adaptive and Self-Managing Systems, SEAMS 2015;2015-08-12;https://api.elsevier.com/content/abstract/scopus_id/84953309690
508;Models@run.time: a guided tour of the state of the art and research challenges;More than a decade ago, the research topic models@run.time was coined. Since then, the research area has received increasing attention. Given the prolific results during these years, the current outcomes need to be sorted and classified. Furthermore, many gaps need to be categorized in order to further develop the research topic by experts of the research area but also newcomers. Accordingly, the paper discusses the principles and requirements of models@run.time and the state of the art of the research line. To make the discussion more concrete, a taxonomy is defined and used to compare the main approaches and research outcomes in the area during the last decade and including ancestor research initiatives. We identified and classified 275 papers on models@run.time, which allowed us to identify the underlying research gaps and to elaborate on the corresponding research challenges. Finally, we also facilitate sustainability of the survey over time by offering tool support to add, correct and visualize data.;Springer Verlagservice@springer.de;Journal;Software and Systems Modeling;2019-10-01;https://api.elsevier.com/content/abstract/scopus_id/85059780955
509;A local and global tour on MOMoT;Many model transformation scenarios require flexible execution strategies as they should produce models with the highest possible quality. At the same time, transformation problems often span a very large search space with respect to possible transformation results. Recently, different proposals for finding good transformation results without enumerating the complete search space have been proposed by using meta-heuristic search algorithms. However, determining the impact of the different kinds of search algorithms, such as local search or global search, on the transformation results is still an open research topic. In this paper, we present an extension to MOMoT, which is a search-based model transformation tool, for supporting not only global searchers for model transformation orchestrations, but also local ones. This leads to a model transformation framework that allows as the first of its kind multi-objective local and global search. By this, the advantages and disadvantages of global and local search for model transformation orchestration can be evaluated. This is done in a case-study-based evaluation, which compares different performance aspects of the local- and global-search algorithms available in MOMoT. Several interesting conclusions have been drawn from the evaluation: (1) local-search algorithms perform reasonable well with respect to both the search exploration and the execution time for small input models, (2) for bigger input models, their execution time can be similar to those of global-search algorithms, but global-search algorithms tend to outperform local-search algorithms in terms of search exploration, (3) evolutionary algorithms show limitations in situations where single changes of the solution can have a significant impact on the solution’s fitness.;Springer Verlagservice@springer.de;Journal;Software and Systems Modeling;2019-04-04;https://api.elsevier.com/content/abstract/scopus_id/85035793889
510;Collaborative Model-Driven Software Engineering — A systematic survey of practices and needs in industry;The engineering of modern software-intensive systems is carried out in collaboration among stakeholders with specialized expertise. The complexity of such systems often also necessitates employing more rigorous approaches, such as Model-Driven Software Engineering (MDSE). Collaborative MDSE is the combination of the two disciplines, with its specific opportunities and challenges. The rapid expansion and maturation of the field started attracting tool builders from outside of academia. However, available systematic studies on collaborative MDSE focus exclusively on mapping academic research and fail to identify how academic research aligns with industry practices and needs. To address this shortcoming, we have carried out a mixed-method survey on the practices and needs concerning collaborative MDSE. First, we carried out a qualitative survey in two focus group sessions, interviewing seven industry experts. Second, based on the results of the interviews, we constructed a questionnaire and carried out a questionnaire survey with 41 industry expert participants. In this paper, we report the results of our study, investigate the alignment of academic research with the needs of practitioners, and suggest directions on research and development of the supporting techniques of collaborative MDSE.;Elsevier Inc.;Journal;Journal of Systems and Software;2023-05-01;https://api.elsevier.com/content/abstract/scopus_id/85147541731
511;Towards scalable search-based model engineering with MDEOptimiser scale;Running scientific experiments using search-based model engineering (SBME) tools is a complex task, that poses a number of challenges, starting from defining an experiment workflow, to parameter tuning, finding optimal computational resources to run on, collecting and interpreting metrics and making the entire process easily reproducible. Despite the proliferation of easily accessible hardware, as a result of the increased availability of infrastructure-as-a-service providers, many SBME tools are rarely using this technology for accelerating experimentation. Running many experiments on a single machine implies much longer waiting times and reduces the ability to increase the speed of iterations when doing SBME research, thus, slowing down the entire process. In this paper, we introduce a domain-specific language (DSL) and a framework that can be used to configure and run experiments at scale, on cloud infrastructure, in a reproducible way. We will describe our DSL and framework architecture along with an example to showcase how a case study can be evaluated using two different model optimisation tools.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2019 ACM/IEEE 22nd International Conference on Model Driven Engineering Languages and Systems Companion, MODELS-C 2019;2019-09-01;https://api.elsevier.com/content/abstract/scopus_id/85075931263
512;Verification and Uncertainties in Self-integrating System;Self-integrating and self-improving system are required to verify their state in order to understand whether they have achieved their goal or need to adapt themselves to reach it. In this short position paper, we outline the main challenges specifically when verifying systems interacting with each other and operating under uncertainties. A short outline of the uncertainties is given as well as a brief roadmap to overcome the main challenges faced by autonomous interwoven systems, operating in an open world with incomplete knowledge.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2021 IEEE International Conference on Autonomic Computing and Self-Organizing Systems Companion, ACSOS-C 2021;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85123452376
513;Introduction to Digital Twin Engineering;Cyber-Physical Systems (CPSs) are getting increasingly complex and generate large amounts of data. Analyzing such data provides us an insight into a given system. The digital twin concept emerges as an attempt to seamlessly integrate the data and insight in order to improve system performances. It enables applications such as visualization, monitoring, state estimation, and self-adaptation. In this paper, we demonstrate the construction of a digital twin exemplified by an incubator system, including the benefits and challenges of each application. The result is a description of the building blocks of a digital twin.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings of the 2021 Annual Modeling and Simulation Conference, ANNSIM 2021;2021-07-19;https://api.elsevier.com/content/abstract/scopus_id/85117417192
514;Multi-modelling and Co-simulation in the Engineering of Cyber-Physical Systems: Towards the Digital Twin;Ensuring the dependability of Cyber-Physical Systems (CPSs) poses challenges for model-based engineering, stemming from the semantic heterogeneity of the models of computational, physical and human processes, and from the range of stakeholders involved. We argue that delivering such dependability requires a marriage of multi-disciplinary models developed during design with models derived from real operational data. Assets developed during design thus become the basis of a learning digital twin, able to support decision making both in redesign and in responsive operation. Starting from an open integrated toolchain leveraging formal models for CPS design, we consider the extension of this concept towards digital twins. A small example inspired by agricultural robotics illustrates some of the opportunities for research and innovation in delivering digital twins that contribute to dependability.;Springer Verlagservice@springer.de;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85073679094
515;Understanding UMTS Radio Network Modelling, Planning and Automated Optimisation: Theory and Practice;This book sets out to provide the theoretical foundations that will enable radio network planners to plan model and optimize radio networks using state-of-the-art findings from around the globe. It adopts a logical approach, beginning with the background to the present status of UMTS radio network technology, before devoting equal coverage to planning, modelling and optimization issues. All key planning areas are covered, including the technical and legal implications of network infrastructure sharing, hierarchical cell structure (HCS) deployment, ultra-high-site deployment and the benefits and limitations of using computer-aided design (CAD) software. Theoretical models for UMTS technology are explained as generic system models, stand-alone services and mixed services. Business modelling theory and methods are put forward, taking in propagation calculations, link-level, UMTS static and UMTS dynamic simulations. The challenges and goals of the automated optimization process are explored in depth using cutting-edge cost function and optimization algorithms. This theory-based resource containing prolific illustrative case studies explains the reasons for UMTS radio networks performance issues and how to use this foundational knowledge to model, plan and optimize present and future systems.;Wiley Blackwell;Book;Understanding UMTS Radio Network Modelling, Planning and Automated Optimisation: Theory and Practice;2006-06-19;https://api.elsevier.com/content/abstract/scopus_id/84948761913
516;Explaining quality attribute tradeoffs in automated planning for self-adaptive systems;Self-adaptive systems commonly operate in heterogeneous contexts and need to consider multiple quality attributes. Human stakeholders often express their quality preferences by defining utility functions, which are used by self-adaptive systems to automatically generate adaptation plans. However, the adaptation space of realistic systems is large and it is obscure how utility functions impact the generated adaptation behavior, as well as structural, behavioral, and quality constraints. Moreover, human stakeholders are often not aware of the underlying tradeoffs between quality attributes. To address this issue, we present an approach that uses machine learning techniques (dimensionality reduction, clustering, and decision tree learning) to explain the reasoning behind automated planning. Our approach focuses on the tradeoffs between quality attributes and how the choice of weights in utility functions results in different plans being generated. We help humans understand quality attribute tradeoffs, identify key decisions in adaptation behavior, and explore how differences in utility functions result in different adaptation alternatives. We present two systems to demonstrate the approach's applicability and consider its potential application to 24 exemplar self-adaptive systems. Moreover, we describe our assessment of the tradeoff between the information reduction and the amount of explained variance retained by the results obtained with our approach.;Elsevier Inc.;Journal;Journal of Systems and Software;2023-04-01;https://api.elsevier.com/content/abstract/scopus_id/85145663959
517;A survey and statistical analysis of smart grid co-simulations;Smart Grids consist of multiple actors and physical phenomena, which are often difficult to capture in one single simulation framework. Therefore, researchers increasingly couple distinct simulators to form novel “co-simulations”. In this paper we present a literature survey of 26 smart grid co-simulation frameworks. First of all, we present our understanding of a co-simulation. We then classify the 26 frameworks on multiple characteristics, such as simulation tools, synchronization methods and research topics. Finally, we present correlations between different key characteristics, analyze possible research gaps and discuss possible trends and future development areas in the field of smart grid co-simulations.;Elsevier Ltd;Journal;Applied Energy;2018-07-15;https://api.elsevier.com/content/abstract/scopus_id/85044976965
518;Case-base injection schemes to case adaptation using genetic algorithms;Case adaptation has always been a difficult process to engineer within the case-based reasoning (CBR) cycle. To combat the difficulties of CBR adaptation, such as its domain dependency, computational cost and the inability to produce novel cases to solve new problems, genetic algorithms (GAs) have been applied to CBR adaptation. As the quality of cases stored in a case library has a significant effect on the solutions produced by a case-based reasoner, it is important to investigate the impact of the quality and quantity of cases injected into a GA initial population for adapting fitter solutions to new problems. This work explores a method applying a GA to CBR adaptation, where a learning mechanism is applied to feed knowledge back from the CBR revision stage into the reuse stage, allowing the GA to learn which mutations result in invalid solutions. In collaboration with this learning mechanism, the number of cases to be injected, and the fitness of cases to be injected from retrieval into reuse is explored. The fitness of adapted cases and their response to our developed learning feedback is also trialled through varying the size and quality of the GA initial population. © Springer-Verlag 2004.;Springer Verlag;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2004-01-01;https://api.elsevier.com/content/abstract/scopus_id/35048870186
519;Searching for Optimal Models: Comparing Two Encoding Approaches (Summary);This work summarizes our paper originally published in The Journal of Object Technology in the course of the International Conference on Model Transformations 2019 [Jo19].;Gesellschaft fur Informatik (GI);Conference Proceeding;Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI);2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85138673031
520;Digital Twin in manufacturing: A categorical literature review and classification;The Digital Twin (DT) is commonly known as a key enabler for the digital transformation, however, in literature is no common understanding concerning this term. It is used slightly different over the disparate disciplines. The aim of this paper is to provide a categorical literature review of the DT in manufacturing and to classify existing publication according to their level of integration of the DT. Therefore, it is distinct between Digital Model (DM), Digital Shadow (DS) and Digital Twin. The results are showing, that literature concerning the highest development stage, the DT, is scarce, whilst there is more literature about DM and DS.;Elsevier B.V.;Conference Proceeding;IFAC-PapersOnLine;2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85052915281
521;Digital Twin Platforms: Requirements, Capabilities, and Future Prospects;Digital twins (DTs) have emerged as a paradigm for the virtual representation of complex systems alongside their underlying hardware. We investigate the benefits of Amazon, Eclipse, and Microsoft DT platforms and assess the extent to which they meet standard requirements.;IEEE Computer Society;Journal;IEEE Software;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85121363965
522;Bayesian Network Structure Learning Using Case-Injected Genetic Algorithms;In this paper, we propose a new hybrid structure learning method that incorporates case-injected genetic algorithms as a score-And-search method for determining Bayesian network structure from data. In our approach, we first find the probabilistic dependencies among variables to constrain the search space and then employ case-injected genetic algorithms in the score-And-search phase to find a quality structure from the reduced search space. The novelty of our work lies with the introduction of combining case-based reasoning with genetic algorithms to evolve a near-optimal Bayesian network in fewer generations compared to a randomly initialized genetic algorithm. Our case-injected genetic algorithms enhance Bayesian network structure learning performance over a sequence of similar problems by extracting and storing knowledge from previously solved problems and utilizing the accumulated knowledge to solve subsequent similar problems. To evaluate the viability of our proposed approach, we conducted a series of experiments by generating a sequence of similar problems based on using data sets obtained randomly from three well-known benchmark Bayesian networks. We also compared the performance of our proposed approach with the state-of-The-Art algorithm. Our preliminary results show that case-injected genetic algorithms provide better performance in learning Bayesian network structure compared to GA and the state-of-The-Art algorithm. Our proposed approach has applications in real-world domains such as e-commerce system and health care.;IEEE Computer Society;Conference Proceeding;Proceedings - International Conference on Tools with Artificial Intelligence, ICTAI;2020-11-01;https://api.elsevier.com/content/abstract/scopus_id/85098772558
523;A four-layer architecture pattern for constructing and managing digital twins;The promise of a digital twin is to make asset lifecycle information accessible by providing a single access point to the information. Thereby, it reduces the required time and effort and enables new data-intensive use cases. This paper provides an abstract four-layer architecture pattern to construct digital twins and to incorporate information from various kinds of sources. The pattern is designed to be flexibly extensible with new information sources and can flexibly support new kinds of proprietary or standard information. We discuss various alternatives to implement the pattern and provide an example realization based on microservices and OPC UA.;Springer Verlagservice@springer.de;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85072820852
524;Towards Engineering Digital Twins by Active Behaviour Mining;In the context of Confirm, the Irish Research Centre on Smart Manufacturing, field demonstrators are used to show new techniques to industrial partners, various kinds of students, and the general public alike. Considering the robotics demonstrator for the Digital Thread concept used in Confirm, which is a small cyberphysical system based on the UR3 cobot and a web controller for it, we apply Active Automata Learning in order to obtain a Digital Twin for it. Behavior mining done in this fashion is nowadays uncommon, but it has various advantages over, e.g., models obtained with popular AI techniques in that the AAL models are accurate deterministic behavioural explanations for the system behaviour at the chosen level of abstraction, and they may be further amenable to formal verification, e.g., by model checking, in order to establish properties of interest. This extension has the effect of showcasing the Digital Twin concept, the AAL technique, the use of model checking, and the importance of working with formal models that are amenable to these technologies. We then reflect on the nature of the models and their uses and meaning, from the point of view of the comments and questions we receive in the demonstrations. We also consider the use of a feature-based approach to modelling the systems and their interactions, which is a further aspect for which the demonstrator could be used, with a special attention to the aspects of this work, like AAL and the feature based and feature interaction research, that connect directly with the collaboration with and the research of Bengt Jonsson.;Springer Science and Business Media Deutschland GmbH;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85120864161
525;Introduction to Genetic Algorithm with a Simple Analogy;"Genetic Algorithm (GA), which is now considered as a well-established and one of the most widely applied optimization techniques, started its journey when Von Neumann first forwarded the theory of self-reproducing automata during fifties (Fellenius W: Calculation of the stability of earth dams. Trans, of 2nd congress on Large Dams, vol 4, pp 445--459, 1936). However, implementation of this ideas came into application during eighties (Baker R: Determination of the critical slip surface in slope stability computations. Int J Numer Anal Methods Geomech 4:333--359, 1980; Bishop AW: The use of slip circle in the stability analysis of slopes. Geotechnique London 5:7--17, 1955; Chen Z-Y, Shao C-M: Evolution of minimum factor of safety in slope stability analysis. Canadian Geotech J Ottawa 25:735--748, 1988; Celestino TB, Duncan JM: Simplified search for noncircular slip surface. In: Proceedings of the 10th international conference on SMFE, pp 391--394, 1981). Because of the obvious advantage of using GA in optimizing even complex non-linear functions, it has now been used by many researchers for solving varieties of optimization problems. Basically GA is a computerized search optimization algorithms based on the principles of survival of the fittest, first laid down by Charles Darwin. Concept of GA has so far been presented by different researchers in different forms, mostly in a mathematical framework. The terms like gene, chromosome, cross over, mutation and generation, which are basically derived from biological origin, many a time, become confusing to readers of other disciplines and also it become difficult to appreciate how these processes will lead to an optimal solution. Therefore, in this article, the basic philosophy of GA is presented by highlighting how it works and how the natural biological processes can help in obtaining the most optimal or at least near optimal solution through a simple analogy.";Springer;Book Series;Modeling and Optimization in Science and Technologies;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85078161080
526;Enabling technologies and tools for digital twin;Digital twin is revolutionizing industry. Fired by sensor updates and history data, the sophisticated models can mirror almost every facet of a product, process or service. In the future, everything in the physical world would be replicated in the digital space through digital twin technology. As a cutting-edge technology, digital twin has received a lot of attention. However, digital twin is far from realizing their potential, which is a complex system and long-drawn process. Researchers must model all the different parts of the objects or systems. Varied types of data needed to be collected and merged. Many researchers and participators in engineering are not clear which technologies and tools should be used. 5-dimension digital twin model provides reference guidance for understanding and implementing digital twin. From the perspective of 5-dimension digital twin model, this paper tries to investigate and summarize the frequently-used enabling technologies and tools for digital twin to provide technologies and tools references for the applications of digital twin in the future.;Elsevier B.V.;Journal;Journal of Manufacturing Systems;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85074335396
527;Experimentable Digital Twins-Streamlining Simulation-Based Systems Engineering for Industry 4.0;"Digital twins represent real objects or subjects with their data, functions, and communication capabilities in the digital world. As nodes within the internet of things, they enable networking and thus the automation of complex value-added chains. The application of simulation techniques brings digital twins to life and makes them experimentable; digital twins become experimentable digital twins (EDTs). Initially, these EDTs communicate with each other purely in the virtual world. The resulting networks of interacting EDTs model different application scenarios and are simulated in virtual testbeds, providing new foundations for comprehensive simulation-based systems engineering. Its focus is on EDTs, which become more detailed with every single application. Thus, complete digital representations of the respective real assets and their behaviors are created successively. The networking of EDTs with real assets leads to hybrid application scenarios in which EDTs are used in combination with real hardware, thus realizing complex control algorithms, innovative user interfaces, or mental models for intelligent systems.";IEEE Computer Societyhelp@computer.org;Journal;IEEE Transactions on Industrial Informatics;2018-04-01;https://api.elsevier.com/content/abstract/scopus_id/85041837589
528;An architecture of an Intelligent Digital Twin in a Cyber-Physical Production System;The role of a Digital Twin is increasingly discussed within the context of Cyber-Physical Production Systems. Accordingly, various architectures for the realization of Digital Twin use cases are conceptualized. There lacks, however, a clear, encompassing architecture covering necessary components of a Digital Twin to realize various use cases in an intelligent automation system. In this contribution, the added value of a Digital Twin in an intelligent automation system is highlighted and various existing definitions and architectures of the Digital Twin are discussed. Flowingly, an architecture for a Digital Twin and an architecture for an Intelligent Digital Twin and their required components are proposed, with which use cases such as plug and produce, self-x and predictive maintenance are enabled. In the opinion of the authors, a Digital Twin requires three main characteristics: Synchronization with the real asset, active data acquisition from the real environment and the ability of simulation. In addition to all the characteristics of a Digital Twin, an Intelligent Digital Twin must also include the characteristics of Artificial Intelligence. The Intelligent Digital Twin can be used for the realization of the autonomous Cyber-Physical Production Systems. In order to realize the proposed architecture for a Digital Twin, several methods, namely the Anchor-Point-Method, a method for heterogeneous data acquisition and data integration as well as an agent-based method for the development of a co-simulation between Digital Twins were implemented and evaluated.;De Gruyter Oldenbourg;Journal;At-Automatisierungstechnik;2019-09-25;https://api.elsevier.com/content/abstract/scopus_id/85073869890
529;Knowledge map and forecast of digital twin in the construction industry: State-of-the-art review using scientometric analysis;"With the advancement of Industry 4.0 and the development of science and technology, industries have seen the advantages of digital twin (DT) implementations and concepts. Although the construction industry is still in the early stage of DT development and implementation, it is urgent for the industry to have a DT agenda. This paper identifies 1158 related bibliographic records from the Web of Science and 745 records from the Derwent Patent Database and quantitatively analyzed them to describe patterns of publications. Two knowledge mapping tools were selected to visualize and analyze the literature in the relevant scientific domain. Then, we integrated clustering, knowledge mapping, and network analysis methods to show the current foci and future directions of DT-MT derived from the data of time distribution, journal areas, and subject distribution. The results indicate that DT is a cross-disciplinary information technology with great development potential, and its development in the construction industry is scattered with the leading advancement in the manufacturing of construction materials and components. The derived knowledge map shows three stages of construction DT, including (1) data collection and creation of DT framework and database; (2) implementation of planning and design modules in detail and control of construction sites; and (3) carrying out asset management and fault prediction in the operation and maintenance phase of projects. The novelty of this paper is the specific analysis of DT in the construction industry. This study adds value to the architecture, engineering, and construction industries by shedding light on the focus of DT practical applications and the formation of a development path of construction DT.";Elsevier Ltd;Journal;Journal of Cleaner Production;2023-01-10;https://api.elsevier.com/content/abstract/scopus_id/85143719809
530;Leveraging Iterative Plan Refinement for Reactive Smart Manufacturing Systems;Industry 4.0 production systems must support flexibility in various dimensions, such as for the products to be produced, for the production processes to be applied, and for the available machinery. In this article, we present a novel approach to design and control smart manufacturing systems. The approach is reactive, that is responds to unplanned situations and implements an iterative refinement technique, that is, optimizes itself during runtime to better accommodate production goals. For realizing these advances, we present a model-driven methodology and we provide a prototypical implementation of such a production system. In particular, we employ Planning Domain Definition Language (PDDL) as our artificial intelligence environment for automated planning of production processes and combine it with one of the most prominent Industry 4.0 standards for the fundamental production system model: IEC 62264. We show how to plan the assembly of small trucks from available components and how to assign specific production operations to available production resources, including robotic manipulators and transportation system shuttles. Results of the evaluation indicate that the presented approach is feasible and that it is able to significantly strengthen the flexibility of production systems during runtime. Note to Practitioners - Smart production is an umbrella for a number of shifts and initiatives that deal with digitization of manufacturing/production systems and related issues and potentials. In this work, we present an approach for utilizing automated planning for creating production plans. This is in contrast to the traditional approach, where recipes are programmed into the production system ahead-of-time. However, automated planning relies on specific languages and tools that are hard to master by nonexperts, which is a factor that strongly limited the utilization of plan-driven approaches for industrial automation in practice. Thus, we propose to generate planning tasks automatically with model-driven engineering techniques. We are utilizing the industrial standard IEC 62264 for the description of the production system, and the academic standard Planning Domain Definition Language (PDDL) for planning. PDDL is handled completely transparent to the user, that is the user is shielded from its complexity by employing the IEC 62264 model as the sole frontend.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Transactions on Automation Science and Engineering;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85099384059
531;A Comprehensive System for Digital Assembly Precision Simulation and Optimization of Aircraft;Aircraft is a complex product, and it is made by assembling many parts. There are different types of links, bolts, pins are widely used to join the components of this assembly. Assembly precision analysis is an effective means to check the feasibility and quality of aircraft. Therefore, in order to achieve assembly precision analysis accurately, a comprehensive system for digital assembly precision simulation and optimization is developed. The system framework of assembly precision simulation and optimization for aircraft is proposed. First, the precision information modeling based on MBD is researched. Then, vector loops and vector equations are modeled according to deviation accumulation paths. AndMonte Carlo simulation is also introduced to assembly precision analysis. An application is performed and the result shows that the developed system has a great effect to ensure the assembly precision foraircraft.;Elsevier B.V.;Conference Proceeding;Procedia CIRP;2016-01-01;https://api.elsevier.com/content/abstract/scopus_id/85007007957
532;Rule and branch-and-bound algorithm based sequencing of machining features for process planning of complex parts;The machining sequence of machining features is vital to achieve efficient and high quality manufacturing of complex NC machining parts. In most feature-based process planning system, the machining features are sequenced as the lowest level unit. However, a single machining feature of complex parts such as aircraft structural parts is usually machined by multiple machining operations. The one-to-many mappings between the machining features and the machining operations cause the increase of the non-cutting tool path. In order to solve this problem, some types of machining features of complex parts are decomposed into several sub-machining features that are associated with a single machining operation individually according to the rules which are abstracted from the machining process of complex parts. Benefitting from the decomposition, the sub-machining features from different machining feature can be assembled into a sub-machining feature in order to avoid the cutting tool marks. The different types of sub-machining features are sequenced in the light of some rules which are also extracted from the machining process of complex parts. And the branch-and-bound algorithm are employed to sequence the same type sub-machining features to minimum the non-cutting tool path. A pilot feature-based process planning system has been developed based on this research, and has been used in some aircraft manufacturers in China.;Springer New York LLCbarbara.b.bertram@gsk.com;Journal;Journal of Intelligent Manufacturing;2018-08-01;https://api.elsevier.com/content/abstract/scopus_id/84953291705
533;A hybrid predictive maintenance approach for CNC machine tool driven by Digital Twin;As a typical manufacturing equipment, CNC machine tool (CNCMT) is the mother machine of industry. Fault of CNCMT might cause the loss of precision and affect the production if troubleshooting is not timely. Therefore, the reliability of CNCMT has a big significance. Predictive maintenance is an effective method to avoid faults and casualties. Due to less consideration of the status variety and consistency of CNCMT in its life cycle, current methods cannot achieve accurate, timely and intelligent results. To realize reliable predictive maintenance of CNCMT, a hybrid approach driven by Digital Twin (DT) is studied. This approach is DT model-based and DT data-driven hybrid. With the proposed framework, a hybrid predictive maintenance algorithm based on DT model and DT data is researched. At last, a case study on cutting tool life prediction is conducted. The result shows that the proposed method is feasible and more accurate than single approach.;Elsevier Ltd;Journal;Robotics and Computer-Integrated Manufacturing;2020-10-01;https://api.elsevier.com/content/abstract/scopus_id/85082683374
534;A flexible process information reuse method for similar machining feature;"Dynamically changing machining conditions and uncertain manufacturing resource availability are forcing manufacturing enterprises to search advanced process planning in order to increase productivity and ensure product quality. As growing quantities of the three-dimensional process models are gradually applied, reusing the embedded manufacturing information in process models with less time and lower cost attracts a lot of attention. In this paper, a new flexible method is presented to reuse the existing process information based on retrieval of the similar machining feature. First, the three-level organization model is introduced to represent the process information; the machining feature which is seen as the parent layer carries the corresponding manufacturing information. To ensure accurately that the process information are obtained, the associated mechanism between the machining feature and process information is created. Second, an eight-node representation scheme is designed to represent the similar machining feature having same variations in topology and geometry. For accelerating similar feature retrieval, the extension-attributed adjacency graph and the topological relationship of the machining feature faces are built. Finally, some aircraft structural parts are utilized in the developed prototype module to verify the effectiveness of the proposed method. This method can be used as the basis for accumulation of the process information; it can promote the development and application of the intelligent process planning.";Springer London;Journal;International Journal of Advanced Manufacturing Technology;2017-09-01;https://api.elsevier.com/content/abstract/scopus_id/85013485208
535;Digital twin-based smart assembly process design and application framework for complex products and its case study;"With rapid advances in new generation information technologies, digital twin (DT), and cyber-physical system, smart assembly has become a core focus for intelligent manufacturing in the fourth industrial evolution. Deep integration between information and physical worlds is a key phase to develop smart assembly process design that bridge the gap between product assembly design and manufacturing. This paper presents a digital twin reference model for smart assembly process design, and proposes an application framework for DT-based smart assembly with three layers. Product assembly station components are detailed in the physical space layer; two main modules, communication connection and data processing, are introduced in the interaction layer; and we discuss working mechanisms of assembly process planning, simulation, predication, and control management in the virtual space layer in detail. A case study shows the proposed approach application for an experimental simplified satellite assembly case using the DT-based assembly application system (DT-AAS) to verify the proposed application framework and method effectiveness.";Elsevier B.V.;Journal;Journal of Manufacturing Systems;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85083854199
536;Digital twin modeling method based on biomimicry for machining aerospace components;High-performance aerospace component manufacturing requires stringent in-process geometrical and performance-based quality control. Real-time observation, understanding and control of machining processes are integral to optimizing the machining strategies of aerospace component manufacturing. Digital Twin can be used to model, monitor and control the machining process by fusing multi-dimensional in-context machining process data, such as changes in geometry, material properties and machining parameters. However, there is a lack of systematic and efficient Digital Twin modeling method that can adaptively develop high-fidelity multi-scale and multi-dimensional Digital Twins of machining processes. Aiming at addressing this challenge, we proposed a Digital Twin modeling method based on biomimicry principles that can adaptively construct a multi-physics digital twin of the machining process. With this approach, we developed multiple Digital Twin sub-models, e.g., geometry model, behavior model and process model. These Digital Twin sub-models can interact with each other and compose an integrated true representation of the physical machining process. To demonstrate the effectiveness of the proposed biomimicry-based Digital Twin modeling method, we tested the method in monitoring and controlling the machining process of an air rudder.;Elsevier B.V.;Journal;Journal of Manufacturing Systems;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85085116186
537;Digital Twin-driven machining process for thin-walled part manufacturing;Thin-walled parts are widely used in the aerospace, shipbuilding, and automotive industry, but due to its unique structure and high accuracy requirements, which leads to an increase in scrapped parts, high cost in production, and a more extended period in the trial machining process. However, to adapt to fast production cycles and increase the efficiency of thin-walled parts machining, this paper presents a Digital Twin-driven thin-walled part manufacturing framework to allow the machine operator to manage the product changes, make the start-up phases faster and more accurate. The framework has three parts: preparation, machining, and measurement, driven by Digital Twin technologies in detail. By establishing and updating the workpiece Digital Twin under a different status, various manufacturing information and data can be integrated and available to machine operators and other Digital Twins. It can serve as a guideline for establishing the machine tool and workpiece Digital Twin and integrating them into the machining process. It provides the machine operator opportunities to interact with both the physical manufacturing process and its digital data in real-time. The digital representation of the physical process can support them to manage the trial machining from different aspects. In addition, a demonstrative case study is presented to explain the implementation of this framework in a real manufacturing environment.;Elsevier B.V.;Journal;Journal of Manufacturing Systems;2021-04-01;https://api.elsevier.com/content/abstract/scopus_id/85105002645
538;Requirement-based deployment of applications in Calvin;In order for IoT application developers to deliver on the promise of IoT, new tools and methodologies addressing the challenges associated with development of highly distributed systems running on non-reliable and heterogeneous hardware are required. Some of the main characteristics of cloud computing that has been a driving force for its success, are resource pooling, elasticity and the capacity for combining unrelated services. We believe that a similar approach is needed for IoT as well. In this paper, we show how Calvin, an open source peer-to-peer platform for distributed applications, tackles many of the problems inherent in IoT. By only loosely associating the functionality of a device with a semantics, and having implementations based on conventions rather than pre-defined terminology, it is possible to let a system of Calvin run-times autonomously handle deployment decisions, and respond to changing requirements. We will discuss how to develop and deploy dynamic and adaptive IoT-applications based on capabilities and requirements, and how to resolve requirements by automatically combining information from multiple sources based on encapsulated domain knowledge.;Springer Verlagservice@springer.de;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/85018622215
539;Efficient and deterministic record & Replay for actor languages;With the ubiquity of parallel commodity hardware, developers turn to high-level concurrency models such as the actor model to lower the complexity of concurrent software. However, debugging concurrent software is hard, especially for concurrency models with a limited set of supporting tools. Such tools often deal only with the underlying threads and locks, which obscures the view on e.g. actors and messages and thereby introduces additional complexity. To improve on this situation, we present a low-overhead record & replay approach for actor languages. It allows one to debug concurrency issues deterministically based on a previously recorded trace. Our evaluation shows that the average run-time overhead for tracing on benchmarks from the Savina suite is 10% (min. 0%, max. 20%). For Acme-Air, a modern web application, we see a maximum increase of 1% in latency for HTTP requests and about 1.4 MB/s of trace data. These results are a first step towards deterministic replay debugging of actor systems in production.;Association for Computing Machineryacmhelp@acm.org;Conference Proceeding;ACM International Conference Proceeding Series;2018-09-12;https://api.elsevier.com/content/abstract/scopus_id/85055550844
540;Efficient reordering and replay of execution traces of distributed reactive systems in the context of model-driven development;Ordering and replaying of execution traces of distributed systems is a challenging problem. State-of-the-art approaches annotate the traces with logical or physical timestamps. However, both kinds of timestamps have their drawbacks, including increased trace size. We examine the problem of determining consistent orderings of execution traces in the context of model-driven development of reactive distributed systems, that is, systems whose code has been generated from communicating state machine models. By leveraging key concepts of state machines and existing model analysis and transformation techniques, we propose an approach to collecting and reordering execution traces that does not rely on timestamps. We describe a prototype implementation of our approach and an evaluation. The experimental results show that compared to reordering based on logical timestamps using vector time (clocks), our approach reduces the size of the trace information collected by more than half while incurring similar runtime overhead.;Association for Computing Machinery, Inc;Conference Proceeding;Proceedings - 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS 2020;2020-10-16;https://api.elsevier.com/content/abstract/scopus_id/85096761732
541;Robust estimation of incorrect data using relative correlation clustering technique in wireless sensor networks;Data inaccuracy is an important problem in wireless sensor networks, since the accuracy is affected by harsh environments and malicious nodes. The reason for this data inaccuracy is the improper identification of outliers. To detect exact outliers in the wireless sensor networks, we propose the relative correlation based clustering (RCC) technique with high data accuracy and low computational overhead. Identifying spatial, temporal correlation and attribute correlation is the first phase of the proposed algorithm. The second phase is optimal cluster formation and outlier classification based on two correlation levels. The inference of the proposed idea shows high outlier detection rate with different outlier corruption level. Moreover, our results when compared with previous approach taking the same data into consideration clearly outperform them, identifying high level of detection rate (99.87%) in the top-line with near to the ground false alarm rate.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2014 International Conference on Communication and Network Technologies, ICCNT 2014;2015-03-17;https://api.elsevier.com/content/abstract/scopus_id/84991105170
542;A system of systems architecture for the internet of things exploiting autonomous components;As the internet of things (IoT) becomes more popular, supporting systems and their components become more complex and largely heterogeneous. This paper discusses on a system of systems (SoS) architecture for IoT systems composed by autonomous components. The proposed architecture focuses on a middleware transforming sensor services to REST services, for the development of mixed-criticality applications. The middleware consisting of autonomous aggregation software running on commodity multi-core devices, such as Raspberry Pi. Self-management policies applied are discussed in the paper. The analysis of a smart building system, developed as a use case, provides solid evidence that such an architecture is realistic and can lead to highly competitive systems.;Inderscience Publishers;Journal;International Journal of System of Systems Engineering;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85068067607
543;Deterministic replay: A survey;Deterministic replay is a type of emerging technique dedicated to providing deterministic executions of computer programs in the presence of nondeterministic factors. The application scopes of deterministic replay are very broad, making it an important research topic in domains such as computer architecture, operating systems, parallel computing, distributed computing, programming languages, verification, and hardware testing. In this survey, we comprehensively review existing studies on deterministic replay by introducing a taxonomy. Basically, existing deterministic replay schemes can be classified into two categories, single-processor (SP) schemes and multiprocessor (MP) schemes. By reviewing the details of these two categories of schemes respectively, we summarize and compare how existing schemes address technical issues such as log size, record slowdown, replay slowdown, implementation cost, and probe effect, which may shed some light on future studies on deterministic replay.;Association for Computing Machinery;Journal;ACM Computing Surveys;2015-09-01;https://api.elsevier.com/content/abstract/scopus_id/84942803543
544;Debugging the internet of things: The case of wireless sensor networks;The Internet of Things (IoT) has the strong potential to support a human society interacting more symbiotically with its physical environment. Indeed, the emergence of tiny devices that sense environmental cues and trigger actuators after consulting logic and human preferences promises a more environmentally aware and less wasteful society. However, the IoT inherently challenges software development processes, particularly techniques for ensuring software reliability. Researchers have developed debugging tools for wireless sensor networks (WSNs), which can be viewed as the enablers of perception in the IoT. These tools gather run-time information on individual sensor node executions and node interactions and then compress that information.;IEEE Computer Societyhelp@computer.org;Journal;IEEE Software;2015-01-01;https://api.elsevier.com/content/abstract/scopus_id/84922876049
545;Retrospect: Deterministic replay of MPI applications for interactive distributed debugging;While high performance computing was eagerly adopted by users as a vehicle for satisfying a growing demand on computational power, some areas are still poorly explored. The MPI paradigm is considered as being the keystone for the large development of the HPC infrastructure over the last decade. However, even today the users have to face the lack of tools able to help increase the stability of the software stack and/or of the applications. In this paper we present and evaluate a tool designed to allow developers to further investigate the execution of parallel applications by enabling them to dynamically move back and forth in the execution timeline of a parallel application. Based on an unobtrusive message logging mechanism, deterministic replay is enforced, leading to a simpler and more efficient way to debug parallel software. © Springer-Verlag Berlin Heidelberg 2007.;Springer Verlag;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2007-01-01;https://api.elsevier.com/content/abstract/scopus_id/38449105996
546;ThingML: A language and code generation framework for heterogeneous targets;One of the selling points of Model-Driven Software Engineering (MDSE) is the increase in productivity offered by automatically generating code from models. However, the practical adoption of code generation remains relatively slow and limited to niche applications. Tooling issues are often pointed out but more fundamentally, experience shows that: (i) models and modeling languages used for other purposes are not necessarily well suited for code generation and (ii) code generators are often seen as black-boxes which are not easy to trust and produce sub-optimal code. This paper presents and discusses our experiences applying the ThingML approach to different domains. ThingML includes a modeling language and tool designed for supporting code generation and a highly customizable multi-platform code generation framework. The approach is implemented in an open-source tool providing a family of code generators targeting heterogeneous platforms. It has been evaluated through several case studies and is being used for in the development of a commercial ambient assisted living system.;Association for Computing Machinery, Incacmhelp@acm.org;Conference Proceeding;Proceedings - 19th ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS 2016;2016-10-02;https://api.elsevier.com/content/abstract/scopus_id/85008457888
547;Model-driven digital twin construction: Synthesizing the integration of cyber-physical systems with their information systems;Digital twins emerge in many disciplines to support engineering, monitoring, controlling, and optimizing cyber-physical systems, such as airplanes, cars, factories, medical devices, or ships. There is an increasing demand to create digital twins as representation of cyber-physical systems and their related models, data traces, aggregated data, and services. Despite a plethora of digital twin applications, there are very few systematic methods to facilitate the modeling of digital twins for a given cyber-physical system. Existing methods focus only on the construction of specific digital twin models and do not consider the integration of these models with the observed cyber-physical system. To mitigate this, we present a fully model-driven method to describe the software of the cyber-physical system, its digital twin information system, and their integration. The integration method relies on MontiArc models of the cyber-physical system's architecture and on UML/P class diagrams from which the digital twin information system is generated. We show the practical application and feasibility of our method on an IoT case study. Explicitly modeling the integration of digital twins and cyber-physical systems eliminates repetitive programming activities and can foster the systematic engineering of digital twins.;Association for Computing Machinery, Inc;Conference Proceeding;Proceedings - 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS 2020;2020-10-16;https://api.elsevier.com/content/abstract/scopus_id/85096992990
548;MontiThings: Model-Driven Development and Deployment of Reliable IoT Applications;Internet of Things (IoT) applications are exposed to harsh conditions due to factors such as device failure, network problems, or implausible sensor values. We investigate how the inherent encapsulation of component and connector (C&C) architectures can be used to develop and deploy reliable IoT applications. Existing C&C languages for the development of IoT applications mainly focus on the description of architectures and the distribution of components to IoT devices. Furthermore, related approaches often pollute the models with low-level implementation details, tying the models to a particular platform and making them harder to understand. In this paper, we introduce MontiThings, a C&C language offering automatic error handling capabilities and a clear separation between business logic and implementation details. The error-handling methods presented in this paper can make C&C-based IoT applications more reliable without cluttering the business logic with error-handling code that is time-consuming to develop and makes the models hard to understand, especially for non-experts.;Elsevier Inc.;Journal;Journal of Systems and Software;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85116410296
549;SEA4DQ 2022 - Proceedings of the 2nd International Workshop on Software Engineering and AI for Data Quality in Cyber-Physical Systems/Internet of Things, co-located with ESEC/FSE 2022;"The proceedings contain 6 papers. The topics discussed include: data quality issues in online reinforcement learning for self-adaptive systems; data quality as a microservice: an ontology and rule based approach for quality assurance of sensor data in manufacturing machines; effect of time patterns in mining process invariants for industrial control systems: an experimental study; preliminary findings on the occurrence and causes of data smells in a real-world business travel data processing pipeline; data quality issues for vibration sensors: a case study in ferrosilicon production; and data quality issues in solar panels installations: a case study.";Association for Computing Machinery, Inc;Conference Proceeding;SEA4DQ 2022 - Proceedings of the 2nd International Workshop on Software Engineering and AI for Data Quality in Cyber-Physical Systems/Internet of Things, co-located with ESEC/FSE 2022;2022-11-07;https://api.elsevier.com/content/abstract/scopus_id/85143222236
550;WiDS checker: Combating bugs in distributed systems;Despite many efforts, the predominant practice of debugging a distributed system is still printf-based log mining, which is both tedious and error-prone. In this paper, we present WiDS Checker, a unified framework that can check distributed systems through both simulation and reproduced runs from real deployment. All instances of a distributed system can be executed within one simulation process, multiplexed properly to observe the “happens-before” relationship, thus accurately reveal full system state. A versatile script language allows a developer to refine system properties into straightforward assertions, which the checker inspects for violations. Combining these two components, we are able to check distributed properties that are otherwise impossible to check. We applied WiDS Checker over a suite of complex and real systems and found non-trivial bugs, including one in a previously proven Paxos specification. Our experience demonstrates the usefulness of the checker and allows us to gain insights beneficial to future research in this area.;USENIX Association;Conference Proceeding;4th Symposium on Networked Systems Design and Implementation, NSDI 2007;2007-01-01;https://api.elsevier.com/content/abstract/scopus_id/79960508731
551;Noise Removal in the Presence of Significant Anomalies for Industrial IoT Sensor Data in Manufacturing;The emergence of the Industrial Internet of Things (IIoT) to enhance manufacturing and industrial processes allows data analysts to address significant problems such as predictive maintenance. For the purpose of accurate data analysis, cleansing noisy sensor data is one of the most fundamental and necessary steps. Without first removing the noise, the anomaly detection techniques are likely to give a large number of false positives. However, using traditional outlier detection methods directly for such analysis are not appropriate as both noise and significant anomalies might exist in the sensor data. This article introduces the new challenges and proposes a novel solution to address the issue of removing noise while preserving anomalies in the IIoT Data. It proposes an approach that measures both the rate of change and deviation to compute the noise score. It employs a sliding window technique to define the analysis unit of the contrast measure which is used in conjunction with statistical techniques. Extensive experiments demonstrate that the proposed approach outperforms the other state-of-the-art noise detection methods, providing a clean data set that preserves the anomalies on which one can effectively apply anomaly detection techniques.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Internet of Things Journal;2020-08-01;https://api.elsevier.com/content/abstract/scopus_id/85089953058
552;Model-Based, Platform-Independent Logging for Heterogeneous Targets;"A recurring issue in generative approaches, in particular if they generate code for multiple target languages, is logging. How to ensure that logging is performed consistently for all the supported languages? How to ensure that the specific semantics of the source language, e.g. a modeling language or a domain-specific language, is reflected in the logs? How to expose logging concepts directly in the source language, so as to let developers specify what to log? This paper reports on our experience developing a concrete logging approach for ThingML, a textual modeling language built around asynchronous components, statecharts and a first-class action language, as well as a set of ""compilers"" targeting C, Go, Java and JavaScript.";Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2019 ACM/IEEE 22nd International Conference on Model Driven Engineering Languages and Systems, MODELS 2019;2019-09-01;https://api.elsevier.com/content/abstract/scopus_id/85075941811
553;The internet of things vision: A comprehensive review of architecture, enabling technologies, adoption challenges, research open issues and contemporary applications;With the improvements in machine-to-machine (M2M) communication, ubiquitous computing, and wireless sensor networks, the Internet of Things (IoT) has become a notion that is constantly rising in importance. Using uniquely addressable IDs, the Internet of Things links diverse physical items and allows them to communicate with one another through the Internet. A general overview of the IoT in the context of the architecture and associated technologies is provided in this article. On the other hand, the Internet of Things does not follow a standardised architecture model. This is accomplished by describing widely recognised architectural concepts that are subsequently refined with the associated technology in various tiers. Also included are some solutions that have been developed and future directions for addressing the obstacles faced by the IoT paradigm. Finally, the article discusses several Internet of Things applications to demonstrate the viability of the IoT idea in real-world settings.;Penerbit Akademia Baru;Journal;Journal of Advanced Research in Applied Sciences and Engineering Technology;2022-03-01;https://api.elsevier.com/content/abstract/scopus_id/85132528085
554;Model-Based Software Engineering to Tame the IoT Jungle;The Internet of Things (IoT) is a challenging combination of distribution and heterogeneity. A number of software engineering solutions address those challenges in isolation, but few solutions tackle them in combination, which poses a set of concrete challenges. The ThingML (Internet of Things Modeling Language) approach attempts to address those challenges. This model-driven, generative approach, which was inspired by UML, integrates concepts targeted at the IoT. Over the past six years, it has been continuously evolved and applied to cases in different domains, including a commercial e-health solution.;IEEE Computer Societyhelp@computer.org;Journal;IEEE Software;2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/85010402413
555;A Review of the Roles of Digital Twin in CPS-based Production Systems;"The Digital Twin (DT) is one of the main concepts associated to the Industry 4.0 wave. This term is more and more used in industry and research initiatives; however, the scientific literature does not provide a unique definition of this concept. The paper aims at analyzing the definitions of the DT concept in scientific literature, retracing it from the initial conceptualization in the aerospace field, to the most recent interpretations in the manufacturing domain and more specifically in Industry 4.0 and smart manufacturing research. DT provides virtual representations of systems along their lifecycle. Optimizations and decisions making would then rely on the same data that are updated in real-time with the physical system, through synchronization enabled by sensors. The paper also proposes the definition of DT for Industry 4.0 manufacturing, elaborated by the European H2020 project MAYA, as a contribution to the research discussion about DT concept.";Elsevier B.V.;Conference Proceeding;Procedia Manufacturing;2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/85029833606
556;Code-transparent discrete event simulation for time-accurate wireless prototyping;Exhaustive testing of wireless communication protocols on prototypical hardware is costly and time-consuming. An alternative approach is network simulation, which, however, often strongly abstracts from the actual hardware. Especially in the wireless domain, such abstractions often lead to inaccurate simulation results. Therefore, we propose a code-transparent discrete event simulator that enables a direct simulation of existing code for wireless prototypes. With a focus on lower layers of the communication stack, we enable a parametrization of the simulation timings based on real-world measurements to increase the simulation accuracy. Our evaluation shows that we achieve close results for throughput (deviation below 3 % for UDP) and latency (corrected deviation about 13 %) compared to real-world setups, while providing the benefits of code-transparent simulation, i.e., to flexibly simulate large topologies with existing prototype code. Moreover, we demonstrate that our approach finds implementation defects in existing hardware prototype software, which are otherwise difficult to track down in real deployments.;Association for Computing Machinery, Incacmhelp@acm.org;Conference Proceeding;SIGSIM-PADS 2017 - Proceedings of the 2017 ACM SIGSIM Conference on Principles of Advanced Discrete Simulation;2017-05-16;https://api.elsevier.com/content/abstract/scopus_id/85020717823
557;Actoverse: A reversible debugger for actors;The Actor model is a concurrent computation model based on asynchronous message passing and shared-nothing principle. These characteristics and the absence of locks guarantee that actor-based programs can avoid simple concurrency bugs such as data races and deadlocks. However, they are not completely free from application level concurrency bugs that occur, for example, due to the indeterminate arrival order of messages. To assist discovering such bugs in actor-based systems, we designed and implemented Actoverse, a debugger that adopts reverse debugging and provides an interactive aid for controlling the arrival order of messages upon re-execution. This paper briefly presents its architecture and utilization in Akka-based applications.;Association for Computing Machinery, Incacmhelp@acm.org;Conference Proceeding;AGERE 2017 - Proceedings of the 7th ACM SIGPLAN International Workshop on Programming Based on Actors, Agents, and Decentralized Control, co-located with SPLASH 2017;2017-10-23;https://api.elsevier.com/content/abstract/scopus_id/85037101293
558;A Roadmap to the Programmable World: Software Challenges in the IoT Era;The Internet of Things (IoT) represents the next significant step in the evolution of the Internet and software development. Although most IoT research focuses on data acquisition, analytics, and visualization, a subtler but equally important transition is underway. Hardware advances are making it possible to embed fully fledged virtual machines and dynamic language runtimes virtually everywhere, leading to a Programmable World in which all our everyday things are connected and programmable dynamically. The emergence of millions of remotely programmable devices in our surroundings will pose significant software development challenges. A roadmap from today's cloud-centric, data-centric IoT systems to the Programmable World highlights the technical challenges that deserve to be part of developer education and deserve deeper investigation beyond those IoT topics that receive the most attention today.;IEEE Computer Societyhelp@computer.org;Journal;IEEE Software;2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/85010433150
559;A concept in synchronization of virtual production system with real factory based on anchor-point method;A Digital Twin, an always in sync digital model of existing manufacturing cells, can be used to reduce time and risk of reconfiguration by early detection of design or process sequence flaws of the system in virtual commissioning and simulation. In this paper the need of Digital Twins in future production plants as well as the structure of the Digital Twin is presented. The engineering process of production systems is a cross-domain challenge between mechanics, electrics and software, but a lack of collaboration and universal information transfer between the domains leads to a high investment volume by synchronization the digital model from the time of commissioning. To synchronize cross-domain mechatronic data models of mechatronic components in the digital world during the life cycle of existing production systems this paper presents the anchor point method to firstly detect variances of cross-domain mechatronic data structure between the digital model and the real system in the specific domains electrics, mechanics and software and update the virtual models to have a consistent data model of the Digital Twin.;Elsevier B.V.;Conference Proceeding;Procedia CIRP;2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85044658638
560;The Role of AI, Machine Learning, and Big Data in Digital Twinning: A Systematic Literature Review, Challenges, and Opportunities;Digital twinning is one of the top ten technology trends in the last couple of years, due to its high applicability in the industrial sector. The integration of big data analytics and artificial intelligence/machine learning (AI-ML) techniques with digital twinning, further enriches its significance and research potential with new opportunities and unique challenges. To date, a number of scientific models have been designed and implemented related to this evolving topic. However, there is no systematic review of digital twinning, particularly focusing on the role of AI-ML and big data, to guide the academia and industry towards future developments. Therefore, this article emphasizes the role of big data and AI-ML in the creation of digital twins (DTs) or DT-based systems for various industrial applications, by highlighting the current state-of-the-art deployments. We performed a systematic review on top of multidisciplinary electronic bibliographic databases, in addition to existing patents in the field. Also, we identified development-tools that can facilitate various levels of the digital twinning. Further, we designed a big data driven and AI-enriched reference architecture that leads developers to a complete DT-enabled system. Finally, we highlighted the research potential of AI-ML for digital twinning by unveiling challenges and current opportunities.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85101961329
561;Digital twin: Mitigating unpredictable, undesirable emergent behavior in complex systems;Systems do not simply pop into existence. They progress through lifecycle phases of creation, production, operations, and disposal. The issues leading to undesirable and unpredicted emergent behavior are set in place during the phases of creation and production and realized during the operational phase, with many of those problematic issues due to human interaction. We propose that the idea of the Digital Twin, which links the physical system with its virtual equivalent can mitigate these problematic issues. We describe the Digital Twin concept and its development, show how it applies across the product lifecycle in defining and understanding system behavior, and define tests to evaluate how we are progressing. We discuss how the Digital Twin relates to Systems Engineering and how it can address the human interactions that lead to “normal accidents.” We address both Digital Twin obstacles and opportunities, such as system replication and front running. We finish with NASA's current work with the Digital Twin.;Springer International Publishing;Book;Transdisciplinary Perspectives on Complex Systems: New Findings and Approaches;2016-01-01;https://api.elsevier.com/content/abstract/scopus_id/85006339863
562;Towards Model-Driven Digital Twin Engineering: Current Opportunities and Future Challenges;Digital Twins have emerged since the beginning of this millennium to better support the management of systems based on (real-time) data collected in different parts of the operating systems. Digital Twins have been successfully used in many application domains, and thus, are considered as an important aspect of Model-Based Systems Engineering (MBSE). However, their development, maintenance, and evolution still face major challenges, in particular: (i) the management of heterogeneous models from different disciplines, (ii) the bi-directional synchronization of digital twins and the actual systems, and (iii) the support for collaborative development throughout the complete life-cycle. In the last decades, the Model-Driven Engineering (MDE) community has investigated these challenges in the context of software systems. Now the question arises, which results may be applicable for digital twin engineering as well. In this paper, we identify various MDE techniques and technologies which may contribute to tackle the three mentioned digital twin challenges as well as outline a set of open MDE research challenges that need to be addressed in order to move towards a digital twin engineering discipline.;Springer Science and Business Media Deutschland GmbHinfo@springer-sbm.com;Book Series;Communications in Computer and Information Science;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85094117399
563;Digital Twin for Legacy Systems: Simulation Model Testing and Validation;In this paper, an approach to incorporate a digital twin for legacy production systems is presented. Hardware-in-the-loop setups are routinely used by manufacturing companies to carry out virtual commissioning. However, manufacturing companies having online legacy production systems are still struggling to incorporate a digital twin due to the absence of verified and validated simulation models. Companies that use virtual commissioning as a part of their engineering tool chain, usually perform offline verification of the simulation model. This approach is typically based on visual inspection and is a tedious task as each aspect of the model has to be visually validated. For legacy systems, only assessing the behavior visually in the absence of updated documents can result in an incorrect simulation model, i.e. simulating incorrect behavior with respect to the specification. Due to this, such simulation models cannot be incorporated in the engineering tool chain, as the simulated results can lead to improper decisions and can even cause equipment damage. This paper presents a platform and an approach, based on model-based testing, that is a first step for manufacturing companies to incorporate a validated simulation model for existing online production systems that will serve as a digital twin.;IEEE Computer Societyhelp@computer.org;Conference Proceeding;IEEE International Conference on Automation Science and Engineering;2018-12-04;https://api.elsevier.com/content/abstract/scopus_id/85059985353
564;Leveraging digital twin technology in model-based systems engineering;Digital twin, a concept introduced in 2002, is becoming increasingly relevant to systems engineering and, more specifically, to model-based system engineering (MBSE). A digital twin, like a virtual prototype, is a dynamic digital representation of a physical system. However, unlike a virtual prototype, a digital twin is a virtual instance of a physical system (twin) that is continually updated with the latter’s performance, maintenance, and health status data throughout the physical system’s life cycle. This paper presents an overall vision and rationale for incorporating digital twin technology into MBSE. The paper discusses the benefits of integrating digital twins with system simulation and Internet of Things (IoT) in support of MBSE and provides specific examples of the use and benefits of digital twin technology in different industries. It concludes with a recommendation to make digital twin technology an integral part of MBSE methodology and experimentation testbeds.;MDPI AG;Journal;Systems;2019-03-01;https://api.elsevier.com/content/abstract/scopus_id/85111581098
565;Model-driven digital twin construction: Synthesizing the integration of cyber-physical systems with their information systems;Digital twins emerge in many disciplines to support engineering, monitoring, controlling, and optimizing cyber-physical systems, such as airplanes, cars, factories, medical devices, or ships. There is an increasing demand to create digital twins as representation of cyber-physical systems and their related models, data traces, aggregated data, and services. Despite a plethora of digital twin applications, there are very few systematic methods to facilitate the modeling of digital twins for a given cyber-physical system. Existing methods focus only on the construction of specific digital twin models and do not consider the integration of these models with the observed cyber-physical system. To mitigate this, we present a fully model-driven method to describe the software of the cyber-physical system, its digital twin information system, and their integration. The integration method relies on MontiArc models of the cyber-physical system's architecture and on UML/P class diagrams from which the digital twin information system is generated. We show the practical application and feasibility of our method on an IoT case study. Explicitly modeling the integration of digital twins and cyber-physical systems eliminates repetitive programming activities and can foster the systematic engineering of digital twins.;Association for Computing Machinery, Inc;Conference Proceeding;Proceedings - 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS 2020;2020-10-16;https://api.elsevier.com/content/abstract/scopus_id/85096992990
566;Towards a Reference Architecture for Leveraging Model Repositories for Digital Twins;"In the area of Cyber-Physical Systems (CPS), the degree of complexity continuously increases mainly due to new key-enabling technologies supporting those systems. One way to deal with this increasing complexity is to create a digital representation of such systems, a so-called Digital Twin (DT), which virtually acts in parallel ideally across the entire life-cycle of a CPS. For this purpose, the DT uses simulated or real-time data to mimic operations, control, and may modify the CPS's behaviour at runtime. However, building such DTs from scratch is not trivial, mainly due to the integration needed to deal with heterogeneous systems residing in different technological spaces. In order to tackle this challenge, Model-Driven Engineering (MDE) allows to logically model a CPS with its physical components. Usually, in MDE such ""logical models""are created at design time which keep them detached from the deployed system during runtime. Instead of building bilateral solutions between each runtime environment and every engineering tool, a dedicated integration layer is needed which can deal with both, design and runtime aspects. Therefore, we present a reference architecture that allows on the one side to query data from model repositories to enrich the running system with design-time knowledge, and on the other side, to be able to reasoning about system states at runtime in design-time models. We introduce a model repository query and management engine as mediator and show its feasibility by a demonstration case.";Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;IEEE International Conference on Emerging Technologies and Factory Automation, ETFA;2020-09-01;https://api.elsevier.com/content/abstract/scopus_id/85093356602
567;Self-Adaptive Manufacturing with Digital Twins;Digital Twins are part of the vision of Industry 4.0 to represent, control, predict, and optimize the behavior of Cyber-Physical Production Systems (CPPSs). These CPPSs are long-living complex systems deployed to and configured for diverse environments. Due to specific deployment, configuration, wear and tear, or other environmental effects, their behavior might diverge from the intended behavior over time. Properly adapting the configuration of CPPSs then relies on the expertise of human operators. Digital Twins (DTs) that reify this expertise and learn from it to address unforeseen challenges can significantly facilitate self-adaptive manufacturing where experience is very specific and, hence, insufficient to employ deep learning techniques. We leverage the explicit modeling of domain expertise through case-based reasoning to improve the capabilities of Digital Twins for adapting to such situations. To this effect, we present a modeling framework for self-adaptive manufacturing that supports modeling domain-specific cases, describing rules for case similarity and case-based reasoning within a modular Digital Twin. Automatically configuring Digital Twins based on explicitly modeled domain expertise can improve manufacturing times, reduce wastage, and, ultimately, contribute to better sustainable manufacturing.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2021 International Symposium on Software Engineering for Adaptive and Self-Managing Systems, SEAMS 2021;2021-05-01;https://api.elsevier.com/content/abstract/scopus_id/85113473628
568;Towards a Model-Driven Architecture for Interactive Digital Twin Cockpits;Digital twins promise tremendous potential to reduce time and cost in the smart manufacturing of Industry 4.0. Engineering and monitoring interactive digital twins currently demands integrating different piecemeal technologies that effectively hinders their application and deployment. Current research on digital twins focuses on specific implementations or abstract models on how digital twins could be conceived. We propose model-driven software engineering to realize interactive digital twins and user-specific cockpits to interact with the digital twin by generating the infrastructure from common data structure models. To this end, we present a model-driven architecture for digital twins, its integration with an interactive cockpit, and a systematic method of realizing both. Through this, modeling, deploying, and monitoring interactive digital twins becomes more feasible and fosters their successful application in smart manufacturing.;Springer Science and Business Media Deutschland GmbH;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85097375593
569;Model-Driven Development of a Digital Twin for Injection Molding;Digital Twins (DTs) of Cyber-Physical Production Systems (CPPSs) enable the smart automation of production processes, collection of data, and can thus reduce manual efforts for supervising and controlling CPPSs. Realizing DTs is challenging and requires significant efforts for their conception and integration with the represented CPPS. To mitigate this, we present an approach to systematically engineering DTs for injection molding that supports domain-specific customizations and automation of essential development activities based on a model-driven reference architecture. In this approach, reactive CPPS behavior is defined in terms of a Domain-Specific Language (DSL) for specifying events that occur in the physical system. The reference architecture connects to the CPPS through a novel DSL for representing OPC-UA bindings. We have evaluated this approach with a DT of an injection molding machine that controls the machine to optimize the Design of Experiment (DoE) parameters between experiment cycles before the products are molded. Through this, our reference implementation of the DT facilitates the time-consuming setup of a DT and the subsequent injection molding activities. Overall, this facilitates to systematically engineer digital twins with reactive behavior that help to optimize machine use.;Springer;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85086228557
570;Achieving model quality through model validation, verification and exploration;System development strategies, like model-driven engineering (MDE), help to abstract architectures and provide a promising way to deal with architecture complexity and design quality. Thus, the importance for the underlying models to be correct arises. Today's validation and verification tools should support the developer in generating test cases and provide good concepts for fault detection. We here introduce and structure essential use cases for model validation, verification and exploration that help developers find faults in model descriptions and thus enhance model quality. Along with the use cases, we demonstrate a modern instance finder for UML and OCL models based on an implementation of relational logic and present the results and findings from the tool.;Elsevier Ltd;Journal;Computer Languages, Systems and Structures;2018-12-01;https://api.elsevier.com/content/abstract/scopus_id/85044652759
571;On OCL-based imperative languages;The Object Constraint Language (OCL) is a well-accepted ingredient in model-driven engineering and accompanying modeling languages such as UML (Unified Modeling Language) and EMF (Eclipse Modeling Framework) that support object-oriented software development. Among various possibilities, OCL offers the formulation of class invariants and operation contracts in form of pre- and postconditions, and side-effect free query operations. Much research has been done on OCL and various mature implementations are available for it. OCL is also used as the foundation for several modeling-specific programming and transformation languages. However, an intrusive way of embedding OCL into these language hampers us when we want to benefit from the existing achievements for OCL. In response to this shortcoming, we propose the language SOIL (Simple OCL-like Imperative Language), which we implemented in the UML and OCL modeling tool USE to amend its declarative model validation features. The expression sub-language of SOIL is identical to OCL. SOIL adds imperative constructs for programming in the domain of models. Thus by employing OCL and SOIL, it is possible to describe any operation in a declarative way and in an operational way on the modeling level without going into the details of a conventional programming language. In contrast to other similar approaches, the embedding of OCL into SOIL is done in a careful, non-intrusive way so that purity of OCL is preserved. © 2013 Elsevier B.V.;Elsevier;Journal;Science of Computer Programming;2014-10-05;https://api.elsevier.com/content/abstract/scopus_id/84902009107
572;Digital twin driven prognostics and health management for complex equipment;Prognostics and health management (PHM) is crucial in the lifecycle monitoring of a product, especially for complex equipment working in a harsh environment. In order to improve the accuracy and efficiency of PHM, digital twin (DT), an emerging technology to achieve physical–virtual convergence, is proposed for complex equipment. A general DT for complex equipment is first constructed, then a new method using DT driven PHM is proposed, making effective use of the interaction mechanism and fused data of DT. A case study of a wind turbine is used to illustrate the effectiveness of the proposed method.;Elsevier USA;Journal;CIRP Annals;2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85047291024
573;Knowledge map and forecast of digital twin in the construction industry: State-of-the-art review using scientometric analysis;"With the advancement of Industry 4.0 and the development of science and technology, industries have seen the advantages of digital twin (DT) implementations and concepts. Although the construction industry is still in the early stage of DT development and implementation, it is urgent for the industry to have a DT agenda. This paper identifies 1158 related bibliographic records from the Web of Science and 745 records from the Derwent Patent Database and quantitatively analyzed them to describe patterns of publications. Two knowledge mapping tools were selected to visualize and analyze the literature in the relevant scientific domain. Then, we integrated clustering, knowledge mapping, and network analysis methods to show the current foci and future directions of DT-MT derived from the data of time distribution, journal areas, and subject distribution. The results indicate that DT is a cross-disciplinary information technology with great development potential, and its development in the construction industry is scattered with the leading advancement in the manufacturing of construction materials and components. The derived knowledge map shows three stages of construction DT, including (1) data collection and creation of DT framework and database; (2) implementation of planning and design modules in detail and control of construction sites; and (3) carrying out asset management and fault prediction in the operation and maintenance phase of projects. The novelty of this paper is the specific analysis of DT in the construction industry. This study adds value to the architecture, engineering, and construction industries by shedding light on the focus of DT practical applications and the formation of a development path of construction DT.";Elsevier Ltd;Journal;Journal of Cleaner Production;2023-01-10;https://api.elsevier.com/content/abstract/scopus_id/85143719809
574;Modeling Behavioral Deontic Constraints Using UML and OCL;Business rules specify the required or desirable states of affairs or behavior of IT systems, and typically involve deontic constraints that must be adequately specified to enable their appropriate representation and effective analysis. Such deontic constraints focus on the permitted actions and obligations of the agents to carry them out. In this paper we present a proposal to explicitly specify dynamic deontic constraints in UML and OCL so that, on the one hand, they can guide and restrict the system behavior and, on the other hand, allow us to reason about such deontic behavior, including accountability analysis.;Springer Science and Business Media Deutschland GmbH;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85097413450
575;(An Example for) Formally Modeling Robot Behavior with UML and OCL;One of the problems that the design and development of robotic applications currently have is the lack of unified formal modeling notations and tools that can address the many different aspects of these kinds of applications. This paper presents a small example of a chain of robotized arms that move parts in a production line, modeled using a combination of UML and OCL. We show the possibilities that these high-level notations provide to describe the structure and behaviour of the system, to model some novel aspects such as measurement uncertainty and tolerance of physical elements, and to perform several kinds of analyses.;Springer Verlagservice@springer.de;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85042677687
576;Modeling Behavioral Deontic Constraints Using UML and OCL;Business rules specify the required or desirable states of affairs or behavior of IT systems, and typically involve deontic constraints that must be adequately specified to enable their appropriate representation and effective analysis. Such deontic constraints focus on the permitted actions and obligations of the agents to carry them out. In this paper we present a proposal to explicitly specify dynamic deontic constraints in UML and OCL so that, on the one hand, they can guide and restrict the system behavior and, on the other hand, allow us to reason about such deontic behavior, including accountability analysis.;Springer Science and Business Media Deutschland GmbH;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85097413450
577;OCL-based runtime monitoring of JVM hosted applications;In this paper we present an approach that enables users to monitor and verify the behavior of an application running on a virtual machine at the model level. Concrete implementations of object-oriented software usually contain a lot of technical classes. Thus, the central parts of an application, e.g., the business rules, may be hidden among peripheral functionality like user-interface classes or classes managing persistency. Our approach makes use of modern virtual machines and allows the devloper to profile an application in order to achieve an abstract monitoring and verification of central application components. We represent virtual machine bytecode in form of a so-called platform-aligned model (PAM) comprising OCL invariants and pre- and postconditions. In contrast to related work, our approach uses the original source or bytecode of the monitored application as it stands and does not require any changes. We show a prototype implementation as an extension of the UML and OCL tool USE. Also, we investigate the impact of our approach to the execution time of a monitored system.;Universitatsbibliothek TU Berlineceasst@journal.ub.tu-berlin.de;Journal;Electronic Communications of the EASST;2011-01-01;https://api.elsevier.com/content/abstract/scopus_id/85015057935
578;Digital Twins: State of the art theory and practice, challenges, and open research questions;"Digital Twin was introduced over a decade ago, as an innovative all-encompassing tool, with perceived benefits including real-time monitoring, simulation, optimisation and accurate forecasting. However, the theoretical framework and practical implementations of digital twin (DT) are yet to fully achieve this vision at scale. Although an increasing number of successful implementations exist in research and industrial works, sufficient implementation details are not publicly available, making it difficult to fully assess their components and effectiveness, to draw comparisons, identify successful solutions, share lessons, and thus to jointly advance and benefit from the DT methodology. This work first presents a review of relevant DT research and industrial works, focusing on the key DT features, current approaches in different domains, and successful DT implementations, to infer the key DT components and properties, and to identify current limitations and reasons behind the delay in the widespread implementation and adoption of digital twin. This work identifies that the major reasons for this delay are: the fact the DT is still a fast evolving concept; the lack of a universal DT reference framework, e.g. DT standards are scarce and still evolving; problem- and domain-dependence; security concerns over shared data; lack of DT performance metrics; and reliance of digital twin on other fast-evolving technologies. Advancements in machine learning, Internet of Things (IoT) and big data have led to significant improvements in DT features such as real-time monitoring and accurate forecasting. Despite this progress and individual company-based efforts, certain research and implementation gaps exist in the field, which have so far prevented the widespread adoption of the DT concept and technology; these gaps are also discussed in this work. Based on reviews of past work and the identified gaps, this work then defines a conceptualisation of DT which includes its components and properties; these also validate the uniqueness of DT as a concept, when compared to similar concepts such as simulation, autonomous systems and optimisation. Real-life case studies are used to showcase the application of the conceptualisation. This work discusses the state-of-the-art in DT, addresses relevant and timely DT questions, and identifies novel research questions, thus contributing to a better understanding of the DT paradigm and advancing the theory and practice of DT and its allied technologies.";Elsevier B.V.;Journal;Journal of Industrial Information Integration;2022-11-01;https://api.elsevier.com/content/abstract/scopus_id/85137748309
579;Information Systems Engineering with Digital Shadows: Concept and Case Studies: An Exploratory Paper;"The production sector has faced many difficulties in taking full advantage of opportunities found in other web application domains. Production research has focused on sophisticated mathematical models ranging from molecular materials modeling to efficient production control to inter-company supply network logistics. Often, these models have no closed-form solutions; this led to intense simulation research for individual modeling viewpoints, often labeled “Digital Twins”. However, the complexity of the overall system precludes Digital Twins covering more than just a few system perspectives, especially if near-realtime performance is required. Moreover, the wide variety of individual situations and behaviors is usually captured only as statistical uncertainty. In order to achieve better performance and more context adaptation, the interdisciplinary research cluster “Internet of Production” at RWTH Aachen University is exploring the concept of “Digital Shadows”. Digital Shadows can be understood as compact views on dynamic processes, usually combining condensed measurement data with highly efficient simplified mathematical models. In this exploratory paper, we argue based on a couple of initial case studies that Digital Shadows are not just valuable carriers of deep engineering knowledge but due to their small size also help in reducing network congestion and enabling edge computing. These properties could make Digital Shadows an interesting solution to address resilience in other information-intensive dynamic systems.";Springer;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85086253990
580;Meta-model-based shop-floor digital twin architecture, modeling and application;Digital twin is regarded as the virtual counterpart of physical entities, which can mirror the physical behavior and performance. Digital twin technology provides strong support for the achievement of cyber-physical system and intelligent manufacturing. Many investigations have been carried out for the digital twin of specific products. However, there are less researches on digital twin in the shop-floor domain, and there is a lack of model-driven digital twin comprehensive architecture. The modeling approach to the full lifecycle of digital twin is not considered enough. This paper proposes a meta-model-based shop-floor digital twin construction approach and a comprehensive architecture. A meta-model based on RAMI 4.0 is constructed, which provide a novel idea for the description of manufacturing resources and their status. The proposed shop-floor digital twin architecture consists of three key implementation elements: the meta-model construction, data modeling (including data interaction between cyber-physical spaces) and constructing different integration level models of shop-floor digital twin based on iteration feedback between the demands and models. The proposed approach is validated through a case study of the fischer learning factory 4.0.;Elsevier Ltd;Journal;Robotics and Computer-Integrated Manufacturing;2023-12-01;https://api.elsevier.com/content/abstract/scopus_id/85160515920
581;Applications of Digital Twin across Industries: A Review;One of the most promising technologies that is driving digitalization in several industries is Digital Twin (DT). DT refers to the digital replica or model of any physical object (physical twin). What differentiates DT from simulation and other digital or CAD models is the automatic bidirectional exchange of data between digital and physical twins in real-time. The benefits of implementing DT in any sector include reduced operational costs and time, increased productivity, better decision making, improved predictive/preventive maintenance, etc. As a result, its implementation is expected to grow exponentially in the coming decades as, with the advent of Industry 4.0, products and systems have become more intelligent, relaying on collection and storing incremental amounts of data. Connecting that data effectively to DTs can open up many new opportunities and this paper explores different industrial sectors where the implementation of DT is taking advantage of these opportunities and how these opportunities are taking the industry forward. The paper covers the applications of DT in 13 different industries including the manufacturing, agriculture, education, construction, medicine, and retail, along with the industrial use case in these industries.;MDPI;Journal;Applied Sciences (Switzerland);2022-06-01;https://api.elsevier.com/content/abstract/scopus_id/85131861164
582;Overview on Digital Twin for Autonomous Electrical Vehicles Propulsion Drive System;The significant progress in the electric automotive industry brought a higher need for new technological innovations. Digital Twin (DT) is one of the hottest trends of the fourth industrial revolution. It allows representing physical assets under various operating conditions in a low-cost and zero-risk environment. DTs are used in many different fields from aerospace to healthcare. However, one of the perspective applications of such technology is the automotive industry. This paper presents an overview of the implementation of DT technology in electric vehicles (EV) propulsion drive systems. A general review of DT technology is supplemented with main applications analysis and comparison between different simulation technologies. Primary attention is given to the adaptation of DT technology for EV propulsion drive systems.;MDPI;Journal;Sustainability (Switzerland);2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85122399284
583;Digital twins for wind energy conversion systems: A literature review of potential modelling techniques focused on model fidelity and computational load;The Industry 4.0 concept of a Digital Twin will bring many advantages for wind energy conversion systems, e.g., in condition monitoring, predictive maintenance and the optimisation of control or design parameters. A virtual replica is at the heart of a digital twin. To construct a virtual replica, appropriate modelling techniques must be selected for the turbine components. These models must be chosen with the intended use case of the digital twin in mind, finding a proper balance between the model fidelity and computational load. This review article presents an overview of the recent literature on modelling techniques for turbine aerodynamics, structure and drivetrain mechanics, the permanent magnet synchronous generator, the power electronic converter and the pitch and yaw systems. For each component, a balanced overview is given of models with varying model fidelity and computational load, ranging from simplified lumped parameter models to advanced numerical Finite Element Method (FEM)-based models. The results of the literature review are presented graphically to aid the reader in the model selection process. Based on this review, a high-level structure of a digital twin is proposed together with a virtual replica with a minimum computational load. The concept of a multi-level hierarchical virtual replica is presented.;MDPI;Journal;Processes;2021-12-01;https://api.elsevier.com/content/abstract/scopus_id/85121752336
584;Overview of Digital Twin Platforms for EV Applications;Digital twin (DT) technology has been used in a wide range of applications, including electric vehicles. The DT platform provides a virtual representation or advanced simulation of a physical object in real-time. The implementation of DT on various aspects of EVs has recently transpired in different research studies. Generally, DT can emulate the actual vehicle on the road to predict/optimize its performance and improve vehicle safety. Additionally, DT can be used for the optimization of manufacturing processes, real-time condition monitoring (at all levels and in all powertrain components), energy management optimization, repurposing of the components, and even recycling processes. This paper presents an overview of different DT platforms that can be used in EV applications. A deductive comparison between model-based and data-driven DT was performed. EV main systems have been discussed regarding the usable DT platform. DT platforms used in the EV industry were addressed. Finally, the review showed the superiority of data-driven DTs over model-based DTs due to their ability to handle systems with high complexity.;MDPI;Journal;Sensors;2023-02-01;https://api.elsevier.com/content/abstract/scopus_id/85147992220
585;Broken Bar Fault Detection and Diagnosis Techniques for Induction Motors and Drives: State of the Art;Motors are the higher energy-conversion devices that consume around 40% of the global electrical generated energy. Induction motors are the most popular motor type due to their reliability, robustness, and low cost. Therefore, both condition monitoring and fault diagnosis of induction motor faults have motivated considerable research efforts. In this paper, a comprehensive review of the recent techniques proposed in the literature for broken bar faults detection and diagnosis is presented. This paper mainly investigates the fault detection methods in line-fed and inverter-fed motors proposed after 2015 and published in most relevant journals and conferences. The introduced review has deeply discussed the main features of the reported methods and compared them in many different aspects. Finally, the study has highlighted the main issues and the gaps that require more attention from researchers in this field.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85136709295
586;VTOL UAV digital twin for take-off, hovering and landing in different wind conditions;With UAVs becoming increasingly popular in the industry, vertical take-off and landing (VTOL) convertiplanes are emerging as a compromise between the advantages of planes and multicopters. Due to their large wing surface area, VTOL convertiplanes are subject to a strong wind dependence on critical phases such as take-off, landing, and hovering. Developing a new and improved unmanned aerial vehicle (UAV) is often expensive and associated with failures and accidents. This paper proposes the dynamic characterization of a commercial VTOL convertiplane UAV in copter mode and provides a novel method to estimate the aerodynamic forces and moments for any possible wind speed and direction. Starting from Euler's equations of rigid body dynamics, we have derived the mathematical formulation to precisely consider aerodynamic forces and moments caused by any wind speed and direction. This unique approach will allow for VTOL convertiplane UAVs to be trained and tested digitally in take-off, hovering, and landing maneuvers without the cost and hassle of physical testing, and the dependence on existing wind conditions. A digital twin of a VTOL convertiplane UAV in copter mode has been modeled and tested in the Gazebo robotics simulator. Take-off, hovering and landing maneuvers have been compared with and without the wind physics model. Finally, the simulator has been tested against real flight conditions (reproducing the mean wind speed and direction only), showing a natural and realistic behavior.;Elsevier B.V.;Journal;Simulation Modelling Practice and Theory;2023-02-01;https://api.elsevier.com/content/abstract/scopus_id/85143850586
587;Interface Development for Digital Twin of an Electric Motor Based on Empirical Performance Model;The concept of Digital Twin is creating and maintaining a digital representation of the real physical entity and supporting its performance utilizing simulation and optimization tools, which are fed with the real data obtained from the physical equipment. Development and implementation of the Digital Twin technology are one of the main challenges for today's industry, more detailed studies are needed on design methods for Digital Twins. Besides using Digital Twin as a high-quality simulation, one of the commitments is monitoring and maintaining control of the whole system via a constant live link between virtual and physical entities. The related research study presents a detailed structural description of the developed Digital Twin virtual entity and the development of a framework that allows Robot Operating System (ROS) to securely communicate with remote Digital Twins via the Internet and harness ROS's adaptability across vast distances and multiple systems. This paper is an extended version of the authors' International Conference on Electrical Power Drive Systems (ICEPDS20) paper, in which we propose a development case study of Digital Twin for an electric motor based on an empirical performance model.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85124176939
588;Multi-dimensional modeling and abnormality handling of digital twin shop floor;Digital twin is an enabling technology of smart manufacturing. The core of the manufacturing is the shop floor, where the digital twin shop floor (DTS) is applied to facilitate its intellectualization. DTS enables the high-fidelity mapping for physical shop floor and provides intelligent services. However, the high-fidelity mapping of DTS requires modeling from multiple dimensions. In this paper, the geometric modeling of the DTS is conducted based on model reuse first. Next, the behavior modeling of equipment production in DTS and DTS production process is performed. Then the DTS service of the abnormality handling is derived. Finally, an aerospace product assembly shop floor is chosen to verify the proposed procedures and methods.;Elsevier B.V.;Journal;Journal of Industrial Information Integration;2023-10-01;https://api.elsevier.com/content/abstract/scopus_id/85165089372
589;Digital twins as electric motor soft-sensors in the automotive industry;Digital Twins can be defined as virtual representation of physical assets enabled through data and simulators, for real time prediction, optimization, control, and decision making improvements. In this paper, the concept of digital twin is applied to electric motors. In particular, the use of this technology is shown to solve general problems related to the application of electric motors in the automotive industry, such as estimation of the driving torque and the internal rotor temperature to improve cooling control. Proof-of-concept results are shown, showing the validity of the adopted methodology and the effectiveness of the proposed solution.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2021 IEEE International Workshop on Metrology for Automotive, MetroAutomotive 2021 - Proceedings;2021-07-01;https://api.elsevier.com/content/abstract/scopus_id/85114962774
590;Digital Twin Service Unit for AC Motor Stator Inter-Turn Short Circuit Fault Detection;A modern trend for industry digitalization brings new demands for the development and application of the modeling and simulation approach. It is already not enough to have only a virtual representation of the object and run it independently from the physical object. The Digital Twin (DT) aspect indicates a connection between the physical object and the corresponding virtual twin established by generating real-time data using sensors. The DT represents physical object operation throughout its life cycle, making it an essential tool for improving that object's reliability. In this paper, an application of the DT service unit for AC motor stator inter-turn short circuit fault detection is presented. According to real-time measurements, Linux Robot Operation System (ROS) simulates AC electrical machine-specific behavior in case of unbalanced stator currents and notify about possible fault appearance and propagation. Fault, such as discussed in the paper (AC machine stator inter-turn) is considered one of the most prevalent possible electrical motor failure.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2021 28th International Workshop on Electric Drives: Improving Reliability of Electric Drives, IWED 2021 - Proceedings;2021-01-27;https://api.elsevier.com/content/abstract/scopus_id/85103860218
591;Spectrum analysis for condition monitoring and fault diagnosis of ventilation motor: A case study;In modern power systems, since most loads are inductive by nature, there is an ongoing power quality issue and researchers’ interest in improving the power factor is widespread, as inductive loads have a low power factor that depletes the system’s capacity and has an adverse effect on the voltage level. The measurement and acute analysis of voltage-and current-level waveforms is essential to tackle power quality issues. This article presents a detailed case study and analysis of real-time data measured from a frequency converter, which is used to operate the motor of a ventilation system. The output of the frequency converter is a highly distorted current wave. A hybrid Fourier transform (FT)-and wavelet transform-based solution has been proposed here to diagnose and identify the causes of motor failure in the ventilation system. The traditional FT did not give a detailed analysis of this type of signal, which is highly contaminated by noise. Therefore, first, the signal is preprocessed for data denoising using the wavelet transform. Second, the Fourier analysis is performed on the filtered signal for frequency analysis and segregation of fundamental frequency components, higher-order harmonics, and suppressed noise. The spectrum analysis reveals that the noise is generated due to the rapidly switching circuits in the frequency converter and this unfiltered signal at the output of the frequency converter causes motor failure.;MDPI AG;Journal;Energies;2021-04-01;https://api.elsevier.com/content/abstract/scopus_id/85106503610
592;Digital twins for automotive development: Two wheelers application;Shortening product lifecycles and increasing customer demands are forcing manufacturers to increase the efficiency and effectiveness of their product development process to stay competitive in an increasingly global setting. The effectiveness of current day product development is hampered by the availability of real-world data that allows the deduction of comprehensive customer requirements. Key to solving this is a tight connection between the manufacturer and the vehicle in-use. Founded by technological advances put forward by Industry 4.0, the digital twin provides the tools needed to strengthen this connection. Driven by the difficulties automotive manufacturers face in generating insights in customer usage of the vehicle, the present work develops a general digital twin framework for the automotive industry, characterizing the digital twin as a holistic representation of a physical vehicle with the appropriate fidelity throughout its lifecycle. Further highlighting that this holistic portrayal requires models which depict the human interaction with the vehicle. To illustrate this, a digital twin model capable of capturing human interaction with automotive products, more specifically motorcycles, is presented. Data generated by this digital twin model provides a data-based foundation for the development of customer requirements, increasing the effectiveness of next-generation vehicle development.;Elsevier Ltd;Journal;Advanced Engineering Informatics;2023-04-01;https://api.elsevier.com/content/abstract/scopus_id/85154033810
593;Conceptual Modelling of an EV-Permanent Magnet Synchronous Motor Digital Twin;Digital twin (DT) technology has contributed to the development process of many applications, including electric vehicles (EVs). The DT concept is to create a digital representation of a real physical asset and support its performance by utilizing simulation and optimization tools fed with real-time data. DT technology can be used to solve general problems related to EV motors, such as estimation of the driving torque and the internal rotor temperature. This paper provides the concepts for implementing a DT of an EV permanent magnet synchronous motor (PMSM) based on its analytical performance model. DT architecture comprises two main components: virtual model and real-time data exchange set. The motor physical model (test bench) was provided in detail. An analytical performance q-d mathematical model supported by the motor equivalent circuit was explained. The motor virtual model was built based on the proposed analytical model using MATLAB/Simulink. Robot operating system V.2 (ROS2) node, implemented on a microcontroller, was used for real-time data exchange between the physical and the virtual motor models. The main target is to monitor the physical motor performance and estimate its torque through its digital twin. The obtained results from the DT showed the effectiveness of the proposed method.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2022 IEEE 20th International Power Electronics and Motion Control Conference, PEMC 2022;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85144022754
594;Digital Twin applications toward Industry 4.0: A Review;Digital Twin is a virtual representation of objects, processes, and systems that exist in real-time. While Digital Twin can represent digital objects, they are often used to connect the physical and digital worlds. This technology plays a vital role in fulfilling various requirements of Industry 4.0. It gives a digital image of a factory's operations, a communications network's activities, or the movement of items through a logistics system. This paper studies Digital Twin and its need in Industry 4.0. Then the process and supportive features of Digital Twin for Industry 4.0 are diagrammatically discussed, and finally, the major applications of Digital Twin for Industry 4.0 are identified. Digital Twin sophistication depends on the process or product represented and the data available. Manufacturers can learn how assets will behave in real-time, in the physical world, by putting sensors on particular assets, gathering data, creating digital duplicates, and employing machine intelligence. They can confidently make wise judgments, which helps improve company performance. Digital Twin assesses material usage to save costs, discover inefficiencies, replicate tool tracking systems, and do other things. Manufacturers construct a digital clone for specific equipment and tools, exclusive products or systems, entire procedures, or anything else they want to improve on the factory floor. Sensors and other equipment that collect real-time data on the state of the process or product collect this information, which on the other hand, must be handled and processed appropriately. It is made feasible by IoT sensors, which collect data from the physical environment and transmit it to be virtually recreated. This information comprises design and engineering details that explain the asset's shape, materials, components, and behaviour or performance.;KeAi Communications Co.;Journal;Cognitive Robotics;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85152954260
595;Digital twin: Universal user interface for online management of the manufacturing system;"Industry 4.0 concept enables connecting a multitude of equipment to computer simulations through IoT and virtual commissioning, but using conventional interfaces for each separate piece of equipment for control and maintenance of Digital Twins is not always an optimal solution. Industrial Digital Twins software toolkits usually consist of simulation or offline programming tools. It can even connect real machines and controllers and sensors to feed a simulation with actual production data and later analyze it. Moreover, Virtual Reality (VR) and Augmented Reality (AR) are used in different ways for monitoring and design purposes. However, there are many software tools for the simulation and re-programming of robots on the market already, but those are a limited number of software that combine all these features, and all of those send data only in one way, not allowing to re-program machines from the simulations. The related research aims to build a modular framework for designing and deploying Digital Twins of industrial equipment (i.e., robots, manufacturing lines), focusing on online connectivity for monitoring and control. A developed use-case solution enables one to operate the equipment in VR/AR/Personal Computer (PC) and mobile interfaces from any point globally while receiving real-time feedback and state information of the machinery equipment. Gamified multiplatform interfaces allow for more intuitive interactions with Digital Twins, providing a real-scale model of the real device, augmented by spatial UIs, actuated physical elements, and gesture tracking. The introduced solution can control and simulate any aspect of the production line without limitation of brand or type of the machine and being managed and self-learning independently by exploiting Machine Learning algorithms. Moreover, various interfaces such as PC, mobile, VR, and AR give an unlimited number of options for interactions with your manufacturing shop floor both offline and online. Furthermore, when it comes to manufacturing floor data monitoring, all gathered data is being used for statistical analysis, and in a later phase, predictive maintenance functions are enabled based on it. However, the research scope is broader; this particular research paper introduces a use-case interface on a mobile platform, monitoring and controlling the production unit of three various industrial- and three various mobile robots, partially supported by data monitoring sensors. The solution is developed using the game engine Unity3D, Robot Operation System (ROS), and MQTT for connectivity. Thus, developed is a universal modular Digital Twin all-in-one software platform for users and operators, enabling full control over the manufacturing system unit.";American Society of Mechanical Engineers (ASME);Conference Proceeding;ASME International Mechanical Engineering Congress and Exposition, Proceedings (IMECE);2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85124397592
596;VTOL UAV digital twin for take-off, hovering and landing in different wind conditions;With UAVs becoming increasingly popular in the industry, vertical take-off and landing (VTOL) convertiplanes are emerging as a compromise between the advantages of planes and multicopters. Due to their large wing surface area, VTOL convertiplanes are subject to a strong wind dependence on critical phases such as take-off, landing, and hovering. Developing a new and improved unmanned aerial vehicle (UAV) is often expensive and associated with failures and accidents. This paper proposes the dynamic characterization of a commercial VTOL convertiplane UAV in copter mode and provides a novel method to estimate the aerodynamic forces and moments for any possible wind speed and direction. Starting from Euler's equations of rigid body dynamics, we have derived the mathematical formulation to precisely consider aerodynamic forces and moments caused by any wind speed and direction. This unique approach will allow for VTOL convertiplane UAVs to be trained and tested digitally in take-off, hovering, and landing maneuvers without the cost and hassle of physical testing, and the dependence on existing wind conditions. A digital twin of a VTOL convertiplane UAV in copter mode has been modeled and tested in the Gazebo robotics simulator. Take-off, hovering and landing maneuvers have been compared with and without the wind physics model. Finally, the simulator has been tested against real flight conditions (reproducing the mean wind speed and direction only), showing a natural and realistic behavior.;Elsevier B.V.;Journal;Simulation Modelling Practice and Theory;2023-02-01;https://api.elsevier.com/content/abstract/scopus_id/85143850586
597;Parametric digital twin of autonomous electric vehicle transmission;Variable applications and methodologies are used in the Digital Twin technology. Digital Twin as a trending technology is also a general topic of many industry-oriented research projects. To develop and implement a novel technology, a detailed study of any single part of a system is required. This paper presents a development case study of the parametric Digital Twin of autonomous electric vehicle transmission. Digital Twin combines the advantages of software models and real equipment to reduce total test runs and safe maintenance. The primary duty of the Digital Twin is to allow complete synchronization and connectivity between virtual and real entities. The paper presents a detailed structural description of the virtual entity that considers the parametrization of the transmission.;Editorial Institution of Wrocaw Board of Scientific;Journal;Journal of Machine Engineering;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85112503436
598;EV-Powertrain Test Bench for Digital Twin Development;The paper is devoted to the development of a PC-controlled experimental bench dedicated to the testing of an electric vehicle (EV) powertrain. The test bench was built with the goal of facilitating the creation of digital twin (DT) that simulate the real EV propulsion drive system. Different components of the test bench were described in detail. The potentialities of the developed bench are highlighted through the emulation of different automotive cycles including acceleration and braking.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2022 IEEE 20th International Power Electronics and Motion Control Conference, PEMC 2022;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85144089096
599;ROS middle-layer integration to Unity3D as an interface option for propulsion drive simulations of autonomous vehicles;As autonomous vehicle development continues at growing speeds, so does the need for optimization, diagnosis, and testing of various autonomous systems elements, under different conditions. However, since such processes should be carried out in parallel, it may result in bottlenecks in development and increased complexity. The trend for Digital Twins brings a promising option for the diagnosis and testing to be carried out separately from the physical devices, incl. Autonomous vehicles, in the virtual world. The idea of intercommunication between virtual and physical twins provides possibilities to estimate risks, drawbacks, physical damages to the vehicle's drive systems, and the physical one's critical conditions. Although the problem of providing communications between these systems arises, at the speed that will be adequate to represent the physical vehicle in the virtual world correctly, it is still a trending topic. The paper aims to demonstrate a way to solve this problem - by using ROS as a middleware interface between two twining systems on the autonomous vehicle propulsion drive example. Data gathered from the physical and virtual world can be exchanged in the middle to allow continuous training and optimization of the propulsion drive model, leading to more efficient path planning and energy-efficient drive of the autonomous vehicle itself.;DAAAM International Vienna;Conference Proceeding;"Proceedings of the International Conference of DAAAM Baltic &quot;Industrial Engineering&quot;";2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85138995530
600;Quickly and High-Precision Digital Twin Device-Level Simulation Modeling of Permanent Magnet Synchronous Generator and Voltage Stabilizing System;The traditional finite element model of permanent magnet synchronous generator (PMSG) is time-consuming due to the need for nonlinear iteration of each grid. Besides, the performance of various components of the voltage regulator controller (VRC) will be affected by the operating environment. The traditional component library cannot meet the accurate digital twin effect. Taking an emergency power supply system for an unmanned aerial vehicle as an example, this paper uses the device-level modeling method to build a digital twin simulation model (DTSM) of a PMSG and its AC-DC regulated power supply system, which simulation results can guarantee real-time output results in synchronization with the experiment and has an agile digital twin effect. Finally, the calculated results are compared with the experimental values to verify the accuracy of the proposed digital twin device-level model, which is of great significance to the combined design of PMSGs and VRCs.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Digests of the Intermag Conference;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85121700782
601;Cognitive neuroscience and robotics: Advancements and future research directions;In recent years, brain-based technologies that capitalise on human abilities to facilitate human–system/robot interactions have been actively explored, especially in brain robotics. Brain–computer interfaces, as applications of this conception, have set a path to convert neural activities recorded by sensors from the human scalp via electroencephalography into valid commands for robot control and task execution. Thanks to the advancement of sensor technologies, non-invasive and invasive sensor headsets have been designed and developed to achieve stable recording of brainwave signals. However, robust and accurate extraction and interpretation of brain signals in brain robotics are critical to reliable task-oriented and opportunistic applications such as brainwave-controlled robotic interactions. In response to this need, pervasive technologies and advanced analytical approaches to translating and merging critical brain functions, behaviours, tasks, and environmental information have been a focus in brain-controlled robotic applications. These methods are composed of signal processing, feature extraction, representation of neural activities, command conversion and robot control. Artificial intelligence algorithms, especially deep learning, are used for the classification, recognition, and identification of patterns and intent underlying brainwaves as a form of electroencephalography. Within the context, this paper provides a comprehensive review of the past and the current status at the intersection of robotics, neuroscience, and artificial intelligence and highlights future research directions.;Elsevier Ltd;Journal;Robotics and Computer-Integrated Manufacturing;2024-02-01;https://api.elsevier.com/content/abstract/scopus_id/85165534271
602;Knowledge driven rapid development of white box digital twins for industrial plant systems;Industrial systems like power plants need a significant domain and engineering expertise for their efficient operations. Experts make decisions for multiple operational objectives such as minimizing cost, maximizing productivity, ensuring compliance to environmental conditions, etc. However, deciding strategies to achieve an objective can be highly non-trivial as it may lead to conflicting outcomes concerning other objectives. Modern digital twin(DT) technologies make it possible to build systems to support such decision-making to validate critical decisions. DTs are developed as one-off solutions for individual plants in the current practice, requiring high efforts and domain knowledge. Our work demonstrates the use of a knowledge-driven approach to reduce DT development efforts significantly. The main contribution of our work is an end-to-end architecture that allows us to explicate, structure, and reuse domain knowledge to semi-automate DT development for industrial plants. We integrate technologies like semantic web, model-driven engineering, and formal methods to realize the architecture. Our approach to developing a DT supporting a fault management scenario in a power plant reduced 70% development time and 50% manual efforts.;IEEE Computer Society;Conference Proceeding;IECON Proceedings (Industrial Electronics Conference);2021-10-13;https://api.elsevier.com/content/abstract/scopus_id/85119495014
603;A survey on AI-driven digital twins in industry 4.0: Smart manufacturing and advanced robotics;Digital twin (DT) and artificial intelligence (AI) technologies have grown rapidly in recent years and are considered by both academia and industry to be key enablers for Industry 4.0. As a digital replica of a physical entity, the basis of DT is the infrastructure and data, the core is the algorithm and model, and the application is the software and service. The grounding of DT and AI in industrial sectors is even more dependent on the systematic and in-depth integration of domain-specific expertise. This survey comprehensively reviews over 300 manuscripts on AI-driven DT technologies of Industry 4.0 used over the past five years and summarizes their general developments and the current state of AI-integration in the fields of smart manufacturing and advanced robotics. These cover conventional sophisticated metal machining and industrial automation as well as emerging techniques, such as 3D printing and human–robot interaction/cooperation. Furthermore, advantages of AI-driven DTs in the context of sustainable development are elaborated. Practical challenges and development prospects of AI-driven DTs are discussed with a respective focus on different levels. A route for AI-integration in multiscale/fidelity DTs with multiscale/fidelity data sources in Industry 4.0 is outlined.;MDPI;Journal;Sensors;2021-10-01;https://api.elsevier.com/content/abstract/scopus_id/85115401810
604;A Cross-Domain Systematic Mapping Study on Software Engineering for Digital Twins;Digital Twins are currently investigated as the technological backbone for providing an enhanced understanding and management of existing systems as well as for designing new systems in various domains, e.g., ranging from single manufacturing components such as sensors to large-scale systems such as smart cities. Given the diverse application domains of Digital Twins, it is not surprising that the characterization of the term Digital Twin, as well as the needs for developing and operating Digital Twins are multi-faceted. Providing a better understanding what the commonalities and differences of Digital Twins in different contexts are, may allow to build reusable support for developing, running, and managing Digital Twins by providing dedicated concepts, techniques, and tool support. In this paper, we aim to uncover the nature of Digital Twins based on a systematic mapping study which is not limited to a particular application domain or technological space. We systematically retrieved a set of 1471 unique publications of which 356 were selected for further investigation. In particular, we analyzed the types of research and contributions made for Digital Twins, the expected properties Digital Twins have to fulfill, how Digital Twins are realized and operated, as well as how Digital Twins are finally evaluated. Based on this analysis, we also contribute a novel feature model for Digital Twins from a software engineering perspective as well as several observations to further guide future software engineering research in this area.;Elsevier Inc.;Journal;Journal of Systems and Software;2022-11-01;https://api.elsevier.com/content/abstract/scopus_id/85135797712
605;A Computer Science Perspective on Digital Transformation in Production;"The Industrial Internet-of-Things (IIoT) promises significant improvements for the manufacturing industry by facilitating the integration of manufacturing systems by Digital Twins. However, ecological and economic demands also require a cross-domain linkage of multiple scientific perspectives from material sciences, engineering, operations, business, and ergonomics, as optimization opportunities can be derived from any of these perspectives. To extend the IIoT to a true Internet of Production, two concepts are required: first, a complex, interrelated network of Digital Shadows which combine domain-specific models with data-driven AI methods; and second, the integration of a large number of research labs, engineering, and production sites as a World Wide Lab which offers controlled exchange of selected, innovation-relevant data even across company boundaries. In this article, we define the underlying Computer Science challenges implied by these novel concepts in four layers: Smart human interfaces provide access to information that has been generated by model-integrated AI. Given the large variety of manufacturing data, new data modeling techniques should enable efficient management of Digital Shadows, which is supported by an interconnected infrastructure. Based on a detailed analysis of these challenges, we derive a systematized research roadmap to make the vision of the Internet of Production a reality.";Association for Computing Machinery;Journal;ACM Transactions on Internet of Things;2022-05-01;https://api.elsevier.com/content/abstract/scopus_id/85121783951
606;Conceptualizing Digital Twins;Properly arranging models, data sources, and their relations to engineer digital twins is challenging. We propose a conceptual modeling framework for digital twins that captures the combined usage of heterogeneous models and their respective evolving data for the twinâs entire lifecycle.;IEEE Computer Society;Journal;IEEE Software;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85120045327
607;A Conceptual Model for Digital Shadows in Industry and Its Application;Smart manufacturing demands to process data in domain-specific real-time. Engineering models created for constructing, commissioning, planning, or simulating manufacturing systems can facilitate aggregating and abstracting the wealth of manufacturing data to faster processable data structures for more timely decision making. Current research lacks conceptual foundations for how data and engineering models can be exploited in an integrated way to achieve this. Such research demands expertise from different smart manufacturing domains to harmonize the notion space. We propose a conceptual model to describe digital shadows, data structures tailored to exploit models and data in smart manufacturing, through a metamodel and its notion space. This conceptual model was established through interdisciplinary research in the German excellence cluster “Internet of Production” and evaluated in various real-world manufacturing scenarios. This foundation for an understanding helps to manage complexity, automated analyses, and syntheses, and, ultimately, facilitates cross-domain collaboration.;Springer Science and Business Media Deutschland GmbH;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85118142665
608;Towards a Model-Driven Architecture for Interactive Digital Twin Cockpits;Digital twins promise tremendous potential to reduce time and cost in the smart manufacturing of Industry 4.0. Engineering and monitoring interactive digital twins currently demands integrating different piecemeal technologies that effectively hinders their application and deployment. Current research on digital twins focuses on specific implementations or abstract models on how digital twins could be conceived. We propose model-driven software engineering to realize interactive digital twins and user-specific cockpits to interact with the digital twin by generating the infrastructure from common data structure models. To this end, we present a model-driven architecture for digital twins, its integration with an interactive cockpit, and a systematic method of realizing both. Through this, modeling, deploying, and monitoring interactive digital twins becomes more feasible and fosters their successful application in smart manufacturing.;Springer Science and Business Media Deutschland GmbH;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85097375593
609;Generating customized low-code development platforms for digital twins;A digital twin improves our use of a cyber–physical system and understanding of its emerging behavior. To this effect, a digital twin is to be developed and configured and potentially also operated by domain experts, who rarely have a professional software engineering background and for whom easy access and support, e.g., in form of low-code platforms are missing. In this paper, we report on an integrated method for the model-driven engineering of low-code development platforms for digital twins that enables domain experts to create and operate digital twins for cyber–physical systems using the most appropriate modeling languages. The foundation of this method is (1) a code generation infrastructure for information systems combined with (2) an extensible base architecture for self-adaptive digital twins and (3) reusable language components for their configuration. Using this method, software engineers first configure the information system with the required modeling languages to generate the low-code development platform for digital twins before domain experts leverage the generated platform to create digital twins. This two-step method facilitates creating tailored low-code development platforms as well as creating and operating customized digital twins for a variety of applications.;Elsevier Ltd;Journal;Journal of Computer Languages;2022-06-01;https://api.elsevier.com/content/abstract/scopus_id/85129984615
610;A machine learning digital twin approach for critical process parameter prediction in a catalyst manufacturing line;Digital twins (DTs) are rapidly changing how manufacturing companies leverage the large volumes of data they generate daily to gain a competitive advantage and optimize their supply chains. When coupled with recent developments in machine learning (ML), DTs have the potential to generate invaluable insights for process manufacturing companies to help them optimize their manufacturing processes. However, this potential has yet to be fully exploited due to the challenges that process manufacturing companies face in developing and implementing DTs in their organizations. Although DTs are receiving increasing attention in both industry and academia, there is limited literature on how to apply them in the process industry. To address this gap, this paper presents a framework for developing ML-based DTs to predict critical process parameters in real time. The proposed framework is tested through a case study at an international process manufacturing company in which it was used to collect and process plant data, build accurate predictive models for two critical process parameters, and develop a DT application to visualize the models’ predictions. The case study demonstrated the usefulness of the proposed DT–ML framework in the sense that it provided the company with more accurate predictions than the models it previously applied. The study provides insights into the value of applying ML-based DT in the process industry and sheds light on some of the challenges associated with the application of this technology.;Elsevier B.V.;Journal;Computers in Industry;2023-10-01;https://api.elsevier.com/content/abstract/scopus_id/85164238444
611;Self-Adaptive Manufacturing with Digital Twins;Digital Twins are part of the vision of Industry 4.0 to represent, control, predict, and optimize the behavior of Cyber-Physical Production Systems (CPPSs). These CPPSs are long-living complex systems deployed to and configured for diverse environments. Due to specific deployment, configuration, wear and tear, or other environmental effects, their behavior might diverge from the intended behavior over time. Properly adapting the configuration of CPPSs then relies on the expertise of human operators. Digital Twins (DTs) that reify this expertise and learn from it to address unforeseen challenges can significantly facilitate self-adaptive manufacturing where experience is very specific and, hence, insufficient to employ deep learning techniques. We leverage the explicit modeling of domain expertise through case-based reasoning to improve the capabilities of Digital Twins for adapting to such situations. To this effect, we present a modeling framework for self-adaptive manufacturing that supports modeling domain-specific cases, describing rules for case similarity and case-based reasoning within a modular Digital Twin. Automatically configuring Digital Twins based on explicitly modeled domain expertise can improve manufacturing times, reduce wastage, and, ultimately, contribute to better sustainable manufacturing.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2021 International Symposium on Software Engineering for Adaptive and Self-Managing Systems, SEAMS 2021;2021-05-01;https://api.elsevier.com/content/abstract/scopus_id/85113473628
612;Process-aware digital twin cockpit synthesis from event logs;The engineering of digital twins and their user interaction parts with explicated processes, namely process-aware digital twin cockpits (PADTCs), is challenging due to the complexity of the systems and the need for information from different disciplines within the engineering process. Therefore, it is interesting to investigate how to facilitate their engineering by using already existing data, namely event logs, and reducing the number of manual steps for their engineering. Current research lacks systematic, automated approaches to derive process-aware digital twin cockpits even though some helpful techniques already exist in the areas of process mining and software engineering. Within this paper, we present a low-code development approach that reduces the amount of hand-written code needed and uses process mining techniques to derive PADTCs. We describe what models could be derived from event log data, which generative steps are needed for the engineering of PADTCs, and how process mining could be incorporated into the resulting application. This process is evaluated using the MIMIC III dataset for the creation of a PADTC prototype for an automated hospital transportation system. This approach can be used for early prototyping of PADTCs as it needs no hand-written code in the first place, but it still allows for the iterative evolvement of the application. This empowers domain experts to create their PADTC prototypes.;Elsevier Ltd;Journal;Journal of Computer Languages;2022-06-01;https://api.elsevier.com/content/abstract/scopus_id/85131671533
613;Using UML and OCL Models to Realize High-Level Digital Twins;Digital twins constitute virtual representations of physically existing systems. However, their inherent complexity makes them difficult to develop and prove correct. In this paper we explore the use of UML and OCL, complemented with an executable language, SOIL, to build and test digital twins at a high level of abstraction. We also show how to realize the bidirectional connection between the UML models of the digital twin in the USE tool with the physical twin, using an architectural framework centered on a data lake. We have built a prototype of the framework to demonstrate our ideas, and validated it by developing a digital twin of a Lego Mindstorms car. The results allow us to show some interesting advantages of using high-level UML models to specify virtual twins, such as simulation, property checking and some other types of tests.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Companion Proceedings - 24th International Conference on Model-Driven Engineering Languages and Systems, MODELS-C 2021;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85123990225
614;Data Sovereignty and the Internet of Production;While the privacy of personal data has captured great attention in the public debate, resulting, e.g., in the European GDPR guideline, the sovereignty of knowledge-intensive small and medium enterprises concerning the usage of their own data in the presence of dominant data-hungry players in the Internet needs more investigation. In Europe, even the legal concept of data ownership is unclear. We reflect on requirements analyses, reference architectures and solution concepts pursued by the International Data Spaces Initiative to address these issues. The second part will more deeply explore our current interdisciplinary research in a visionary “Internet of Production” with 27 research groups from production and materials engineering, computer science, business and social sciences. In this setting, massive amounts of heterogeneous data must be exchanged and analyzed across organizational and disciplinary boundaries, throughout the lifecycle from (re-)engineering, to production, usage and recycling, under hard resource and time constraints. A shared metaphor, borrowed from Plato’s famous Cave Allegory, serves as the core modeling and data management approach from conceptual, logical, physical, and business perspectives.;Springer;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85086271667
615;AML4DT: A Model-Driven Framework for Developing and Maintaining Digital Twins with AutomationML;As technologies such as the Internet of Things (IoT) and Cyber-Physical Systems (CPS) are becoming ubiquitous, systems adopting these technologies are getting increasingly complex. Digital Twins (DTs) provide comprehensive views on such systems, the data they generate during runtime, as well as their usage and evolution over time. Setting up the required infrastructure to run a Digital Twin is still an ambitious task that involves significant upfront efforts from domain experts, although existing knowledge about the systems, such as engineering models, may be already available for reuse. To address this issue, we present AML4DT, a model-driven framework supporting the development and maintenance of Digital Twin infrastructures by employing AutomationML (AML) models. We automatically establish a connection between systems and their DTs based on dedicated DT models. These DT models are automatically derived from existing AutomationML models, which are produced in the engineering phases of a system. Additionally, to alleviate the maintenance of the DTs, AML4DT facilitates the synchronization of the AutomationML models with the DT infrastructure for several evolution cases. A case study shows the benefits of developing and maintaining DTs based on AutomationML models using the proposed AML4DT framework. For this particular study, the effort of performing the required tasks could be reduced by about 50%.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;IEEE International Conference on Emerging Technologies and Factory Automation, ETFA;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85122957318
616;Towards digital shadows for production planning and control in injection molding;In dynamic production environments, bringing flexibility to production planning and control (PPC) against continuously changing requirements is key to fulfill production objectives. Such environments often involve various information systems that make the integration of knowledge on the current state of production more challenging. In this paper, we present a conceptual approach of Digital Shadows that allow for a holistic data view on PPC-specific tasks based on an ontology, serving as a knowledge base of semantic-enriched data and production constraints. An exemplary real-world application for PPC in injection molding demonstrates the benefits of the concept.;Elsevier Ltd;Journal;CIRP Journal of Manufacturing Science and Technology;2022-08-01;https://api.elsevier.com/content/abstract/scopus_id/85134073675
617;The Digital Twin of a System: A Structure for Networks of Digital Twins;There is a growing interest in the concept of a Digital Twin, and more and more companies want to take advantage of the benefits and demand them on the market. As the number of Digital Twins continues to grow, however, the question arises how to deal with a multitude of Digital Twins in a factory, and especially how to integrate Digital Twins on a certain level of detail into a Digital Twin on a higher level of abstractions, and how these networks can be managed if each Digital Twin is to be considered individually. The concept presented in this paper shows a possibility to combine Digital Twins in a structured network which is controlled by one single point of truth, called the Digital Twin of a System. An exemplary application of the Digital Twin of a System is presented. Furthermore advantages of the Digital Twin of a System are introduced and discussed. Finally directions for future research on this topic are suggested.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;IEEE International Conference on Emerging Technologies and Factory Automation, ETFA;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85122939911
618;Integration Challenges for Digital Twin Systems-of-Systems;Research and industry leverage digital twins to monitor and control (cyber-physical) systems in various domains. For their efficient engineering, these twins need to become Systems-of-Systems (SoS), in which digital twins of smaller systems (e.g., a production machine) become parts of digital twins of larger systems (e.g., a factory). Yet, research on digital twins as SoS largely ignores reusing digital twins in SoS. Based on our experience in engineering digital twins with experts from various domains related to production systems engineering, we present insights on the challenges of composing and integrating that need to be addressed for efficient engineering of digital twins as SoS. These insights may guide future research on engineering digital twins as well as practitioners considering the challenges in building and composing digital twin systems-of-systems.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 10th IEEE/ACM International Workshop on Software Engineering for Systems-of-Systems and Software Ecosystems, SESoS 2022;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85135174156
619;Generating Digital Twin Cockpits for Parameter Management in the Engineering of Wind Turbines;The complexity of wind energy systems combined with an increased trend towards mass customization require the collaboration of many experts to achieve high quality products. Currently, a major issue arises from the lack of data integration among the different tools used during the engineering process which may cause system failures eventually. Existing tools largely do not support automatic detection and indication of erroneous or contradictory parameter values between artifacts of different tools. Employing a model-driven and functional engineering approach enables to establish an integrated toolchain for the management and visualization of engineering artifacts that consume and produce the data. Within this paper, we present an automatic approach to derive an engineering digital twin for the cooperative development and management of engineering artifacts from functional models of the system under development. We evaluate our approach on the example of a hydraulic pump within the cooling system of a wind turbine. The prototype can be coupled with an existing engineering tool ecosystem. The approach enables to exchange the data produced by engineering artifacts according to a functional system model which facilitates the cooperation between different stakeholders throughout the development process.;Gesellschaft fur Informatik (GI);Conference Proceeding;Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI);2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85138312179
620;Towards Development Platforms for Digital Twins: A Model-Driven Low-Code Approach;Digital Twins in smart manufacturing must be highly adaptable for different challenges, environments, and system states. In practice, there is a need for enabling the configuration of Digital Twins by domain experts. Low-code approaches seem to be a meaningful solution for configuration purposes but often lack extension options. We propose a model-driven low-code approach for the configuration and reconfiguration of Digital Twins using language plugins. This approach uses model-driven software engineering and software language engineering methods to derive a configurable digital twin implementation. Moreover, we discuss some remaining challenges such as interoperability, language modularity, evolution, integration of assistive services, collaborative development, and web-based debugging.;Springer Science and Business Media Deutschland GmbH;Book Series;IFIP Advances in Information and Communication Technology;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85115225554
621;Air Quality Management: An Exemplar for Model-Driven Digital Twin Engineering;Since its first mentioning in the literature, the concept of Digital Twin has gained traction in both industry and academia. However, there are still many open challenges when applying Digital Twins to industry-scale use cases. Applying Model-Driven Engineering techniques to the creation and maintenance of Digital Twins (also referred to as Model-Driven Digital Twin Engineering) promises automation and consistency throughout the life cycle of a Digital Twin. The exemplar provided in this paper can be used to identify open challenges when it comes to Model-Driven Digital Twin Engineering, and to demonstrate how approaches can solve them. This exemplar applies Digital Twins to an indoor air quality management use case, where CO2, temperature, and humidity values of rooms within a building are measured. These values can be used to derive actions to improve work productivity and reduce the risk for virus infections. We describe three applications that make use of this Digital Twin (i.e., runtime visualization, physical simulation, and ML-based predictions), and provide an online repository with the artefacts of this exemplar.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Companion Proceedings - 24th International Conference on Model-Driven Engineering Languages and Systems, MODELS-C 2021;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85124047367
622;A review of unit level digital twin applications in the manufacturing industry;"In recent years, the hype around Digital Twins (DTs) has been exponentially increasing in both industry and academia. DTs are a potential solution to increase automation and advance towards Smart Manufacturing. Manufacturing DTs have been implemented at different hierarchical levels, ranging from system of systems to unit level. Increasing computational capacity and data exchange rates can enable DT implementations for real-time applications. Several literature reviews on manufacturing DTs have been published. However, no previous paper focuses on manufacturing DTs at the unit level for which real-time control is most applicable. Simultaneously, the challenges to engineer DTs with real-time capabilities are enormous, both from a scientific and technological perspective. Therefore, we focus on DTs of single production units such as traditional machine tools, additive manufacturing machines and advanced robotic applications. In this systematic literature review, 96 papers about practical unit level DT applications found in the Scopus database using a combination of the keywords “Digital Twin”, “Production” and “Manufacturing” are reviewed. We summarize how DTs are currently implemented and operated, and what potential benefits DTs offer at the unit process level in four categories: generic reference models, services, DT content (models and data) and DT deployment (hardware and software). Following the thematic analysis, an overall discussion, summary of key contributions and identified research gaps, and outlook into future research avenues is given. Key findings of this review can be summarized as: focus on DT components versus being holistic; need to share data and models across multiple stakeholders; lack of physical fidelity of the models; stark contrast of lab scale developments and real world testing, e.g., historical data and storage related challenges; lack of clear definition of DT in industry, and missing semantic interoperability between a wide variety of domains.";Elsevier Ltd;Journal;CIRP Journal of Manufacturing Science and Technology;2023-10-01;https://api.elsevier.com/content/abstract/scopus_id/85164018738
623;Towards an ontology-based dictionary for production planning and control in the domain of injection molding as a basis for standardized asset administration shells;The use of digital technologies in the industrial environment enables great potential for increasing efficiency in manufacturing. One building block are production environments that plan and control their production flow autonomously and decentrally. To this end, all machines and systems (so-called “assets”) need to communicate with each other and derive suitable actions based on the exchanged information. Therefore, all assets need to be represented in the virtual world. This can be realized with digital twins. A concrete implementation of digital twins is the asset administration shell, which comprises all the assets’ properties and the endpoint of the corresponding asset, so intercommunication is possible. Here, the challenges comprise establishing a manufacturer-independent vocabulary that standardizes the assets’ properties and enabling the machines and systems to interpret this vocabulary semantically. Existing standards and information models represent only a fraction of the information requirements (i.e., terms) in this domain, making autonomous production planning and control (PPC) challenging to implement. Furthermore, the information requirements of the machines and peripheral assets as well as the corresponding information flows are insufficiently defined. Therefore, this contribution aims to build a comprehensive vocabulary for the domain of PPC, which serves as a basis for standardized asset administration shells that realize machine-to-machine communication. In particular, PPC processes concerning the injection molding domain's characteristics are considered since the interaction between the domain's assets, i.e., injection molding machines, molds, peripheral assets, raw materials, and operators, are especially complex. For this purpose, the relevant input and output information within the injection molding domain was first collected for each process step in PPC. After that, a UML class diagram was modeled under consideration of established standards. The result of this work is an ontology, which can be used as a dictionary for the PPC in the injection molding domain and as a foundation of standardized digital twins in the form of asset administration shells.;Elsevier B.V.;Journal;Journal of Industrial Information Integration;2023-10-01;https://api.elsevier.com/content/abstract/scopus_id/85164690457
624;A machine learning digital twin approach for critical process parameter prediction in a catalyst manufacturing line;Digital twins (DTs) are rapidly changing how manufacturing companies leverage the large volumes of data they generate daily to gain a competitive advantage and optimize their supply chains. When coupled with recent developments in machine learning (ML), DTs have the potential to generate invaluable insights for process manufacturing companies to help them optimize their manufacturing processes. However, this potential has yet to be fully exploited due to the challenges that process manufacturing companies face in developing and implementing DTs in their organizations. Although DTs are receiving increasing attention in both industry and academia, there is limited literature on how to apply them in the process industry. To address this gap, this paper presents a framework for developing ML-based DTs to predict critical process parameters in real time. The proposed framework is tested through a case study at an international process manufacturing company in which it was used to collect and process plant data, build accurate predictive models for two critical process parameters, and develop a DT application to visualize the models’ predictions. The case study demonstrated the usefulness of the proposed DT–ML framework in the sense that it provided the company with more accurate predictions than the models it previously applied. The study provides insights into the value of applying ML-based DT in the process industry and sheds light on some of the challenges associated with the application of this technology.;Elsevier B.V.;Journal;Computers in Industry;2023-10-01;https://api.elsevier.com/content/abstract/scopus_id/85164238444
625;Information systems engineering with Digital Shadows: Concept and use cases in the Internet of Production;Entering the second decade of the Industrie 4.0 vision, the production sector is facing challenges in taking full advantage of global digitalization. Production research has focused on sophisticated mathematical models ranging from molecular materials modeling to production control to supply chain logistics. These models help simulate and control the related physical system but the variety of individual situations and behaviors is captured only as statistical uncertainty. The emergence of data-driven methods adds statistical or AI models learned from real-time production data to Digital Twins, and ideally allows for continuous synchronization (twinning) between physical and virtual system. However, the complexity of today's production systems precludes Digital Twins covering more than just a few system perspectives, especially if realtime performance is required. To achieve better performance and more precise context adaptation, the interdisciplinary research cluster “Internet of Production” at RWTH Aachen University is exploring the concept of Digital Shadows. We conceptualize Digital Shadows as a generalization of compact views on dynamic processes, whose defining “query” combines condensed measurement data with efficient simplified mathematical models. Their small size makes Digital Shadows amenable to dynamic function allocation in hybrid cloud–edge settings. In addition to showing the similarities and differences to the traditional view concept, we also present a conceptual embedding of Digital Shadows in the context of large distributed system architectures, and sovereign data exchange in international Data Space communities. Two production use case experiences demonstrate that Digital Shadows can be valuable carriers of deep and reusable engineering knowledge for technical and ecological progress.;Elsevier Ltd;Journal;Information Systems;2023-03-01;https://api.elsevier.com/content/abstract/scopus_id/85147195669
626;A Hierarchical Domain-Specific Language for Cyber-physical Production Systems Integrating Asset Administration Shells;Due to the distributed architecture of cyber-physical production systems (CPPS), the design of automation software is difficult and error-prone. It requires process domain-specific knowledge and a service-oriented approach to be able to design a requirement-specific solution. Previous software design methods for CPPS have several drawbacks. Either these insufficiently take into account the properties of distributed systems or, in the case of Domain-Specific Languages (DSL), their focus lies on interaction logic rather than on production-specific specialties. Similarly, the possibilities for using information from the Asset Administration Shell (AAS) have so far not been integrated. Therefore, we propose a new service-oriented hierarchical DSL consisting of layers with different levels of abstraction, allowing successive and distributed software design with different degrees of detail. Hence, both process engineers and software engineers can work together during the software developing process. By incorporating information from the AAS, a static and also dynamic parameterization of the individual DSL services becomes possible. Finally, a case-study in the field of process engineering demonstrates the advantages and the applicability of the proposed approach.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;IEEE International Conference on Emerging Technologies and Factory Automation, ETFA;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85122962003
627;Extracting Functional Machine Knowledge from STEP Files for Digital Twins;The current challenges of industrial manufacturing forces producers to optimize and to digitize their facilities. The Digital Twin as a digital representation of both the product and the production is a key enabler to efficiency, flexibility, and sustainability. Unfortunately, the development of Digital Twins is sophisticated and hampered by manual tasks. This paper presents an approach to automatically create digital models of the objects which are to be represented, based on 3D CAD data. Therefore, the CAD data, which is stored as a STEP file, is analysed to extract relevant information for the following graph analysis, which is used to identify components, their dependencies and the resulting functional modules. The graph analysis results will be used in future work to implement a digital twin.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;IEEE International Conference on Emerging Technologies and Factory Automation, ETFA;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85141390550
628;Engineering Digital Twins and Digital Shadows as Key Enablers for Industry 4.0;Industry 4.0 opens up new potentials for the automation and improvement of production processes, but the associated digitization also increases the complexity of this development. Monitoring and maintenance activities in production processes still require high manual effort and are only partially automated due to immature data aggregation and analysis, resulting in expensive downtimes, inefficient use of machines, and too much production of waste. To maintain control over the growing complexity and to provide insight into the production, concepts such as Digital Twins, Digital Shadows, and modelbased systems engineering for Industry 4.0 emerge. Digital Shadows consist of data traces of an observed Cyber-Physical Production System. Digital Twins operate on Digital Shadows to enable novel analysis, monitoring, and optimization.We present a general overview of the concepts of Digital Twins, Digital Shadows, their usage and realization in Data Lakes, their development based on engineering models, and corresponding engineering challenges. This provides a foundation for implementing Digital Twins, which constitute a main driver for future innovations in Industry 4.0 digitization.;Springer Berlin Heidelberg;Book;Digital Transformation: Core Technologies and Emerging Topics from a Computer Science Perspective;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85161813629
629;Time series data for process monitoring in injection molding: A quantitative study of the benefits of a high sampling rate;Process monitoring systems are playing an increasingly important role in reducing production capacity losses in injection molding. Process monitoring and optimization systems are mostly based on processing data of injection molding machine control systems. These data consist of scalar data and time series. This paper introduces a novel approach to modelling injection molding processes using only time series data and evaluates the quantitative influences of varying sampling times on calculation of integral values and model quality. On the basis of the first experiment, it is shown that the sampling rates of these time series have a large influence on information which can be derived from this data (e.g. injection work). These findings provide an assessment of whether the effort is justified for the respective requirements on the accuracy of the injection work and other parameters derived from the time series. In the second experiment, a model is presented which uses only the injection flow and injection pressure profile as input and achieves high coefficients of determination for the prediction of the part weight, despite the absence of mold sensor data and scalar data. It is shown that higher sampling rates of time series results in higher prediction quality of these models. This improves the understanding of the data needed for high quality machine learning models of injection molding processes and enable users to estimate a lower bound for the sample rates of time series for their use cases.;Walter de Gruyter GmbH;Journal;International Polymer Processing;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85154585916
630;Digital twins for the rapid startup of manufacturing processes: a case study in PVC tube extrusion;In this work, a soft sensor–based digital twin (DT) was developed to reduce the startup time in manufacturing plastic tubes and enable real-time product quality monitoring, i.e., the weight per unit length and the inner and outer diameters of the tube. An experimental campaign was conducted on a real tube extrusion line using three polyvinyl chloride (PVC) compounds and different process conditions, and machine learning regression algorithms were trained and tested to create the models of the extruder and the extrusion die the DT is based on. The characterization of the considered material, whose properties were given as input to the digital models, was carried out according to a procedure based only on the data collected by the production line. The DT was tested for the startup of the production of a single-layer tube and allowed to achieve the specified customer requirements (thickness and weight) in a few minutes. The proposed solution thus proved to be a valuable tool for reducing the setup time, thus increasing the efficiency of the process.;Springer Science and Business Media Deutschland GmbH;Journal;International Journal of Advanced Manufacturing Technology;2023-08-01;https://api.elsevier.com/content/abstract/scopus_id/85164837924
631;Data and Model Harmonization Research Challenges in a Nation Wide Digital Twin;Nation Wide Digital Twin is an emerging paradigm that pushes the context of a classical Digital Twin to a whole country. Under this perspective, models, which are central for digital twins, will play a key role for the design and implementation of such a specific digital twin. However, to achieve a nation wide digital twin vision, a whole set of problems related to models have to be solved. In this paper, we detailed the notion of nation wide digital twin with respect to well known digital twin from a model point of view and discuss the problems the community is facing in this context. As a result, from the identified challenges, we propose a research road-map paving the way for future scientific contributions.;MDPI;Journal;Systems;2023-02-01;https://api.elsevier.com/content/abstract/scopus_id/85149235136
632;Online Prediction of Molded Part Quality in the Injection Molding Process Using High-Resolution Time Series;Process-data-supported process monitoring in injection molding plays an important role in compensating for disturbances in the process. Until now, scalar process data from machine controls have been used to predict part quality. In this paper, we investigated the feasibility of incorporating time series of sensor measurements directly as features for machine learning models, as a suitable method of improving the online prediction of part quality. We present a comparison of several state-of-the-art algorithms, using extensive and realistic data sets. Our comparison demonstrates that time series data allow significantly better predictions of part quality than scalar data alone. In future studies, and in production-use cases, such time series should be taken into account in online quality prediction for injection molding.;MDPI;Journal;Polymers;2023-02-01;https://api.elsevier.com/content/abstract/scopus_id/85149015208
633;Towards a digital twin for cyber-physical production systems: A multi-paradigm modeling approach in the postal industry;This paper presents our early-stage research on a Multi-Paradigm Modeling (MPM) approach as an initial step towards the definition of a Digital Twin (DT) for Cyber-Physical Production Systems (CPPSs). This work takes place in the context of the digitalization of the mail sorting process at La Poste, the French national postal service company. Indeed, La Poste is currently investing on robotics modules for automatically loading mail containers. The main objective is to reduce the painful work for human operators while optimizing the robots usage. We already worked on targeting such a balance in a past effort that resulted in the production of different kinds of models of the La Poste CPPS. However, these models were defined separately and are not directly related to the underlying business process in particular. Thus, we propose an MPM approach starting from this business process as now modeled explicitly in a BPMN model. Then, we refine the high-level business activities into finer-grained activities represented in a UML Activity model. From these latest, we derive the specification of a Multi-Agent System (MAS) developed with the JADE framework and emulating the behavior of the La Poste CPPS. Our longer term objective is to pave the way for supporting the definition of a DT for this CPPS, and potentially for other CPPSs in different contexts in the future.;Association for Computing Machinery, Inc;Conference Proceeding;Proceedings - 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS-C 2020 - Companion Proceedings;2020-10-16;https://api.elsevier.com/content/abstract/scopus_id/85096756100
634;A pattern catalog for augmenting Digital Twin models with behavior Ein Musterkatalog zur Erweiterung von digitalen Zwillingsmodellen um Verhaltenssichten;Digital Twins are emerging as a solution to build and extend existing software systems to make better use of data produced by physical systems. For supporting the development of Digital Twins, several software vendors are offering dedicated tool support, often referred to as Digital Twin platforms. The modeling capabilities of these platforms are mostly concerned with structural viewpoints, i.e., providing an overview of available components including their current and historical sensor values. However, behavioral viewpoints did not yet receive much attention on these platforms. As behavioral models are often used during the design processes, e.g., for simulation and synthesis, it would be beneficial for having them included in Digital Twin platforms, e.g., for reasoning on the set of possible next actions or for checking the execution history to perform runtime validation. In this paper, we present a catalog of modeling patterns for augmenting Digital Twin models with behavioral models and their corresponding runtime information without requiring any extension of the code bases of Digital Twin platforms. We demonstrate the presented modeling patterns by applying them to the Digital Twin platform offered by Microsoft, in an additive manufacturing use case of a 3D printer in a production line.;De Gruyter Oldenbourg;Journal;At-Automatisierungstechnik;2023-06-01;https://api.elsevier.com/content/abstract/scopus_id/85161546216
635;Towards a Product Line Architecture for Digital Twins;Digital twins are a new kind of software systems for which corresponding architectures in different engineering domains have emerged for enabling the efficient interaction of software systems with physical systems to realize cyber-physical systems (CPS). To facilitate the development of digital twins, various software platforms emerged in recent years, which often come with a certain architecture for the developed systems together with a set of domain-specific languages (DSLs) that help domain experts to configure the platform and implement the digital twins. This results in a set of architectures and DSLs which are currently used to realize the various concerns of digital twins. Thus, creating a comprehensive digital twin for a given system requires the combination of several architectures and DSLs, which is challenging as (i) the components of the different architectures have to be combined on a technological level, and (ii) the concerns specified with the different DSLs are developed in isolation which potentially leads to inconsistencies, especially during the evolution of digital twins.To tackle these challenges, we outline our vision of a product line architecture that explicitly specifies the different concerns of digital twins and their alignment on both, the technological level considering the different architectural elements as well as on the language level considering the different language elements. As a result, glue code that is currently required to compose the individual features together into particular digital twin systems is automatically generated. We demonstrate the applicability of this approach by (i) specifying an example product line architecture for selected structural and behavioral concerns of digital twins, and (ii) configuring an existing digital twin based architecture for self-adaptive systems based on this product line architecture by (iii) applying the selected platforms realizing these concerns to a smart room use case. Finally, we discuss expected benefits of the presented approach, such as plug-&-play of digital twin modules, as well as sketch out future work to realize the presented vision.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - IEEE 20th International Conference on Software Architecture Companion, ICSA-C 2023;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85159120968
636;Automatic Test Suite Generation for PLC Software in the Internet of Production;Automatic test suite generation is an established technique used to generate test suites adhering to structural coverage metrics of PLC software. In order to reduce redundancy in the test suite generation after a structural reconfiguration to the PLC software has occurred, reusable summaries of program parts should be employed. This paper presents a combination of state-of-the-art symbolic execution and static analysis algorithms for test suite generation and summary reuse. The general rationale is to improve efficiency by not doing redundant work. For this purpose, summaries of function blocks are cached and reused to benefit from the previous analysis. As code untouched from reconfigurations will result in equivalent path conditions summaries can aid in speeding up regression testing. The proto-typical implementations of several techniques are evaluated and compared using selected domain-specific benchmarks showing the ineffectiveness of using summarization during test suite generation for reconfigurable logic control software.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;IEEE International Conference on Emerging Technologies and Factory Automation, ETFA;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85141355319
637;Building Digital Shadows for Production Control;Digital Shadows can support stakeholders in production control by providing context-aware and aggregated information serving a specific task and thus supporting in the decision-making. In this paper, we propose a methodology for building Digital Shadows with focus on production control. We identify the building blocks for defining Digital Shadows consisting of purpose, models and data. Furthermore, we suggest an implementation for the methodology as a decision support tool for the stakeholders in production control. Finally, we illustrate the use of our methodology on the basis of a exemplary use-case of production control.;Springer Science and Business Media Deutschland GmbH;Book Series;IFIP Advances in Information and Communication Technology;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85140463916
638;Designing Secure and Privacy-Preserving Information Systems for Industry Benchmarking;Benchmarking is an essential tool for industrial organizations to identify potentials that allows them to improve their competitive position through operational and strategic means. However, the handling of sensitive information, in terms of (i) internal company data and (ii) the underlying algorithm to compute the benchmark, demands strict (technical) confidentiality guarantees—an aspect that existing approaches fail to address adequately. Still, advances in private computing provide us with building blocks to reliably secure even complex computations and their inputs, as present in industry benchmarks. In this paper, we thus compare two promising and fundamentally different concepts (hardware- and software-based) to realize privacy-preserving benchmarks. Thereby, we provide detailed insights into the concept-specific benefits. Our evaluation of two real-world use cases from different industries underlines that realizing and deploying secure information systems for industry benchmarking is possible with today’s building blocks from private computing.;Springer Science and Business Media Deutschland GmbH;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85163976802
639;Investigation of Warpage and Tolerances in Injection Moulding Components Based on Simulation and Experimental Validation;This paper presents a systematic approach to model and simulate the influence that the variation of process parameters has on the final quality of an injection moulded component. In the first phase, we define a multi-steps procedure to develop a reliable digital model of the injection moulding process by the fine-tuning of the part cavity and the mould elements (e.g. detail simplification, discretization and mesh density, elements modelling, etc.) using real data as validation. In the second phase, we investigate the correlation between selected process parameters and the final tolerances of the moulded component, based on a Design of Experiments. As a case study, we selected the body of a mass airflow sensor for an automotive high performance engines, made of polybutylene terephthalate reinforced with glass-fibre, which presents roundness issues on functional features. The effects of the injection velocity and packing pressure on the deformation of the component are investigated, identifying the best combination of their values that leads to compliance with the roundness tolerances on its functional features. The injection moulding Computer Aided Engineering (CAE) software Moldex3D (CoreTech) is used to run the simulations, and the results are finally validated by comparing the experimental data obtained from the injection moulding machine that produces the component.;Springer Science and Business Media Deutschland GmbH;Book Series;Lecture Notes in Mechanical Engineering;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85121815134
640;Corrigendum to: ORYX-MRSI : A fully-automated open-source software for proton magnetic resonance spectroscopic imaging data analysis (International Journal of Imaging Systems and Technology, (2022), 32, 4, (1068-1083), 10.1002/ima.22748);We regret to report a technical error in our manuscript entitled ‘ORYX-MRSI: A fully-automated open-source software for proton magnetic resonance spectroscopic imaging data analysis’. The volume of interest (VOI) for all the MR spectroscopic metabolites, other than the reference metabolite, are shifted in space by their respective chemical shift amounts as calculated by Equation 2 due to the chemical shift error. Even though there is a shift in the VOIs of different metabolites, it was incorrect to shift the metabolite maps along with their corresponding VOIs. This technical error has been corrected in the Oryx-MRSI source code, which has been updated on our laboratory's GitHub page. Currently, if the chemical shift correction is set to ‘on’, the corresponding VOIs for the metabolites are shifted in space by their respective chemical shift amounts, and the metabolite intensities are evaluated at their respective locations. Additionally, the metabolite ratios are evaluated only in the region that is located at the intersection of the corresponding metabolite VOIs. Moreover, the tissue fractions are calculated only once at the reference VOI. As a result, Figure 5 is not accurate after correction and hence should not be considered for further discussion. The authors thank Wolfgang Bogner, Ph.D. and Gilbert Hangel, Ph.D. for their careful reviews of the published manuscript and apologize for this error.;John Wiley and Sons Inc;Journal;International Journal of Imaging Systems and Technology;2023-03-01;https://api.elsevier.com/content/abstract/scopus_id/85149190357
641;Measuring the fidelity of digital twin systems;A digital twin is a virtual replica of a system at a certain level of fidelity, synchronized at a specific frequency. Digital twins often replicate physical systems whose simulations are usually computationally costly. One of the solutions to this problem proposed in the literature is to define a hierarchy of multi-fidelity digital twins, where we use one twin or another depending on the specific purpose. However, one of the challenges of this proposal is the need to determine whether the different twins are equivalent to each other and the physical system. In this thesis, we explore different methods to measure this equivalence by analyzing the state and behavior of the twins with the aid of high-level software models.;Association for Computing Machinery, Inc;Conference Proceeding;Proceedings - ACM/IEEE 25th International Conference on Model Driven Engineering Languages and Systems, MODELS 2022: Companion Proceedings;2022-10-23;https://api.elsevier.com/content/abstract/scopus_id/85142936449
642;A pattern catalog for augmenting Digital Twin models with behavior Ein Musterkatalog zur Erweiterung von digitalen Zwillingsmodellen um Verhaltenssichten;Digital Twins are emerging as a solution to build and extend existing software systems to make better use of data produced by physical systems. For supporting the development of Digital Twins, several software vendors are offering dedicated tool support, often referred to as Digital Twin platforms. The modeling capabilities of these platforms are mostly concerned with structural viewpoints, i.e., providing an overview of available components including their current and historical sensor values. However, behavioral viewpoints did not yet receive much attention on these platforms. As behavioral models are often used during the design processes, e.g., for simulation and synthesis, it would be beneficial for having them included in Digital Twin platforms, e.g., for reasoning on the set of possible next actions or for checking the execution history to perform runtime validation. In this paper, we present a catalog of modeling patterns for augmenting Digital Twin models with behavioral models and their corresponding runtime information without requiring any extension of the code bases of Digital Twin platforms. We demonstrate the presented modeling patterns by applying them to the Digital Twin platform offered by Microsoft, in an additive manufacturing use case of a 3D printer in a production line.;De Gruyter Oldenbourg;Journal;At-Automatisierungstechnik;2023-06-01;https://api.elsevier.com/content/abstract/scopus_id/85161546216
643;Case study on automated and continuous reliability assessment of software-defined manufacturing based on digital twins;Traditional production systems are characterized by rare software updates and fixed production lines. Each production unit is designed and programmed for a specific task. Therefore, the reliability assessment is conducted once before the operation, mostly manually, and is based on traditional reliability models, such as event trees, fault trees, or reliability block diagrams. In comparison to traditional production systems, the focus of modern, complex production systems is shifted towards the software part. This is emphasized by the concepts of digital twins and Software-Defined Manufacturing (SDM). These software-intensive and safety-critical systems have more frequent software updates to address higher system flexibility and adjustable production processes. Therefore, SDM systems require a new approach to reliability assessment. Each software update can change the system behavior significantly. This leads to the necessity to reconduct the reliability assessment automatically before each software update. Advanced and hybrid reliability models are the key enabling technology. These models must be automatically generated and synchronized with the available system models and digital twins. Model-To-Model (M2M) transformation methods are another enabling technology. In this paper, we present a case study on automated and continuous reliability assessment of SDM. It shows, that our new method is a suitable candidate to enable the reliability assessment of SDM based on digital twins. The method includes (i) the extension of SysML v2 for reliability assessment, (ii) the automatic generation of hybrid reliability models from the digital twin, and (iii) their reliability assessment with new solvers developed for our OpenPRA framework.;Association for Computing Machinery, Inc;Conference Proceeding;Proceedings - ACM/IEEE 25th International Conference on Model Driven Engineering Languages and Systems, MODELS 2022: Companion Proceedings;2022-10-23;https://api.elsevier.com/content/abstract/scopus_id/85142927244
644;A Community-sourced view on engineering digital twins: A report from the edt community;Digital Twins are an important concept, enabling what-if scenario exploration, predictive maintenance, and other approaches. They help in saving time and physical resources when developing and evolving systems, whether natural or engineered. However, constructing and maintaining digital twins is a challenging engineering task-and, to date, there is a lack of understanding of the engineering techniques and methodologies required. To address these challenges, we created EDT.Community, a programme of seminars on the engineering of digital twins hosting digital twins experts from academia and industry. In this paper, we report on the main topics of discussion from the first year of the programme. We contribute by providing (1) a common understanding of open challenges in research and practice of the engineering of digital twins, and (2) an entry point to researchers who aim to close gaps in the current state of the art.;Association for Computing Machinery, Inc;Conference Proceeding;Proceedings - ACM/IEEE 25th International Conference on Model Driven Engineering Languages and Systems, MODELS 2022: Companion Proceedings;2022-10-23;https://api.elsevier.com/content/abstract/scopus_id/85142928470
645;A Conceptual Model for Digital Shadows in Industry and Its Application;Smart manufacturing demands to process data in domain-specific real-time. Engineering models created for constructing, commissioning, planning, or simulating manufacturing systems can facilitate aggregating and abstracting the wealth of manufacturing data to faster processable data structures for more timely decision making. Current research lacks conceptual foundations for how data and engineering models can be exploited in an integrated way to achieve this. Such research demands expertise from different smart manufacturing domains to harmonize the notion space. We propose a conceptual model to describe digital shadows, data structures tailored to exploit models and data in smart manufacturing, through a metamodel and its notion space. This conceptual model was established through interdisciplinary research in the German excellence cluster “Internet of Production” and evaluated in various real-world manufacturing scenarios. This foundation for an understanding helps to manage complexity, automated analyses, and syntheses, and, ultimately, facilitates cross-domain collaboration.;Springer Science and Business Media Deutschland GmbH;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85118142665
646;A Computer Science Perspective on Digital Transformation in Production;"The Industrial Internet-of-Things (IIoT) promises significant improvements for the manufacturing industry by facilitating the integration of manufacturing systems by Digital Twins. However, ecological and economic demands also require a cross-domain linkage of multiple scientific perspectives from material sciences, engineering, operations, business, and ergonomics, as optimization opportunities can be derived from any of these perspectives. To extend the IIoT to a true Internet of Production, two concepts are required: first, a complex, interrelated network of Digital Shadows which combine domain-specific models with data-driven AI methods; and second, the integration of a large number of research labs, engineering, and production sites as a World Wide Lab which offers controlled exchange of selected, innovation-relevant data even across company boundaries. In this article, we define the underlying Computer Science challenges implied by these novel concepts in four layers: Smart human interfaces provide access to information that has been generated by model-integrated AI. Given the large variety of manufacturing data, new data modeling techniques should enable efficient management of Digital Shadows, which is supported by an interconnected infrastructure. Based on a detailed analysis of these challenges, we derive a systematized research roadmap to make the vision of the Internet of Production a reality.";Association for Computing Machinery;Journal;ACM Transactions on Internet of Things;2022-05-01;https://api.elsevier.com/content/abstract/scopus_id/85121783951
647;Generating customized low-code development platforms for digital twins;A digital twin improves our use of a cyber–physical system and understanding of its emerging behavior. To this effect, a digital twin is to be developed and configured and potentially also operated by domain experts, who rarely have a professional software engineering background and for whom easy access and support, e.g., in form of low-code platforms are missing. In this paper, we report on an integrated method for the model-driven engineering of low-code development platforms for digital twins that enables domain experts to create and operate digital twins for cyber–physical systems using the most appropriate modeling languages. The foundation of this method is (1) a code generation infrastructure for information systems combined with (2) an extensible base architecture for self-adaptive digital twins and (3) reusable language components for their configuration. Using this method, software engineers first configure the information system with the required modeling languages to generate the low-code development platform for digital twins before domain experts leverage the generated platform to create digital twins. This two-step method facilitates creating tailored low-code development platforms as well as creating and operating customized digital twins for a variety of applications.;Elsevier Ltd;Journal;Journal of Computer Languages;2022-06-01;https://api.elsevier.com/content/abstract/scopus_id/85129984615
648;Self-Adaptive Manufacturing with Digital Twins;Digital Twins are part of the vision of Industry 4.0 to represent, control, predict, and optimize the behavior of Cyber-Physical Production Systems (CPPSs). These CPPSs are long-living complex systems deployed to and configured for diverse environments. Due to specific deployment, configuration, wear and tear, or other environmental effects, their behavior might diverge from the intended behavior over time. Properly adapting the configuration of CPPSs then relies on the expertise of human operators. Digital Twins (DTs) that reify this expertise and learn from it to address unforeseen challenges can significantly facilitate self-adaptive manufacturing where experience is very specific and, hence, insufficient to employ deep learning techniques. We leverage the explicit modeling of domain expertise through case-based reasoning to improve the capabilities of Digital Twins for adapting to such situations. To this effect, we present a modeling framework for self-adaptive manufacturing that supports modeling domain-specific cases, describing rules for case similarity and case-based reasoning within a modular Digital Twin. Automatically configuring Digital Twins based on explicitly modeled domain expertise can improve manufacturing times, reduce wastage, and, ultimately, contribute to better sustainable manufacturing.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2021 International Symposium on Software Engineering for Adaptive and Self-Managing Systems, SEAMS 2021;2021-05-01;https://api.elsevier.com/content/abstract/scopus_id/85113473628
649;Using UML and OCL Models to Realize High-Level Digital Twins;Digital twins constitute virtual representations of physically existing systems. However, their inherent complexity makes them difficult to develop and prove correct. In this paper we explore the use of UML and OCL, complemented with an executable language, SOIL, to build and test digital twins at a high level of abstraction. We also show how to realize the bidirectional connection between the UML models of the digital twin in the USE tool with the physical twin, using an architectural framework centered on a data lake. We have built a prototype of the framework to demonstrate our ideas, and validated it by developing a digital twin of a Lego Mindstorms car. The results allow us to show some interesting advantages of using high-level UML models to specify virtual twins, such as simulation, property checking and some other types of tests.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Companion Proceedings - 24th International Conference on Model-Driven Engineering Languages and Systems, MODELS-C 2021;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85123990225
650;AML4DT: A Model-Driven Framework for Developing and Maintaining Digital Twins with AutomationML;As technologies such as the Internet of Things (IoT) and Cyber-Physical Systems (CPS) are becoming ubiquitous, systems adopting these technologies are getting increasingly complex. Digital Twins (DTs) provide comprehensive views on such systems, the data they generate during runtime, as well as their usage and evolution over time. Setting up the required infrastructure to run a Digital Twin is still an ambitious task that involves significant upfront efforts from domain experts, although existing knowledge about the systems, such as engineering models, may be already available for reuse. To address this issue, we present AML4DT, a model-driven framework supporting the development and maintenance of Digital Twin infrastructures by employing AutomationML (AML) models. We automatically establish a connection between systems and their DTs based on dedicated DT models. These DT models are automatically derived from existing AutomationML models, which are produced in the engineering phases of a system. Additionally, to alleviate the maintenance of the DTs, AML4DT facilitates the synchronization of the AutomationML models with the DT infrastructure for several evolution cases. A case study shows the benefits of developing and maintaining DTs based on AutomationML models using the proposed AML4DT framework. For this particular study, the effort of performing the required tasks could be reduced by about 50%.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;IEEE International Conference on Emerging Technologies and Factory Automation, ETFA;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85122957318
651;Towards Development Platforms for Digital Twins: A Model-Driven Low-Code Approach;Digital Twins in smart manufacturing must be highly adaptable for different challenges, environments, and system states. In practice, there is a need for enabling the configuration of Digital Twins by domain experts. Low-code approaches seem to be a meaningful solution for configuration purposes but often lack extension options. We propose a model-driven low-code approach for the configuration and reconfiguration of Digital Twins using language plugins. This approach uses model-driven software engineering and software language engineering methods to derive a configurable digital twin implementation. Moreover, we discuss some remaining challenges such as interoperability, language modularity, evolution, integration of assistive services, collaborative development, and web-based debugging.;Springer Science and Business Media Deutschland GmbH;Book Series;IFIP Advances in Information and Communication Technology;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85115225554
652;Air Quality Management: An Exemplar for Model-Driven Digital Twin Engineering;Since its first mentioning in the literature, the concept of Digital Twin has gained traction in both industry and academia. However, there are still many open challenges when applying Digital Twins to industry-scale use cases. Applying Model-Driven Engineering techniques to the creation and maintenance of Digital Twins (also referred to as Model-Driven Digital Twin Engineering) promises automation and consistency throughout the life cycle of a Digital Twin. The exemplar provided in this paper can be used to identify open challenges when it comes to Model-Driven Digital Twin Engineering, and to demonstrate how approaches can solve them. This exemplar applies Digital Twins to an indoor air quality management use case, where CO2, temperature, and humidity values of rooms within a building are measured. These values can be used to derive actions to improve work productivity and reduce the risk for virus infections. We describe three applications that make use of this Digital Twin (i.e., runtime visualization, physical simulation, and ML-based predictions), and provide an online repository with the artefacts of this exemplar.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Companion Proceedings - 24th International Conference on Model-Driven Engineering Languages and Systems, MODELS-C 2021;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85124047367
653;Data and Model Harmonization Research Challenges in a Nation Wide Digital Twin;Nation Wide Digital Twin is an emerging paradigm that pushes the context of a classical Digital Twin to a whole country. Under this perspective, models, which are central for digital twins, will play a key role for the design and implementation of such a specific digital twin. However, to achieve a nation wide digital twin vision, a whole set of problems related to models have to be solved. In this paper, we detailed the notion of nation wide digital twin with respect to well known digital twin from a model point of view and discuss the problems the community is facing in this context. As a result, from the identified challenges, we propose a research road-map paving the way for future scientific contributions.;MDPI;Journal;Systems;2023-02-01;https://api.elsevier.com/content/abstract/scopus_id/85149235136
654;A pattern catalog for augmenting Digital Twin models with behavior Ein Musterkatalog zur Erweiterung von digitalen Zwillingsmodellen um Verhaltenssichten;Digital Twins are emerging as a solution to build and extend existing software systems to make better use of data produced by physical systems. For supporting the development of Digital Twins, several software vendors are offering dedicated tool support, often referred to as Digital Twin platforms. The modeling capabilities of these platforms are mostly concerned with structural viewpoints, i.e., providing an overview of available components including their current and historical sensor values. However, behavioral viewpoints did not yet receive much attention on these platforms. As behavioral models are often used during the design processes, e.g., for simulation and synthesis, it would be beneficial for having them included in Digital Twin platforms, e.g., for reasoning on the set of possible next actions or for checking the execution history to perform runtime validation. In this paper, we present a catalog of modeling patterns for augmenting Digital Twin models with behavioral models and their corresponding runtime information without requiring any extension of the code bases of Digital Twin platforms. We demonstrate the presented modeling patterns by applying them to the Digital Twin platform offered by Microsoft, in an additive manufacturing use case of a 3D printer in a production line.;De Gruyter Oldenbourg;Journal;At-Automatisierungstechnik;2023-06-01;https://api.elsevier.com/content/abstract/scopus_id/85161546216
655;Measuring the fidelity of digital twin systems;A digital twin is a virtual replica of a system at a certain level of fidelity, synchronized at a specific frequency. Digital twins often replicate physical systems whose simulations are usually computationally costly. One of the solutions to this problem proposed in the literature is to define a hierarchy of multi-fidelity digital twins, where we use one twin or another depending on the specific purpose. However, one of the challenges of this proposal is the need to determine whether the different twins are equivalent to each other and the physical system. In this thesis, we explore different methods to measure this equivalence by analyzing the state and behavior of the twins with the aid of high-level software models.;Association for Computing Machinery, Inc;Conference Proceeding;Proceedings - ACM/IEEE 25th International Conference on Model Driven Engineering Languages and Systems, MODELS 2022: Companion Proceedings;2022-10-23;https://api.elsevier.com/content/abstract/scopus_id/85142936449
656;A pattern catalog for augmenting Digital Twin models with behavior Ein Musterkatalog zur Erweiterung von digitalen Zwillingsmodellen um Verhaltenssichten;Digital Twins are emerging as a solution to build and extend existing software systems to make better use of data produced by physical systems. For supporting the development of Digital Twins, several software vendors are offering dedicated tool support, often referred to as Digital Twin platforms. The modeling capabilities of these platforms are mostly concerned with structural viewpoints, i.e., providing an overview of available components including their current and historical sensor values. However, behavioral viewpoints did not yet receive much attention on these platforms. As behavioral models are often used during the design processes, e.g., for simulation and synthesis, it would be beneficial for having them included in Digital Twin platforms, e.g., for reasoning on the set of possible next actions or for checking the execution history to perform runtime validation. In this paper, we present a catalog of modeling patterns for augmenting Digital Twin models with behavioral models and their corresponding runtime information without requiring any extension of the code bases of Digital Twin platforms. We demonstrate the presented modeling patterns by applying them to the Digital Twin platform offered by Microsoft, in an additive manufacturing use case of a 3D printer in a production line.;De Gruyter Oldenbourg;Journal;At-Automatisierungstechnik;2023-06-01;https://api.elsevier.com/content/abstract/scopus_id/85161546216
657;Case study on automated and continuous reliability assessment of software-defined manufacturing based on digital twins;Traditional production systems are characterized by rare software updates and fixed production lines. Each production unit is designed and programmed for a specific task. Therefore, the reliability assessment is conducted once before the operation, mostly manually, and is based on traditional reliability models, such as event trees, fault trees, or reliability block diagrams. In comparison to traditional production systems, the focus of modern, complex production systems is shifted towards the software part. This is emphasized by the concepts of digital twins and Software-Defined Manufacturing (SDM). These software-intensive and safety-critical systems have more frequent software updates to address higher system flexibility and adjustable production processes. Therefore, SDM systems require a new approach to reliability assessment. Each software update can change the system behavior significantly. This leads to the necessity to reconduct the reliability assessment automatically before each software update. Advanced and hybrid reliability models are the key enabling technology. These models must be automatically generated and synchronized with the available system models and digital twins. Model-To-Model (M2M) transformation methods are another enabling technology. In this paper, we present a case study on automated and continuous reliability assessment of SDM. It shows, that our new method is a suitable candidate to enable the reliability assessment of SDM based on digital twins. The method includes (i) the extension of SysML v2 for reliability assessment, (ii) the automatic generation of hybrid reliability models from the digital twin, and (iii) their reliability assessment with new solvers developed for our OpenPRA framework.;Association for Computing Machinery, Inc;Conference Proceeding;Proceedings - ACM/IEEE 25th International Conference on Model Driven Engineering Languages and Systems, MODELS 2022: Companion Proceedings;2022-10-23;https://api.elsevier.com/content/abstract/scopus_id/85142927244
658;Integrating process management and event processing in smart factories: A systems architecture and use cases;The developments of new concepts for an increased digitization of manufacturing industries in the context of Industry 4.0 have brought about novel system architectures and frameworks for smart production systems. These range from generic frameworks for Industry 4.0 to domain-specific architectures for Industrial Internet of Things (IIoT). While most of the approaches include a service-based architecture for selective integration with enterprise systems, a close two-way integration of the production control systems and IIoT sensors and actuators with Process-Aware Information Systems (PAIS) on the management level for automation and mining of production processes is rarely discussed. This fusion of Business Process Management (BPM) with IIoT can be mutually beneficial for both research areas, but is still in its infancy. We propose a systems architecture for IIoT that shows how to integrate the low-level hardware components–sensors and actuators–of a smart factory with BPM systems. We discuss the software components and their interactions to address challenges of device encapsulation, integration of sensor events, and interaction with existing BPM systems. This integration is demonstrated within several use cases regarding process modeling, automation and mining for a smart factory model, showing benefits of using BPM technologies to analyze, control, and adapt discrete production processes in IIoT.;Elsevier B.V.;Journal;Journal of Manufacturing Systems;2022-04-01;https://api.elsevier.com/content/abstract/scopus_id/85131145401
659;A Holistic Overview of the Internet of Things Ecosystem;The Internet of Things (IoT) is a complex ecosystem of connected devices that exchange data over a wired or wireless network and whose final aim is to provide services either to humans or machines. The IoT has seen rapid development over the past decade. The total number of installed connected devices is expected to grow exponentially in the near future, since more and more domains are looking for IoT solutions. As a consequence, an increasing number of developers are approaching IoT technology for the first time. Unfortunately, the number of IoT-related studies published every year is becoming huge, with the obvious consequence that it would be impossible for anyone to predict the time that could be necessary to find a paper talking about a given problem at hand. This is the reason why IoT-related discussions have become predominant in various practitioners’ forums, which moderate thousands of posts each month. The present paper’s contribution is twofold. First, it aims at providing a holistic overview of the heterogeneous IoT world by taking into account a technology perspective and a business perspective. For each topic taken into account, a tutorial introduction (deliberately devoid of technical content to make this document within the reach of non-technical readers as well) is provided. Then, a table of very recent review papers is given for each topic, as the result of a systematic mapping study.;MDPI;Journal;IoT;2022-12-01;https://api.elsevier.com/content/abstract/scopus_id/85149171845
660;MontiThings: Model-Driven Development and Deployment of Reliable IoT Applications;Internet of Things (IoT) applications are exposed to harsh conditions due to factors such as device failure, network problems, or implausible sensor values. We investigate how the inherent encapsulation of component and connector (C&C) architectures can be used to develop and deploy reliable IoT applications. Existing C&C languages for the development of IoT applications mainly focus on the description of architectures and the distribution of components to IoT devices. Furthermore, related approaches often pollute the models with low-level implementation details, tying the models to a particular platform and making them harder to understand. In this paper, we introduce MontiThings, a C&C language offering automatic error handling capabilities and a clear separation between business logic and implementation details. The error-handling methods presented in this paper can make C&C-based IoT applications more reliable without cluttering the business logic with error-handling code that is time-consuming to develop and makes the models hard to understand, especially for non-experts.;Elsevier Inc.;Journal;Journal of Systems and Software;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85116410296
661;Digital Twin Platforms: Requirements, Capabilities, and Future Prospects;Digital twins (DTs) have emerged as a paradigm for the virtual representation of complex systems alongside their underlying hardware. We investigate the benefits of Amazon, Eclipse, and Microsoft DT platforms and assess the extent to which they meet standard requirements.;IEEE Computer Society;Journal;IEEE Software;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85121363965
662;The OMiLAB Digital Innovation environment: Agile conceptual models to bridge business value with Digital and Physical Twins for Product-Service Systems development;OMiLAB is a community of practice which offers a digital ecosystem bringing together open technologies to investigate and apply conceptual modeling methods for varying purposes and domains. One of the core value propositions is a dedicated Digital Innovation environment comprising several toolkits and workspaces, designed to support Product-Service Systems (PSS) prototyping – a key ingredient for PSS lifecycle management. At the core of this environment is a notion of Agile Digital Twin – a conceptual representation that can be tailored with knowledge engineering means to bridge the semantic and functional gap between a business perspective (focusing on value creation) and an engineering perspective (focusing on cyber-physical proofs-of-concept). To facilitate this bridging, the hereby proposed environment orchestrates, across three abstraction layers, methods such as Design Thinking, Agile Modeling Method Engineering and Model-driven Engineering to turn Ideation into smart Product-Service Systems experiments, in a laboratory setting. The proposed environment was built following Design Science principles. It addresses the problem of historically-disconnected skills required for Digital Innovation projects and it provides a testbed for feasibility experimentation. For design-oriented, artifact building research, a higher Technology Readiness Level can thus be achieved (compared to the level that idea development methods typically attain).;Elsevier B.V.;Journal;Computers in Industry;2022-06-01;https://api.elsevier.com/content/abstract/scopus_id/85125407746
663;Model-driven Self-adaptive Deployment of Internet of Things Applications with Automated Modification Proposals;Today's Internet of Things (IoT) applications are mostly developed as a bundle of hardware and associated software. Future cross-manufacturer app stores for IoT applications will require that the strong coupling of hardware and software is loosened. In the resulting IoT applications, a quintessential challenge is the effective and efficient deployment of IoT software components across variable networks of heterogeneous devices. Current research focuses on computing whether deployment requirements fit the intended target devices instead of assisting users in successfully deploying IoT applications by suggesting deployment requirement relaxations or hardware alternatives. This can make successfully deploying large-scale IoT applications a costly trial-and-error endeavor. To mitigate this, we have devised a method for providing such deployment suggestions based on search and backtracking. This can make deploying IoT applications more effective and more efficient, which, ultimately, eases reducing the complexity of deploying the software surrounding us.;Association for Computing Machinery;Journal;ACM Transactions on Internet of Things;2022-09-06;https://api.elsevier.com/content/abstract/scopus_id/85141044295
664;An Interactive Method for Detection of Process Activity Executions from IoT Data †;The increasing number of IoT devices equipped with sensors and actuators pervading every domain of everyday life allows for improved automated monitoring and analysis of processes executed in IoT-enabled environments. While sophisticated analysis methods exist to detect specific types of activities from low-level IoT data, a general approach for detecting activity executions that are part of more complex business processes does not exist. Moreover, dedicated information systems to orchestrate or monitor process executions are not available in typical IoT environments. As a consequence, the large corpus of existing process analysis and mining techniques to check and improve process executions cannot be applied. In this work, we develop an interactive method guiding the analysis of low-level IoT data with the goal of detecting higher-level process activity executions. The method is derived following the exploratory data analysis of an IoT data set from a smart factory. We propose analysis steps, sensor-actuator-activity patterns, and the novel concept of activity signatures that are applicable in many IoT domains. The method shows to be valuable for the early stages of IoT data analyses to build a ground truth based on domain knowledge and decisions of the process analyst, which can be used for automated activity detection in later stages.;MDPI;Journal;Future Internet;2023-02-01;https://api.elsevier.com/content/abstract/scopus_id/85148896026
665;Understanding and improving model-driven IoT systems through accompanying digital twins;Developers questioning why their system behaves differently than expected often have to rely on time-consuming and error-prone manual analysis of log files. Understanding the behavior of Internet of Things (IoT) applications is a challenging task because they are not only inherently hard-to-trace distributed systems, but their integration with the environment via sensors adds another layer of complexity. Related work proposes to record data during the execution of the system, which can later be replayed to analyze the system. We apply the model-driven development approach to this idea and leverage digital twins to collect the required data. We enable developers to replay and analyze the system's executions by applying model-to-model transformations. These transformations instrument component and connector (C&C) architecture models with components that reproduce the system's environment based on the data recorded by the system's digital twin. We validate and evaluate the feasibility of our approach using a heating, ventilation, and air conditioning (HVAC) case study. By facilitating the reproduction of the system's behavior, our method lowers the barrier to understanding the behavior of model-driven IoT systems.;Association for Computing Machinery, Inc;Conference Proceeding;GPCE 2021 - Proceedings of the 20th ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences, co-located with SPLASH 2021;2021-10-17;https://api.elsevier.com/content/abstract/scopus_id/85120898349
666;Towards a Model-Integrated Runtime Monitoring Infrastructure for Cyber-Physical Systems;Runtime monitoring is essential for ensuring the safe operation and enabling self-adaptive behavior of Cyber-Physical Systems (CPS). It requires the creation of system monitors, instrumentation for data collection, and the definition of constraints. All of these aspects need to evolve to accommodate changes in the system. However, most existing approaches lack support for the automated generation and setup of monitors and constraints for diverse technologies and do not provide adequate support for evolving the monitoring infrastructure. Without this support, constraints and monitors can become stale and become less effective in long-running, rapidly changing CPS. In this 'new and emerging results' paper we propose a novel framework for model-integrated runtime monitoring. We combine model-driven techniques and runtime monitoring to automatically generate large parts of the monitoring framework and to reduce the maintenance effort necessary when parts of the monitored system change. We build a prototype and evaluate our approach against a system for controlling the flights of unmanned aerial vehicles.;IEEE Computer Society;Conference Proceeding;Proceedings - International Conference on Software Engineering;2021-05-01;https://api.elsevier.com/content/abstract/scopus_id/85115603171
667;Modeling Objects with Uncertain Behaviors;Modeling the behavior of complex systems that operate in real environments, deal with physical elements, or interact with humans is a challenging task. It involves the explicit representation of aspects of behavioral uncertainty that are inherent in the system, but generally neglected in software models. In this paper, we focus on the explicit representation of the behavior of objects of complex systems, considering their motivations, randomness, and the different types of underlying uncertainty that affect their actions. We show how such uncertain behaviors can be effectively modeled in UML and OCL, and how the specifications produced can be used to simulate and analyze these systems.;Association Internationale pour les Technologies Objets;Journal;Journal of Object Technology;2021-06-01;https://api.elsevier.com/content/abstract/scopus_id/85109427167
668;Towards a Digital Twin Modelling Notation;Digital Twins (DTs) constitute a growing and promising trend recognised by academia and industry. They are virtual replicas of distinctive objects, processes, buildings, or humans. DTs are used to reason about their physical counterparts' functionalities, interactions, behaviours, and overall to plan optimal actions that they can perform or be subjected to. Given their intrinsic complexity, no standard definition nor a unified solution is yet available for designing and developing DTs. Intending to shed light on such a complex topic, we analysed the literature and derived a list of twelve pivotal characteristics of DTs. Such characteristics will be used as requirements for defining a Digital Twin Modelling Notation that will enable reasoning about the design of DT solutions.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings of the 2022 IEEE International Conference on Dependable, Autonomic and Secure Computing, International Conference on Pervasive Intelligence and Computing, International Conference on Cloud and Big Data Computing, International Conference on Cyber Science and Technology Congress, DASC/PiCom/CBDCom/CyberSciTech 2022;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85145346103
669;Toward cognitive digital twins using a BIM-GIS asset management system for a diffused university;The integrated use of building information modeling (BIM) and geographic information system (GIS) is promising for the development of asset management systems (AMSs) for operation and maintenance (O&M) in smart university campuses. The combination of BIM-GIS with cognitive digital twins (CDTs) can further facilitate the management of complex systems such as university building stock. CDTs enable buildings to behave as autonomous entities, dynamically reacting to environmental changes. Timely decisions based on the actual conditions of buildings and surroundings can be provided, both in emergency scenarios or when optimized and adaptive performances are required. The research aims to develop a BIM-GIS-based AMS for improving user experience and enabling the optimal use of resources in the O&M phase of an Italian university. Campuses are complex assets, mainly diffused with buildings spread across the territory, managed with still document-based and fragmented databases handled by several subjects. This results in incomplete and asymmetrical information, often leading to ineffective and untimely decisions. The paper presents a methodology for the development of a BIM-GIS web-based platform (i.e., AMS-app) providing the real-time visualization of the asset in an interactive 3D map connected to analytical dashboards for management support. Two buildings of the University of Turin are adopted as demonstrators, illustrating the development of an easily accessible, centralized database by integrating spatial and functional data, useful also to develop future CDTs. As a first attempt to show the AMS app potential, crowd simulations have been conducted to understand the buildings’ actual level of safety in case of fire emergency and demonstrate how CDTs could improve it. The identification of data needed, also gathered through the future implementation of suitable sensors and Internet of Things networks, is the core issue together with the definition of effective asset visualization and monitoring methods. Future developments will explore the integration of artificial intelligence and immersive technologies to enable space use optimization and real-time wayfinding during evacuation, exploiting digital tools to alert and drive users or authorities for safety improvement. The ability to easily optimize the paths with respect to the actual occupancy and conditions of both the asset and surroundings will be enabled.;Frontiers Media S.A.;Journal;Frontiers in Built Environment;2022-12-01;https://api.elsevier.com/content/abstract/scopus_id/85144066596
670;Modeling should be an independent scientific discipline;Software modeling started as a paradigm to help developers build better software faster by enabling them to specify, reason and manipulate software systems at a higher-abstraction level while ignoring irrelevant low-level technical details. But this same principle manifests in any other domain that has to deal with complex systems, software-based or not. We argue that bringing to other engineering and scientific fields, our modeling expertise is a win–win opportunity where we can all learn from each other as we all model, but in complementary ways. Nevertheless, to fully unleash the benefits of this collaboration, we must go beyond individual efforts trying to adapt single techniques from one field to another. It requires a deeper reformulation of modeling as a whole. It is time for modeling to become an independent discipline where all fields of knowledge can contribute and benefit from.;Springer Science and Business Media Deutschland GmbH;Journal;Software and Systems Modeling;2022-12-01;https://api.elsevier.com/content/abstract/scopus_id/85135298798
671;On modeling data for iot agroecology applications by means of a UML profile;"The adoption and deployment of the Internet of Things (IoT) technologies in agroecology raise a challenging research agenda. Agroecology IoT projects feature complex requirements involving: heterogeneous hardware and heterogeneous software systems; data collection architectures, stream and queuing systems as well as data management systems for real-time and batch processing with different data models. On top of that, agroecology IoT applications are characterized by complex spatio-temporal data and low quality communication networks. Developing conceptual models of such complex systems is mandatory for successful projects, but it is much more challenging than for traditional systems. To the best of our knowledge, a comprehensive (end-to-end) data modeling method applicable to such systems has not been provided yet. It motivated us to propose and assess a new UML profile for data modeling across an IoT ecosystem for agroecology applications. The modeling approach allows to represent the following components of a system: data producers, data integration and storage as well as data analytics. The profile has been validated in a real project on monitoring autonomous agricultural robots.";Association for Computing Machinery;Conference Proceeding;ACM International Conference Proceeding Series;2021-11-01;https://api.elsevier.com/content/abstract/scopus_id/85121648163
672;Design of integrated manufacturing information systems for reconfigurability and adaptability by modularizing the system architecture;The present study addresses integrated manufacturing information systems (IMIS) and highlights importance of realizing ‘adaptability’ and ‘reconfigurability’ characteristics in the system architecture of IMISs, where engineering design for system adaptability is interested. This study develops a matrix-based probabilistic definition for the manufacturing information system (MIS) reconfigurability and proposes modularization of physical architecture of the system as an effective design solution for fulfilling system reconfigurability and adaptability requirements. To modularize the physical architecture, Design Structure Matrix (DSM) method is employed. Moreover, information axiom of Axiomatic Design (AD) theory is also utilized to develop helpful indicators for evaluating the adaptability characteristic for the architecture and support engineering designers to make sound decisions in design for adaptability. To verify the developed methodology, the MIS in a real case (Barez Industrial Group in Iran) is addressed and design of the physical architecture for this system is studied. A new optimally modularized design for the physical architecture of the MIS of interest is finally presented and examined. Results of the indicators reflecting reconfigurability and adaptability of the architecture indicate that the new proposed design of the concerned MIS is highly capable of coping with the rapidly changing manufacturing environment.;Taylor and Francis Ltd.;Journal;International Journal of Computer Integrated Manufacturing;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85165439693
673;PLC Integration into Industry 4.0 Middleware: Function Block Library for the Interaction with REST and OPC UA Asset Administration Shells;An asset administration shell (AAS), as a key concept of Industry 4.0 (I4.0), provides a machine-accessible interface to any kind of asset. To enable interoperability and smooth integration of the devices into the I4.0 middleware, an application implementing the device's functionality should be able to interact with different AASs. In this work, we investigate the integration of the Programmable Logic Controller (PLC) runtime systems into the I4.0 middleware. For doing this, we specify the function blocks (FBs) for connecting the PLCs with AASs and other I4.0 components, such as registry and discovery server. We analyze the requirements of such FBs while focusing on REST/HTTP- and OPC UA-based AASs, and provide interface specification for IEC 61499- and IEC 61131-3-based FBs. Furthermore, we implemented an FB library that enables communication with an AAS from the respective control applications. Those FBs allow accessing properties and invoking operations of remote AASs, as well as hosting AASs submodels. Common functionalities, such as registering the runtime system at the registry component, or finding AASs, are also supported. The results obtained in this paper will ease interaction with the complex AAS structure from the low-level devices.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;IEEE International Conference on Emerging Technologies and Factory Automation, ETFA;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85122913107
674;Incremental causal connection for self-adaptive systems based on relational reference attribute grammars;Even though model-driven engineering reduces complexity during the development of self-adaptive systems and models@run.time enables using them during runtime, connecting models to different external systems still involves manual work. Those connections are essential to the complete system, as they enable external systems to react to changes in the internal model and vice versa. In our case, the model is based on Relational Reference Attribute Grammars, an extension of Attribute Grammars to enable conceptual models at runtime while retaining their benefits of modular specification and an incremental evaluation scheme. We present an approach to enable concise specification of the causal connection and needed transformations to match required formats or semantics. To show its applicability, a case study showing the coordination of multiple industrial robot arms using models is presented. We show that using our approach, connections can be specified more concisely while maintaining the same efficiency as hand-written code. The artefact comprising all source code and an executable version of the case studies is available at https://doi.org/10.5281/zenodo.7009758.;Association for Computing Machinery, Inc;Conference Proceeding;Proceedings - 25th ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS 2022;2022-10-23;https://api.elsevier.com/content/abstract/scopus_id/85141832184
675;Design and Implementation of Hierarchical Digital Twins in Industrial Production Environments;The increasing requirements for industrial production environments due to customer expectations, the implementation of batch size 1, and further automation of production processes are confronting companies with new challenges. In particular, the emergence of cyber-physical systems is influencing and complicating manufacturing processes by capturing an increasing amount of information within production facilities. Digital twins are an interdisciplinary technology that may solve these issues because they serve to monitor, control, and optimize cyber-physical systems by creating a digital representation of real-world objects. Existing concepts for digital twins usually only consider individual machines without their context. This is of limited use for production environments due to a multitude of different machines and associated sensor types. Therefore, we propose a requirements catalog, concept, and prototypical implementation for the hierarchical structuring of digital twins in this paper.;IEEE Computer Society;Conference Proceeding;Proceedings of the Annual Hawaii International Conference on System Sciences;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85152136621
676;DTMN a Modelling Notation for Digital Twins;Modelling and developing digital twin solutions is a growing and promising trend followed by enterprises with the ambition to improve decision-making and accelerate risk assessment and production time. However, as a current emerging trend, there is no recognised standard nor a unique solution that provides support for all the characteristics of a digital twin. This article builds upon the result of a literature review that we conducted to extract the main characteristics attributed to Digital Twins. The identified characteristics guided the proposal of a Digital Twin Modelling Notation (DTMN). In this work we present the DTMN meta-model supported by a graphical modelling notation. This modelling notation can be used as a starting point to design and reason about Digital Twin solutions.;Springer Science and Business Media Deutschland GmbH;Book Series;Lecture Notes in Business Information Processing;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85149833934
677;Architecting Digital Twins Using a Domain-Driven Design-Based Approach*;The Digital Twin (DT) concept has overcome its initial definition based on a purely descriptive approach focusing on modelling physical objects, often using CAD. Today DT often describes a behavioural approach that can simulate an object's dynamics, monitor its state, and control or predict its behaviour. Although DTs are attracting significant attention and offer many advantages in the design of especially cyber-physical systems, most proposals have focused on developing DTs for a specific use case or need without providing a more holistic approach to its design. We aim to propose a domain-agnostic approach for architecting DTs. Here, DTs are directly supported by Domain-Driven Design's notion of Bounded Contexts (BCs), hiding all the domain-inherent specifications behind BC boundaries. These BCs are also the central abstraction in many microservice architectures and can be used to describe DTs. A Wind Turbine DT architecture is used as a running example to describe how every relevant DT property can be satisfied following our proposal for architecting digital twins. A qualitative evaluation of this case by five external practitioners shows that our DDD-based proposal consistently outperforms the 5-dimension model used as the reference approach.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - IEEE 20th International Conference on Software Architecture, ICSA 2023;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85159152753
678;Optimal graph partitioning for time-sensitive flow scheduling towards digital twin networks;The growing maturity of Digital Twin (DT) technology represents a quantum leap towards the realisation of Industry 4.0 and beyond. DT refers to virtual representations (in a virtual space) of physical objects/processes/systems (in a physical space), where information is regularly exchanged between them to enable real-time remote control and monitoring. DT will significantly improve product life-cycles and will transform industries such as smart manufacturing, smart transportation, and so forth. Digital Twin Networks (DTNs) are envisaged to be the norm where multiple DTs are logically connected to their respective physical objects, forming a many-to-many communication relationship. Strict real-time communication for bi-directional data flows is required in DTNs for DTs to accurately reflect the changes in the physical objects, and vice-versa. One potential candidate to achieve real-time data transmission is Time Sensitive Networking (TSN). The IEEE 802.1Q working group has developed a set of TSN standards to facilitate data transmissions that require low-latency, high availability and reliability. In TSN, the Central Network Controller (CNC) computes the schedule of frame transmission. However, the computational time required can exponentially increase as the number of nodes and data flows increases (already typical in industrial environments and will increase exponentially with DTNs). In this paper, we propose a novel technique using multi-level graph partitioning theory with Integer Linear Programming (ILP) to facilitate TSN scheduling. Our results demonstrated significant improvements in computational time and the success rate of scheduled data flows in complex networks where there are up to 100 nodes and 350 data flows.;Association for Computing Machinery, Inc;Conference Proceeding;AIIOT 2022 - Proceedings of the 2022 1st Workshop on Digital Twin and Edge AI for Industrial IoT, Part of MobiCom 2022;2022-10-17;https://api.elsevier.com/content/abstract/scopus_id/85144205251
679;Challenging Digital Innovation Through the OMiLAB Community of Practice;Digitalization requires cyber-physical ecosystems to achieve the goals of its transformation process, which should be primarily driven by innovation. OMi- LAB (www.omilab.org) supports digital innovation within a community of practice and technical environment, based on a global network of physical laboratory nodes. The Digital Innovation Environment (DiEn) powered by OMiLAB located at industrial and academic organizations responds to digital transformation challenges. It facilitates the co-creation, design, and engineering of early prototypes. Digital innovation is challenged by the OMiLAB community of practice through tool-aided conceptual modelling and elevates model value in domain-specific scenarios and experiments.;Springer International Publishing;Book;Domain-Specific Conceptual Modeling: Concepts, Methods and ADOxx Tools;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85125410078
680;DataTime: A Framework to smoothly Integrate Past, Present and Future into Models;Models at runtime have been initially investigated for adaptive systems. Models are used as a reflective layer of the current state of the system to support the implementation of a feedback loop. More recently, models at runtime have also been identified as key for supporting the development of full-fledged digital twins. However, this use of models at runtime raises new challenges, such as the ability to seamlessly interact with the past, present and future states of the system. In this paper, we propose a framework called DataTime to implement models at runtime which capture the state of the system according to the dimensions of both time and space, here modeled as a directed graph where both nodes and edges bear local states (ie. values of properties of interest). DataTime provides a unifying interface to query the past, present and future (predicted) states of the system. This unifying interface provides i) an optimized structure of the time series that capture the past states of the system, possibly evolving over time, ii) the ability to get the last available value provided by the system's sensors, and iii) a continuous micro-learning over graph edges of a predictive model to make it possible to query future states, either locally or more globally, thanks to a composition law. The framework has been developed and evaluated in the context of the Intelligent Public Transportation Systems of the city of Rennes (France). This experimentation has demonstrated how DataTime can deprecate the use of heterogeneous tools for managing data from the past, the present and the future, and facilitate the development of digital twins.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 24th International Conference on Model-Driven Engineering Languages and Systems, MODELS 2021;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85123423166
681;Digital Twin based Fault Analysis in Hybrid-cloud Applications;"Hybrid clouds bring together the advantages of the on-premises, private, and public cloud services. Agility, privacy, and regulatory compliance are some of the advantages of hybrid clouds. However, the key characteristics of complex hybrid cloud application such as heterogeneity, reliability, interoperability, scalability, and dynamic nature also makes old static approaches brittle. A digital twin can capture real-time (meta) data of a hybrid cloud application and supply valuable insights for efficient management of the cloud services and analyzing faults. In this paper, we propose a digital twin assisted approach to analyze the faults, interoperability, and reliability issues of a hybrid cloud-based application. We also present some metamorphic relations to analyze the reliability of our twin. Insights from the digital twin can assist developers to take proactive measures before a fault occur. The digital twin can also help detect faults and identify the cause and remediation steps through data insights. The key advantage of using digital twin is that it helps detect issues in complex hybrid cloud applications in a holistic way.CCS CONCEPTS• Software and its engineering; • Computer systems organization ? Embedded and cyber-physical systems;";Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 10th IEEE/ACM International Workshop on Software Engineering for Systems-of-Systems and Software Ecosystems, SESoS 2022;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85135190705
682;A Framework for the Optimization of Complex Cyber-Physical Systems via Directed Acyclic Graph;"Mathematical modeling and data-driven methodologies are frequently required to optimize industrial processes in the context of Cyber-Physical Systems (CPS). This paper introduces the PipeGraph software library, an open-source python toolbox for easing the creation of machine learning models by using Directed Acyclic Graph (DAG)-like implementations that can be used for CPS. scikit-learn’s Pipeline is a very useful tool to bind a sequence of transformers and a final estimator in a single unit capable of working itself as an estimator. It sequentially assembles several steps that can be cross-validated together while setting different parameters. Steps encapsulation secures the experiment from data leakage during the training phase. The scientific goal of PipeGraph is to extend the concept of Pipeline by using a graph structure that can handle scikit-learn’s objects in DAG layouts. It allows performing diverse operations, instead of only transformations, following the topological ordering of the steps in the graph; it provides access to all the data generated along the intermediate steps; and it is compatible with GridSearchCV function to tune the hyperparameters of the steps. It is also not limited to (X, y) entries. Moreover, it has been proposed as part of the scikit-learn-contrib supported project, and is fully compatible with scikit-learn. Documentation and unitary tests are publicly available together with the source code. Two case studies are analyzed in which PipeGraph proves to be essential in improving CPS modeling and optimization: the first is about the optimization of a heat exchange management system, and the second deals with the detection of anomalies in manufacturing processes.";MDPI;Journal;Sensors;2022-02-01;https://api.elsevier.com/content/abstract/scopus_id/85124464020
683;Data-centric UML Profile for Agroecology Applications: Agricultural Autonomous Robots Monitoring Case Study;The conceptual design of information systems is mandatory in several application domains. The advent of the Internet of Things (IoT) technologies pushes conceptual design tools and methodologies to consider the complexity of IoT data, architectures, and communication networks. In agroecology applications, the usage of IoT is quite promising, but it raises several methodological and technical issues. These issues are related to the complexity and heterogeneity of data (social, economic, environmental, and agricultural) needed by agroecology practices. Motivated by the lack of a conceptual model for IoT data, in this work, we present a UML profile taking into account different kinds of data (e.g., sensors, stream, or transactional) and non-functional Requirements. We show how the UML profile integrates with classical UML diagrams to support the design of complex systems. Moreover, We prove the feasibility of our conceptual framework through a theoretical quality assessment and its implementation in the agroecology case study concerning the monitoring of autonomous agricultural robots.;ComSIS Consortium;Journal;Computer Science and Information Systems;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85149380119
684;DTMN a Modelling Notation for Digital Twins;Modelling and developing digital twin solutions is a growing and promising trend followed by enterprises with the ambition to improve decision-making and accelerate risk assessment and production time. However, as a current emerging trend, there is no recognised standard nor a unique solution that provides support for all the characteristics of a digital twin. This article builds upon the result of a literature review that we conducted to extract the main characteristics attributed to Digital Twins. The identified characteristics guided the proposal of a Digital Twin Modelling Notation (DTMN). In this work we present the DTMN meta-model supported by a graphical modelling notation. This modelling notation can be used as a starting point to design and reason about Digital Twin solutions.;Springer Science and Business Media Deutschland GmbH;Book Series;Lecture Notes in Business Information Processing;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85149833934
685;Automatic Generation of Digital Twin Models for Simulation of Reconfigurable Robotic Fabrication Systems for Timber Prefabrication;Timber construction and prefabrication are becoming increasingly important in the building and construction industry. The degree of automation in this area is low. Caused by the great variability of construction projects and building components, automation systems that can adapt flexibly to different construction projects are required. However, a system that fulfills these conditions does not yet exist. Down-times for reconfiguration in between projects must be short. The use of robotics for the automation of prefabrication is constantly developing. Recent publications present a novel, flexible, reconfigurable, and transportable manufacturing platform using industrial robots. A system consisting of several of these modular platforms can be flexibly adapted to the changing requirements of different construction projects and set up on-site at local timber construction companies. To ensure the manufacturability of the timber components and to minimize downtimes between projects, the entire workflow from digital design to fabrication must be considered. The co-design approach makes this possible. It breaks up the currently existing sequential process from design to fabrication and considers all sub-steps holistically. Thus, enabling the consideration of the fabrication capabilities during building design. This allows the planning of building components and system layout so that fabrication is feasible. To achieve this, the fabricability of a given system layout has to be evaluated. This requires a digital twin of the fabrication system as a simulation model. The reconfigurability of the fabrication system must be reflected by the digital twin. The fabrication tasks and the system configuration are constantly changed in search of a valid combination. Therefore, with each iteration, the digital twin must be adapted or newly created. At present, this is mostly a manual process. This makes the whole approach unfeasible. To solve this problem, this work presents an approach for the automated, model-based generation of digital twins for the simulation of reconfigurable fabrication systems for timber prefabrication.;International Association for Automation and Robotics in Construction (IAARC);Conference Proceeding;Proceedings of the International Symposium on Automation and Robotics in Construction;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85127550647
686;Supporting the Implementation of Digital Twins for IoT-Enhanced BPs;IoT-Enhanced Business Processes make use of Internet of Things technology to integrate physical devices into the process as digital actors. Closely related to this topic arises the concept of Digital Twin, which is a virtual representation of real-world entities and processes that connect to the physical counterpart to represent, simulate, or predict changes in the physical system. There are many works that focus on supporting the high-fidelity implementation of Digital Twins for specific physical devices. However, few of them consider the process as a real-world entity to be integrated into the Digital Twin. In this work, we present a microservice architecture to support the implementation of Digital Twins for IoT-Enhanced Business Processes, considering not only the physical devices but also the process itself and the relationship among them. This architectural solution is supported by a model-driven development approach, which proposes (1) the construction of a BPMN model to represent an IoT-enhanced Business Process and (2) the application of model transformation to automatically generate both Digital Twin Definition Language (DTDL) models and microservice Java code templates. DTDL models are used in the implementation of the Digital Twins for the IoT-Enhanced Business Process. Java code templates are used to facilitate the implementation of the microservices required to deploy the IoT-enhanced Business Process and its Digital Twins into the proposed architecture and maintain the digital and physical parts synchronised.;Springer Science and Business Media Deutschland GmbH;Book Series;Lecture Notes in Business Information Processing;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85163280406
687;A model driven method to design educational cyber physical systems;Instructional design is a major concern in TELE (Technology Enhanced Learning Environments) research, especially since the beginning of the Covid-19 health crisis. Since the beginning of this crisis, emergency remote teaching has been widely used. Accordingly, the primary objective in these circumstances is not to re-create a robust educational ecosystem, but rather to provide adapted access to instructional support, learning materials, services and objects. However, design connectedness in such environments is still required regarding the emergence of IoT (Internet of things) and CPS (Cyber Physical Systems) in everyday life and thus in educational environments. In this paper, we propose a model-driven engineering method for the design of Educational Cyber Physical Systems (ECPS). Our method deals with the separation of concerns when it comes to considering a Platform Independent Model (educational aspect) and a Platform Description Model (connected aspect). This practice could then be adopted in order to design further environments by adapting the required models.;SciTePress;Conference Proceeding;Proceedings of the 16th International Conference on Software Technologies, ICSOFT 2021;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85111753929
688;Design and Modeling in Pervasive Information Systems;The previous chapter highlighted the different requirements that a pervasive information system should fulfill, namely Context-awareness, Managing heterogeneity, Transparency, Fulfillment of the requirements and Adaptation.;Springer International Publishing;Book;The Evolution of Pervasive Information Systems;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85160115116
689;Conceptual Modeling Systems: A Vision for the Future of Conceptual Modeling;Although conceptual modeling has been integral to information systems development and use, much of its potential remains underutilized. This is evidenced by the lack of a broad adoption of modeling concepts beyond traditional database design and process modeling applications. In this paper, we propose a fundamentally new perspective on conceptual modeling that integrates artificial intelligence (AI) components with conceptual modeling. This perspective enables us to go beyond passive conceptual modeling representations, such as diagrams, to design conceptual modeling systems that have the capability to learn and evolve.;CEUR-WS;Conference Proceeding;CEUR Workshop Proceedings;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85138735745
690;Digital Twin Ancient Architecture: The Exploration of the Digital Protection of Ancient Architecture;The digital protection of ancient architectures has achieved important achievements. However, technology development has encountered a bottleneck. The main problem is that the digitization of ancient buildings is limited to building static and isolated three-dimensional models, which cannot meet the increasing professional requirements of digital protection. To solve the above problems, the concept of digital twin ancient architecture (DTAA) is proposed, focusing on the high-dimensional data integration method of the DTAA, as well as the construction method and technical route. Finally, the development and application of digital twin ancient architecture are discussed. The proposed method can bring new ideas to the field of digital protection of ancient architectures.;Springer Science and Business Media Deutschland GmbH;Book Series;Lecture Notes on Data Engineering and Communications Technologies;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85153360763
691;Reasoning over time into models with DataTime;Models at runtime have been initially investigated for adaptive systems. Models are used as a reflective layer of the current state of the system to support the implementation of a feedback loop. More recently, models at runtime have also been identified as key for supporting the development of full-fledged digital twins. However, this use of models at runtime raises new challenges, such as the ability to seamlessly interact with the past, present, and future states of the system. In this paper, we propose a framework called DataTime to implement models at runtime which capture the state of the system according to the dimensions of both time and space, here modeled as a directed graph where both nodes and edges bear local states (i.e., values of properties of interest). DataTime offers a unifying interface to query the past, present, and future (predicted) states of the system. This unifying interface provides (i) an optimized structure of the time series that capture the past states of the system, possibly evolving over time, (ii) the ability to get the last available value provided by the system’s sensors, and (iii) a continuous micro-learning over graph edges of a predictive model to make it possible to query future states, either locally or more globally, thanks to a composition law. The framework has been developed and evaluated in the context of the Intelligent Public Transportation Systems of the city of Rennes (France). This experimentation has demonstrated how DataTime can be used for managing data from the past, the present, and the future and facilitate the development of digital twins.;Springer Science and Business Media Deutschland GmbH;Journal;Software and Systems Modeling;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85145994488
692;Digital twin application in heritage facilities management: systematic literature review and future development directions;Purpose: This paper aims to investigate the theoretical and practical links between digital twin (DT) application in heritage facilities management (HFM) from a life cycle management perspective and to signpost the future development directions of DT in HFM. Design/methodology/approach: This state-of-the-art review was conducted using a systematic literature review method. Inclusive and exclusive criteria were identified and used to retrieve relevant literature from renowned literature databases. Shortlisted publications were analysed using the VOSviewer software and then critically reviewed to reveal the status quo of research in the subject area. Findings: The review results show that DT has been mainly adopted to support decision-making on conservation approach and method selection, performance monitoring and prediction, maintenance strategies design and development, and energy evaluation and management. Although many researchers attempted to develop DT models for part of a heritage building at component or system level and test the models using real-life cases, their works were constrained by availability of empirical data. Furthermore, data capture approaches, data acquisition methods and modelling with multi-source data are found to be the existing challenges of DT application in HFM. Originality/value: In a broader sense, this study contributes to the field of engineering, construction and architectural management by providing an overview of how DT has been applied to support management activities throughout the building life cycle. For the HFM practice, a DT-cum-heritage building information modelling (HBIM) framework was developed to illustrate how DT can be integrated with HBIM to facilitate future DT application in HFM. The overall implication of this study is that it reveals the potential of heritage DT in facilitating HFM in the urban development context.;Emerald Publishing;Journal;Engineering, Construction and Architectural Management;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85150965220
693;City Digital Twins: their maturity level and differentiation from 3D city models;The emerging field of City Digital Twins has advanced in recent years with the help of digital infrastructure and technologies connected to the Internet of Things (IoT). However, the evolution of this field has been so fast that a gap has opened in relation to systematic reviews of the relevant literature and the maturation of City Digital Twins on an urban scale. Our work bridges this gap by highlighting maturity in the field. We conducted a systematic literature review with bibliometric and content analysis of 41 selected papers published in Web of Science and Scopus databases, covering five areas: data types and sources, case studies, applied technologies and methods, maturity spectrum, and applications. Based on maturity indicators, the majority of the reviewed studies (90%) were at initial to medium stages of maturity (up to element 3), most of them focused on 3D modelling, monitoring and visualisation. However, digital twins cannot be limited to 3D models, monitoring and visualisation, for they can be developed to include two-directional interactions between humans and computers. Such a high level of maturity, which was not found in the reviewed studies, requires advanced technologies and methods such as cloud computing, artificial intelligence, BIM and GIS. We also found that further studies are essential if the field is to handle the complex urban challenges of multidisciplinary digital twins. While City Digital Twins extend by definition beyond mere 3D city modelling, some studies involving 3D city models still refer to their subjects as City Digital Twins. Among the research gaps we identified, we’d like to highlight the need for near-real-time data analytics algorithms, which could furnish City Digital Twins with big data insights. Other opportunities include public participation capabilities to increase social collaboration, integrating BIM and GIS technologies and improving storage and computation infrastructure.;Taylor and Francis Ltd.;Journal;Big Earth Data;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85146697786
694;From consistency to flexibility: Handling spatial information schema thanks to a middleware in a 3D city modeling context;Twinning elements of reality gains a growing interest in support of decision-making, learning, and simulations: a single and shared model should provide a unique integrative basis for managing assets of any replica of the real world. From a technical viewpoint, sharing and opening information requires both an exchange format and a high degree of freedom and flexibility. It should allow an important number of users to manage this information, to modify it, etc. Storing and manipulating spatial information concerning the urban built context currently focuses on ensuring consistency thanks to relational databases and predefined schemas. Following a paradigm shift from a relational database to a NoSQL database, a schema validation middleware is proposed to improve the flexibility of storage by conceding a share of its consistency. The flexibility improvements thus provide users a common basis that is able to evolve all along the lifecycle of their models and applications as required for twinning things. It allows users and their applications to take advantage of new storage features such as common: versioning, partitioning, prioritization, applications profiles, etc. The middleware and their new capabilities are illustrated thanks to the CityJSON encoding and its simplified schema for a document-oriented database.;John Wiley and Sons Inc;Journal;Transactions in GIS;2023-02-01;https://api.elsevier.com/content/abstract/scopus_id/85145273719
695;Air Quality Management: An Exemplar for Model-Driven Digital Twin Engineering;Since its first mentioning in the literature, the concept of Digital Twin has gained traction in both industry and academia. However, there are still many open challenges when applying Digital Twins to industry-scale use cases. Applying Model-Driven Engineering techniques to the creation and maintenance of Digital Twins (also referred to as Model-Driven Digital Twin Engineering) promises automation and consistency throughout the life cycle of a Digital Twin. The exemplar provided in this paper can be used to identify open challenges when it comes to Model-Driven Digital Twin Engineering, and to demonstrate how approaches can solve them. This exemplar applies Digital Twins to an indoor air quality management use case, where CO2, temperature, and humidity values of rooms within a building are measured. These values can be used to derive actions to improve work productivity and reduce the risk for virus infections. We describe three applications that make use of this Digital Twin (i.e., runtime visualization, physical simulation, and ML-based predictions), and provide an online repository with the artefacts of this exemplar.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Companion Proceedings - 24th International Conference on Model-Driven Engineering Languages and Systems, MODELS-C 2021;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85124047367
696;Digital Twin based Fault Analysis in Hybrid-cloud Applications;"Hybrid clouds bring together the advantages of the on-premises, private, and public cloud services. Agility, privacy, and regulatory compliance are some of the advantages of hybrid clouds. However, the key characteristics of complex hybrid cloud application such as heterogeneity, reliability, interoperability, scalability, and dynamic nature also makes old static approaches brittle. A digital twin can capture real-time (meta) data of a hybrid cloud application and supply valuable insights for efficient management of the cloud services and analyzing faults. In this paper, we propose a digital twin assisted approach to analyze the faults, interoperability, and reliability issues of a hybrid cloud-based application. We also present some metamorphic relations to analyze the reliability of our twin. Insights from the digital twin can assist developers to take proactive measures before a fault occur. The digital twin can also help detect faults and identify the cause and remediation steps through data insights. The key advantage of using digital twin is that it helps detect issues in complex hybrid cloud applications in a holistic way.CCS CONCEPTS• Software and its engineering; • Computer systems organization ? Embedded and cyber-physical systems;";Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 10th IEEE/ACM International Workshop on Software Engineering for Systems-of-Systems and Software Ecosystems, SESoS 2022;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85135190705
697;Sustainability requirements of digital twin-based systems: A meta systematic literature review;"Sustainable development was defined by the UN in 1987 as development that meets the needs of the present without compromising the ability of future generations to meet their own needs, and this is a core concept in this paper. This work acknowledges the three dimensions of sustainability, i.e., economic, social, and environmental, but its focus is on this last one. A digital twin (DT) is frequently described as a physical entity with a virtual counterpart, and the data, connections between the two, implying the existence of connectors and blocks for efficient and effective data communication. This paper provides a meta systematic literature review (SLR) (i.e., an SLR of SLRs) regarding the sustainability requirements of DT-based systems. Numerous papers on the subject of DT were also selected because they cited the analyzed SLRs and were considered relevant to the purposes of this research. From the selection and analysis of 29 papers, several limitations and challenges were identified: the perceived benefits of DTs are not clearly understood; DTs across the product life cycle or the DT life cycle are not sufficiently studied; it is not clear how DTs can contribute to reducing costs or supporting decision-making; technical implementation of DTs must be improved and better integrated in the context of the IoT; the level of fidelity of DTs is not entirely evaluated in terms of their parameters, accuracy, and level of abstraction; and the ownership of data stored within DTs should be better understood. Furthermore, from our research, it was not possible to find a paper discussing DTs only in regard to environmental sustainability.";MDPI AG;Journal;Applied Sciences (Switzerland);2021-06-02;https://api.elsevier.com/content/abstract/scopus_id/85108827458
698;Design of a Digital Twin Training Centre for an Industrial Robot Arm;The Cyber-Physical and Intelligent Robotics Laboratory has been digitally recreated, and it includes all the key elements that allow 6-axis industrial robots to perform PTP, LIN, and CIRC motions. Furthermore, the user can create a program with these motion types. The human–machine interface is also integrated into our system. It can also assist SMEs in developing their in-house training. After all, training on an industrial robot unit does not entail installation costs within the facility. Nor are there any maintenance and servicing costs. Since the lab is digital, additional robot units can be added or removed. Thus, areas for training or production can be pre-configured within each facility. Because of the customizability and virtual education format, there is no room capacity problem, and trainees can participate in the exercises in parallel. Exercises were also conducted to evaluate the program’s impact on teaching, and the results showed that using machine units can improve teaching. Even today’s digital labs cannot physically convey the sense of space or the relative weights of different elements in virtual space. Even with these features, individuals can operate a machine more effectively than relying solely on traditional, non-interactive demonstration materials.;MDPI;Journal;Applied Sciences (Switzerland);2022-09-01;https://api.elsevier.com/content/abstract/scopus_id/85137759099
699;Application of Digital Twins in multiple fields;With the development of science and technology, the high-tech industry is developing rapidly, and various new-age technologies continue to appear, and Digital Twins (DT) is one of them. As a brand-new interactive technology, DT technology can handle the interaction between the real world and the virtual world well. It has become a hot spot in the academic circles of all countries in the world. DT have developed rapidly in recent years result from centrality, integrity and dynamics. It is integrated with other technologies and has been applied in many fields, such as smart factory in industrial production, digital model of life in medical field, construction of smart city, security guarantee in aerospace field, immersive shopping in commercial field and so on. The introduction of DT is mostly a summary of concepts, and few practical applications of Digital Twins are introduced. The purpose of this paper is to enable people to understand the application status of DT technology. At the same time, the introduction of core technologies related to DT is interspersed in the application introduction. Finally, combined with the current development status of DT, predict the future development trend of DT and make a summary.;Springer;Journal;Multimedia Tools and Applications;2022-08-01;https://api.elsevier.com/content/abstract/scopus_id/85124832719
700;The Forging of Autonomic and Cooperating Digital Twins;Digital twins (DTs) will enable the long-anticipated convergence between physical and virtual worlds. This disruptive convergence will augment operations and services that are traditionally constrained to physical spaces with new virtual-based capabilities. Nevertheless, achieving this point to its full extent will demand DTs with increased autonomy and enhanced ability to monitor, reason about, and react upon relevant phenomena. This article discusses pivotal research advances toward the realization of autonomic and cooperative DTs. We elaborate on fundamental technical considerations of advanced and robust DTs by describing a reference framework that enables increased autonomy and enhanced cooperation. Then, we identify opportunities for further DT research and technological advances in diverse contexts.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Internet Computing;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85099728707
701;Modelling guidance in software engineering: a systematic literature review;Despite potential benefits in Software Engineering, adoption of software modelling in industry is low. Technical issues such as tool support have gained significant research before, but individual guidance and training have received little attention. As a first step towards providing the necessary guidance in modelling, we conduct a systematic literature review to explore the current state of the art. We searched academic literature for guidance on model creation and selected 35 papers for full-text screening through three rounds of selection. We find research on model creation guidance to be fragmented, with inconsistent usage of terminology, and a lack of empirical validation or supporting evidence. We outline the different dimensions commonly used to provide guidance on software and system model creation. Additionally, we provide definitions of the three terms modelling method, style, and guideline as current literature lacks a well-defined distinction between them. These definitions can help distinguishing between important concepts and provide precise modelling guidance.;Springer Science and Business Media Deutschland GmbH;Journal;Software and Systems Modeling;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85164973624
702;Toward Autonomic, Software-Intensive Digital Twin Systems;Digital twins (DTs) mirror and model the characteristics and properties of dynamic, real-world entities known as real twins (RTs). Ensuring the delivery of consistent and reliable RT insights over time demands DTs preserve the correspondence with their counterparts, notwithstanding change.;IEEE Computer Society;Journal;IEEE Software;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85121376519
703;Designing Run-time Evolution for Dependable and Resilient Cyber-Physical Systems Using Digital Twins;The proliferation of Smart Cyber-Physical Systems (SCPS) is increasingly blurring the boundaries between physical and virtual entities. This trend is revolutionizing multiple application domains along the whole human activity spectrum, while pushing the growth of new businesses and innovations such as smart manufacturing, cities and transportation systems, as well as personalized healthcare. Technological advances in the Internet of Things, Big Data, Cloud Computing and Artificial Intelligence have effected tremendous progress toward the autonomic control of SCPS operations. However, the inherently dynamic nature of physical environments challenges SCPS' ability to perform adequate control actions over managed physical assets in myriad of contexts. From a design perspective, this issue is related to the system states of operation that cannot be predicted entirely at design time, and the consequential need to define adequate capabilities for run-time self-adaptation and self-evolution. Nevertheless, adaptation and evolution actions must be assessed before realizing them in the managed system in order to ensure resiliency while minimizing the risks. Therefore, the design of SCPS must address not only dependable autonomy but also operational resiliency. In light of this, the contribution of this paper is threefold. First, we propose a reference architecture for designing dependable and resilient SCPS that integrates concepts from the research areas of Digital Twin, Adaptive Control and Autonomic Computing. Second, we propose a model identification mechanism for guiding self-evolution, based on continuous experimentation, evolutionary optimization and dynamic simulation, as the architecture's first major component for dependable autonomy. Third, we propose an adjustment mechanism for self-adaptation, based on gradient descent, as the architecture's second major component, addressing operational resiliency. Our contributions aim to further advance the research of reliable self-adaptation and self-evolution mechanisms and their inclusion in the design of SCPS. Finally, we evaluate our contributions by implementing prototypes and showing their viability using real data from a case study in the domain of intelligent transportation systems.;IOS Press BV;Journal;Journal of Integrated Design and Process Science;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85125289569
704;Society 5.0: technologies for collecting, analyzing, and sharing data about individuals Sociedade 5.0: tecnologias de recolha, análise e partilha de dados sobre os indivíduos;The proposal of Sociedade 5.0 is to contribute to a better quality of life for individuals, and for this, it is also necessary to know these individuals. This need has led researchers and organizations to develop and use technological systems and devices for data collection. These systems and devices take different forms and are increasingly present in the daily lives of individuals. Data collection is performed actively, namely through sensors, or passively, receiving the data that is entered by its users, often unconsciously. This paper presents an initial literature review where it is intended to investigate which technologies and the main sources for collecting information about individuals and how this information can be gathered to contribute to Society 5.0. This investigation aims to know some of the possibilities of these technologies and contribute to future work on this topic.;Associacao Portuguesa de Sistemas de Informacao;Conference Proceeding;Atas da Conferencia da Associacao Portuguesa de Sistemas de Informacao;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85139975743
705;Conceptual Modelling of an EV-Permanent Magnet Synchronous Motor Digital Twin;Digital twin (DT) technology has contributed to the development process of many applications, including electric vehicles (EVs). The DT concept is to create a digital representation of a real physical asset and support its performance by utilizing simulation and optimization tools fed with real-time data. DT technology can be used to solve general problems related to EV motors, such as estimation of the driving torque and the internal rotor temperature. This paper provides the concepts for implementing a DT of an EV permanent magnet synchronous motor (PMSM) based on its analytical performance model. DT architecture comprises two main components: virtual model and real-time data exchange set. The motor physical model (test bench) was provided in detail. An analytical performance q-d mathematical model supported by the motor equivalent circuit was explained. The motor virtual model was built based on the proposed analytical model using MATLAB/Simulink. Robot operating system V.2 (ROS2) node, implemented on a microcontroller, was used for real-time data exchange between the physical and the virtual motor models. The main target is to monitor the physical motor performance and estimate its torque through its digital twin. The obtained results from the DT showed the effectiveness of the proposed method.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2022 IEEE 20th International Power Electronics and Motion Control Conference, PEMC 2022;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85144022754
706;Broken Bar Fault Detection and Diagnosis Techniques for Induction Motors and Drives: State of the Art;Motors are the higher energy-conversion devices that consume around 40% of the global electrical generated energy. Induction motors are the most popular motor type due to their reliability, robustness, and low cost. Therefore, both condition monitoring and fault diagnosis of induction motor faults have motivated considerable research efforts. In this paper, a comprehensive review of the recent techniques proposed in the literature for broken bar faults detection and diagnosis is presented. This paper mainly investigates the fault detection methods in line-fed and inverter-fed motors proposed after 2015 and published in most relevant journals and conferences. The introduced review has deeply discussed the main features of the reported methods and compared them in many different aspects. Finally, the study has highlighted the main issues and the gaps that require more attention from researchers in this field.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85136709295
707;Interface Development for Digital Twin of an Electric Motor Based on Empirical Performance Model;The concept of Digital Twin is creating and maintaining a digital representation of the real physical entity and supporting its performance utilizing simulation and optimization tools, which are fed with the real data obtained from the physical equipment. Development and implementation of the Digital Twin technology are one of the main challenges for today's industry, more detailed studies are needed on design methods for Digital Twins. Besides using Digital Twin as a high-quality simulation, one of the commitments is monitoring and maintaining control of the whole system via a constant live link between virtual and physical entities. The related research study presents a detailed structural description of the developed Digital Twin virtual entity and the development of a framework that allows Robot Operating System (ROS) to securely communicate with remote Digital Twins via the Internet and harness ROS's adaptability across vast distances and multiple systems. This paper is an extended version of the authors' International Conference on Electrical Power Drive Systems (ICEPDS20) paper, in which we propose a development case study of Digital Twin for an electric motor based on an empirical performance model.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85124176939
708;Digital twins as electric motor soft-sensors in the automotive industry;Digital Twins can be defined as virtual representation of physical assets enabled through data and simulators, for real time prediction, optimization, control, and decision making improvements. In this paper, the concept of digital twin is applied to electric motors. In particular, the use of this technology is shown to solve general problems related to the application of electric motors in the automotive industry, such as estimation of the driving torque and the internal rotor temperature to improve cooling control. Proof-of-concept results are shown, showing the validity of the adopted methodology and the effectiveness of the proposed solution.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2021 IEEE International Workshop on Metrology for Automotive, MetroAutomotive 2021 - Proceedings;2021-07-01;https://api.elsevier.com/content/abstract/scopus_id/85114962774
709;Quickly and High-Precision Digital Twin Device-Level Simulation Modeling of Permanent Magnet Synchronous Generator and Voltage Stabilizing System;The traditional finite element model of permanent magnet synchronous generator (PMSG) is time-consuming due to the need for nonlinear iteration of each grid. Besides, the performance of various components of the voltage regulator controller (VRC) will be affected by the operating environment. The traditional component library cannot meet the accurate digital twin effect. Taking an emergency power supply system for an unmanned aerial vehicle as an example, this paper uses the device-level modeling method to build a digital twin simulation model (DTSM) of a PMSG and its AC-DC regulated power supply system, which simulation results can guarantee real-time output results in synchronization with the experiment and has an agile digital twin effect. Finally, the calculated results are compared with the experimental values to verify the accuracy of the proposed digital twin device-level model, which is of great significance to the combined design of PMSGs and VRCs.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Digests of the Intermag Conference;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85121700782
710;Digital Twin Service Unit for AC Motor Stator Inter-Turn Short Circuit Fault Detection;A modern trend for industry digitalization brings new demands for the development and application of the modeling and simulation approach. It is already not enough to have only a virtual representation of the object and run it independently from the physical object. The Digital Twin (DT) aspect indicates a connection between the physical object and the corresponding virtual twin established by generating real-time data using sensors. The DT represents physical object operation throughout its life cycle, making it an essential tool for improving that object's reliability. In this paper, an application of the DT service unit for AC motor stator inter-turn short circuit fault detection is presented. According to real-time measurements, Linux Robot Operation System (ROS) simulates AC electrical machine-specific behavior in case of unbalanced stator currents and notify about possible fault appearance and propagation. Fault, such as discussed in the paper (AC machine stator inter-turn) is considered one of the most prevalent possible electrical motor failure.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2021 28th International Workshop on Electric Drives: Improving Reliability of Electric Drives, IWED 2021 - Proceedings;2021-01-27;https://api.elsevier.com/content/abstract/scopus_id/85103860218
711;Modeling of discrete event systems using finite automata with variables;To get industrial acceptance of supervisory control theory, there is a need to bridge the gap between the signal-based industrial reality and the event-based supervisory control framework. This paper tries to do this by introducing a modeling formalism with automata extended with variables, guard expressions and action functions. The formalism is suitable for modeling plants and specifications in the supervisory control framework. An algorithm that transforms a set of extended automata into a set of ordinary automata with equivalent behavior, is presented. This allows the user to model complex behaviors with a compact representation, and at the same time use existing algorithms for analysis. © 2007 IEEE.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings of the IEEE Conference on Decision and Control;2007-01-01;https://api.elsevier.com/content/abstract/scopus_id/62749203693
712;Knowledge-based engineering of automation systems using ontologies and engineering data;Ontologies provide an effective way for describing and using knowledge of a specific domain. In engineering workflows the reusability and quick adoption of knowledge is needed for solving several tasks in efficient ways. Engineering data is mostly structured in hierarchical documents and exchange formats, but is not represented in ontologies. Therefore a connection between engineering data and the knowledge in ontologies is needed. In this article we present a bridge concept for connecting engineering data with an OWL-based ontology. For this we use an example ontology containing security knowledge of automation systems.;SciTePress;Conference Proceeding;IC3K 2015 - Proceedings of the 7th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management;2015-01-01;https://api.elsevier.com/content/abstract/scopus_id/84961126728
713;Design and Development of Digital Twins: a Case Study in Supply Chains;Digital twin technology consists of creating virtual replicas of objects or processes that simulate the behavior of their real counterparts. The objective is to analyze its effectiveness or behavior in certain cases to improve its effectiveness. Applied to products, machines and even complete business ecosystems, the digital twin model can reveal information from the past, optimize the present and even predict the future performance of the different areas analyzed. In the context of supply chains, digital twins are changing the way they do business, providing a range of options to facilitate collaborative environments and data-based decision making and making business processes more robust. This paper proposes the design and development of a digital twin for a case study of a pharmaceutical company. The technology used is based on simulators, solvers and data analytic tools that allow these functions to be connected in an integral interface for the company.;Springer;Journal;Mobile Networks and Applications;2020-12-01;https://api.elsevier.com/content/abstract/scopus_id/85085970937
714;Digital Twin for rotating machinery fault diagnosis in smart manufacturing;With significant advancement in information technologies, Digital Twin has gained increasing attention as it offers an enabling tool to realise digitally-driven, cloud-enabled manufacturing. Given the nonlinear dynamics and uncertainty involved during the process of machinery degradation, proper design and adaptability of a Digital Twin model remain a challenge. This paper presents a Digital Twin reference model for rotating machinery fault diagnosis. The requirements for constructing the Digital Twin model are discussed, and a model updating scheme based on parameter sensitivity analysis is proposed to enhance the model adaptability. Experimental data are collected from a rotor system that emulates an unbalance fault and its progression. The data are then input to a Digital Twin model of the rotor system to investigate its ability of unbalance quantification and localisation for fault diagnosis. The results show that the constructed Digital Twin rotor model enables accurate diagnosis and adaptive degradation analysis.;Taylor and Francis Ltd.michael.wagreich@univie.ac.at;Journal;International Journal of Production Research;2019-06-18;https://api.elsevier.com/content/abstract/scopus_id/85058187499
715;A simulation-based architecture for smart cyber-physical systems;In order to accurately predict future states of a smart cyber-physical system, which can change its behavior to a large degree in response to environmental influences, the existence of precise models of the system and its surroundings is demandable. In machine engineering, ultra-high fidelity simulations have been developed to better understand both constraints in system design and possible consequences of external influences during the system's operation. These digital twins enable further applications in software design for complex cyber-physical systems as online planning methods can utilize good simulations to continuously optimize the system behavior, yielding a software architecture framework based on the information flow between the cyber-physical system, its physical environment and the digital twin model.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2016 IEEE International Conference on Autonomic Computing, ICAC 2016;2016-09-21;https://api.elsevier.com/content/abstract/scopus_id/84991687905
716;A data- And knowledge-driven framework for digital twin manufacturing cell;Intelligent manufacturing is regarded as the next generation manufacturing mode with powerful learning and cognitive capacities enabled by new generation information technologies such as Internet of Things, big data analytics, edge computing and artificial intelligence. To provide an insight into intelligent manufacturing, this paper takes autonomous manufacturing cell as implementation scenario and proposes a data- and knowledge-driven framework for digital twin manufacturing cell (DTMC), which could support autonomous manufacturing by an intelligent perceiving, simulating, understanding, predicting, optimizing and controlling strategy. In addition, three key enabling technologies including digital twin model, dynamic knowledge bases and knowledge-based intelligent skills for supporting the above strategy are analyzed. Then, the implementing methods of DTMC are introduced through a thus constructed digital twin robot, and the usage of data and knowledge for supporting the automous operations of DTMC is also discussed. Finally, benefits of DTMC in smart product-service systems (PSS) and its current challenges are summarized.;Elsevier B.V.;Conference Proceeding;Procedia CIRP;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85070560451
717;Towards Next Generation of Pedestrian and Connected Vehicle In-the-Loop Research: A Digital Twin Co-Simulation Framework;Digital Twin is an emerging technology that replicates real-world entities into a digital space. It has attracted increasing attention in the transportation field and many researchers are exploring its future applications in the development of Intelligent Transportation System (ITS) technologies. Connected vehicles (CVs) and pedestrians are among the major traffic participants in ITS. However, the usage of Digital Twin in research involving both CV and pedestrian remains largely unexplored. In this study, a Digital Twin framework for CV and pedestrian in-the-loop simulation is proposed. The proposed framework consists of the physical world, the digital world, and data transmission in between. The features for the entities (CV and pedestrian) that need digital twining are divided into external state and internal state, and the attributes in each state are described. We also demonstrate a sample architecture under the proposed Digital Twin framework, which is based on Carla-Sumo Co-simulation and Cave automatic virtual environment (CAVE). A case study that investigates Vehicle-Pedestrian (V2P) warning system is conducted to validate the effectiveness of the presented architecture. The proposed framework is expected to provide guidance to the future Digital Twin research, and the architecture we build can serve as the testbed for further research and development of ITS applications on CV and pedestrians.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Transactions on Intelligent Vehicles;2023-04-01;https://api.elsevier.com/content/abstract/scopus_id/85149371903
718;TOWARD A UNIFIED ENGLISH-LIKE REPRESENTATION of SEMANTIC MODELS, DATA, and GRAPH PATTERNS for SUBJECT MATTER EXPERTS;The Semantic Application Design Language (SADL) combines advances in standardized declarative modeling languages based on formal logic with advances in domain-specific language (DSL) development environments to create a controlled-English language that translates directly into the Web Ontology Language (OWL), the SPARQL graph query language, and a compatible if/then rule language. Models in the SADL language can be authored, tested, and maintained in an Eclipse-based integrated development environment (IDE). This environment offers semantic highlighting, statement completion, expression templates, hyperlinking of concepts to their definition, model validation, automatic error correction, and other advanced authoring features to enhance the ease and productivity of the modeling environment. In addition, the SADL language offers the ability to build in validation tests and test suites that can be used for regression testing. Through common Eclipse functionality, the models can be easily placed under source code control, versioned, and managed throughout the life of the model. Differences between versions can be compared side-by-side. Finally, the SADL-IDE offers an explanation capability that is useful in understanding what was inferred by the reasoner/rule engine and why those conclusions were reached. Perhaps more importantly, explanation is available of why an expected inference failed to occur. The objective of the language and the IDE is to enable domain experts to play a more active and productive role in capturing their knowledge and making it available as computable artifacts useful for automation where appropriate and for decision support systems in applications that benefit from a collaborative human-computer approach. SADL is built entirely on open source code and most of SADL is itself released to open source. This paper explores the concepts behind the language and provides details and examples of the authoring and model lifecycle support facilities.;World Scientific Publishing Co. Pte Ltdwspc@wspc.com.sg;Journal;International Journal of Semantic Computing;2013-09-01;https://api.elsevier.com/content/abstract/scopus_id/84979072313
719;Verification and control of hybrid systems: A symbolic approach;Hybrid systems describe the interaction of software, modeled by finite-state systems such as finite-state machines, with the physical world, described by infinite-state systems such as differential equations. Verification and Control of Hybrid Systems provides a unique systematic exposition of several classes of hybrid systems, admitting symbolic models along with the relationships between them. The text outlines several key verification and control synthesis results for hybrid systems, guided by the concept of bisimulation, and illustrated by numerous examples. The book is divided into four parts: Part I presents basic concepts centered on a notion of system that is general enough to describe finite-state, infinite-state, and hybrid systems. Part II discusses the ways in which systems relate to other systems, such as behavioral inclusion/equivalence and simulation/bisimulation, using these relationships to study verification and control synthesis problems for finite-state systems. Part III draws inspiration from timed automata to present several classes of hybrid systems, with richer continuous dynamics, that can be related to finite-state symbolic systems. Once such relationships are established, verification and control synthesis problems for these hybrid systems can be immediately solved by resorting to the techniques described in Part II for finite-state systems. Part IV follows the same strategy by generalizing simulation/bisimulation relationships to approximate simulation/bisimulation relationships that can be used for a wider class of hybrid systems. This comprehensive treatment will appeal to researchers, engineers, computer scientists, and graduate students in the areas of formal methods, verification, model checking, and control and will undoubtedly inspire further study of the specialized literature. © Springer Science+Business Media, LLC 2009. All rights reserved.;Springer US;Book;Verification and Control of Hybrid Systems: A Symbolic Approach;2009-12-01;https://api.elsevier.com/content/abstract/scopus_id/84891403588
720;M&C ML: A modeling language for monitoring and control systems;The use of System Engineering (SE) language such as SysML [1,20] is common within the community of control system designers. However the design handoff to the subsequent phases of the control system development is carried out manually in most cases without much tool support. The approach to agreeing on the control interface between components is a good example where engineers still rely on either manually created Interface Control Documents (ICD) or one off tools implemented by individual projects. Square Kilometer Array (SKA) [2] and International Thermonuclear Experimental Reactor (ITER) [3] are two good examples of such large projects adopting these approaches. This results in non-uniformity in the overall system design since individual groups invent their own vocabulary while using a language like SysML which leads to inconsistencies across the design, interface and realized code. To mitigate this, we propose the development of a Monitoring and Control Modeling Language (M&CML), a domain specific language (DSL) [4,22] for specifying M&C solutions. M&C ML starts with defining a vocabulary borrowing concepts from standard practices used in the control domain and incorporates a language which ensures uniformity and consistency across the M&C design, interfaces and implementation artifacts. In this paper we discuss this language with an analysis of its usage to point out its benefits.;Elsevier Ltd;Journal;Fusion Engineering and Design;2016-11-15;https://api.elsevier.com/content/abstract/scopus_id/84969672798
721;Introduction to SCXML;SCXML is a control flow language based on Harel State Charts. It offers powerful, application-independent control constructs, along with a plug-in capability that allows platforms to customize the language for specific domains. This paper offers an overview of the language along with examples of its use.;Springer International Publishing;Book;Multimodal Interaction with W3C Standards: Toward Natural User Interfaces to Everything;2016-01-01;https://api.elsevier.com/content/abstract/scopus_id/85009675124
722;Building code generators for DSLs using a partial evaluator for the Xtend language;For several years now, domain-specific languages (DSLs) are a mainstream tool for establishing model-based development environments in real-world projects. Typical back-end tools for external DSLs are interpreters and code generators. Partial evaluation is a well-known technique for program specialization, with the use case of specializing interpreters to target programs. However, the automatic generation of code generators from a DSL’s interpreter is by no means ubiquitous in industrial DSL projects. In this paper, we show how interpreters for a DSL can be used as a basis for automatic generation of efficient target code. This is possible by implementing a partial evaluator for the mainstream DSL toolset Xtext/Xtend.;Springer Verlag;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2014-01-01;https://api.elsevier.com/content/abstract/scopus_id/84910655351
723;Digital twin: Mitigating unpredictable, undesirable emergent behavior in complex systems;Systems do not simply pop into existence. They progress through lifecycle phases of creation, production, operations, and disposal. The issues leading to undesirable and unpredicted emergent behavior are set in place during the phases of creation and production and realized during the operational phase, with many of those problematic issues due to human interaction. We propose that the idea of the Digital Twin, which links the physical system with its virtual equivalent can mitigate these problematic issues. We describe the Digital Twin concept and its development, show how it applies across the product lifecycle in defining and understanding system behavior, and define tests to evaluate how we are progressing. We discuss how the Digital Twin relates to Systems Engineering and how it can address the human interactions that lead to “normal accidents.” We address both Digital Twin obstacles and opportunities, such as system replication and front running. We finish with NASA's current work with the Digital Twin.;Springer International Publishing;Book;Transdisciplinary Perspectives on Complex Systems: New Findings and Approaches;2016-01-01;https://api.elsevier.com/content/abstract/scopus_id/85006339863
724;Digital twin modeling method based on biomimicry for machining aerospace components;High-performance aerospace component manufacturing requires stringent in-process geometrical and performance-based quality control. Real-time observation, understanding and control of machining processes are integral to optimizing the machining strategies of aerospace component manufacturing. Digital Twin can be used to model, monitor and control the machining process by fusing multi-dimensional in-context machining process data, such as changes in geometry, material properties and machining parameters. However, there is a lack of systematic and efficient Digital Twin modeling method that can adaptively develop high-fidelity multi-scale and multi-dimensional Digital Twins of machining processes. Aiming at addressing this challenge, we proposed a Digital Twin modeling method based on biomimicry principles that can adaptively construct a multi-physics digital twin of the machining process. With this approach, we developed multiple Digital Twin sub-models, e.g., geometry model, behavior model and process model. These Digital Twin sub-models can interact with each other and compose an integrated true representation of the physical machining process. To demonstrate the effectiveness of the proposed biomimicry-based Digital Twin modeling method, we tested the method in monitoring and controlling the machining process of an air rudder.;Elsevier B.V.;Journal;Journal of Manufacturing Systems;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85085116186
725;Enabling technologies and tools for digital twin;Digital twin is revolutionizing industry. Fired by sensor updates and history data, the sophisticated models can mirror almost every facet of a product, process or service. In the future, everything in the physical world would be replicated in the digital space through digital twin technology. As a cutting-edge technology, digital twin has received a lot of attention. However, digital twin is far from realizing their potential, which is a complex system and long-drawn process. Researchers must model all the different parts of the objects or systems. Varied types of data needed to be collected and merged. Many researchers and participators in engineering are not clear which technologies and tools should be used. 5-dimension digital twin model provides reference guidance for understanding and implementing digital twin. From the perspective of 5-dimension digital twin model, this paper tries to investigate and summarize the frequently-used enabling technologies and tools for digital twin to provide technologies and tools references for the applications of digital twin in the future.;Elsevier B.V.;Journal;Journal of Manufacturing Systems;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85074335396
726;A digital twin-based flexible cellular manufacturing for optimization of air conditioner line;In a personalized and various production mode, the production line needs to be updated quickly to meet market demand. The Optimization of production line is taken as the object. To address the coupling problems, such as unreasonable production line layout, unbalanced process capability, inaccurate logistics distribution and unintelligent equipment testing, a method of flexible cellular manufacturing based on digital twin is put forward. Decoupling based on event mechanisms and multi-objective optimization will be used in the design of methods, which will be continuously optimized in the simulation and will eventually be validated. After the implementation of an air conditioner line, the production capacity increased by 58.3 %, the WIP decreased by 77.8 %, the balance rate of the production line increased by 25.2 %, and the per capita production capacity increased by 29.8 %. The number of operators decreased by 28.3 %. The results show that the optimization method of flexible cellular manufacturing based on digital twin has practical value and guiding significance to improve the efficiency of production line.;Elsevier B.V.;Journal;Journal of Manufacturing Systems;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85089001454
727;Digital Twin for rotating machinery fault diagnosis in smart manufacturing;With significant advancement in information technologies, Digital Twin has gained increasing attention as it offers an enabling tool to realise digitally-driven, cloud-enabled manufacturing. Given the nonlinear dynamics and uncertainty involved during the process of machinery degradation, proper design and adaptability of a Digital Twin model remain a challenge. This paper presents a Digital Twin reference model for rotating machinery fault diagnosis. The requirements for constructing the Digital Twin model are discussed, and a model updating scheme based on parameter sensitivity analysis is proposed to enhance the model adaptability. Experimental data are collected from a rotor system that emulates an unbalance fault and its progression. The data are then input to a Digital Twin model of the rotor system to investigate its ability of unbalance quantification and localisation for fault diagnosis. The results show that the constructed Digital Twin rotor model enables accurate diagnosis and adaptive degradation analysis.;Taylor and Francis Ltd.michael.wagreich@univie.ac.at;Journal;International Journal of Production Research;2019-06-18;https://api.elsevier.com/content/abstract/scopus_id/85058187499
728;Building a right digital twin with model engineering;In recent years, the concept of digital twin (DT) is attracting more and more attention from researchers and engineers. But there is still no consensus on what a right DT is. On one hand, some common models are renamed as DTs. On the other hand, some DTs extremely pursue ‘the same’ as physical objects, which bring unnecessary complexities to them. In this paper, we try to answer two questions from the point of view of model engineering: how to define a right digital twin, and how to build a right digital twin. The concept and related technologies of model engineering are introduced. Some basic principles and a set of metrics for a right DT are given. An evolutionary concurrent modeling method for DT (ECoM4DT) is proposed not only inheriting the theory from classic M&S methods but also highlighting the characteristics of DT compared with traditional models to systemically guide the DT modeling process.;Elsevier B.V.;Journal;Journal of Manufacturing Systems;2021-04-01;https://api.elsevier.com/content/abstract/scopus_id/85101656955
729;The Digital Twin Paradigm Applied to Soil Quality Assessment: A Systematic Literature Review;This article presents the results regarding a systematic literature review procedure on digital twins applied to precision agriculture. In particular, research and development activities aimed at the use of digital twins, in the context of predictive control, with the purpose of improving soil quality. This study was carried out through an exhaustive search of scientific literature on five different databases. A total of 158 articles were extracted as a result of this search. After a first screening process, only 11 articles were considered to be aligned with the current topic. Subsequently, these articles were categorised to extract all relevant information, using the preferred reporting items for systematic reviews and meta-analyses methods. Based on the obtained results, there are two main conclusions to draw: First, when compared with industrial processes, there is only a very slight rising trend regarding the use of digital twins in agriculture. Second, within the time frame in which this work was carried out, it was not possible to find any published paper on the use of digital twins for soil quality improvement within a model predictive control context.;MDPI;Journal;Sensors;2023-01-01;https://api.elsevier.com/content/abstract/scopus_id/85146668292
730;Digital Twin in manufacturing: A categorical literature review and classification;The Digital Twin (DT) is commonly known as a key enabler for the digital transformation, however, in literature is no common understanding concerning this term. It is used slightly different over the disparate disciplines. The aim of this paper is to provide a categorical literature review of the DT in manufacturing and to classify existing publication according to their level of integration of the DT. Therefore, it is distinct between Digital Model (DM), Digital Shadow (DS) and Digital Twin. The results are showing, that literature concerning the highest development stage, the DT, is scarce, whilst there is more literature about DM and DS.;Elsevier B.V.;Conference Proceeding;IFAC-PapersOnLine;2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85052915281
731;Digital twins: An analysis framework and open issues;The concept of twinning an operational physical system with a functional replica is not new, having been practiced in the space sector for over 50 years. Advances in digitalisation have created opportunities to extract data, obtain insights and achieve greater situational awareness of a physical system's performance. Increasing interest in the concept has led to a proliferation of digital twin definitions, which are used to frame discussions about specific digital twins. Consequentially comparison of the capabilities of specific digital twins is difficult as they are analysed using different definitions. This paper proposes an analysis framework that enables the characteristics of all digital twins to be matched to this framework. Using this framework, a digital twin may be characterised, or two or more digital twins may be compared. By establishing a framework that contains common functional characteristics, we aim to reduce the confusion caused by the plethora of digital twin definitions and their interpretation by suppliers. By focusing only on functionality and not addressing non-functional requirements the analysis allows comparison of different physical and logical instantiations of digital twins.;Elsevier B.V.;Journal;Computers in Industry;2022-12-01;https://api.elsevier.com/content/abstract/scopus_id/85136148334
732;Peeking into the void: Digital twins for construction site logistics;Construction is one of the least-digitized industries in the economy. To rein in the rising costs of building activities, digital transformation is one of the pillars that industry leaders rely on. A case in point are logistics processes which are characterized by very limited visibility and inefficient organization. To progress beyond this current state of the art, we conceptualize the idea of a lightweight digital twin for non-high-tech industries. In collaboration with a leading supplier of building materials, we explore the opportunities offered by digital silo twin capabilities. Focusing on fill level monitoring we identify diverse opportunities for generating informational, automational and transformational business value. Leveraging new information sources for the redesign of core business processes drastically increases the complexity of operational decision-making. To tap into these opportunities, we design and implement a decision support system for silo dispatch and replenishment activity.;Elsevier B.V.;Journal;Computers in Industry;2020-10-01;https://api.elsevier.com/content/abstract/scopus_id/85087681639
733;Digital twin-enabled smart modular integrated construction system for on-site assembly;Modular Integrated Construction (MiC) is a game-changing approach with enhanced quality, productivity, and sustainability, which transforms cast-in-situ into on-site assembly of prefabricated modules. On-site assembly is an uncertain and complex stage in MiC scenario, due to high variability of outside conditions, organization of multi-contractors, and geographic dispersion of activities. Information and Communication Technology (ICT) is adopted to support the reengineering of on-site assembly, however, on-site resources couldn't be efficiently and consistently digitalized and the cyber-physical interoperation is fragmented and out-of-date. Digital twin is a key enabler of ICT revolution to address these challenges towards automated and intelligent construction. This paper introduces a digital twin-enabled smart MiC system (DT-SMiCS) with a robotic demonstration for reengineered on-site assembly. On-site resources are converted into Smart MiC Objects (SMiCOs) attaching with UWB and RFID devices to collect and integrate real-time nD data, such as identity, location, cost, and construction progress. Digital twins of SMiCOs with similar properties and behaviors are instantiated from unified object-oriented templates for item-level mapping and characterizing. Through smart mobile gateway, various on-site resources and activities could be real-timely interoperated with their corresponding digital twins. Cloud-based services are provided for real-time monitoring through high-fidelity virtual models, and remote control with automatic navigations. A testbed robotic demonstration is conducted to verify DT-SMiCS for reengineered on-site assembly.;Elsevier B.V.;Journal;Computers in Industry;2022-04-01;https://api.elsevier.com/content/abstract/scopus_id/85121923542
734;Digital twin aided sustainability-based lifecycle management for railway turnout systems;Railway turnouts or so-called ‘switches and crossings’ are complex systems by nature of design and construction. Railway turnouts are used to change direction of trains from one to another. They require high-quality construction and maintenance, in order to minimise rapid degradation and component failures that could result in train derailments. Due to the complexity of railway turnouts, the efficiency and effectiveness of maintenance can be improved by integrating existing practice by Building Information Modelling (BIM). This research establishes and analyses the world's first 6D BIM for life cycle management of a railway turnout system. The BIM (Level 3)has integrated 6-dimensions of field data information based on Revit-2018 and Navisworks-2018 platforms. The digital twins of a railway turnout in 3D embrace time schedule, costs and sustainability across the whole life cycle. The use of BIM for railway turnout systems has the potential to improve the overall information flow of the turnout planning and design, manufacturing pre-assembly and logistic, construction and installation, operation and management and demolition, thereby achieving better project performance and quality. Based on integrated information of railway turnout system, the 6D BIM has the ability to assess on economic, management and sustainability, and achieve a balance among them. This is the word first to demonstrate that BIM can fully deliver its essential benefits by information sharing, easing technical communication, improving design quality, reducing of design errors, accelerating implementation, speeding up work, shortening construction duration, reducing construction costs, enhancing carbon efficiency, supporting project management, and providing its owners with higher operational efficiency over the railway turnout system life-cycle. The results reveal that embodied material emission is the main contributor towards carbon footprint, especially produced during the manufacturing stage. The reconstruction stage contributes the most expensive phase of life cycle. The insight will significantly benefit the co-value creation among engineers, project managers, technicians, and senior management team.;Elsevier Ltd;Journal;Journal of Cleaner Production;2019-08-10;https://api.elsevier.com/content/abstract/scopus_id/85065500423
735;A review of unit level digital twin applications in the manufacturing industry;"In recent years, the hype around Digital Twins (DTs) has been exponentially increasing in both industry and academia. DTs are a potential solution to increase automation and advance towards Smart Manufacturing. Manufacturing DTs have been implemented at different hierarchical levels, ranging from system of systems to unit level. Increasing computational capacity and data exchange rates can enable DT implementations for real-time applications. Several literature reviews on manufacturing DTs have been published. However, no previous paper focuses on manufacturing DTs at the unit level for which real-time control is most applicable. Simultaneously, the challenges to engineer DTs with real-time capabilities are enormous, both from a scientific and technological perspective. Therefore, we focus on DTs of single production units such as traditional machine tools, additive manufacturing machines and advanced robotic applications. In this systematic literature review, 96 papers about practical unit level DT applications found in the Scopus database using a combination of the keywords “Digital Twin”, “Production” and “Manufacturing” are reviewed. We summarize how DTs are currently implemented and operated, and what potential benefits DTs offer at the unit process level in four categories: generic reference models, services, DT content (models and data) and DT deployment (hardware and software). Following the thematic analysis, an overall discussion, summary of key contributions and identified research gaps, and outlook into future research avenues is given. Key findings of this review can be summarized as: focus on DT components versus being holistic; need to share data and models across multiple stakeholders; lack of physical fidelity of the models; stark contrast of lab scale developments and real world testing, e.g., historical data and storage related challenges; lack of clear definition of DT in industry, and missing semantic interoperability between a wide variety of domains.";Elsevier Ltd;Journal;CIRP Journal of Manufacturing Science and Technology;2023-10-01;https://api.elsevier.com/content/abstract/scopus_id/85164018738
736;Building a digital twin for additive manufacturing through the exploitation of blockchain: A case analysis of the aircraft industry;Blockchain is becoming a widespread digital technology that allows every transaction to be tracked in an inviolable way, hence making it possible to go back through the entire history of products and product components. Its idiosyncratic characteristics can be especially useful in the aircraft industry, a highly technologically-based sector, wherein manufacturers of components are governed by stringent technical standards, the aim of which is to certify and monitor the whole component production process. In addition, the sector makes significant use of additive manufacturing technologies to perform the rapid prototyping of product components, realized through the supply chain, hence reducing time-to-market, while ensuring quality and containing costs. Starting from these premises, the paper focuses on the phases characterizing the metal additive manufacturing process, in which a component for the aircraft industry can be produced and proposes a digital twin for additive manufacturing in the aircraft industry through the exploitation of Blockchain solutions. In doing so, the paper provides a conceptual answer to securing and organizing the data generated through an end-to-end additive manufacturing process in the aircraft industry and underlines how companies exploiting Blockchain can build secure and connected manufacturing infrastructure.;Elsevier B.V.;Journal;Computers in Industry;2019-08-01;https://api.elsevier.com/content/abstract/scopus_id/85065156908
737;Autonomous, context-aware, adaptive Digital Twins—State of the art and roadmap;Digital Twins are an important concept in the comprehensive digital representation of manufacturing assets, products, and other resources, comprising their design and configuration, state, and behaviour. Digital Twins provide information about and services based on their physical counterpart's current condition, history and predicted future. They are the building blocks of a vision of future Digital Factories where stakeholders collaborate via the information Digital Twins provide about physical assets in the factory and throughout the product lifecycle. Digital Twins may also contribute to more flexible and resilient Digital Factories. To achieve this, Digital Twins will need to evolve from today's expert-centric tools towards active entities which extend the capabilities of their physical counterparts. Required features include sensing and processing their environment and situation, pro-actively communicating with each other, taking decisions towards their own or cooperative goals, and adapting themselves and their physical counterparts to achieve those goals. Future Digital Twins will need to be context-aware, autonomous, and adaptive. This paper aims to establish a roadmap for this evolution. It sets the scene by proposing a working definition of Digital Twins and examines the state-of-the-art in the three topics in their relation to DTs. It then elaborates potentials for each topic mapped against the working definition, to finally identify research gaps allowing for the definition of a roadmap towards the full realisation of autonomous, context-aware, adaptive Digital Twins as building blocks of tomorrow's Digital Factories.;Elsevier B.V.;Journal;Computers in Industry;2021-12-01;https://api.elsevier.com/content/abstract/scopus_id/85116889271
738;Study on city digital twin technologies for sustainable smart city design: A review and bibliometric analysis of geographic information system and building information modeling integration;"Geographic information system (GIS) data provide geospatial data on cities and spatial analysis functions that are essential for urban design. Building information modeling (BIM) includes a digital entity of construction, a passive presentation of micro-digital information on real entities, and an active application of models in the entire life cycle realization of the architecture, engineering, and construction industries. A combination of these technologies could provide a core technology for the urban digital twin to support sustainable smart city design. Through an insightful literature review, this paper summarizes the different disciplinary classifications of GIS and BIM functional integration, distills the value of data, and discusses the ontology-based data integration approach that GIS and BIM should take in the future to conduct research on integration applications in smart cities. To verify this view, keyword analysis, co-country analysis, and co-citation and coupling analyses are conducted using CiteSpace. GIS and BIM integration has attracted much attention. However, a professional disconnect and fragmented composition pose challenges in the field of GIS and BIM integration. Future research should focus on smart city planning, updating, management; ontology-based GIS and BIM data integration platform; and operation; and the collaborative management of urban rail transportation engineering.";Elsevier Ltd;Journal;Sustainable Cities and Society;2022-09-01;https://api.elsevier.com/content/abstract/scopus_id/85132815297
739;Digital Twin and Big Data Towards Smart Manufacturing and Industry 4.0: 360 Degree Comparison;With the advances in new-generation information technologies, especially big data and digital twin, smart manufacturing is becoming the focus of global manufacturing transformation and upgrading. Intelligence comes from data. Integrated analysis for the manufacturing big data is beneficial to all aspects of manufacturing. Besides, the digital twin paves a way for the cyber-physical integration of manufacturing, which is an important bottleneck to achieve smart manufacturing. In this paper, the big data and digital twin in manufacturing are reviewed, including their concept as well as their applications in product design, production planning, manufacturing, and predictive maintenance. On this basis, the similarities and differences between big data and digital twin are compared from the general and data perspectives. Since the big data and digital twin can be complementary, how they can be integrated to promote smart manufacturing are discussed.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2018-01-12;https://api.elsevier.com/content/abstract/scopus_id/85041173790
740;The connotation of digital twin, and the construction and application method of shop-floor digital twin;"Digital twin (DT) technology provides a novel, feasible, and clear implementation path for the realization of smart manufacturing and cyber-physical systems (CPS). Currently, DT is applied to all stages of the product lifecycle, including design, production, and service, although its application in the production stage is not yet extensive. Shop-floor digital twin (SDT) is a digital mapping model of the corresponding physical shop-floor. How to build and apply SDT has always been challenging when applying DT technology in the production phase. To address the existing problems, this paper first reviews the origin and evolution of DT, including its application status in the production stage. Then, an implementation framework for the construction and application of SDT is proposed. Three key implementation techniques are explained in detail: the five-dimensional modeling of SDT; DT-based 3D visual and real-time monitoring of shop-floor operating status; and prediction of shop-floor operating status based on SDT using Markov chain. A DT-based visual monitoring and prediction system (DT-VMPS) for shop-floor operating status is developed, and the feasibility and effectiveness of the proposed method are demonstrated through the use of an engineering case study. Finally, a summary of the contributions of the paper is given, and future research issues are discussed.";Elsevier Ltd;Journal;Robotics and Computer-Integrated Manufacturing;2021-04-01;https://api.elsevier.com/content/abstract/scopus_id/85094857400
741;A Review of Digital Twin Leveraging Technology, Concepts, Tools and Industrial Applications;The mission of Digital Twin is to disseminate authoritative academic works in an effort to advance the state of the art in digital twin and inspire originality in the creation of effective, resilient, and sustainable transdisciplinary applications across a wide range of disciplines. A digital twin is an up-to-date, virtual version of a physical item or system that may be used to aid in decision-making via the use of simulation, machine learning, and logic. The term 'digital twin' refers to a digital model created to be an exact digital replica of a real thing. Several sensors relating to core functions have been included in the item. The sensors provide information on the physical object's performance in many contexts, including energy output, temperature, weather conditions, and more.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2022 1st International Conference on Computational Science and Technology, ICCST 2022 - Proceedings;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85149373647
742;Experimentable digital twins for model-based systems engineering and simulation-based development;"The concepts and methodologies behind Model-based Systems Engineering (MBSE) hold great promises concerning the development of complex systems. Various projects have been carried out successfully during the last years and demonstrated the power behind the overall concept - and the practical problems to reach the ambitious overall goals. Whereas the first steps of MBSE like the iterative modeling of requirements, designs, behaviors, and tests became standard procedures in Systems Engineering (SE), the transition to simulation often is still restricted to quite simple scenarios. Although elaborated system models deliver all the information needed, the simulation of the overall system in prospective working environments interacting with other systems is rather an exception. The problem is that there is still quite a gap between the first SE steps and the various algorithms simulation technology can offer today. Major reasons for this seem to be the resulting complexity of the system model when modeling complex interactions, the complexity of using state-of-the-art simulation technology and the absence of simulation frameworks for simulations across multiple domains and disciplines. ""Experimentable Digital Twins"", a concept originally developed for the eRobotics methodology, seem to have the potential to close the gap between SE and simulation by introducing a new structuring element to configure simulations. A new simulation system architecture integrating well-known simulation algorithms provides Virtual Testbeds for the simultaneous simulation of a network of different Digital Twins interacting with each other in various ways (i.e. a network of different systems, their components and their working environment). This approach has been successfully used for a variety of different applications in multiple research areas. As one application, it allows for the simulation-based optimization of parameters, system structure etc.";Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;11th Annual IEEE International Systems Conference, SysCon 2017 - Proceedings;2017-05-26;https://api.elsevier.com/content/abstract/scopus_id/85021452617
743;State-of-practice survey of model-based systems engineering;This paper aims to examine and document the current state of practice of model-based systems engineering (MBSE), and how organizations look toward the future. The paper is based on a survey of how MBSE has been applied and factors that influenced the perceived benefits and results. The survey was designed to evaluate the maturity and status of the implementation of MBSE (also called model-centric systems engineering), within industry, academia, and governments. The approach to the survey development is described along with the survey results. The study indicates that one of the main hurdles to introducing a model-based approach is the lack of clear and adopted organizational structures and an understanding of required conditions and needs at a management level. The survey also indicates that 50–75% of the respondents noted some improvement or a significant improvement across almost all systems engineering tasks.;John Wiley and Sons Inc.P.O.Box 18667NewarkNJ 07191-8667;Journal;Systems Engineering;2019-03-01;https://api.elsevier.com/content/abstract/scopus_id/85052963713
744;Meta-modeling of high-fidelity FEA simulation for efficient product and process design in additive manufacturing;Finite element analysis (FEA) has been widely adopted to identify potential defects in additive manufacturing (AM) processes. For personalized product realization, it is necessary to validate a number of heterogeneous product and process designs before or during manufacturing by using FEA. Multi-fidelity FEA simulations can be readily implemented with different capabilities in terms of simulation accuracy. However, due to its complexity, high-fidelity FEA simulation is time-consuming and decreases the efficiency of product realization in AM, while low-fidelity FEA simulation has fast computation speed yet limited capability. Hence, our objective is to improve the capability of FEA by providing an efficient data-driven model. In this research, a Gaussian process-constrained general path model is proposed to approximate the high-fidelity FEA simulation results based on low-fidelity results voxel-by-voxel. The proposed model quantifies the heterogeneous discrepancies between low- and high-fidelity FEA simulation results by incorporating the product design information (e.g., Cartesian coordinates of deposition sequence) and process design information from inputs of FEA simulation (e.g., input heat). Therefore, it enables the validation of new product and process designs based on the simulation results with the desired capability in a timely manner. The advantages of the proposed method are illustrated by FEA simulations of the fused deposition modeling (FDM) process with two levels of fidelity (i.e., low- and high-fidelity).;Elsevier B.V.;Journal;Additive Manufacturing;2020-10-01;https://api.elsevier.com/content/abstract/scopus_id/85087520691
745;Knowledge map and forecast of digital twin in the construction industry: State-of-the-art review using scientometric analysis;"With the advancement of Industry 4.0 and the development of science and technology, industries have seen the advantages of digital twin (DT) implementations and concepts. Although the construction industry is still in the early stage of DT development and implementation, it is urgent for the industry to have a DT agenda. This paper identifies 1158 related bibliographic records from the Web of Science and 745 records from the Derwent Patent Database and quantitatively analyzed them to describe patterns of publications. Two knowledge mapping tools were selected to visualize and analyze the literature in the relevant scientific domain. Then, we integrated clustering, knowledge mapping, and network analysis methods to show the current foci and future directions of DT-MT derived from the data of time distribution, journal areas, and subject distribution. The results indicate that DT is a cross-disciplinary information technology with great development potential, and its development in the construction industry is scattered with the leading advancement in the manufacturing of construction materials and components. The derived knowledge map shows three stages of construction DT, including (1) data collection and creation of DT framework and database; (2) implementation of planning and design modules in detail and control of construction sites; and (3) carrying out asset management and fault prediction in the operation and maintenance phase of projects. The novelty of this paper is the specific analysis of DT in the construction industry. This study adds value to the architecture, engineering, and construction industries by shedding light on the focus of DT practical applications and the formation of a development path of construction DT.";Elsevier Ltd;Journal;Journal of Cleaner Production;2023-01-10;https://api.elsevier.com/content/abstract/scopus_id/85143719809
746;Digital twin-driven rapid reconfiguration of the automated manufacturing system via an open architecture model;Increasing individualization demands in products call for high flexibility in the manufacturing systems to adapt changes. This paper proposes a novel digital twin-driven approach for rapid reconfiguration of automated manufacturing systems. The digital twin comprises two parts, the semi-physical simulation that maps data of the system and provides input data to the second part, which is optimization. The results of the optimization part are fed back to the semi-physical simulation for verification. Open-architecture machine tool (OAMT) is defined and developed as a new class of machine tools comprising a fixed standard platform and various individualized modules that can be added and rapidly swapped. Engineers can flexibly reconfigure the manufacturing system for catering to process planning by integrating personalized modules into its OAMTs. Key enabling techniques, including how to twin cyber and physical system and how to quickly bi-level program the production capacity and functionality of manufacturing systems to adapt rapid changes of products, are detailed. A physical implementation is conducted to verify the effectiveness of the proposed approach to achieving improved system performance while minimizing the overheads of the reconfiguration process by automating and rapidly optimizing it.;Elsevier Ltd;Journal;Robotics and Computer-Integrated Manufacturing;2020-06-01;https://api.elsevier.com/content/abstract/scopus_id/85076833589
747;A generic tri-model-based approach for product-level digital twin development in a smart manufacturing environment;Smart manufacturing, as an emerging manufacturing paradigm, leverages massive in-context data from manufacturing systems for intelligent decision makings. In such context, Cyber-Physical Systems (CPS) play a key role in digitizing manufacturing systems and integrating multiple systems together for collaborative works. Amongst different levels of smartness and connectedness of CPS, Digital Twin (DT), as an exact digital copy of a physical object or system including its properties and relationship with the environment, has a significant impact on realizing smart manufacturing. A DT constantly synchronizes with its physical system and provides real-time high-fidelity simulations of the system and offers ubiquitous control over the system. Despite its great advantages, few works have been discussed about DT reference models, let alone a generic manner to establish it for smart manufacturing. Aiming to fill the gap, this research introduces a generic CPS system architecture for DT establishment in smart manufacturing with a novel tri-model-based approach (i.e. digital model, computational model and graph-based model) for product-level DT development. The tri-model works concurrently to simulate real-world physical behaviour and characteristics of the digital model. To validate the proposed architecture and approach, a case study of an open source 3D printer DT establishment is further conducted. Conclusions and future works are also highlighted to provide insightful knowledge to both academia and industries at last.;Elsevier Ltd;Journal;Robotics and Computer-Integrated Manufacturing;2020-08-01;https://api.elsevier.com/content/abstract/scopus_id/85079352073
748;A digital-twin visualized architecture for Flexible Manufacturing System;The new generation of industrial 4.0 intelligent manufacturing system consists of Human-Cyber-Physical System (HCPS), integrating human with cyber and physical systems. In manufacturing, a digital-twin visualization architecture is to solve the human-machine interaction problem that concerns digital-twin modeling on the Cyber-Physical (C-P) side and on the Human-Cyber side. Although there are many related research and applications, there lacks attention in terms of full life cycle functional services and lightweight architecture. This paper presents a general architecture of digital-twin visualization for flexible manufacturing systems (FMS). How the digital-twin C-P modeling of multi-source heterogeneous information can be described is investigated and how the 3D visualized human-machine interaction with digital-twin scenario information is explored in the proposed architecture. Besides, the visualization method of high-value information, relating to the life cycle planning, design, debugging and service stages, is studied and discussed thoroughly. Also, a digital-twin modeling concept of “Geometric information (G)-Historical samples (H)-Object attribute (O)-Snapshot collection (S)-Topology constraint (T)” (GHOST) is proposed, and methods for developing virtual digital-twin scenes architecture are presented. Based on the proposed modeling concept of GHOST for digital-twin, prototypes have been developed for the general platform of digital-twin RESTful services and the cross-platform general visual mock-up software. Experimental results show that this method is effective in the FMS lifecycle in various aspects.;Elsevier B.V.;Journal;Journal of Manufacturing Systems;2021-07-01;https://api.elsevier.com/content/abstract/scopus_id/85107675373
749;Digital Twin-driven smart manufacturing: Connotation, reference model, applications and research issues;This paper reviews the recent development of Digital Twin technologies in manufacturing systems and processes, to analyze the connotation, application scenarios, and research issues of Digital Twin-driven smart manufacturing in the context of Industry 4.0. To understand Digital Twin and its future potential in manufacturing, we summarized the definition and state-of-the-art development outcomes of Digital Twin. Existing technologies for developing a Digital Twin for smart manufacturing are reviewed under a Digital Twin reference model to systematize the development methodology for Digital Twin. Representative applications are reviewed with a focus on the alignment with the proposed reference model. Outstanding research issues of developing Digital Twins for smart manufacturing are identified at the end of the paper.;Elsevier Ltd;Journal;Robotics and Computer-Integrated Manufacturing;2020-02-01;https://api.elsevier.com/content/abstract/scopus_id/85070213247
750;Digital twin-enabled reconfigurable modeling for smart manufacturing systems;The digital twin-based manufacturing system is a typical representative of smart manufacturing and has a number of advantages beyond the state of the art. However, when a manufacturing system needs to be reconfigured to meet new requirements of production, manual reconfiguration is time-consuming and high labor cost because of the complexity of the digital twin-based manufacturing system and the imperfection of related models. This problem will be even worse if there are industrial robots with characteristics of complex functions and inflexible programming in the manufacturing system. This paper presents a five-dimensional fusion model of a digital twin virtual entity for robotics-based smart manufacturing systems to support automatic reconfiguration, which can not only realistically describes physical manufacturing resources, but also represents the capabilities and dependencies of the digital twins. Reconfigurable strategies based on service function blocks, which can improve the reusability of functions and algorithms, are proposed to make the robotics-based manufacturing system satisfy the various reconfigurable requirements of different granularities and goals. Finally, a prototype system is developed to demonstrate the performance of the reconfigurable digital twin-based manufacturing system, which can improve the operation efficiency of such systems for carrying out the reconfiguring production tasks in a flexible way.;Taylor and Francis Ltd.;Journal;International Journal of Computer Integrated Manufacturing;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85077166195
751;Digital twin in manufacturing: conceptual framework and case studies;The digital twin (DT) concept has a key role in the future of the smart manufacturing industry. This review paper aims to investigate the development of the digital twin concept, its maturity and its vital role in the fourth industrial revolution. Having identified its potential functionalities for the digitalisation of the manufacturing industry, the digital twin concept, its origin and perspectives from both the academic and industrial sectors are presented. The identified research gaps, trends and technical limitations hampering the implementation of digital twins are also discussed. In particular, this review attempts to address the research question on how the digital twin concept can support the realisation of an integrated, flexible and collaborative manufacturing environment which is one of the goals projected by the fourth industrial revolution. To address this, a conceptual framework supporting an integrated product-process digital twin for application in digitised manufacturing is proposed. The application and benefits of the proposed framework are presented in three case studies.;Taylor and Francis Ltd.;Journal;International Journal of Computer Integrated Manufacturing;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85123736057
752;Digital Twin-driven machining process for thin-walled part manufacturing;Thin-walled parts are widely used in the aerospace, shipbuilding, and automotive industry, but due to its unique structure and high accuracy requirements, which leads to an increase in scrapped parts, high cost in production, and a more extended period in the trial machining process. However, to adapt to fast production cycles and increase the efficiency of thin-walled parts machining, this paper presents a Digital Twin-driven thin-walled part manufacturing framework to allow the machine operator to manage the product changes, make the start-up phases faster and more accurate. The framework has three parts: preparation, machining, and measurement, driven by Digital Twin technologies in detail. By establishing and updating the workpiece Digital Twin under a different status, various manufacturing information and data can be integrated and available to machine operators and other Digital Twins. It can serve as a guideline for establishing the machine tool and workpiece Digital Twin and integrating them into the machining process. It provides the machine operator opportunities to interact with both the physical manufacturing process and its digital data in real-time. The digital representation of the physical process can support them to manage the trial machining from different aspects. In addition, a demonstrative case study is presented to explain the implementation of this framework in a real manufacturing environment.;Elsevier B.V.;Journal;Journal of Manufacturing Systems;2021-04-01;https://api.elsevier.com/content/abstract/scopus_id/85105002645
753;Meta-model-based shop-floor digital twin architecture, modeling and application;Digital twin is regarded as the virtual counterpart of physical entities, which can mirror the physical behavior and performance. Digital twin technology provides strong support for the achievement of cyber-physical system and intelligent manufacturing. Many investigations have been carried out for the digital twin of specific products. However, there are less researches on digital twin in the shop-floor domain, and there is a lack of model-driven digital twin comprehensive architecture. The modeling approach to the full lifecycle of digital twin is not considered enough. This paper proposes a meta-model-based shop-floor digital twin construction approach and a comprehensive architecture. A meta-model based on RAMI 4.0 is constructed, which provide a novel idea for the description of manufacturing resources and their status. The proposed shop-floor digital twin architecture consists of three key implementation elements: the meta-model construction, data modeling (including data interaction between cyber-physical spaces) and constructing different integration level models of shop-floor digital twin based on iteration feedback between the demands and models. The proposed approach is validated through a case study of the fischer learning factory 4.0.;Elsevier Ltd;Journal;Robotics and Computer-Integrated Manufacturing;2023-12-01;https://api.elsevier.com/content/abstract/scopus_id/85160515920
754;How to model and implement connections between physical and virtual models for digital twin application;Digital twin (DT) is a virtual mirror (representation) of a physical world or a system along its lifecycle. As for a complex discrete manufacturing system (DMS), it is a digital model for emulating or reproducing the functions or actions of a real manufacturing system by giving the system simulation information or directly driven by a real system with proper connections between the DT model and the real-world system. It is a key building block for smart factory and manufacturing under the Industry 4.0 paradigm. The key research question is how to effectively create a DT model during the design stage of a complex manufacturing system and to make it usable throughout the system's lifecycle such as the production stage. Given that there are some existing discussions on DT framework development, this paper focuses on the modeling methods for rapidly creating a virtual model and the connection implementation mechanism between a physical world production system at a workshop level and its mirrored virtual model. To reach above goals, in this paper, the discrete event system (DES) modeling theory is applied to the three-dimension DT model. First, for formally representing a manufacturing system and creating its virtual model, seven basic elements: controller, executor, processor, buffer, flowing entity, virtual service node and logistics path of a DMS have been identified and the concept of the logistics path network and the service cell is introduced to uniformly describe a manufacturing system. Second, for implementing interconnection and interaction, a new interconnection and data interaction mechanism between the physical system and its virtual model for through-life applications has been designed. With them, each service cell consists of seven elements and encapsulates input/output information and control logic. All the discrete cells are constructed and mapped onto different production-process-oriented digital manufacturing modules by integrating logical, geometric and data models. As a result, the virtual-physical connection is realized to form a DT model. The proposed virtual modeling method and the associated connection mechanism have been applied to a real-world workshop DT to demonstrate its practicality and usefulness.;Elsevier B.V.;Journal;Journal of Manufacturing Systems;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85085651159
755;Modular based flexible digital twin for factory design;Factory design offers many promising capabilities regarding productivity and floor utilization. To evaluate the design and help the designer to escape design flaws, digital twin is proposed to support factory design. With considering of frequently changing in design phase, a modular approach was proposed to help building flexible digital twin and conducting corresponding changes. By using flexible digital twin, designer can quickly evaluate different designs and find design flaws in an easy way. And consequently time saving can be benefited. A case study of application on real factory is presented to illustrate the advantage.;Springer Verlagservice@springer.de;Journal;Journal of Ambient Intelligence and Humanized Computing;2019-03-13;https://api.elsevier.com/content/abstract/scopus_id/85050657407
756;Design and implementation of a digital twin application for a connected micro smart factory;Recently, manufacturing concepts, such as personalized production and distributed manufacturing, have attracted attention owing to the ongoing revolution in industrial technology. Connected micro smart factories in factory-as-a-service system with these new manufacturing paradigms and Industrial Internet of Things (IIoT) are inefficient in terms of cost and production. To solve these problems, a digital twin, which uses a digital representation of a process, with the same configuration of manufacturing elements, synchronized information, and functional units, was designed and implemented. The digital twin utilizes the latest information from the Internet to gather data from IIoT devices and interoperates in a variety of applications. In addition, it derives the components of a detailed design of the digital twin application, to which it performs procedure definition. This research differs from other digital twin studies that concentrate on the prognostic health management of only a single machine. This study could help managers organize the benefits of utilization through a digital twin based on a hierarchy as they could receive real-time monitoring of the present, tracking information from the past, and operational decision-making support for the future. In addition, the proposed application reduces the cost and production inefficiencies, ultimately resulting in the efficient operation of a manufacturing system.;Taylor and Francis Ltd.michael.wagreich@univie.ac.at;Journal;International Journal of Computer Integrated Manufacturing;2019-06-03;https://api.elsevier.com/content/abstract/scopus_id/85063878454
757;Digital twin-based designing of the configuration, motion, control, and optimization model of a flow-type smart manufacturing system;Digital twins can achieve hardware-in-the-loop simulation of both physical equipment and cyber model, which could be used to avoid the considerable cost of manufacturing system reconfiguration if the design deficiencies are found in the deployment process of the traditional irreversible design approach. Based on the digital twin technology, a quad-play CMCO (i.e., Configuration design-Motion planning-Control development-Optimization decoupling) design architecture is put forward for the design of the flow-type smart manufacturing system in the Industry 4.0 context. The iteration logic of the CMCO design model is expounded. Two key enabling technologies for enabling the customized and software-defined design of flow-type smart manufacturing systems are presented, including the generalized encapsulation of the quad-play CMCO model and the digital twin technique. A prototype of a digital twin-based manufacturing system design platform, named Digital Twin System, is presented based on the CMCO model. The digital twin-based design platform is verified with a case study of the hollow glass smart manufacturing system. The result shows that the Digital Twin System-based design approach is feasible and efficient.;Elsevier B.V.;Journal;Journal of Manufacturing Systems;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85083837378
758;A Requirements Driven Digital Twin Framework: Specification and Opportunities;Among the tenets of Smart Manufacturing (SM) or Industry 4.0 (I4.0), digital twin (DT), which represents the capabilities of virtual representations of components and systems, has been cited as the biggest technology trend disrupting engineering and design today. DTs have been in use for years in areas such as model-based process control and predictive maintenance, however moving forward a framework is needed that will support the expected pervasiveness of DT technology in the evolution of SM or I4.0. A set of requirements for a DT framework has been derived from analysis of DT definitions, DTs in use today, expected DT applications in the near future, and longer-term DT trends and the DT vision in SM. These requirements include elements of re-usability, interoperability, interchangeability, maintainability, extensibility, and autonomy across the entire DT lifecycle. A baseline framework for DT technology has been developed that addresses many aspects of these requirements and enables the addressing of the requirements more fully through additional specification. The baseline framework includes a definition of a DT and an object-oriented (O-O) architecture for DTs that defines generalization, aggregation and instantiation of DT classes. Case studies using and extending the baseline framework illustrate its advantages in supporting DT solutions and trends in SM.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85086995372
759;Digital Twin Shop-Floor: A New Shop-Floor Paradigm Towards Smart Manufacturing;With the developments and applications of the new information technologies, such as cloud computing, Internet of Things, big data, and artificial intelligence, a smart manufacturing era is coming. At the same time, various national manufacturing development strategies have been put forward, such as Industry 4.0, Industrial Internet, manufacturing based on Cyber-Physical System, and Made in China 2025. However, one of specific challenges to achieve smart manufacturing with these strategies is how to converge the manufacturing physical world and the virtual world, so as to realize a series of smart operations in the manufacturing process, including smart interconnection, smart interaction, smart control and management, etc. In this context, as a basic unit of manufacturing, shop-floor is required to reach the interaction and convergence between physical and virtual spaces, which is not only the imperative demand of smart manufacturing, but also the evolving trend of itself. Accordingly, a novel concept of digital twin shop-floor (DTS) based on digital twin is explored and its four key components are discussed, including physical shop-floor, virtual shop-floor, shop-floor service system, and shop-floor digital twin data. What is more, the operation mechanisms and implementing methods for DTS are studied and key technologies as well as challenges ahead are investigated, respectively.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2017-09-24;https://api.elsevier.com/content/abstract/scopus_id/85030752762
760;Data Construction Method for the Applications of Workshop Digital Twin System;Data is the key to the operation of manufacturing workshop Digital Twin System (DTS) and also supports the top-level applications of DTS. However, manufacturing data has the characteristics of coupling and large-amount, which lead to inefficient and inaccurate operations of applications. In order to provide stable and efficient data support for the applications of DTS, this paper proposed a data construction method. The framework of data construction is designed based on the functional requirements, which are analyzed according to the characteristics of manufacturing data. Then, module implementation of the framework, including data representation module, data organization module and data management module, is introduced in detail. Finally, application of cutting tool wear prediction is taken as a case study to show the feasibility and effectiveness of the proposed data construction method.;Elsevier B.V.;Journal;Journal of Manufacturing Systems;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85080033682
761;Digital twin-based smart production management and control framework for the complex product assembly shop-floor;Digital twin technology is considered as a key technology to realize cyber-physical systems (CPS). However, due to the complexity of building a digital equivalent in virtual space to its physical counterpart, very little progress has been achieved in digital twin application, especially in the complex product assembly shop-floor. In this paper, we propose a framework of digital twin-based smart production management and control approach for complex product assembly shop-floors. Four core techniques embodied in the framework are illustrated in detail as follows: (1) real-time acquisition, organization, and management of the physical assembly shop-floor data, (2) construction of the assembly shop-floor digital twin, (3) digital twin and big data-driven prediction of the assembly shop-floor, and (4) digital twin-based assembly shop-floor production management and control service. To elaborate how to apply the proposed approach to reality, we present detailed implementation process of the proposed digital twin-based smart production management and control approach in a satellite assembly shop-floor scenario. Meanwhile, the future work to completely fulfill digital twin-based smart production management and control concept for complex product assembly shop-floors are discussed.;Springer London;Journal;International Journal of Advanced Manufacturing Technology;2018-04-01;https://api.elsevier.com/content/abstract/scopus_id/85041548794
762;A multi-scale modeling method for digital twin shop-floor;Digital twin has attracted more and more attentions in the past few years. To put digital twin into practice, modeling is one of the most important foundations. Under this background, some modeling research on digital twin shop-floor which is regarded as the basic unit for realizing smart manufacturing has been carried out. However, current research pays scant attention to the multi-scale features of shop-floor, which hinders the effective application of digital twin shop-floor. As for the problem about how to realize the model construction from the perspective of time-scale and space-scale, this paper firstly proposed a multi-layer modeling framework for supporting model construction from unit layer to system layer to system of system layer. Moreover, the mechanism of model changes over time is also considered. Then, the specific procedures and methods of model assembly, model fusion and model update towards machines and shop-floor are discussed respectively. Finally, a satellite AIT(Assembly, Integration and Test) shop-floor is chosen as the case to validate the correctness and feasibility of proposed framework, procedures and methods.;Elsevier B.V.;Journal;Journal of Manufacturing Systems;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85122468289
763;A data- And knowledge-driven framework for digital twin manufacturing cell;Intelligent manufacturing is regarded as the next generation manufacturing mode with powerful learning and cognitive capacities enabled by new generation information technologies such as Internet of Things, big data analytics, edge computing and artificial intelligence. To provide an insight into intelligent manufacturing, this paper takes autonomous manufacturing cell as implementation scenario and proposes a data- and knowledge-driven framework for digital twin manufacturing cell (DTMC), which could support autonomous manufacturing by an intelligent perceiving, simulating, understanding, predicting, optimizing and controlling strategy. In addition, three key enabling technologies including digital twin model, dynamic knowledge bases and knowledge-based intelligent skills for supporting the above strategy are analyzed. Then, the implementing methods of DTMC are introduced through a thus constructed digital twin robot, and the usage of data and knowledge for supporting the automous operations of DTMC is also discussed. Finally, benefits of DTMC in smart product-service systems (PSS) and its current challenges are summarized.;Elsevier B.V.;Conference Proceeding;Procedia CIRP;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85070560451
764;Knowledge-driven digital twin manufacturing cell towards intelligent manufacturing;Rapid advances in new generation information technologies, such as big data analytics, internet of things (IoT), edge computing and artificial intelligence, have nowadays driven traditional manufacturing all the way to intelligent manufacturing. Intelligent manufacturing is characterised by autonomy and self-optimisation, which proposes new demands such as learning and cognitive capacities for manufacturing cell, known as the minimum implementation unit for intelligent manufacturing. Consequently, this paper proposes a general framework for knowledge-driven digital twin manufacturing cell (KDTMC) towards intelligent manufacturing, which could support autonomous manufacturing by an intelligent perceiving, simulating, understanding, predicting, optimising and controlling strategy. Three key enabling technologies including digital twin model, dynamic knowledge bases and knowledge-based intelligent skills for supporting the above strategy are analysed, which equip KDTMC with the capacities of self-thinking, self-decision-making, self-execution and self-improving. The implementing methods of KDTMC are also introduced by a thus constructed test bed. Three application examples about intelligent process planning, intelligent production scheduling and production process analysis and dynamic regulation demonstrate the feasibility of KDTMC, which provides a practical insight into the intelligent manufacturing paradigm.;Taylor and Francis Ltd.michael.wagreich@univie.ac.at;Journal;International Journal of Production Research;2020-02-16;https://api.elsevier.com/content/abstract/scopus_id/85065139151
765;Construction of intelligent integrated model framework for the workshop manufacturing system via digital twin;With the boosting development of the advanced manufacturing industry in the world, the original production pattern transformed from the traditional industries into the intelligence mode is completed with the least delay possible, which are still facing new challenges. The timeliness, stability, and reliability of them are significantly restricted due to the lack of real-time communication. Therefore, a model framework of intelligent workshop manufacturing system based on a digital twin is proposed in this paper, driving the deep information integration among the physical entity, data collection, and information decision-making. The traditional digital twin of conceptualization and fuzziness needs to be refined, optimized, and upgraded on the basis of the four-dimension collaborative model thinking. The model framework of a refined nine-layer intelligent digital twin is established. Firstly, the physical evaluation is refined into entity layer, auxiliary layer, and interface layer, scientific managing the physical resources and the instrument, and coordinating the overall system. Secondly, dividing the data evaluation into the data layer and the processing layer can greatly improve the flexible response-ability and ensure the synchronization of the real-time data. Finally, the system evaluation is subdivided into information layer, algorithm layer, scheduling layer, and functional layer, developing flexible manufacturing plan more reasonably, shortening the production cycle, and reducing logistics cost. Simultaneously, combining SLP and artificial bee colonies is applied to investigate the production system optimization of the textile workshop. The results indicate that the production efficiency of the optimized production system is increased by 34.46%.;Springer Science and Business Media Deutschland GmbH;Journal;International Journal of Advanced Manufacturing Technology;2022-02-01;https://api.elsevier.com/content/abstract/scopus_id/85116796365
766;Construction method of shop-floor digital twin based on MBSE;Digital twin (DT) technology is essential for achieving the fusion of virtual-real cyber-physical systems. Academics and companies have made great strides in the theoretical research and case studies of constructing the shop-floor digital twin (SDT), which is the premise of applying DT technology on the shop floor. A shop floor is a large complex system that involves many elements including people, machines, materials, methods, and the environment and processes, such as the technical flow, business process, logistics, and control flow. However, most of the developed cases lack a hierarchical, structured and modularized implementation framework for the development of an SDT system, which leads to problems such as a low reuse rate of the system blocks, lack of scalability, and high upgrade and maintenance costs. In response to these issues, we propose a construction method of the DT for the shop floor based on model-based systems engineering from the perspective of the system. In this method, a comprehensive DT model for the shop floor is gradually constructed by using system modeling language, the modeling method “MagicGrid,” and the “V model” of systems engineering. The model includes four dimensions of the shop-floor requirements, structure, behavior, and parameters, as well as three stages (the problem domain, solution domain, and implementation domain), and connects nine steps of the “V model,” including the system requirements, system architecture, subsystem implementation, subsystem integration, and system verification. Then, based on an example of a real NC machining shop floor, subsystems including a visualization system, synchronization system, and simulation system, are discussed. Finally, the functions of the integrated systems are verified based on the requirements, including the real-time synchronization of “man, machine, material, and method” and the transient simulation in real time. The numerical indicators of the integrated system are verified, including the model completeness and synchronization timeliness.;Elsevier B.V.;Journal;Journal of Manufacturing Systems;2021-07-01;https://api.elsevier.com/content/abstract/scopus_id/85106942746
767;The emergence of cognitive digital twin: vision, challenges and opportunities;As a key enabling technology of Industry 4.0, Digital Twin (DT) has been widely applied to various industrial domains covering different lifecycle phases of products and systems. To fully realize the Industry 4.0 vision, it is necessary to integrate multiple relevant DTs of a system according to a specific mission. This requires integrating all available data, information and knowledge related to the system across its entire lifecycle. It is a challenging task due to the high complexity of modern industrial systems. Semantic technologies such as ontology and knowledge graphs provide potential solutions by empowering DTs with augmented cognitive capabilities. The Cognitive Digital Twin (CDT) concept has been recently proposed which reveals a promising evolution of the current DT concept towards a more intelligent, comprehensive, and full lifecycle representation of complex systems. This paper reviews existing studies relevant to the CDT concept, and further explores its definitions and key features. To facilitate CDT development, a reference architecture is proposed based on the RAMI4.0 and some other existing architectures. Moreover, some key enabling technologies and several application scenarios of CDT are introduced. The challenges and opportunities are discussed in the end to boost future studies.;Taylor and Francis Ltd.;Journal;International Journal of Production Research;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85121805559
768;Digital twins of product families in aviation based on an MBSE-assisted approach;In this paper an approach to combine the basic concept of Digital Twins with research in product family development applied to civil aviation is presented. Concomitant benefits but also challenges regarding the management of information are introduced as well as the possibility to solve them by using the tools and methods of Model-Based Systems Engineering. As this conjoins three different topics, the basics of each of them in reference to the approach is introduced before they are subsequently combined. In the process, respective past and future research is presented as well.;Elsevier B.V.;Conference Proceeding;Procedia CIRP;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85107828851
769;Operationalizing digital twins through model-based systems engineering methods;In recent years there has been increased demand for readiness and availability metrics across many industries and especially in national defense to enable data-driven decision making at all levels of planning, maintenance, and operations, and in leveraging integrated models that inform stakeholders of current operational system health and performance metrics. The digital twin (DT) has been identified as a promising approach for deploying these models to fielded systems although several challenges exist in wide adoption and implementation. Two challenges examined in this article are that the nature of DT development is a system-specific endeavor, and the development is usually an additional effort that begins after initial system fielding. A fundamental challenge with DT development, which sets it apart from traditional models, is the DT itself is treated as a separate system, and therefore the physical asset/DT construct becomes a system-of-systems problem. This article explores how objectives in DT development align with those of model-based systems engineering (MBSE), and how the MBSE process can answer questions necessary to define the DT. The key benefits to the approach are leveraging work already being performed during system synthesis and DT development is pushed earlier in a system's lifecycle. This article contributes to the definition and development processes for DTs by proposing a DT development model and path, a method for scoping and defining requirements for a DT, and an approach to integrate DT and system development. An example case study of a Naval unmanned system is presented to illustrate the contributions.;John Wiley and Sons IncPostfach 10 11 61, 69451 WeinheimBoschstrabe 12, 69469 Weinheim, Deutschland69469info@wiley.com;Journal;Systems Engineering;2020-11-01;https://api.elsevier.com/content/abstract/scopus_id/85092395809
770;Systems engineering and digital twin: a vision for the future of cruise ships design, production and operations;Cruise ships are among the most complex and demanding products of the shipbuilding industry. The very special “payload” and exclusive operational profile, i.e. passengers looking for leisure and entertainment, imply outstanding performances in terms of safety standards and customer satisfaction. Attention to environment is relevant as well, since these ships are used to operate in spectacular marine ecosystems. The need of European shipyards to continuously progress to preserve the market leadership requires a virtuous evolution of the ship design process projected on a life cycle perspective. In this regard Systems Engineering appears to be a robust and reliable paradigm, able to provide the necessary comprehensive view of the cruise ship system as a whole together with a systematic methodological framework that, among the other advantages, enables the active and constructive participation of all the involved stakeholders in the decision-making process. In particular, Systems Engineering strongly relies on the so-called model-based engineering to share, integrate, combine and improve the level of details relevant to the system under development. In this paper the digital twin model will be discussed as a natural evolution of above-mentioned model-based engineering and its utilization in the shipbuilding field will be described as a very promising application especially in the field of cruise ships.;Springerspringer@springer.it;Journal;International Journal on Interactive Design and Manufacturing;2020-03-01;https://api.elsevier.com/content/abstract/scopus_id/85074479906
771;A Complexity Analysis Approach for Model-based System Engineering;With the increasing complexity of the highly engineered products, Model-based Systems Engineering (MBSE) is proposed to support the complexity management of the product development. As the basic of complexity management, complexity analysis is used to measure the system complexity for system solution trade-offs. Using traditional MBSE approaches, system architectures of product are formalized as MBSE models whose complexity measurement provides cues to quantitative trade-offs. In this paper, an MBSE approach is proposed to support complex analysis using qualitative and quantitative approaches. A GOPPRR approach is first proposed to support MBSE formalisms. Then a complexity measurement formula is used to calculate the structure complexity of the MBSE models. Finally, through a tool-chain developed based on Open Services for Lifecycle Collaboration (OSLC), a visualization tool is used to analyze the system complexity by measuring and visualizing the model complexity. A case study is proposed to evaluate the potentials of this approach for supporting product trade-offs. From the results, the approach enables to calculate complexity of MBSE models and virtualizes the model topologies.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;SOSE 2020 - IEEE 15th International Conference of System of Systems Engineering, Proceedings;2020-06-01;https://api.elsevier.com/content/abstract/scopus_id/85091650491
772;A visualization framework for product manufacturing data;Model-based systems engineering (MBSE) plays a vital role in complex product development. In order to make the system modeling processes consistent with the business processes of the industry, it is necessary to use the product lifecycle management (PLM) system to manage system models. In this paper a SysML-based domain specific meta-model is proposed to support a visualization framework that includes graphics and data synchronization, which enables PLM software to present the product manufacturing data and models under the practicing of MBSE. Product manufacturing process and data are described, and the allocation of resource is represented in the early design phase.;Elsevier B.V.;Conference Proceeding;Procedia CIRP;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85121646029
773;A Metamodel for the Manufacturing Process Information Modeling;Since the manufacturing process information and their mutual relationship are complex and diverse, the clear and accurate description and modeling of manufacturing process information is a challenge in related study of manufacturing process. Considering the diversity of the process data, a four-layer framework for manufacturing process information modeling based on metamodel is proposed. A 4-tuple manufacturing process information metamodel is specified and the concepts and relationships of the manufacturing process information are represented by UML. Following the four-layer hierarchical modeling procedures in the framework, manufacturing process information can be modeled from metamodel to model in consistence with their data relationships and representations. An instance of information model regarding to machining process is developed for verification. This work provides a systematic and standardized modeling method and information expression mechanism for manufacturing process information modeling.;Elsevier B.V.;Conference Proceeding;Procedia CIRP;2016-01-01;https://api.elsevier.com/content/abstract/scopus_id/85006974309
774;Towards a flexible process-independent meta-model for production data;Data integration is a considerable challenge when investigating information sources from a multi-step manufacturing process. The interpretation of the process data profoundly depends on the incurred meta-data. However, during most data aggregating processes along the production chain, accompanying meta-information of vital importance is lost. To address this shortcoming, we propose a flexible and process-independent meta-model for efficient data integration for multi-step manufacturing processes. The product-oriented model unites process-and meta-data to reflect their mutual relationships within the manufacturing process. The context provided by the meta-information enables automatic data analysis for Predictive Quality applications in a cross-company setting.;Elsevier B.V.;Conference Proceeding;Procedia CIRP;2021-01-01;https://api.elsevier.com/content/abstract/scopus_id/85106424431
775;ADAPT - A decision-model-based Approach for Modeling Collaborative Assembly and Manufacturing Tasks;Modeling assembly and manufacturing tasks accomplished by machines (i.e., robots) using offline programming is quite common today. Considering lot-size-one products human work is still necessary, whereas human tasks are often not considered during the modeling and offline programming process. Therefore this work presents a generic approach, which provides the ability to model variable work tasks of humans and machines together including the variability of any process data using a runtime-decision model. Depending on the detail level of the model it is possible to generate various assets such as work instructions, machine programs or human-machine interfaces. The ADAPT (Asset-Decision-Action-Property-RelaTionship) modeling approach is initially illustrated using a common LEGO assembly use case. Additionally we present a first implementation of a BPMN-based workflow designer that enables the user to model assembly and manufacturing processes in an intuitive way.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - IEEE 16th International Conference on Industrial Informatics, INDIN 2018;2018-09-24;https://api.elsevier.com/content/abstract/scopus_id/85055532547
776;Resource virtualization: A core technology for developing cyber-physical production systems;Smart factory in the context of Industry 4.0 is the next wave of smart manufacturing solution to empower companies to rapidly configure manufacturing facilities and processes to enable the fast production of individualized products at change scales. A key enabling technology for developing a smart factory is resource virtualization or creation of digital twins. The presented research fills the gap that the industry needs a practical methodology to enable themselves to easily virtualize their manufacturing assets for developing a smart factory solution. A test-driven resource virtualization framework is proposed as the recommendation for the industry to adopt to create digital twins for a smart factory. The proposed framework draws inspiration from past resource virtualization outcomes with special attention paid to the usability of the proposed framework in a business environment. It provides a straightforward process for companies to create digital twins by specifying the digital twin hierarchy, the information to be modeled, and the modeling method. To validate the proposed framework, a case study was undertaken at an international company, to create digital twins for all their manufacturing resources. The testing result showed that the proposed resource virtualization framework and developed tools are easy to use in a practical business environment to virtualize complex factory setups in the cyberspace.;Elsevier B.V.;Journal;Journal of Manufacturing Systems;2018-04-01;https://api.elsevier.com/content/abstract/scopus_id/85046643014
777;An eXtended manufacturing integrated system for feature-based manufacturing with STEP-NC;Computer Numerical Control (CNC) feature-based programming with STandard for the Exchange of Product data model-compliant Numerical Control extends the collaborative model of manufacturing data exchange all along the numerical data chain. This study considers the mutations related to this approach from the manufacturing system level to the industrial enterprise as a whole. The eXtended Manufacturing Integrated System concept is introduced to fill in the gap of the current manufacturing data exchange bottleneck. It is composed of eXtended Computer Aided Design (CAD) and eXtended CNC systems to link the CAD model to the real machined part through the Manufacturing Information Pipeline. The contributions associated with these concepts are demonstrated through a validation platform implemented on industrial CNC manufacturing equipments. © 2011 Taylor & Francis.;Taylor and Francis Ltd.michael.wagreich@univie.ac.at;Journal;International Journal of Computer Integrated Manufacturing;2011-01-01;https://api.elsevier.com/content/abstract/scopus_id/80051959788
778;Digital Twin as Enabler for an Innovative Digital Shopfloor Management System in the ESB Logistics Learning Factory at Reutlingen - University;Technologies for mapping the “digital twin” have been under development for approximately 20 years. Nowadays increasingly intelligent, individualized products encourages companies to respond innovatively to customer requirements and to handle the rising product variations quickly. An integrated engineering network, spanning across the entire value chain, is operated to intelligently connect various company divisions, and to generate a business ecosystem for products, services and communities. The conditions for the digital twin are thereby determined in which the digital world can be fed into the real, and the real world back into the digital to deal such intelligent products with rising variations. The term digital twin can be described as a digital copy of a real factory, machine, worker etc., that is created and can be independently expanded, automatically updated as well as being globally available in real time. Every real product and production site is permanently accompanied by a digital twin. First prototypes of such digital twins already exist in the ESB Logistics Learning Factory on a cloud- and app-based software that builds on a dynamic, multidimensional data and information model. A standardized language of the robot control systems via software agents and positioning systems has to be integrated. The aspect of the continuity of the real factory in the digital factory as an economical means of ensuring continuous actuality of digital models looks as the basis of changeability. For the indoor localization sensor combinations that in addition to the hardware already contain the software required for the sensor data fusion should be used. Processing systems, scenario-live-simulations and digital shop floor management results in a mandatory procedural combination. Essential to the digital twin is the ability to consistently provide all subsystems with the latest state of all required information, methods and algorithms.;Elsevier B.V.;Journal;Procedia Manufacturing;2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/85020859111
779;Digital behavioral twins for safe connected cars;Driving is a social activity which involves endless interactions with other agents on the road. Failing to locate these agents and predict their possible future actions may result in serious safety hazards. Traditionally, the responsibility for avoiding these safety hazards is solely on the drivers. With improved sensor quantity and quality, modern ADAS systems are able to accurately perceive the location and speed of other nearby vehicles and warn the driver about potential safety hazards. However, accurately predicting the behavior of a driver remains a challenging problem. In this paper, we propose a framework in which behavioral models of drivers (Digital Behavioral Twins) are shared among connected cars to predict potential future actions of neighboring vehicles, therefore improving the safety of driving. We provide mathematical formulations of models of driver behavior and the environment, and discuss challenging problems during model construction and risk analysis. We also demonstrate that our digital twins framework can accurately predict driver behaviors and effectively prevent collisions using a case study in a virtual driving simulation environment.;Association for Computing Machinery, Incacmhelp@acm.org;Conference Proceeding;Proceedings - 21st ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS 2018;2018-10-14;https://api.elsevier.com/content/abstract/scopus_id/85056832496
780;Engineering tagging languages for DSLs;To keep a DSL clean, readable and reusable in different contexts, it is useful to define a separate tagging language. A tag model logically adds information to the tagged DSL model while technically keeping the artifacts separated. Using a generic tagging language leads to promiscuous tag models, whereas defining a target DSL-specific tag language has a high initial overhead. This paper presents a systematic approach to define a DSL-specific tag language and a corresponding schema language, combining the advantages of both worlds: (a) the tag language specifically fits to the DSL, (b) the artifacts are kept separated and enabling reuse with different tag decorations, (c) the tag language follows a defined type schema, and (d) systematic derivation considerably reduces the effort necessary to implement the tag language. An example shows that it can at least partially be realized by a generator and applied for any kind of DSL.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2015 ACM/IEEE 18th International Conference on Model Driven Engineering Languages and Systems, MODELS 2015 - Proceedings;2015-11-25;https://api.elsevier.com/content/abstract/scopus_id/84961634193
781;Constance: An intelligent data lake system;As the challenge of our time, Big Data still has many research hassles, especially the variety of data. The high diversity of data sources often results in information silos, a collection of non-integrated data management systems with heterogeneous schemas, query languages, and APIs. Data Lake systems have been proposed as a solution to this problem, by providing a schema-less repository for raw data with a common access interface. However, just dumping all data into a data lake without any metadata management, would only lead to a 'data swamp'. To avoid this, we propose Constance1, a Data Lake system with sophisticated metadata management over raw data extracted from heterogeneous data sources. Constance discovers, extracts, and summarizes the structural metadata from the data sources, and annotates data and metadata with semantic information to avoid ambiguities. With embedded query rewriting engines supporting structured data and semi-structured data, Constance provides users a unified interface for query processing and data exploration. During the demo, we will walk through each functional component of Constance. Constance will be applied to two real-life use cases in order to show attendees the importance and usefulness of our generic and extensible data lake system.;Association for Computing Machineryacmhelp@acm.org;Conference Proceeding;Proceedings of the ACM SIGMOD International Conference on Management of Data;2016-06-26;https://api.elsevier.com/content/abstract/scopus_id/84979680970
782;Injection molding setup by means of machine learning based on simulation and experimental data;The process setup in injection molding is a recurring task, which is essential for the product quality and the productivity of the process. In the industrial environment, the setup process still mainly relies on the knowledge and intuition of the machine operator, who sets up the process in a trial and error approach using expensive and time-consuming experiments. Machine learning offers the possibility to optimize and systemize the setup process in injection molding. However, machine learning methods, such as Artificial Neural Networks, need experimental data obtained in injection molding trials as a basis. Since the trials are also time-consuming and expensive, these methods could not be established in an industrial injection molding production yet. Besides the optimization based on experiments, an optimization of the machine setup can be performed based on data determined by numerical simulations. Because of the inevitable gap between the prediction of the simulation and the corresponding results at the machine, further experimental optimization at the machine is nevertheless required. Consequently, a combined machine learning approach using neural networks with simulation and experimental data is analyzed. Six setting parameters of two injection molded parts are varied in simulations and experiments and the effects to specific quality criteria, such as part weight and dimensions, were examined. To identify a suitable structure of neural networks for this data basis, neural networks are trained separately based on simulation and experimental data first. Neural networks with 3 to 6 neurons proved well-suited to model the relationships between setting parameters and single quality criteria. On this basis, a combined learning approach using a pre-training of the neural networks with simulation data and a consecutive refinement with little experimental data is implemented. When only few experimental data are used, the model quality can be improved by a pre-training with simulation data. Nevertheless, the improvements are comparatively small and additional combined training concepts need to be analyzed.;Society of Plastics Engineersinfo@4spe.org;Conference Proceeding;Annual Technical Conference - ANTEC, Conference Proceedings;2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85072959161
783;Combined learning processes for injection moulding based on simulation and experimental data;Injection moulding enables the production of complex formed high-quality plastics parts in a single production step. To achieve a high and constant product quality, an appropriate process set-up with regards to product quality and process robustness is essential. A conventional process set-up requires expensive and time consuming experiments and know-how from the machine operator. One way to overcome this challenge is to make use of machine learning methods for process set-up. These methods can model the relationship between setting parameters and quality values and thus enable the identification of optimal working points. However, the training required for accurate modelling needs experimental data from extensive experiments for each process, too. Numerical simulation can predict quality values based on setting parameters without practical experiments. Whereas trends and the general dependencies between the parameters can be predicted with a satisfying accuracy, a certain discrepancy between the prediction of the simulation and the real process cannot be excluded. A combined approach using data from injection moulding simulations as well as experimental data appears promising to overcome the detriments of the solitary use of simulation for the training of machine learning algorithms. General dependencies could be gained from simulations without practical experiments and fine-tuning could be achieved by experimental trials with a minimal scope. In this paper, data obtained from a 2.5 D injection moulding simulation is compared with experimental data from a plate specimen and a complex formed injection moulded part. Therefore, central composed designs of experiments are used to identify differences in the effects and interdependencies of six setting parameters on quality values like part weight and dimensions. Furthermore, differences in the absolute values and the functionality of the effects are considered. On this basis, a combined machine learning concept using simulation and experimental data is presented.;American Institute of Physics Inc.subs@aip.org;Conference Proceeding;AIP Conference Proceedings;2019-08-26;https://api.elsevier.com/content/abstract/scopus_id/85071520590
784;Approaches of Self-optimising Systems in Manufacturing;Within the Cluster of Excellence “Integrative Production Technology for High-Wage Countries” one major focus is the research and development of self-optimising systems for manufacturing processes. Self-optimising systems with their ability to analyse data, to model processes and to take decisions offer an approach to master processes without explicit control functions. After a brief introduction, two approaches of self-optimising strategies are presented. The first example demonstrates the autonomous generation of technology models for a milling operation. Process knowledge is a key factor in manufacturing and is also an integral part of the self-optimisation approach. In this context, process knowledge in a machine readable format is required in order to provide the self-optimising manufacturing systems a basis for decision making and optimisation strategies. The second example shows a model based self-optimised injection moulding manufacturing system. To compensate process fluctuations and guarantee a constant part quality the manufactured products, the self-optimising approach uses a model, which describes the pvT-behaviour and controls the injection process by a determination of the process optimised trajectory of temperature and pressure in the mould.;Springer Nature;Book Series;Lecture Notes in Production Engineering;2015-01-01;https://api.elsevier.com/content/abstract/scopus_id/85149036760
785;Digital twin-driven manufacturing cyber-physical system for parallel controlling of smart workshop;With increasing diverse product demands, the manufacturing paradigm has been transformed into a mass-individualized one, among which one bottleneck is to achieve the interoperability between physical world and the digital world of manufacturing system for the intelligent organizing of resources. This paper presents a digital twin-driven manufacturing cyber-physical system (MCPS) for parallel controlling of smart workshop under mass individualization paradigm. By establishing cyber-physical connection via decentralized digital twin models, various manufacturing resources can be formed as dynamic autonomous system to co-create personalized products. Clarification on the MCPS concept, characteristics, architecture, configuration, operating mechanism and key enabling technologies are elaborated, respectively. A demonstrative implementation of the digital twin-driven parallel controlling of board-type product smart manufacturing workshop is also presented. It addresses a bi-level online intelligence in proactive decision making for the organization and operation of manufacturing resources.;Springer Verlagservice@springer.de;Journal;Journal of Ambient Intelligence and Humanized Computing;2019-03-13;https://api.elsevier.com/content/abstract/scopus_id/85049566739
786;Next Generation Task Controller for agricultural Machinery using OPC Unified architecture;ISO 11783 is a communication protocol for tractors and implements. It specifies a network of control functions connected with a CAN bus. The task controller is a control function that is used to control implements based on planned tasks. Implements expose their structure to the task controller with Device Descriptor Object Pool XML files. The guidelines for modelling implements leave room for interpretation, which can lead to compatibility issues. The agricultural industry has decided that the physical layer of the future high-speed ISOBUS will use Ethernet, but the higher OSI layers are undecided. One Ethernet-compatible middleware to be considered is OPC UA, a platform-independent communication standard for systems and devices. It uses object-oriented information modelling techniques and allows users to define new information models based on the OPC UA base information model and its standardized extensions. In this article, an OPC UA information model was designed for data exchange between the task controller and implements, and its suitability for use in the high-speed Next-Generation ISO 11,783 Task Controller was evaluated. Modelling rules for the information model were designed with a focus on modelling all types of implements that apply a product or products. OPC UA Implement Server and OPC UA Task Controller applications were developed to test the information model. The evaluation of these OPC UA applications showed that the OPC UA model (OPC UA for the Next Generation ISO 11,783 Task Controller information model) presented is suitable for communication between the task controller and implements.;Elsevier B.V.;Journal;Computers and Electronics in Agriculture;2022-12-01;https://api.elsevier.com/content/abstract/scopus_id/85141278646
787;The digital twin implementation for linking the virtual representation of human-based production tasks to their physical counterpart in the factory-floor;Production systems empowered by digital simulation tools can be improved in a time and cost-effective approach. The enrichment of digital simulations with sensor data, can enhance their realism and improve the accuracy of their results. Hence, this study proposes an implementation of the digital twin approach as part of a wider cyber-physical system (CPS) to enable the optimisation of the planning and commissioning of human-based production processes using simulation-based approaches. This is achieved through a) sensor data fusion and motion recognition of human activities in a factory floor and b) knowledge management mechanism for capturing the implicit knowledge of the task execution. A case study from the intra-factory logistics operations in the white goods industry, demonstrates the feasibility of the proposed approach, by enriching the simulation of manual assembly operations with the operator’s knowledge in the form of spatiotemporal constraints.;Taylor and Francis Ltd.michael.wagreich@univie.ac.at;Journal;International Journal of Computer Integrated Manufacturing;2019-01-02;https://api.elsevier.com/content/abstract/scopus_id/85054903830
788;Modeling of cyber-physical systems and digital twin based on edge computing, fog computing and cloud computing towards smart manufacturing;Nowadays, smart manufacturing has attracted more and more interesting and attentions of researchers. As an important prerequisite for smart manufacturing, the cyber-physical integration of manufacturing is becoming more and more important. Cyber-physical systems (CPS) and digital twin (DT) are the preferred means to achieve the interoperability and integration between the physical and cyber worlds. From the perspective of hierarchy, CPS and DT can be divided into unit level, system level, and SoS (system of system) level. To meet the different requirements of each level, the following three complementary technologies, i.e., edge computing, fog computing and cloud computing, are instrumental to accelerate the development of various CPS and DT. In this article, the perspectives of unit-level, system-level, and SoS-level of CPS and DT supported by edge computing, fog computing and cloud computing are discussed.;American Society of Mechanical Engineers (ASME)infocentral@asme.org;Conference Proceeding;ASME 2018 13th International Manufacturing Science and Engineering Conference, MSEC 2018;2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85055031143
789;Understanding plastics engineering calculations: Hands-on examples and case studies;The plastics engineer working on the shop floor of an industry manufacturing blown film or blow-molded articles or injection-molded parts, to quote a few processes, needs often quick answers to questions such as why the extruder output is low or whether he can expect better quality product by changing the resin or how he can estimate the pressure drop along the runner or gate of an injection mold. Applying the state of the art numerical analysis to address these issues is time-consuming and costly requiring trained personnel. Indeed, as experience shows, most of these issues can be addressed quickly by applying proven, practical calculation procedures which can be handled by pocket calculators and hence can be performed right on the site where the machines are running. © Carl Hanser Verlag, Munich 2012. All rights reserved.;Hanser;Book;Understanding Plastics Engineering Calculations: Hands-on Examples and Case Studies;2012-01-01;https://api.elsevier.com/content/abstract/scopus_id/84905811248
790;Abstraction and Refinement in Hierarchically Decomposable and Underspecified CPS-Architectures;Model-driven development of cyber-physical systems (CPS) requires modeling techniques based on a well-founded theory that supports addressing development techniques, such as decomposition, refinement and the different notions of time required by its components. Based on an elaborated theory for the modeling of underspecification with respect to nondeterminism, hierarchical composition, refinement that is compatible with composition, and finally proven correct evolution patterns, we discuss how such a theory can be practically applied for the development of CPS. Through an orchestrated efficient simulation, we can identify potential bottlenecks, function failures, hardware risks, etc. early. All models as well as the simulation take advantage of the compositionality and the timing refinement properties of the theory. In summary, we discuss how the elaborated theory shapes the simulation and the results.;Springer Verlagservice@springer.de;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85052702289
791;Toward a Digital Twin for real-time geometry assurance in individualized production;Simulations of products and production processes are extensively used in the engineering phase. To secure good geometrical quality in the final product, tolerances, locator positions, clamping strategies, welding sequence, etc. are optimized during design and pre-production. Faster optimization algorithms, increased computer power and amount of available data, can leverage the area of simulation toward real-time control and optimization of products and production systems – a concept often referred to as a Digital Twin. This paper specifies and highlights functionality and data models necessary for real-time geometry assurance and how this concept allows moving from mass production to more individualized production.;Elsevier USA;Journal;CIRP Annals - Manufacturing Technology;2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/85018779245
792;Digital Twin Shop-Floor: A New Shop-Floor Paradigm Towards Smart Manufacturing;With the developments and applications of the new information technologies, such as cloud computing, Internet of Things, big data, and artificial intelligence, a smart manufacturing era is coming. At the same time, various national manufacturing development strategies have been put forward, such as Industry 4.0, Industrial Internet, manufacturing based on Cyber-Physical System, and Made in China 2025. However, one of specific challenges to achieve smart manufacturing with these strategies is how to converge the manufacturing physical world and the virtual world, so as to realize a series of smart operations in the manufacturing process, including smart interconnection, smart interaction, smart control and management, etc. In this context, as a basic unit of manufacturing, shop-floor is required to reach the interaction and convergence between physical and virtual spaces, which is not only the imperative demand of smart manufacturing, but also the evolving trend of itself. Accordingly, a novel concept of digital twin shop-floor (DTS) based on digital twin is explored and its four key components are discussed, including physical shop-floor, virtual shop-floor, shop-floor service system, and shop-floor digital twin data. What is more, the operation mechanisms and implementing methods for DTS are studied and key technologies as well as challenges ahead are investigated, respectively.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2017-09-24;https://api.elsevier.com/content/abstract/scopus_id/85030752762
793;Transfer-Learning: Bridging the Gap between Real and Simulation Data for Machine Learning in Injection Molding;In the field of manufacturing process planning and initial operation of machines, machine parameters are often provided from few either expensive and time-consuming experiments or faster but less accurate numerical simulations. Another option is to use machine learning to predict process qualities based on machine parameters. Thereby, transfer learning can overcome the gap between real and simulation data. We evaluated two different approaches based on artificial neural networks, namely soft-start and random initialization, in a real injection molding process. The results show better learning rates and predictions that are more accurate while using fewer experimental data.;Elsevier B.V.;Conference Proceeding;Procedia CIRP;2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85049564787
794;Modeling languages in Industry 4.0: an extended systematic mapping study;Industry 4.0 integrates cyber-physical systems with the Internet of Things to optimize the complete value-added chain. Successfully applying Industry 4.0 requires the cooperation of various stakeholders from different domains. Domain-specific modeling languages promise to facilitate their involvement through leveraging (domain-specific) models to primary development artifacts. We aim to assess the use of modeling in Industry 4.0 through the lens of modeling languages in a broad sense. Based on an extensive literature review, we updated our systematic mapping study on modeling languages and modeling techniques used in Industry 4.0 (Wortmann et al., Conference on model-driven engineering languages and systems (MODELS’17), IEEE, pp 281–291, 2017) to include publications until February 2018. Overall, the updated study considers 3344 candidate publications that were systematically investigated until 408 relevant publications were identified. Based on these, we developed an updated map of the research landscape on modeling languages and techniques for Industry 4.0. Research on modeling languages in Industry 4.0 focuses on contributing methods to solve the challenges of digital representation and integration. To this end, languages from systems engineering and knowledge representation are applied most often but rarely combined. There also is a gap between the communities researching and applying modeling languages for Industry 4.0 that originates from different perspectives on modeling and related standards. From the vantage point of modeling, Industry 4.0 is the combination of systems engineering, with cyber-physical systems, and knowledge engineering. Research currently is splintered along topics and communities and accelerating progress demands for multi-disciplinary, integrated research efforts.;Springer;Journal;Software and Systems Modeling;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85074431675
795;Digital twin-driven cyber-physical production system towards smart shop-floor;Smart manufacturing is the core in the 4th industrial revolution. Smart shop-floor is one of the basic units of smart manufacturing. With the development of the advanced technologies (e.g. cloud computing, internet of things, model-based definition, advanced simulation, artificial intelligence), a larger number of virtual shop-floors are being built. However, it is very important that how to realize the intelligent interconnection and interaction between physical shop-floors and virtual ones. Digital twin (DT) is one of the key technologies associated to the cyber-physical system. In this paper, we present our vision on the cyber-physical production system (CPPS) towards smart shop-floor at scale via DT. This paper firstly explores a product manufacturing digital twin (PMDT), which focuses on the production phase in smart shop-floor. The proposed PMDT consists of five models: Product Definition Model (PDM), Geometric and Shape Model (GSM), Manufacturing Attribute Model (MAM), Behavior and Rule Model (BRM) and Data Fusion Model (DFM). And then based on PMDT, this paper proposes a new architecture of CPPS, which is composed of five layers (physical layer, network layer, database layer, model layer, application layer). Finally, this paper addresses the opportunities to use DT for the CPPS to support job scheduling during normal operation. Furthermore, the related further work and suggestions are also discussed.;Springer Verlagservice@springer.de;Journal;Journal of Ambient Intelligence and Humanized Computing;2019-11-01;https://api.elsevier.com/content/abstract/scopus_id/85057330632
796;Model-driven separation of concerns for service robotics;Robotics currently adopts model-driven engineering focusing software modeling languages. This forces domain experts to employ these languages instead of enabling application of more appropriate DSLs. This ultimately produces monolithic, hardly reusable applications. We present an infrastructure for the development of service robotics applications employing DSLs aimed at domain experts and tailored to domain challenges. It facilitates separation of concerns of participating robotics, domain, and software engineering experts and integrates their models via a component & connector reference architecture and a combined code generation framework. The infrastructure was successfully deployed and evaluated with robotics manufacturers, caregivers, and software engineers in a German hospital. We believe that model-driven engineering with languages tailored to the various stakeholders' needs can greatly facilitate robotic application engineering.;Association for Computing Machinery, Incacmhelp@acm.org;Conference Proceeding;DSM 2016 - Proceedings of the International Workshop on Domain-Specific Modeling, co-located with SPLASH 2016;2016-10-30;https://api.elsevier.com/content/abstract/scopus_id/85015193041
797;Executing robot task models in dynamic environments;Deploying successful robotics applications requires tremendous effort due to the need for contributions of experts from various domains. We present the iserveU family of executable DSLs that separate the concerns of domain experts and robotics experts and leverage model-transformation at system run-time to enable the robotic platform to flexibly fulfill tasks in a changing real-world environment. Current research in DSLs for robotics applications focuses on abstraction in the solution domain, whereas our DSLs support the domain expert in declaratively describing properties of the domain and loosely coupled tasks. To enable flexible task execution based on the domain expert’s declarative models, these are translated into components of a reference architecture prior to deployment and into planning domain definition language (PDDL) problems at system runtime. Resulting problems are translated into executable plans using the Metric-FF solver and re-translated into iserveU models that ultimately are executed against a loosely coupled robotics middleware. Leveraging model transformation at run-time enables the flexibility necessary for robotics applications deployed to dynamic environments where design-time assumptions and run-time reality diverge easily.;CEUR-WS;Conference Proceeding;CEUR Workshop Proceedings;2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/85041442648
798;Enterprise Information Systems in Academia and Practice: Lessons learned from a MBSE Project;The development of domain-specific information systems, especially web information systems, takes a certain amount of time, needs intensive testing to ensure a certain quality and lacks the consistency of front- and backend. Using model-based strategies for the creation of information systems helps to overcome these problems by fastening the development process, facilitating testing and ensuring consistency-by-construction. In practice, however, they are still rarely used. In this paper, we show that model-based engineering is beneficial for the creation of an enterprise information system and improves the quality of the resulting product. We present the basic functionalities of our Generator for Enterprise Management (MontiGEM) and discuss identified problems and lessons learned in a project in practice. The generator was developed simultaneously with and for an enterprise management system. Our research shows that the use of generative methods and MBSE improves the adaptability and reusability of parts of the application on the one hand but on the other hand, there are still obstacles that slow down its broad application in practice.;Gesellschaft fur Informatik (GI);Conference Proceeding;Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI);2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85115262972
799;Model-based generation of enterprise information systems;Thick clients of client/server-information systems include increasingly more logic which leads to several challenges in the development process: Resulting from the separate development of frontand backend, the risk for inconsistencies between components on the one hand, and communication overhead between developers on the other hand are high. We present an approach which helps to overcome these challenges by using model-driven engineering for the development of data-intensive enterprise information systems. WebDEx was developed as a generator for the creation of such systems. It uses UML/P inspired modelling languages, as models (1) build the base for communication among project members and (2) are used as input for the code generator which ensures consistency by construction. This work relies on an infrastructure created by the language workbench and code generation framework MontiCore. Moreover, this paper presents the practical application of this approach for the agile development of a multi user, adaptable web-application to be used by more than 400 chairs of RWTH Aachen University.;CEUR-WSceurws@sunsite.informatik.rwth-aachen.de;Conference Proceeding;CEUR Workshop Proceedings;2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85048362638
800;AutoFOCUS 3: Tooling concepts for seamless, model-based development of embedded systems;This paper presents tooling concepts in AUTOFOCUS 3 supporting the development of software-intensive embedded system design. AUTOFOCUS 3 is a highly integrated model-based tool covering the complete development process from requirements elicitation, deployment, the modelling of the hardware platform to code generation. This is achieved thanks to precise static and dynamic semantics based on the FOCUS theory [1]. Models are used for requirements, for the software architecture (SA), for the hardware platform and for relations between those different viewpoints: traces from requirements to the SA, refinements between SAs, and deployments of the SA to the platform. This holistic usage of models allows the provision of a wide range of analysis and synthesis techniques such as testing, model checking and deployment and scheduling generation. In this paper, we demonstrate how tooling concepts on different steps in the development process look like, based on these integrated models and implemented in AUTOFOCUS 3.;CEUR-WS;Conference Proceeding;CEUR Workshop Proceedings;2015-01-01;https://api.elsevier.com/content/abstract/scopus_id/84962568901
801;Component and Connector Views in Practice: An Experience Report;Component and Connector (C&C) view specifications, with corresponding verification and synthesis techniques, have been recently suggested as a means for formal yet intuitive structural specification of C&C models. In this paper we report on our recent experience in applying C&C views in industrial practice, where we aimed to answer questions such as: could C&C views be practically used in industry, what are challenges of systems engineers that the use of C&C views could address, and what are some of the technical obstacles in bringing C&C views to the hands of systems engineers. We describe our experience in detail and discuss a list of lessons we have learned, including, e.g., a missing abstraction concept in C&C models and C&C views that we have identified and added to the views language and tool, that engineers can create graphical C&C views quite easily, and how verification algorithms scale on real-size industry models. Furthermore, we report on the non-negligible technical effort needed to translate Simulink block diagrams to C&C models. We make all materials mentioned and used in our experience electronically available for inspection and further research.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - ACM/IEEE 20th International Conference on Model Driven Engineering Languages and Systems, MODELS 2017;2017-11-07;https://api.elsevier.com/content/abstract/scopus_id/85040631558
802;The Facets of Digital Twins in Production and the Automotive Industry;The digital twin is a great term that is frequently used in the context of digitalization and Industry 4.0. In discussions with other researchers and colleagues about the digital twin, it oftentimes becomes clear that everyone understands something different about the digital twin. This paper therefore compares the different facets of digital twins in the industrial environment of production. Different applications are shown, and a list of added values of a digital twin is derived based on these applications. The paper also covers the different facets of digital twins in the automotive industry and evaluates their practical benefits. In addition, the different technologies for realizing a digital twin are examined, and a concept for modeling the lifecycle of a production line via the digital twin is presented.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2019 23rd International Conference on Mechatronics Technology, ICMT 2019;2019-10-01;https://api.elsevier.com/content/abstract/scopus_id/85077963621
803;Towards digital twins for the description of automotive software systems;We present models for automotive software that capture quantitative and qualitative aspects of software systems and the underlying hardware architecture. In particular, we consider different levels of computing power. These range from controllers up to the cloud. We present a modeling approach for software deployment taking different automotive requirements such as criticality, latency, memory, computational resources, and communication into account. Our models capture automotive software and hardware system configurations and can serve as digital twins that are digital counterparts of (usually) physical entities. Furthermore, we highlight connected research areas and challenges.;Open Publishing Association;Conference Proceeding;Electronic Proceedings in Theoretical Computer Science, EPTCS;2020-01-20;https://api.elsevier.com/content/abstract/scopus_id/85079350128
804;Digital twin-the simulation aspect;The vision of the Digital Twin itself refers to a comprehensive physical and functional description of a component, product or system, which includes more or less all information which could be useful in all-the current and subsequent-lifecycle phases. In this chapter we focus on the simulation aspects of the Digital Twin. Today, modelling and simulation is a standard process in system development, e.g. to support design tasks or to validate system properties. During operation and for service first simulation-based solutions are realized for optimized operations and failure prediction. In this sense, simulation merges the physical and virtual world in all life cycle phases. Current practice already enables the users (designer, SW/HW developers, test engineers, operators, maintenance personnel, etc) to master the complexity of mechatronic systems.;Springer International Publishing;Book;Mechatronic Futures: Challenges and Solutions for Mechatronic Systems and Their Designers;2016-01-01;https://api.elsevier.com/content/abstract/scopus_id/85016457439
805;A system of systems architecture for the internet of things exploiting autonomous components;As the internet of things (IoT) becomes more popular, supporting systems and their components become more complex and largely heterogeneous. This paper discusses on a system of systems (SoS) architecture for IoT systems composed by autonomous components. The proposed architecture focuses on a middleware transforming sensor services to REST services, for the development of mixed-criticality applications. The middleware consisting of autonomous aggregation software running on commodity multi-core devices, such as Raspberry Pi. Self-management policies applied are discussed in the paper. The analysis of a smart building system, developed as a use case, provides solid evidence that such an architecture is realistic and can lead to highly competitive systems.;Inderscience Publishers;Journal;International Journal of System of Systems Engineering;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85068067607
806;Digital Twins in health care: Ethical implications of an emerging engineering paradigm;Personalized medicine uses fine grained information on individual persons, to pinpoint deviations from the normal. 'Digital Twins' in engineering provide a conceptual framework to analyze these emerging data-driven health care practices, as well as their conceptual and ethical implications for therapy, preventative care and human enhancement. Digital Twins stand for a specific engineering paradigm, where individual physical artifacts are paired with digital models that dynamically reflects the status of those artifacts. When applied to persons, Digital Twins are an emerging technology that builds on in silico representations of an individual that dynamically reflect molecular status, physiological status and life style over time. We use Digital Twins as the hypothesis that one would be in the possession of very detailed bio-physical and lifestyle information of a person over time. This perspective redefines the concept of 'normality' or 'health,' as a set of patterns that are regular for a particular individual, against the backdrop of patterns observed in the population. This perspective also will impact what is considered therapy and what is enhancement, as can be illustrated with the cases of the 'asymptomatic ill' and life extension via anti-aging medicine. These changes are the consequence of how meaning is derived, in case measurement data is available. Moral distinctions namely may be based on patterns found in these data and the meanings that are grafted on these patterns. Ethical and societal implications of Digital Twins are explored. Digital Twins imply a data-driven approach to health care. This approach has the potential to deliver significant societal benefits, and can function as a social equalizer, by allowing for effective equalizing enhancement interventions. It can as well though be a driver for inequality, given the fact that a Digital Twin might not be an accessible technology for everyone, and given the fact that patterns identified across a population of Digital Twins can lead to segmentation and discrimination. This duality calls for governance as this emerging technology matures, including measures that ensure transparency of data usage and derived benefits, and data privacy.;Frontiers Media S.A.info@frontiersin.org;Journal;Frontiers in Genetics;2018-02-13;https://api.elsevier.com/content/abstract/scopus_id/85042098524
807;Grand challenges in model-driven engineering: an analysis of the state of the research;In 2017 and 2018, two events were held—in Marburg, Germany, and San Vigilio di Marebbe, Italy, respectively—focusing on an analysis of the state of research, state of practice, and state of the art in model-driven engineering (MDE). The events brought together experts from industry, academia, and the open-source community to assess what has changed in research in MDE over the last 10 years, what challenges remain, and what new challenges have arisen. This article reports on the results of those meetings, and presents a set of grand challenges that emerged from discussions and synthesis. These challenges could lead to research initiatives for the community going forward.;Springer;Journal;Software and Systems Modeling;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85077634676
808;Systematic language extension mechanisms for the montiarc architecture description language;Architecture description languages (ADLs) combine the benefits of component-based software engineering and model-driven development. Extending an ADL to domain-specific requirements is a major challenge for its successful application. Most ADLs focus on fixed features and do not consider domain-specific language extension. ADLs focusing on extensibility focus on syntactic augmentation only and neither consider semantics, nor the ADL’s tooling. We present a systematic extension method for the MontiArc component and connector ADL that enables extending its syntax and infrastructure. The MontiArc ADL is built on top of the MontiCore workbench for compositional modeling languages and leverages its powerful language integration facilities. Based on these, we conceived systematic extension activities and present their application to customizing MontiArc for three different domains. This application of software language engineering to ADLs reduces effort for their extension and the presented method guides developers in applying it to their domain. This ultimately fosters the application of ADLs to real-world domain-specific challenges.;Springer Verlagservice@springer.de;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/85025126026
809;MDE4IoT: Supporting the internet of things with model-driven engineering;The Internet of Things (IoT) unleashes great opportunities to improve our way of living and working through a seamless and highly dynamic cooperation among heterogeneous things including both computer-based systems and physical objects. However,properly dealing with the design,development,deployment and runtime management of IoT applications means to provide solutions for a multitude of challenges related to intelligent distributed systems within the IoT. In this paper we propose Model-Driven Engineering (MDE) as a keyenabler for applications running on intelligent distributed IoT systems. MDE helps in tackling challenges and supporting the lifecycle of such systems. Specifically,we introduce MDE4IoT,an MDE approach enabling the modelling of things and supporting intelligence as self-adaptation of Emergent Configurations in the IoT. Moreover,we show how MDE,and in particular MDE4IoT,can help in tackling several challenges by providing the Smart Street Lights concrete case.;Springer Verlagservice@springer.de;Book Series;Studies in Computational Intelligence;2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/84992363346
810;Tagging model properties for flexible communication;"Model-based systems engineering and digital manufacturing aim to facilitate monitoring, integration, and optimization of cyber-physical production systems (CPPS) through so-called ""digital shadows"". In contrast to ""digital twins"", digital shadows are purposefully abstracted models of information emitted by the underlying CPPS, hence they do not manipulate the system themselves.We present a method to derive digital shadows from design-time models that can be extended with sophisticated analyses and operate physically distributed without changing the original models. To this end, tag models assign communication information to properties of design-time models from which we generate an Message Queuing Telemetry Transport (MQTT) based communication infrastructure that makes these accessible to other models. This enables the flexible integration and exchange of model information at runtime without polluting these with extra communication information. We present a tagging language for model communication description, a systematic method to apply this to design-time models, generation of a communication infrastructure, and their implementations with the MontiCore language workbench. This, ultimately, facilitates engineering physically distributed digital shadows and, hence, facilitates developing the interconnected CPPS of the future.";CEUR-WSceurws@sunsite.informatik.rwth-aachen.de;Conference Proceeding;CEUR Workshop Proceedings;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85072778075
811;Modeling deep reinforcement learning based architectures for cyber-physical systems;Reinforcement learning is a sub-field of machine learning where an agent aims to learn a behavior or a policy maximizing a reward function by trial and error. The approach is particularly interesting for the design of autonomous cyber-physical systems such as self-driving cars. In this work we present a generative, domain-specific modeling framework for the design, training and integration of reinforcement learning systems. It consists of a neural network modeling language which is used to design the models to be trained, e.g. actor and critic networks, and a training language used to describe the training procedure and set the corresponding hyperparameters. The underlying component model allows the modeler to embed the trained networks in larger component & connector architectures. We illustrate our framework by the example of a self-driving racing car.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2019 ACM/IEEE 22nd International Conference on Model Driven Engineering Languages and Systems Companion, MODELS-C 2019;2019-09-01;https://api.elsevier.com/content/abstract/scopus_id/85075937600
812;Generated enterprise information systems: MDSE for maintainable co-development of frontend and backend;Universities, like any application domain and industry sector, have to establish a well functioning, reliable management accounting, and financial reporting software system. Currently, chairs have different technical solutions for their financial management such as commercial accounting software tailored to the needs of the central administration as well as the chairs' own data collections with additional information in other software tools. Previous work did not investigate the use of model-driven software engineering methods for the maintainable development of a full-size real-world enterprise information system. This paper shows the application of model-driven software engineering methods to create this system and support the maintainable co-development of frontend and backend written in different programming languages. We are using a variety of models and modeling languages in addition to an application generator that allows for continuous re-generation. Our approach can be easily adapted to other problem domains to create a functional prototype out of models with minimal manual effort.;CEUR-WSceurws@sunsite.informatik.rwth-aachen.de;Conference Proceeding;CEUR Workshop Proceedings;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85080937709
813;Continuous transition from model-driven prototype to full-size real-world enterprise information systems;This paper presents our approach to create an executable prototype of an enterprise information system based only on a data structure model. This prototype, which is still easily adaptable and extendable, can be used for analysis exploration and builds a solid foundation for the final system. The presented approach transforms a data structure model to changeable and extendable graphical user interface models. In a second step, the data structure model and the GUI models are used to generate the resulting system. This approach allows the developer to generate (a) persistence, (b) basic application logic, (c) transportation layers, and (d) a variety of possible graphical representations for the prototype based only on a data structure model. Extensions and changes of the GUI are still possible on model and code level. This is possible by synthetization of GUI models and change operations defined in the same domain-specific language.;Association for Information Systems;Conference Proceeding;26th Americas Conference on Information Systems, AMCIS 2020;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85096970269
814;Engineering tagging languages for DSLs;To keep a DSL clean, readable and reusable in different contexts, it is useful to define a separate tagging language. A tag model logically adds information to the tagged DSL model while technically keeping the artifacts separated. Using a generic tagging language leads to promiscuous tag models, whereas defining a target DSL-specific tag language has a high initial overhead. This paper presents a systematic approach to define a DSL-specific tag language and a corresponding schema language, combining the advantages of both worlds: (a) the tag language specifically fits to the DSL, (b) the artifacts are kept separated and enabling reuse with different tag decorations, (c) the tag language follows a defined type schema, and (d) systematic derivation considerably reduces the effort necessary to implement the tag language. An example shows that it can at least partially be realized by a generator and applied for any kind of DSL.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2015 ACM/IEEE 18th International Conference on Model Driven Engineering Languages and Systems, MODELS 2015 - Proceedings;2015-11-25;https://api.elsevier.com/content/abstract/scopus_id/84961634193
815;Digital twin: Mitigating unpredictable, undesirable emergent behavior in complex systems;Systems do not simply pop into existence. They progress through lifecycle phases of creation, production, operations, and disposal. The issues leading to undesirable and unpredicted emergent behavior are set in place during the phases of creation and production and realized during the operational phase, with many of those problematic issues due to human interaction. We propose that the idea of the Digital Twin, which links the physical system with its virtual equivalent can mitigate these problematic issues. We describe the Digital Twin concept and its development, show how it applies across the product lifecycle in defining and understanding system behavior, and define tests to evaluate how we are progressing. We discuss how the Digital Twin relates to Systems Engineering and how it can address the human interactions that lead to “normal accidents.” We address both Digital Twin obstacles and opportunities, such as system replication and front running. We finish with NASA's current work with the Digital Twin.;Springer International Publishing;Book;Transdisciplinary Perspectives on Complex Systems: New Findings and Approaches;2016-01-01;https://api.elsevier.com/content/abstract/scopus_id/85006339863
816;ThingML: A language and code generation framework for heterogeneous targets;One of the selling points of Model-Driven Software Engineering (MDSE) is the increase in productivity offered by automatically generating code from models. However, the practical adoption of code generation remains relatively slow and limited to niche applications. Tooling issues are often pointed out but more fundamentally, experience shows that: (i) models and modeling languages used for other purposes are not necessarily well suited for code generation and (ii) code generators are often seen as black-boxes which are not easy to trust and produce sub-optimal code. This paper presents and discusses our experiences applying the ThingML approach to different domains. ThingML includes a modeling language and tool designed for supporting code generation and a highly customizable multi-platform code generation framework. The approach is implemented in an open-source tool providing a family of code generators targeting heterogeneous platforms. It has been evaluated through several case studies and is being used for in the development of a commercial ambient assisted living system.;Association for Computing Machinery, Incacmhelp@acm.org;Conference Proceeding;Proceedings - 19th ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS 2016;2016-10-02;https://api.elsevier.com/content/abstract/scopus_id/85008457888
817;Retrofitting controlled dynamic reconfiguration into the architecture description language MontiArcAutomaton;Component & connector architecture description languages (C&C ADLs) provide hierarchical decomposition of system functionality into components and their interaction. Most ADLs fix interaction configurations at design time while some express dynamic reconfiguration of components to adapt to runtime changes. Implementing dynamic reconfiguration in a static C&C ADL by encoding it into component behavior creates implicit dependencies between components and forfeits the abstraction of behavior paramount to C&C models. We developed a mechanism for retrofitting dynamic reconfiguration into the static C&C ADL MontiArcAutomaton. This mechanism lifts reconfiguration to an architecture concern and allows to preserve encapsulation and abstraction of C&C ADLs. Our approach enables efficient retrofitting by a smooth integration of reconfiguration semantics and encapsulation. The new dynamic C&C ADL is fully backwards compatible and wellformedness of configurations can be statically checked at design time. Our work provides dynamic reconfiguration for the C&C ADL Monti- ArcAutomaton.;Springer Verlagservice@springer.de;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2016-01-01;https://api.elsevier.com/content/abstract/scopus_id/84999040147
818;Model-driven development of adaptive IoT systems;There is an increasing demand for software systems that utilize the new Internet of Things (IoT) paradigm to provide users with the best functionalities, through transforming objects from traditional to smart ones. In recent years, a number of approaches have been proposed to enable the development of such IoT systems. However, developing IoT systems that adapt at runtime is still a major challenge. In this paper, we propose a model-driven approach to ease the modeling and realization of adaptive IoT systems. First, to model an IoT system, we adopted SysML4IoT (an extension of the SysML) to specify the system functions and adaptations. We also adopted a publish/subscribe paradigm to model environment information and its relationship with the system. Second, based on the system design model, code is generated which is deployed later on to the hardware platform of the system. To show our approach applicability, we have developed a smart lighting system in the context of the S3P project.;CEUR-WS;Conference Proceeding;CEUR Workshop Proceedings;2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/85041450972
819;A digital twin approach for fault diagnosis in distributed photovoltaic systems;Rooftop and building-integrated distributed photovoltaic (PV) systems are emerging as key technologies for smart building applications. This paper presents the design methodology, mathematical analysis, simulation study, and experimental validation of a digital twin approach for fault diagnosis. We develop a digital twin that estimates the measurable characteristic outputs of a PV energy conversion unit (PVECU) in real time. The PVECU constitutes a PV source and a source-level power converter. The fault diagnosis is performed by generating and evaluating an error residual vector, which is the difference between the estimated and measured outputs. A PV panel-level power converter prototype is built to demonstrate how the sensing, processing, and actuation capabilities of the converter can enable effective fault diagnosis in real time. The experimental results show detection and identification of ten different faults in the PVECU. The time to fault detection (FD) in the power converter and the electrical sensors is less than 290 μs and the identification time is less than 4 ms. The time to FD and identification in the PV panel are less than 80 ms and 1.2 s, respectively. The proposed approach demonstrates higher fault sensitivity than that of existing approaches. It can diagnose a 20% drift in the electrical sensor gains and a 20% shading of a solar cell in the PV panel.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Transactions on Power Electronics;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85074215768
820;Health Care in the Cyberspace: Medical Cyber-Physical System and Digital Twin Challenges;Cyber-Physical Systems and Digital Twins are commonly used today in the industrial sector, and the healthcare sector is keen to implement these technological solutions to enhance their capabilities and offer better services for patient care provision. In fact, the adoption of Wireless Body Area Networks (WBAN) based on IoT along with cloud computing systems has led to the development of new methodologies to monitor and treat patients. However, the adoption of the new technologies comes with several challenges in terms of performance and security. Considering that, WBAN can be wearable or implanted under the skin, and the overall concept leads to several cybersecurity challenges that would require deeper investigation. This chapter presents an analysis of the impact that WBAN has on health care. It also provides some definitions of Medical Cyber-Physical Systems (MCPSs) and Digital Twins along with technological enablers such as cloud and IoT.;Springer International Publishing;Book Series;Internet of Things;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85081088828
821;A Digital Twin-Based Multi-modal UI Adaptation Framework for Assistance Systems in Industry 4.0;As a consequence of digital transformation many aspects related to the industrial manufacturing processes are facing changes. In terms of Human-Machine Interaction, the User Interface (UI) plays the most important role as a mediator between the human and certain assistance systems. In traditional industrial environments, the UIs are usually designed to handle a unimodal input command (via touch screen, keyboard or mouse) and to present a feedback in a visual way. However, due to the nature of the tasks there is a need for the human workers to easily shift tasks and acquire new skills. For this reason, in the UI adaptation process the personal abilities and preferences of the human workers should be taken into consideration. In this paper, we present a novel reference model for multi-modal adaptive UIs for assistance systems in manufacturing processes. Our approach provides a solution framework for adaptation of assistance systems in manufacturing processes not only based on the environmental conditions, but also based on the personal characteristics and abilities of the human workers, obtained by a personalized Digital Twin.;Springer Verlagservice@springer.de;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85069873204
822;The US air force digital thread/digital Twin – life cycle integration and use of computational and experimental knowledge;Computational and experimental fluid dynamics have been integrated into aeronautical system development processes in varying degrees over the last forty years and have yet to achieve their full promise for reducing the cost and time for development. What has been missing is a holistic advance in the integration not just of computers and wind tunnels but of the organizational constructs and development processes that enable unleashing the full capability of integrated computational and experimental methods. Recent Department of Defense (DoD) policies and guidance focused on organic engineering capabilities, government insight into technical performance, and application of system models over the life cycle are enabling a major paradigm shift toward life cycle integration of computational and experimental knowledge. In conjunction with these new policies, the United States Air Force is developing and applying a Digital Thread/Digital Twin analytical framework to provide engineering analysis capabilities and support to decision making over the entire lifecycle of air vehicles. The Digital Thread/Digital Twin merges physics-based modeling and experimental data to generate an authoritative digital representation of the system at each phase of the acquisition and sustainment process of a weapon system. In this paper the history of integrated computational and experimental fluid dynamics is reviewed as a precursor for the emerging paradigm shift toward a virtual government monopsony that enables a focused application of modeling capabilities and management of knowledge and tools over the life cycle. Illustrations of the potential impact of the new paradigm are also presented.;American Institute of Aeronautics and Astronautics Inc, AIAA;Conference Proceeding;54th AIAA Aerospace Sciences Meeting;2016-01-01;https://api.elsevier.com/content/abstract/scopus_id/85007463616
823;Prototyping a Digital Twin for Real Time Remote Control over Mobile Networks: Application of Remote Surgery;"The concept of digital twin (DT) has emerged to enable the benefits of future paradigms such as the industrial Internet of Things and Industry 4.0. The idea is to bring every data source and control interface description related to a product or process available through a single interface, for auto-discovery and automated communication establishment. However, designing the architecture of a DT to serve every future application is an ambitious task. Therefore, the prototyping systems for specific applications are required to design the DT incrementally. We developed a novel DT prototype to analyze the requirements of communication in a mission-critical application such as mobile networks supported remote surgery. Such operations require low latency and high levels of security and reliability and therefore are a perfect subject for analyzing DT communication and cybersecurity. The system comprised of a robotic arm and HTC vive virtual reality (VR) system connected over a 4G mobile network. More than 70 test users were employed to assess the system. To address the cybersecurity of the system, we incorporated a network manipulation module to test the effect of network outages and attacks; we studied state of the art practices and their utilization within DTs. The capability of the system for actual remote surgery is limited by capabilities of the VR system and insufficient feedback from the robot. However, simulations and research of remote surgeries could be conducted with the system. As a result, we propose ideas for communication establishment and necessary cybersecurity technologies that will help in developing the DT architecture. Furthermore, we concluded that developing the DT requires cross-disciplinary development in several different engineering fields. Each field makes use of its own tools and methods, which do not always fit together perfectly. This is a potentially major obstacle in the realization of Industry 4.0 and similar concepts.";Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85062238969
824;IoT sensor integration to Node-RED platform;This paper presents the implementation of an Internet of Things (IoT) application that performs the temperature and humidity sensing using DHT11 sensor on Raspberry Pi, and data transfer to the Cloud of the IBM Bluemix. The implementation is done using programming system Raspbian Stretch Lite on Raspberry Pi and IBM Internet of Things platform based on the Node-RED tool installed on the Raspberry Pi and the IBM Cloud.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2018 17th International Symposium on INFOTEH-JAHORINA, INFOTEH 2018 - Proceedings;2018-04-23;https://api.elsevier.com/content/abstract/scopus_id/85050939004
825;Dynamic Evaluation Method of Machining Process Planning Based on Digital Twin;"Process evaluation is widely accepted as an effective strategy to improve product quality and shorten its development cycle. However, there has been very little research on how to evaluate the process plan with the dynamic change of the machining condition and uncertain available manufacturing resources. This paper proposes a novel process evaluation method based on digital twin technology. Three core technologies embodied in the proposed method are illustrated in details: 1) real-time mapping mechanism between the collected data in machining and the process design information; 2) construction of the digital twin-based machining process evaluation (DT-MPPE) framework; and 3) process evaluation driven by digital twin data. To elaborate on how to apply the proposed method to the reality, we present a detailed implementation process of the proposed DT-MPPE method for the key parts of the marine diesel engine. Meanwhile, the future work to completely fulfill digital twin-based smart process planning for complex products is discussed.";Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85062214330
826;From BIM towards digital twin: Strategy and future development for smart asset management;With the rising adoption of Building Information Model (BIM) for asset management within architecture, engineering, construction and owner-operated (AECO) sector, BIM-enabled asset management has been increasingly attracting more attentions in both research and practice. This study provides a comprehensive review and analysis of the state-of-the-art latest research and industry standards development that impact upon BIM and asset management within the operations and maintenance (O&M) phase. However, BIM is not always enough in whole-life cycle asset management, especially in the O&M phase. Therefore, a framework for future development of smart asset management is proposed, integrating the concept of Digital Twin (DT). DT integrates artificial intelligence, machine learning and data analytics to create dynamic digital models that are able to learn and update the status of the physical counterpart from multiple sources. The findings will contribute to inspiring novel research ideas and promote widespread adoption of smart DT-enabled asset management within the O&M phase.;Springer Verlagservice@springer.de;Book Series;Studies in Computational Intelligence;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85070604150
827;Building a digital twin for additive manufacturing through the exploitation of blockchain: A case analysis of the aircraft industry;Blockchain is becoming a widespread digital technology that allows every transaction to be tracked in an inviolable way, hence making it possible to go back through the entire history of products and product components. Its idiosyncratic characteristics can be especially useful in the aircraft industry, a highly technologically-based sector, wherein manufacturers of components are governed by stringent technical standards, the aim of which is to certify and monitor the whole component production process. In addition, the sector makes significant use of additive manufacturing technologies to perform the rapid prototyping of product components, realized through the supply chain, hence reducing time-to-market, while ensuring quality and containing costs. Starting from these premises, the paper focuses on the phases characterizing the metal additive manufacturing process, in which a component for the aircraft industry can be produced and proposes a digital twin for additive manufacturing in the aircraft industry through the exploitation of Blockchain solutions. In doing so, the paper provides a conceptual answer to securing and organizing the data generated through an end-to-end additive manufacturing process in the aircraft industry and underlines how companies exploiting Blockchain can build secure and connected manufacturing infrastructure.;Elsevier B.V.;Journal;Computers in Industry;2019-08-01;https://api.elsevier.com/content/abstract/scopus_id/85065156908
828;Consistent extra-functional properties tagging for component and connector models;We present a model-driven approach for adding extra-functional properties to component and connector (C&C) models. The approach is based on a tagging mechanism that allows non-invasive extensions of existing languages and their models, here C&C models, with attributes for extra-functional properties. Importantly, our language extension provides means for integrated formal analyses of the consistency of tagged values. Consistency ranges from type-safety and units of quantitative measures to complex dependencies across component hierarchies as well as between component definitions and their instances. We provide a framework for defining and checking rich consistency rules of extra-functional property values based on selection, aggregation, and comparison operators. Our work allows for independent definition and organization of tagged properties to support reuse across models and development stages. The approach is implemented within the MontiCore framework for the C&C architecture description language MontiArc.;CEUR-WS;Conference Proceeding;CEUR Workshop Proceedings;2016-01-01;https://api.elsevier.com/content/abstract/scopus_id/84996931619
829;Presenting a conceptual model for designing hospital architecture with a patient-centered approach based on the patient's lived experience of sense of place in the therapeutic space;BACKGROUND: In recent years, among managers and designers of health-care spaces, there has been a growing tendency to move toward hospital design by combining patient perceptions and expectations of the physical environment of the care area. The main idea of this study was to present a conceptual model of hospital architecture in our country with a patient-centered approach based on some factors that were affecting the sense of place. This model determined the architectural features of treatment spaces from a patient's lived experience that could have a positive mental effect on patients as well. The main question of the research was how to adapt the objective perception to the patient's mental perception to create a sense of place in the hospital space? MATERIALS AND METHODS: This research was qualitative with a phenomenological approach, conducted between July and December 2020. Purposeful sampling consisted of 23 patients, 13 males in the male surgery unit and 10 females in the gynecology unit, who were interviewed in-depth. They were hospitalized for at least 3 days in two hospitals (Dr. Pirooz in Lahijan and Ghaem in Rasht). The data were analyzed by the Colaizzi method. RESULTS: The results consisted of 530 primary codes, 57 subthemes, and 7 main themes. The main themes were hospital location, access to hospital, hospital identity, hospital dependency, hospital attachment, human interactions in the hospital, and hospital evaluation. CONCLUSION: The hospital form guided the patient, and the hospital function directed and obviated the patient's needs. The healing environment and human interactions with it caused the patient to be satisfied with the hospital environment.;Wolters Kluwer Medknow Publications;Journal;Journal of Education and Health Promotion;2022-05-01;https://api.elsevier.com/content/abstract/scopus_id/85134476386
830;A model centered perspective on software-intensive systems;"The aim of this paper contributing to resurrect research interest in conceptual modeling as a means for designing and producing software-intensive systems, as there is still no comprehensive and consistent use of conceptual modeling in practice. The idea is to see any software and information system as a construct consisting of model handlers (model consumers and/or producers). This leads to the paradigm of ""Model Centered Architecture"", which treats all processes, as well as the data they process, as instances of models. These models in turn are instances of metamodels, described using a particular domain specific modeling language (DSML), and represented using a corresponding domain specific representation language. Consequently, all system interfaces are defined through models (via an appropriate DSML) as well. The paper introduces the relevant MCA concepts and sketches open research questions in this field.";CEUR-WSceurws@sunsite.informatik.rwth-aachen.de;Conference Proceeding;CEUR Workshop Proceedings;2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85048362692
831;User-centered and privacy-driven process mining system design for IoT;Process mining uses event data recorded by information systems to reveal the actual execution of business processes in organizations. By doing this, event logs can expose sensitive information that may be attributed back to individuals (e.g., reveal information on the performance of individual employees). Due to GDPR organizations are obliged to consider privacy throughout the complete development process, which also applies to the design of process mining systems. The aim of this paper is to develop a privacy-preserving system design for process mining. The user-centered view on the system design allows to track who does what, when, why, where and how with personal data. The approach is demonstrated on an IoT manufacturing use case.;Springer Verlagservice@springer.de;Book Series;Lecture Notes in Business Information Processing;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85066787588
832;Towards privacy-preserving IoT systems using model driven engineering;Considering the Internet of Things in production processes, the human factor and aspects such as data protection and data transparency are often ignored. However, collecting, storing and processing data is going to be a standard procedure in this domain. This includes data from sensors, machines, and processes as well as individual data about people. Recent approaches such as assistive systems for human-computer and human-machine interaction need more personal data than ever before to provide purposeful, tailored support. For MDE approaches it is important to consider privacy already on model level. This paper discusses a way to create privacy-preserving IoT systems using an MDE approach to support privacy and data transparency. We show the relevance and application on a use case from industrial production processes. Additionally, we discuss abilities for practical realization and its limitation.;CEUR-WSceurws@sunsite.informatik.rwth-aachen.de;Conference Proceeding;CEUR Workshop Proceedings;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85072779130
833;Human behavior, goals and model-driven software engineering for assistive systems;Assistive systems might reason about human behavior and specific actions to be able to assist human activities in everyday life or working situations. It is a challenge to create an adaptive, unobtrusive system with high accuracy of supporting actions. Previous work assumes that either a concrete goal is preset for a whole support application, or is chosen from a finite set of goals by the user or is calculated over a finite set of goals by heuristic algorithms. This novel directions paper discusses ideas to reduce the solution space for assistive systems by using observations of human behavior together with domain-specific and general knowledge. We discuss especially challenges for creating goal models, how to combine them with other existing models, and how to use them in model-based software engineering approaches with automatic code generation. A concrete realization of these ideas enables a variety of design decisions regarding modeling languages, the interplay of different languages, and how to handle goals at run-time.;CEUR-WSceurws@sunsite.informatik.rwth-aachen.de;Conference Proceeding;CEUR Workshop Proceedings;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85094179134
834;Context modeling for active assistance;Context awareness is the key to any active assistance system. The Human Behavior Monitoring and Support project (HBMS) applies a multilevel context modeling approach, aiming to achieve context readability, reuse, adaptability and interoperability. The HBMS-System is the resulting active assistance system, which is multiply deployable in different domains to support the behavior of users in situations referring to the user's own episodic knowledge. The HBMSSystem represents and preserves behavior and context knowledge in form of a Human Cognitive Model (HCM) expressed in a domain specific modeling language, called HCM-L. The first version of the HCM-L particularly focused on user behavior modeling. However, evaluations of first use case scenarios made clear that structural context elements like environment, spatiality and personal and social context have to be dealt in more detail. This paper summarizes the requirements for an extended HBMS context model and presents the advanced HCM-L at meta-level M2 also by giving examples on level M1.;CEUR-WS;Conference Proceeding;CEUR Workshop Proceedings;2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/85035035587
835;Model-Based Software Engineering to Tame the IoT Jungle;The Internet of Things (IoT) is a challenging combination of distribution and heterogeneity. A number of software engineering solutions address those challenges in isolation, but few solutions tackle them in combination, which poses a set of concrete challenges. The ThingML (Internet of Things Modeling Language) approach attempts to address those challenges. This model-driven, generative approach, which was inspired by UML, integrates concepts targeted at the IoT. Over the past six years, it has been continuously evolved and applied to cases in different domains, including a commercial e-health solution.;IEEE Computer Societyhelp@computer.org;Journal;IEEE Software;2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/85010402413
836;Choice of effective messaging protocols for IoT systems: MQTT, CoAP, AMQP and HTTP;"The standard and real-time communication technology is an unalloyed inevitability for the development of Internet of Things (IoT) applications. However, the selection of a standard and effective messaging protocol is a challenging and daunting task for any organisation because it depends on the nature of the IoT system and its messaging requirements. Copious messaging protocols have been developed and employed by various organisations based on their requirements in the last two decades. Though, none of them is able to support all messaging requirements of all types of IoT systems. Messaging protocol is an ongoing dilemma for the IoT industry; consequently, it is important to understand the pros and cons of the widely accepted and emerging messaging protocols for IoT systems to determine their best-fit scenarios. Therefore, this paper presents an evaluation of the four established messaging protocols MQTT, CoAP, AMQP and HTTP for IoT systems. Firstly, it presents the broad comparison among these messaging protocols to introduce their characteristics comparatively. Afterwards, it performs a further in-depth and relative analysis based on some interrelated criteria to gain insight into their strengths and limitations. Thus, based on this detailed evaluation, the user can decide their appropriate usage in various IoT systems according to their requirements and suitability.";Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;2017 IEEE International Symposium on Systems Engineering, ISSE 2017 - Proceedings;2017-10-26;https://api.elsevier.com/content/abstract/scopus_id/85040112745
837;Proceedings of the 13th International Symposium on Games, Automata, Logics and Formal Verification, G and ALF 2022;"The proceedings contain 14 papers. The topics discussed include: techniques for unambiguous systems; learning languages of infinite words; state complexity of population protocols; towards multiset semantics database theory: how i learned to stop worrying and love linear algebra; on the existential fragments of local first-order logics with data; capturing bisimulation-invariant exponential-time complexity classes; complexity through translations for modal logic with recursion; schema-based automata determinization; generating tokenizers with flat automata; parametric interval temporal logic over infinite words; realizable and context-free hyperlanguages; controller synthesis for timeline-based games; and adversarial formal semantics of attack trees and related problems.";Open Publishing Association;Conference Proceeding;Electronic Proceedings in Theoretical Computer Science, EPTCS;2022-09-20;https://api.elsevier.com/content/abstract/scopus_id/85139959305
838;Calvin-merging Cloud and IoT;"Developing applications for IoT and Cloud is difficult for a number of reasons; even without considering the inherent complexity of distributed computing, there are several competing platforms, programming languages and communication protocols. It can be argued that this is holding back the industry as a whole: Applications are difficult to write, deploy and manage. In this position paper we present Calvin, a hybrid framework combining ideas from the Actor model and Flow Based Computing. We show that by dividing applications into four well-defined aspects-describe, connect, deploy, and manage-we get an intuitive method for application development, and a flexible, distributed platform for deploying and managing applications. Additionally, we keep Calvin language and platform agnostic by only prescribing a lightweight runtime API, with a limited number of specified communication protocols-with no requirements on the carrier-for communicating with runtimes, between runtimes, and passing data between components.";Elsevier B.V.;Conference Proceeding;Procedia Computer Science;2015-01-01;https://api.elsevier.com/content/abstract/scopus_id/84939195246
839;OpenRoACH: A durable open-source hexapedal platform with onboard robot operating system (ROS);OpenRoACH is a 15-cm 200-gram self-contained hexapedal robot with an onboard single-board computer. To our knowledge, it is the smallest legged robot with the capability of running the Robot Operating System (ROS) onboard. The robot is fully open sourced, uses accessible materials and off-the-shelf electronic components, can be fabricated with benchtop fast-prototyping machines such as a laser cutter and a 3D printer, and can be assembled by one person within two hours. Its sensory capacity has been tested with gyroscopes, accelerometers, Beacon sensors, color vision sensors, linescan sensors and cameras. It is low-cost within 150 including structure materials, motors, electronics, and a battery. The capabilities of OpenRoACH are demonstrated with multi-surface walking and running, 24-hour continuous walking burn-ins, carrying 200-gram dynamic payloads and 800-gram static payloads, and ROS control of steering based on camera feedback. Information and files related to mechanical design, fabrication, assembly, electronics, and control algorithms are all publicly available on https://wiki.eecs.berkeley.edu/biomimetics/Main/OpenRoACH.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - IEEE International Conference on Robotics and Automation;2019-05-01;https://api.elsevier.com/content/abstract/scopus_id/85071496807
840;Digital twin: Values, challenges and enablers from a modeling perspective;Digital twin can be defined as a virtual representation of a physical asset enabled through data and simulators for real-time prediction, optimization, monitoring, controlling, and improved decision making. Recent advances in computational pipelines, multiphysics solvers, artificial intelligence, big data cybernetics, data processing and management tools bring the promise of digital twins and their impact on society closer to reality. Digital twinning is now an important and emerging trend in many applications. Also referred to as a computational megamodel, device shadow, mirrored system, avatar or a synchronized virtual prototype, there can be no doubt that a digital twin plays a transformative role not only in how we design and operate cyber-physical intelligent systems, but also in how we advance the modularity of multi-disciplinary systems to tackle fundamental barriers not addressed by the current, evolutionary modeling practices. In this work, we review the recent status of methodologies and techniques related to the construction of digital twins mostly from a modeling perspective. Our aim is to provide a detailed coverage of the current challenges and enabling technologies along with recommendations and reflections for various stakeholders.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85081090770
841;Teaching agile model-driven engineering for cyber-physical systems;Agile development methods, model-driven engineering, and cyber-physical systems are important topics in software engineering education. It is not obvious how to teach their combination while respecting individual challenges posed to students and educators. We have devised a software project class for teaching the agile MDE for CPS. The project class was held in three different semesters. In this paper, we report on the setup of our exploratory study and its goals for teaching. We base our evaluation and insights on interviews and questionnaires. Our results show the feasibility of combination of agile MDE for CPS but also the challenges this combination poses to students and educators.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering: Software Engineering and Education Track, ICSE-SEET 2017;2017-06-29;https://api.elsevier.com/content/abstract/scopus_id/85026747612
842;Modeling with UML: Language, Concepts, Methods;This book presents a variant of UML that is especially suitable for agile development of high-quality software. It adjusts the language UML profile, called UML/P, for optimal assistance for the design, implementation, and agile evolution to facilitate its use especially in agile, yet model based development methods for data intensive or control driven systems. After a general introduction to UML and the choices made in the development of UML/P in Chapter 1, Chapter 2 includes a definition of the language elements of class diagrams and their forms of use as views and representations. Next, Chapter 3 introduces the design and semantic facets of the Object Constraint Language (OCL), which is conceptually improved and syntactically adjusted to Java for better comfort. Subsequently, Chapter 4 introduces object diagrams as an independent, exemplary notation in UML/P, and Chapter 5 offers a detailed introduction to UML/P Statecharts. Lastly, Chapter 6 presents a simplified form of sequence diagrams for exemplary descriptions of object interactions. For completeness, appendixes A–C describe the full syntax of UML/P, and appendix D explains a sample application from the E-commerce domain, which is used in all chapters. This book is ideal for introductory courses for students and practitioners alike.;Springer International Publishing;Book;Modeling with UML: Language, Concepts, Methods;2016-01-01;https://api.elsevier.com/content/abstract/scopus_id/85125489900
843;Shaping the digital twin for design and production engineering;The digitalization of manufacturing fuels the application of sophisticated virtual product models, which are referred to as digital twins, throughout all stages of product realization. Particularly, more realistic virtual models of manufactured products are essential to bridge the gap between design and manufacturing and to mirror the real and virtual worlds. In this paper, we propose a comprehensive reference model based on the concept of Skin Model Shapes, which serves as a digital twin of the physical product in design and manufacturing. In this regard, model conceptualization, representation, and implementation as well as applications along the product life-cycle are addressed.;Elsevier USA;Journal;CIRP Annals - Manufacturing Technology;2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/85018723536
844;Code generation using model driven architecture: A systematic mapping study;Model Driven Architecture (MDA) has earned a prominent place in Software Engineering. However, while the application of MDA in software industry has grown, its impact in industry is not being as fast and broad as predicted. Moreover, the emerging use of agile methods have had an effect on the interest of industry and academics on developing software using metamodels. As a result, it is difficult to establish the true interest of practicioners about code generation using model driven architectures. This study investigates the scientific evidence of model driven architecture by conducting a systematic mapping of MDA literature in software engineering between 2008 and 2018. The search strategy resulted in 2.145 studies, of which 50 were identified as primary articles relevant to this study. We have verified that there is a considerable number of research articles that make use of MDA, published in a variety of journals, congresses and workshops, referred to very varied fields of application, and this number of publications seems to be increasing. The study also shows that, while there are few relevant publications that specifically deal with code generation using MDA, most of them show how this technology can be applied successfully to enhance software development.;Elsevier Ltd;Journal;Journal of Computer Languages;2020-02-01;https://api.elsevier.com/content/abstract/scopus_id/85076701164
845;A concept in synchronization of virtual production system with real factory based on anchor-point method;A Digital Twin, an always in sync digital model of existing manufacturing cells, can be used to reduce time and risk of reconfiguration by early detection of design or process sequence flaws of the system in virtual commissioning and simulation. In this paper the need of Digital Twins in future production plants as well as the structure of the Digital Twin is presented. The engineering process of production systems is a cross-domain challenge between mechanics, electrics and software, but a lack of collaboration and universal information transfer between the domains leads to a high investment volume by synchronization the digital model from the time of commissioning. To synchronize cross-domain mechatronic data models of mechatronic components in the digital world during the life cycle of existing production systems this paper presents the anchor point method to firstly detect variances of cross-domain mechatronic data structure between the digital model and the real system in the specific domains electrics, mechanics and software and update the virtual models to have a consistent data model of the Digital Twin.;Elsevier B.V.;Conference Proceeding;Procedia CIRP;2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85044658638
846;Knowledge map and forecast of digital twin in the construction industry: State-of-the-art review using scientometric analysis;"With the advancement of Industry 4.0 and the development of science and technology, industries have seen the advantages of digital twin (DT) implementations and concepts. Although the construction industry is still in the early stage of DT development and implementation, it is urgent for the industry to have a DT agenda. This paper identifies 1158 related bibliographic records from the Web of Science and 745 records from the Derwent Patent Database and quantitatively analyzed them to describe patterns of publications. Two knowledge mapping tools were selected to visualize and analyze the literature in the relevant scientific domain. Then, we integrated clustering, knowledge mapping, and network analysis methods to show the current foci and future directions of DT-MT derived from the data of time distribution, journal areas, and subject distribution. The results indicate that DT is a cross-disciplinary information technology with great development potential, and its development in the construction industry is scattered with the leading advancement in the manufacturing of construction materials and components. The derived knowledge map shows three stages of construction DT, including (1) data collection and creation of DT framework and database; (2) implementation of planning and design modules in detail and control of construction sites; and (3) carrying out asset management and fault prediction in the operation and maintenance phase of projects. The novelty of this paper is the specific analysis of DT in the construction industry. This study adds value to the architecture, engineering, and construction industries by shedding light on the focus of DT practical applications and the formation of a development path of construction DT.";Elsevier Ltd;Journal;Journal of Cleaner Production;2023-01-10;https://api.elsevier.com/content/abstract/scopus_id/85143719809
847;Digital twin-driven product design, manufacturing and service with big data;Nowadays, along with the application of new-generation information technologies in industry and manufacturing, the big data-driven manufacturing era is coming. However, although various big data in the entire product lifecycle, including product design, manufacturing, and service, can be obtained, it can be found that the current research on product lifecycle data mainly focuses on physical products rather than virtual models. Besides, due to the lack of convergence between product physical and virtual space, the data in product lifecycle is isolated, fragmented, and stagnant, which is useless for manufacturing enterprises. These problems lead to low level of efficiency, intelligence, sustainability in product design, manufacturing, and service phases. However, physical product data, virtual product data, and connected data that tie physical and virtual product are needed to support product design, manufacturing, and service. Therefore, how to generate and use converged cyber-physical data to better serve product lifecycle, so as to drive product design, manufacturing, and service to be more efficient, smart, and sustainable, is emphasized and investigated based on our previous study on big data in product lifecycle management. In this paper, a new method for product design, manufacturing, and service driven by digital twin is proposed. The detailed application methods and frameworks of digital twin-driven product design, manufacturing, and service are investigated. Furthermore, three cases are given to illustrate the future applications of digital twin in the three phases of a product respectively.;Springer London;Journal;International Journal of Advanced Manufacturing Technology;2018-02-01;https://api.elsevier.com/content/abstract/scopus_id/85015707925
848;Digital Twins and Cyber–Physical Systems toward Smart Manufacturing and Industry 4.0: Correlation and Comparison;State-of-the-art technologies such as the Internet of Things (IoT), cloud computing (CC), big data analytics (BDA), and artificial intelligence (AI) have greatly stimulated the development of smart manufacturing. An important prerequisite for smart manufacturing is cyber–physical integration, which is increasingly being embraced by manufacturers. As the preferred means of such integration, cyber–physical systems (CPS) and digital twins (DTs) have gained extensive attention from researchers and practitioners in industry. With feedback loops in which physical processes affect cyber parts and vice versa, CPS and DTs can endow manufacturing systems with greater efficiency, resilience, and intelligence. CPS and DTs share the same essential concepts of an intensive cyber–physical connection, real-time interaction, organization integration, and in-depth collaboration. However, CPS and DTs are not identical from many perspectives, including their origin, development, engineering practices, cyber–physical mapping, and core elements. In order to highlight the differences and correlation between them, this paper reviews and analyzes CPS and DTs from multiple perspectives.;Elsevier Ltd;Journal;Engineering;2019-08-01;https://api.elsevier.com/content/abstract/scopus_id/85068798049
849;Comparison of digital twin development in manufacturing and maritime domains;The concept of the digital twin is developing as a key enabler for the Industry 4.0 vision. The digital twin – a virtual representation of a real-world entity to facilitate integration with digital systems – has sparked research and application in different domains. A cross-domain comparison is presented through the review of the development of digital twins in the manufacturing and maritime domains. The comparison focuses on the needs for digital twins, conceptual and implementation frameworks, platforms, and real-world implementations in these two domains.;Springer Verlagservice@springer.de;Book Series;Studies in Computational Intelligence;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85070640016
850;A Systematic Mapping Study on Modeling for Industry 4.0;Industry 4.0 is a vision of manufacturing in which smart, interconnected production systems optimize the complete value-added chain to reduce cost and time-to-market. At the core of Industry 4.0 is the smart factory of the future, whose successful deployment requires solving challenges from many domains. Model-based systems engineering (MBSE) is a key enabler for such complex systems of systems as can be seen by the increased number of related publications in key conferences and journals. This paper aims to characterize the state of the art of MBSE for the smart factory through a systematic mapping study on this topic. Adopting a detailed search strategy, 1466 papers were initially identified. Of these, 222 papers were selected and categorized using a particular classification scheme. Hence, we present the concerns addressed by the modeling community for Industry 4.0, how these are investigated, where these are published, and by whom. The resulting research landscape can help to understand, guide, and compare research in this field. In particular, this paper identifies the Industry 4.0 challenges addressed by the modeling community, but also the challenges that seem to be less investigated.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - ACM/IEEE 20th International Conference on Model Driven Engineering Languages and Systems, MODELS 2017;2017-11-07;https://api.elsevier.com/content/abstract/scopus_id/85040612230
851;On demand data analysis and filtering for inaccurate flight trajectories;This paper reports on work performed in the context of the COMPASS SESAR-JU WP-E project, on developing an approach for identifying and filtering inaccurate trajectories (ghost flights) in historical data originating from the EUROCONTROL-operated Demand Data Repository (DDR).;EUROCONTROL;Conference Proceeding;SIDs 2011 - Proceedings of the SESAR Innovation Days;2011-01-01;https://api.elsevier.com/content/abstract/scopus_id/84925679659
852;GA optimization model for solving tower crane location problem in construction site s;Tower crane is increasingly becoming one of the key components of temporary site layout facilities in most construction projects. Determining the location of tower crane is an essential task of layout planning, which is also the central focus of this study. The optimization of tower crane location depends on many interrelated factors, including site constraints, shape and size of the buildings, type and quantity of required materials, crane configurations, crane type, and construction site layout. These factors vary from one project to another, resulting to complicated site layout strategies and approaches. This fact makes the crane location problem impractical to be solved depending on experience of practitioners only which was gained by assuming and through trial and error. This paper aimed at developing an optimization model to solve tower crane location problem in construction sites. The objective was to minimize the total transportation time. Genetic Algorithms (GA) optimization technique is utilized to solve the problem. A numerical example is presented to test and validate the results obtained by the model.;Elsevier B.V.;Journal;Alexandria Engineering Journal;2015-09-01;https://api.elsevier.com/content/abstract/scopus_id/84947044944
853;Reflections on monadic lenses;Bidirectional transformations (bx) have primarily been modeled as pure functions, and do not account for the possibility of the side-effects that are available in most programming languages. Recently several formulations of bx that use monads to account for effects have been proposed, both among practitioners and in academic research. The combination of bx with effects turns out to be surprisingly subtle, leading to problems with some of these proposals and increasing the complexity of others. This paper reviews the proposals for monadic lenses to date, and offers some improved definitions, paying particular attention to the obstacles to naively adding monadic effects to existing definitions of pure bx such as lenses and symmetric lenses, and the subtleties of equivalence of symmetric bidirectional transformations in the presence of effects.;Springer Verlagservice@springer.de;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2016-01-01;https://api.elsevier.com/content/abstract/scopus_id/84973902366
854;Introduction to bidirectional transformations;Bidirectional transformations (BX) serve to maintain consistency between different representations of related and often overlapping information, translating changes in one representation to the others. We present a brief introduction to the field, in order to provide some common background to the remainder of this volume, which constitutes the lecture notes from the Summer School on Bidirectional Transformations, held in Oxford in July 2016 as one of the closing activities of the UK EPSRC-funded project A Theory of Least Change for Bidirectional Transformations.;Springer Verlagservice@springer.de;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85045183791
855;Analysis and visualization of urban emission measurements in smart cities;Cities worldwide aim to reduce their greenhouse gas emissions and improve air quality for their citizens. Therefore, there is a need to implement smart city approaches to monitor, model, and understand local emissions to better guide these actions. We present our approach that deploys a number of low-cost sensors through a wireless Internet of Things (IoT) backbone and is thus capable of collecting high-granular data. Based on a flexible architecture, we built an ecosystem of data management and data analytics including processing, integration, analysis, and visualization as well as decision-support systems for cities to better understand their emissions. Our prototype system has so far been tested in two Scandinavian cities. We present this system and demonstrate how to collect, integrate, analyze, and visualize real-time air quality data.;OpenProceedings.orgMarc.Scholl@uni-konstanz.de;Conference Proceeding;Advances in Database Technology - EDBT;2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85072048552
856;Detecting shadow for direct radiation using CityGML models for photovoltaic potentiality analysis;Photovoltaic method is very popular for generating electrical power. Its energy production depends on solar radiation on that location and orientation. Shadow rapidly decreases performance of the Photovoltaic system. In this research, it is being investigated that how exactly real-time shadow can be detected. In principle, 3D city models containing roof structure, vegetation, thematically differentiated surface and texture, are suitable to simulate exact real-time shadow. An automated procedure to measure exact shadow effect from the 3D city models and a long-term simulation model to determine the produced energy from the photovoltaic system is being developed here. In this paper, a method for detecting shadow for direct radiation has been discussed with its result using a 3D city model to perform a solar energy potentiality analysis. © 2013 Taylor & Francis Group.;Taylor and Francis - Balkemapub.nl@tandf.co.uk;Conference Proceeding;Urban and Regional Data Management, UDMS Annual 2013 - Proceedings of the Urban Data Management Society Symposium 2013;2013-01-01;https://api.elsevier.com/content/abstract/scopus_id/84877678914
857;Benchmarking bidirectional transformations: theory, implementation, application, and assessment;Bidirectional transformations (bx) are relevant for a wide range of application domains. While bx problems may be solved with unidirectional languages and tools, maintaining separate implementations of forward and backward synchronizers with mutually consistent behavior can be difficult, laborious, and error-prone. To address the challenges involved in handling bx problems, dedicated languages and tools for bx have been developed. Due to their heterogeneity, however, the numerous and diverse approaches to bx are difficult to compare, with the consequence that fundamental differences and similarities are not yet well understood. This motivates the need for suitable benchmarks that facilitate the comparison of bx approaches. This paper provides a comprehensive treatment of benchmarking bx, covering theory, implementation, application, and assessment. At the level of theory, we introduce a conceptual framework that defines and classifies architectures of bx tools. At the level of implementation, we describe Benchmarx, an infrastructure for benchmarking bx tools which is based on the conceptual framework. At the level of application, we report on a wide variety of solutions to the well-known Families-to-Persons benchmark, which were developed and compared with the help of Benchmarx. At the level of assessment, we reflect on the usefulness of the Benchmarx approach to benchmarking bx, based on the experiences gained from the Families-to-Persons benchmark.;Springer;Journal;Software and Systems Modeling;2020-05-01;https://api.elsevier.com/content/abstract/scopus_id/85073810908
858;Establishing a national 3D geo-data model for building data compliant to citygml: Case Of Turkey;This paper presents the generation of the 3D national building geo-data model of Turkey, which is compatible with the international OGC CityGML Encoding Standard. We prepare an ADE named CityGML-TRKBIS.BI that is produced by extending existing thematic modules of CityGML according to TRKBIS needs. All thematic data groups in TRKBIS geo-data model have been remodelled in order to generate the national large scale 3D geo-data model for Turkey. Specific attention has been paid to data groups that have different class structure according to related CityGML data themes such as building data model. Current 2D geo-information model for building data theme of Turkey (TRKBIS.BI) was established based on INSPIRE specifications for building (Core 2D and Extended 2D profiles), ISO/TC 211 standards and OGC web services. New version of TRKBIS.BI which is established according to semantic and geometric rules of CityGML will represent 2D-2.5D and 3D objects. After a short overview on generic approach, this paper describes extending CityGML building data theme according to TRKBIS.BI through several steps. First, building models of both standards were compared according to their data structure, classes and attributes. Second, CityGML building model was extended with respect to TRKBIS needs and CityGML-TRKBIS Building ADE was established in UML. This study provides new insights into 3D applications in Turkey. The generated 3D geo-data model for building thematic class will be used as a common exchange format that meets 2D, 2.5D and 3D implementation needs at national level.;International Society for Photogrammetry and Remote Sensing;Conference Proceeding;International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives;2016-01-01;https://api.elsevier.com/content/abstract/scopus_id/84981200953
859;Calculation Principle and Algorithm for the Window of Exact Acceleration in Real-Time Model Checking 实时模型检测精确加速窗口的计算原理及算法;When real-time systems are modeled as timed automata, different time scales may lead to a lot of fragmentations of the symbolic state space. This problem can be solved by computing the zones which in practice use the abstraction technique. The state-of-the-art abstraction methods produce an approximation that is closer to the actual reachable clock valuation, which are coarser abstractions. The exact acceleration is a finer abstraction way to reduce the required storage space and it can solve or alleviate the state space explosion problem of the fragmentations. Calculating the acceleratable cycle's window is the key technology in exact acceleration. The calculation of the window in acceleratable cycle depends on the location invariant, edge constraint and clock reset. By comprehensively analyzing the exact acceleration principle, an algorithm is proposed to calculate the window in exact acceleration. Firstly, it is important to identify all acceleratable cycles in time automaton. Choose one node with clock reset on incoming edge as the start and check whether there is a clock reset on outgoing edge for every nodes. Secondly, all the recorded nodes link as a new cycle according to the recording ordering. Each node in new cycle has the original location invariant and each edge contains clock reset. In addition, edge constraints need to calculate. Finally, the window of acceleratable cycle can denote an interval [a,b], where a means the sum of edge constraints and b means the sum of location invariants. The time complexity of the algorithm is O(n2). According to the calculation principle, the algorithm can get the valid data of the window, reduce other useless data and nodes, compress the acceleratable cycle, make the model simpler and enhance the computing efficiency. The algorithm lays the foundation for the research and development of the automatic model checking program.;Science Presswangjing@neigae.ac.cn;Journal;Jisuanji Yanjiu yu Fazhan/Computer Research and Development;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85083733821
860;Monitoring mobile and spatially distributed cyber-physical systems;Cyber-Physical Systems (CPS) consist of collaborative, networked and tightly intertwined computational (logical) and physical components, each operating at different spatial and temporal scales. Hence, the spatial and temporal requirements play an essential role for their correct and safe execution. Furthermore, the local interactions among the system components result in global spatio-temporal emergent behaviors often impossible to predict at the design time. In this work, we pursue a complementary approach by introducing STREL a novel spatio-temporal logic that enables the specification of spatio-temporal requirements and their monitoring over the execution of mobile and spatially distributed CPS. Our logic extends the Signal Temporal Logic [15] with two novel spatial operators reach and escape from which is possible to derive other spatial modalities such as everywhere, somewhere and surround. These operators enable a monitoring procedure where the satisfaction of the property at each location depends only on the satisfaction of its neighbours, opening the way to future distributed online monitoring algorithms. We propose both a qualitative and quantitative semantics based on constraint semirings, an algebraic structure suitable for constraint satisfaction and optimisation. We prove that, for a subclass of models, all the spatial properties expressed with reach and escape, using euclidean distance, satisfy all the model transformations using rotation, reflection and translation. Finally, we provide an offline monitoring algorithm for STREL and, to demonstrate the feasibility of our approach, we show its application using the monitoring of a simulated mobile ad-hoc sensor network as running example.;Association for Computing Machinery, Incacmhelp@acm.org;Conference Proceeding;MEMOCODE 2017 - 15th ACM-IEEE International Conference on Formal Methods and Models for System Design;2017-09-29;https://api.elsevier.com/content/abstract/scopus_id/85036454197
861;Applications of 3D city models: State of the art review;"In the last decades, 3D city models appear to have been predominantly used for visualisation; however, today they are being increasingly employed in a number of domains and for a large range of tasks beyond visualisation. In this paper, we seek to understand and document the state of the art regarding the utilisation of 3D city models across multiple domains based on a comprehensive literature study including hundreds of research papers, technical reports and online resources. A challenge in a study such as ours is that the ways in which 3D city models are used cannot be readily listed due to fuzziness, terminological ambiguity, unclear added-value of 3D geoinformation in some instances, and absence of technical information. To address this challenge, we delineate a hierarchical terminology (spatial operations, use cases, applications), and develop a theoretical reasoning to segment and categorise the diverse uses of 3D city models. Following this framework, we provide a list of identified use cases of 3D city models (with a description of each), and their applications. Our study demonstrates that 3D city models are employed in at least 29 use cases that are a part of more than 100 applications. The classified inventory could be useful for scientists as well as stakeholders in the geospatial industry, such as companies and national mapping agencies, as it may serve as a reference document to better position their operations, design product portfolios, and to better understand the market.";MDPI AGPostfachBaselCH-4005;Journal;ISPRS International Journal of Geo-Information;2015-12-01;https://api.elsevier.com/content/abstract/scopus_id/84952802912
862;Collaborative Model-Driven Software Engineering — A systematic survey of practices and needs in industry;The engineering of modern software-intensive systems is carried out in collaboration among stakeholders with specialized expertise. The complexity of such systems often also necessitates employing more rigorous approaches, such as Model-Driven Software Engineering (MDSE). Collaborative MDSE is the combination of the two disciplines, with its specific opportunities and challenges. The rapid expansion and maturation of the field started attracting tool builders from outside of academia. However, available systematic studies on collaborative MDSE focus exclusively on mapping academic research and fail to identify how academic research aligns with industry practices and needs. To address this shortcoming, we have carried out a mixed-method survey on the practices and needs concerning collaborative MDSE. First, we carried out a qualitative survey in two focus group sessions, interviewing seven industry experts. Second, based on the results of the interviews, we constructed a questionnaire and carried out a questionnaire survey with 41 industry expert participants. In this paper, we report the results of our study, investigate the alignment of academic research with the needs of practitioners, and suggest directions on research and development of the supporting techniques of collaborative MDSE.;Elsevier Inc.;Journal;Journal of Systems and Software;2023-05-01;https://api.elsevier.com/content/abstract/scopus_id/85147541731
863;'I t’s not going to be a one size fits all': a qualitative exploration of the potential utility of three drug checking service models in Scotland;Background: Scotland currently has the highest rates of drug-related deaths in Europe, so drug checking services are being explored due to their potential role in reducing these deaths and related harms. Drug checking services allow individuals to submit presumed psychoactive drug samples for analysis, and then receive individualised feedback and counselling. This paper explores participants’ views on the advantages and challenges of three hypothetical service models, to inform future service delivery in Scotland. Methods: Semi-structured interviews were conducted with 43 people: 27 professional stakeholders, 11 people with experience of drug use, and five family members across three cities. Vignettes were used to provide short descriptions of three hypothetical service models during the interviews. Interviews were audio-recorded, transcribed and analysed using thematic analysis. Results: Participants identified advantages and challenges for each of the three potential service models. The third sector (not-for-profit) model was favoured overall by participants, and the NHS substance use treatment service was the least popular. Participants also noted that multiple drug checking sites within one city, along with outreach models would be advantageous, to meet the diverse needs of different groups of people who use drugs. Conclusions: Drug checking services need to be tailored to local context and needs, with a range of service models being possible, in order to meet the needs of a heterogeneous group of people who use drugs. Addressing issues around stigma, accessibility, and concerns about the potential impact of accessing drug checking on access to and outcomes of drug treatment, are essential for successful service delivery.;BioMed Central Ltd;Journal;Harm Reduction Journal;2023-12-01;https://api.elsevier.com/content/abstract/scopus_id/85165886173
864;Multiple-scenario unmanned aerial system control: A systems engineering approach and review of existing control methods;The use of unmanned aerial systems (UASs) in both the public and military environments is predicted to grow significantly. As the demand for UASs grows, the availability of more robust and capable vehicles that can perform multiple mission types will be needed. In the public sector, the demand will grow for UASs to be used for agriculture, forestry, and search and rescue missions. Militaries continue to demand more UAS capabilities for diverse operations around the world. Significant research has been performed and continues to progress in the areas of autonomous UAS control. A majority of the work focuses on subsets of UAS control: path planning, autonomy, small UAS controls, and sensors. Minimal work exists on a system-level problem of multiple-scenario UAS control for integrated systems. This paper provides a high-level modular system architecture definition that is modifiable across platform types and mission requirements. Areview of the current research and employment of UAS capabilities is provided to evaluate the state of the capabilities required to enable the proposed architecture.;MDPI Multidisciplinary Digital Publishing Institutesupport@mdpi.com;Journal;Aerospace;2016-03-01;https://api.elsevier.com/content/abstract/scopus_id/84980392368
865;Distributed Parallel Needleman-Wunsch Algorithm on Heterogeneous Cluster System;At first, the needleman-wunsch algorithm that relies the optimal matching result is regarded as the basic algorithm to solve the problem of sequence alignment. Nevertheless, as the result of sequence database capacity index increased year by year and the algorithm of time and space complexity are higher, O (m×n). Facing these problems, researchers need to reduce the sequence alignment algorithm becomes more important for time and space complexity basic algorithm to solve the problem of sequence alignment. Therefore, this paperuses the characteristics of heterogeneous cluster, basing on the theory of divisible load, using the communication strategy of LIFO, simplex communication model, the design bases on dual sequence global alignment parallel algorithm of Needleman-Wunsch, the algorithm puts forward the strategy of partitioning score data matrix, to determine the optimal number of iterations and assigns to the child nodes of sub-sequence length ability to making full use of each node and performs tasks in a row, at the same time puts forward the strategy of backtracking, reduces the algorithm operation time, makes integral algorithm optimal.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2015 International Conference on Network and Information Systems for Computers, ICNISC 2015;2015-10-28;https://api.elsevier.com/content/abstract/scopus_id/84964895451
866;Bidirectional transformation enabled improvement in strength and ductility of metastable Fe50Mn30Co10Cr10 complex concentrated alloy under dynamic deformation;High strain rate compression experiments performed on a non-equiatomic metastable fcc + hcp Fe50Mn30Co10Cr10 high entropy alloy using split Hopkinson pressure bar setup shows improved flow stress and compression ductility compared to quasistatic deformed samples. The deformation response was characterised by the occurrence of hardening and softening stages compared to sustained strain hardening for quasistatic deformation. Detailed EBSD, BSE imaging analysis coupled with TEM shows significant bi-directional transformation (B-TRIP) and increased fcc γ phase stability in high strain rate regime while only forward (fcc to hcp) transformation dominates with increasing fraction of hcp ε phase in the quasistatic regime of deformation. Bidirectional transformation aided by adiabatic heating and heterogeneous deformation in the high strain rate regime leads to optimal stress and strain partitioning between the two phases and delays the initiation of damage at the interface. The presence of concomitant strain rate hardening and improvement in ductility in the dynamic deformation regime opens up avenues for microstructural tunability to achieve simultaneous improvement in strength and ductility using the metastability paradigm in complex concentrated alloys.;Elsevier Ltd;Journal;International Journal of Plasticity;2023-07-01;https://api.elsevier.com/content/abstract/scopus_id/85159200362
867;Bidirectional transformations with QVT-R: A case study in round-trip engineering UML class models and Java source code;Model-driven software engineering has become more and more important during the last few years. Model transformations constitute the core essence of model-driven development. Throughout the years, the concept of unidirectional model transformations and corresponding tool support has become mature and usable. Transformations of this kind are widely used in model-driven development, for forward or reverse engineering or mainly for code generation. Bidirectional transformations, on the other hand, aim to provide support for (incrementally) transforming one or more source models to one or more target models and vice versa from only one transformation description. However, they seem to be rarely used in model-driven software development although modelers need round-trip support between the different stages of development models. In this paper we present a QVT implementation of a bidirectional model transformation. Our case study keeps UML class diagrams consistent with a Java model during round-trip engineering and thereby shows a real world application. The results and experiences gained in this case study are discussed in detail.;SciTePress;Conference Proceeding;MODELSWARD 2016 - Proceedings of the 4th International Conference on Model-Driven Engineering and Software Development;2016-01-01;https://api.elsevier.com/content/abstract/scopus_id/84969921746
868;Model synchronization based on triple graph grammars: correctness, completeness and invertibility;Triple graph grammars (TGGs) have been used successfully to analyze correctness and completeness of bidirectional model transformations, but a corresponding formal approach to model synchronization has been missing. This paper closes this gap by providing a formal synchronization framework with bidirectional update propagation operations. They are generated from a given TGG, which specifies the language of all consistently integrated source and target models. As our main result, we show that the generated synchronization framework is correct and complete, provided that forward and backward propagation operations are deterministic. Correctness essentially means that the propagation operations preserve and establish consistency while completeness ensures that the operations are defined for all possible inputs. Moreover, we analyze the conditions under which the operations are inverse to each other. All constructions and results are motivated and explained by a running example, which leads to a case study, using concrete visual syntax and abstract syntax notation based on typed attributed graphs.;Springer Verlag;Journal;Software and Systems Modeling;2015-02-01;https://api.elsevier.com/content/abstract/scopus_id/84922337865
869;Principles and practice of bidirectional programming in BiGUL;Putback-based bidirectional programming allows the programmer to write only one backward transformation, from which the unique corresponding forward transformation is derived for free. A key distinguishing feature of putback-based bidirectional programming is full control over the bidirectional behavior, which is important for specifying intended bidirectional transformations without any ambiguity. In this chapter, we will introduce BiGUL, a simple yet powerful putback-based bidirectional programming language, explaining the underlying principles and showing how various kinds of bidirectional application can be developed in BiGUL.;Springer Verlagservice@springer.de;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85045189048
870;An EMOF-compliant abstract syntax for bigraphs;"Bigraphs are an emerging modeling formalism for structures in ubiquitous computing. Besides an algebraic notation, which can be adopted to provide an algebraic syntax for bigraphs, the bigraphical theory introduces a visual concrete syntax which is intuitive and unambiguous at the same time; the standard visual notation can be customized and thus tailored to domain-specific requirements. However, in contrast to modeling standards based on the Meta-Object Facility (MOF) and domain-specific languages typically used in model-driven engineering (MDE), the bigraphical theory lacks a precise definition of an abstract syntax for bigraphical modeling languages. As a consequence, available modeling and analysis tools use proprietary formats for representing bigraphs internally and persistently, which hampers the exchange of models across tool boundaries. Moreover, tools can be hardly integrated with standard MDE technologies in order to build sophisticated tool chains and modeling environments, as required for systematic engineering of large systems or fostering experimental work to evaluate the bigraphical theory in real-world applications. To overcome this situation, we propose an abstract syntax for bigraphs which is compliant to the Essential MOF (EMOF) standard defined by the Object Management Group (OMG). We use typed graphs as a formal underpinning of EMOF-based models and present a canonical mapping which maps bigraphs to typed graphs in a natural way. We also discuss application-specific variation points in the graph-based representation of bigraphs. Following standard techniques from software product line engineering, we present a framework to customize the graph-based representation to support a variety of application scenarios.";Open Publishing Association;Conference Proceeding;Electronic Proceedings in Theoretical Computer Science, EPTCS;2016-12-04;https://api.elsevier.com/content/abstract/scopus_id/85018662272
871;An axiomatic basis for bidirectional programming;Among the frameworks of bidirectional transformations proposed for addressing various synchronisation (consistency maintenance) problems, Foster et al.'s [2007] asymmetric lenses have influenced the design of a generation of bidirectional programming languages. Most of these languages are based on a declarative programming model, and only allow the programmer to describe a consistency specification with ad hoc and/or awkward control over the consistency restoration behaviour. However, synchronisation problems are diverse and require vastly different consistency restoration strategies, and to cope with the diversity, the bidirectional programmer must have the ability to fully control and reason about the consistency restoration behaviour. The putback-based approach to bidirectional programming aims to provide exactly this ability, and this paper strengthens the putback-based position by proposing the first fully fledged reasoning framework for a bidirectional language - a Hoare-style logic for Ko et al.'s [2016] putback-based language BiGUL. The Hoarestyle logic lets the BiGUL programmer precisely characterise the bidirectional behaviour of their programs by reasoning solely in the putback direction, thereby offering a unidirectional programming abstraction that is reasonably straightforward to work with and yet provides full control not achieved by previous approaches. The theory has been formalised and checked in Agda, but this paper presents the Hoare-style logic in a semi-formal way to make it easily understood and usable by the working BiGUL programmer.;Association for Computing Machinery;Journal;Proceedings of the ACM on Programming Languages;2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85120124335
872;BiGUL: A formally verified core language for putback-based bidirectional programming;"Putback-based bidirectional programming allows the programmer to write only one putback transformation, from which the unique corresponding forward transformation is derived for free. The logic of a putback transformation is more sophisticated than that of a forward transformation and does not always give rise to well-behaved bidirectional programs; this calls for more robust language design to support development of well-behaved putback transformations. In this paper, we design and implement a concise core language BiGUL for putback-based bidirectional programming to serve as a foundation for higher-level putback-based languages. BiGUL is completely formally verified in the dependently typed programming language AGDA to guarantee that any putback transformation written in BiGUL is well-behaved.";Association for Computing Machinery, Incacmhelp@acm.org;Conference Proceeding;PEPM 2016 - Proceedings of the 2016 ACM SIGPLAN Workshop on Partial Evaluation and Program Manipulation, co-located with POPL 2016;2016-01-11;https://api.elsevier.com/content/abstract/scopus_id/84966586668
873;CityGML: Interoperable access to 3D city models;Virtual 3D city models provide important information for different aspects of disaster management. In this context, up-to-dateness of and flexible access to 3D city models are of utmost importance. Spatial Data Infrastructures (SDI) provide the appropriate framework to cover both aspects, integrating distributed data sources on demand. In this paper we present CityGML, a multi-purpose and multi-scale representation for the storage of and interoperable access to 3D city models in SDIs. CityGML is based on the standard GML3 of the Open Geospatial Consortium and covers the geometrical, topological, and semantic aspects of 3D city models. The class taxonomy distinguishes between buildings and other man-made artifacts, vegetation objects, waterbodies, and transportation facilities like streets and railways. Spatial as well as semantic properties are structured in five consecutive levels of detail. Throughout the paper, special focus is on the utilization of model concepts with respect to different tasks in disaster management. © 2005 Springer-Verlag Berlin Heidelberg.;Springer Berlin Heidelberg;Book;Geo-information for Disaster Management;2005-12-01;https://api.elsevier.com/content/abstract/scopus_id/84895343560
874;CityGML 3.0: New Functions Open Up New Applications;The development of the next major version 3.0 of the international OGC standard CityGML is nearing its end. CityGML 3.0 will come up with a variety of new features and revisions of existing modules that will increase the usability of CityGML for more user groups and areas of application. This includes a new space concept, a revised level-of-detail (LOD) concept, the representation of time-dependent properties, the possibility to manage multiple versions of cities, the representation of city objects by point clouds, an improved modelling of constructions, the representation of building units and storeys, an improved representation of traffic infrastructure as well as a clear separation of the conceptual model and the data encodings that allow for providing further encoding specifications besides GML. This paper gives an overview of these new and revised concepts, and illustrates their application through selected use cases.;Springer Science and Business Media Deutschland GmbH;Journal;PFG - Journal of Photogrammetry, Remote Sensing and Geoinformation Science;2020-02-01;https://api.elsevier.com/content/abstract/scopus_id/85081034645
875;Declarative Specification of Bidirectional Transformations Using Design Patterns;Bidirectional transformations (bx) are a specific form of model transformation (MT) used in model-driven engineering to maintain consistency between two models, which may change independently. Currently bx are defined using a number of specialized transformation languages, which have had limited uptake due to complex semantics and poor efficiency. In contrast, unidirectional transformation languages such as ATL have been widely adopted, but require separate forward and reverse transformations to be written to address model synchronization requirements. In this paper, we provide declarative specification techniques for bx, systematically constructed using MT design patterns. We define two approaches to declarative bx definition: 1) by automatically bidirectionalizing unidirectional transformation specifications and 2) by developing specification guidelines for the QVT-R standard language to make it more effective for bx in practice. The approaches are evaluated using a large-scale code-generator bx from UML to ANSI C and other examples. Their semantic validity is demonstrated by rigorous arguments.;Institute of Electrical and Electronics Engineers Inc.;Journal;IEEE Access;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85059252286
876;SLA-Driven modeling and verifying cloud systems: A Bigraphical reactive systems-based approach;We propose a formal approach based on Bigraphical Reactive Systems (BRSs) and model checking techniques for modeling and verifying the interaction behaviours of SLA-based cloud computing systems. In the first phase of this approach, we address the modeling of the static structure and the dynamic behavior of cloud systems using BRSs. We show how bigraphs enable the description of the different cloud entities, including cloud actors, cloud services, Service Level Agreements (SLAs), the diversity of their properties, and the complex interactions and dependencies among them. Furthermore, we propose a four-stages SLA lifecycle, and define a set of bigraphical reaction rules to abstract these stages and model the dynamic nature of the cloud. The second phase of this approach verifies that the behavior of services and cloud actors will cope with the agreed SLA terms during the lifecycle of the SLA. We map the proposed bigraphical models into SMV descriptions. Then, we express the interaction behaviors as a set of liveness and safety properties using Linear Temporal Logic (LTL) and Computation Tree Logic (CTL) formulas, and we use the NuSMV model checker to verify them. Finally, we define a case study on which we illustrate the application of our proposed approach.;Elsevier B.V.;Journal;Computer Standards and Interfaces;2021-02-01;https://api.elsevier.com/content/abstract/scopus_id/85092243933
877;The space and motion of communicating agents;"The world is increasingly populated with interactive agents distributed in space, real or abstract. These agents can be artificial, as in computing systems that manage and monitor traffic or health; or they can be natural, e.g. communicating humans, or biological cells. It is important to be able to model networks of agents in order to understand and optimize their behavior. Robin Milner describes in this book just such a model, by presenting a unified and rigorous structural theory, based on bigraphs, for systems of interacting agents. This theory is a bridge between the existing theories of concurrent processes and the aspirations for ubiquitous systems, whose enormous size challenges our understanding. The book is self-contained mathematically and is designed to be learned from: examples and exercises abound, solutions for the latter are provided.";Cambridge University Press;Book;The Space and Motion of Communicating Agents;2009-01-01;https://api.elsevier.com/content/abstract/scopus_id/84924452673
878;Modeling multiple space views for schematic building design using space ontologies and layout transformation operations;Modeling multiple views of spaces involves mapping or transformation between multiple models. Automated model transformation is challenging as semantic and spatial criteria need to be considered. This paper proposes a novel method and data processing pipeline to define space views and semi-automatically transform room-based building data created in BIM authoring systems into multi-view space models. The method is based on space ontologies and their integration with space layout transformation operations. It is used to define a set of functional views that are relevant to schematic building design. An existing space modeling system is extended with the method and data processing pipeline. Results from a validation study show that the method can cover specific semantic and spatial aspects of space views. Both are relevant for consistent model transformation and accurate analysis. Results further show that it is feasible to fully automate data processing steps, except for space classification, which is semi-automated.;Elsevier B.V.;Journal;Automation in Construction;2022-02-01;https://api.elsevier.com/content/abstract/scopus_id/85121647584
879;Processing BIM and GIS models in practice: Experiences and recommendations from a GeoBIM project in The Netherlands;"It is widely acknowledged that the integration of BIM and GIS data is a crucial step forward for future 3D city modelling, but most of the research conducted so far has covered only the high-level and semantic aspects of GIS-BIM integration. This paper presents the results of the GeoBIM project, which tackled three integration problems focussing instead on aspects involving geometry processing: (i) the automated processing of complex architectural IFC models; (ii) the integration of existing GIS subsoil data in BIM; and (iii) the georeferencing of BIM models for their use in GIS software. All the problems have been studied using real world models and existing datasets made and used by practitioners in The Netherlands. For each problem, this paper exposes in detail the issues faced, proposed solutions, and recommendations for a more successful integration.";MDPI AGPostfachBaselCH-4005;Journal;ISPRS International Journal of Geo-Information;2018-08-01;https://api.elsevier.com/content/abstract/scopus_id/85051740461
880;Breaking into BIM: Performing static and dynamic security analysis with the aid of BIM;The design and construction industry is moving towards Building Information Models (BIM) that provide all of the strengths of traditional 3D CAD with an added layer of data allowing new and powerful applications. We investigate the concept of using the data within BIM to better explore security design and considerations. We achieve this by first graphing the physical entities of BIM to capture their relational representation as nodes and links. This graph representation will facilitate the use of graph theory or agent-based simulation to assist in the analysis of the static and dynamic behaviour of the environment around the BIM. We also demonstrate an application of graphing by investigating the use of BIM to explore automated infrastructure security design and consideration via red-teaming. The intent is to make security analysis easier and a process that can be carried out during the design phase of a project, even by non-expert users. © 2014 The Authors. Published by Elsevier B.V. All rights reserved.;Elsevier B.V.;Journal;Automation in Construction;2014-04-15;https://api.elsevier.com/content/abstract/scopus_id/84893484214
881;Utilities of Virtual 3D City Models Based on CityGML: Various Use Cases;Virtual 3D city models are increasingly being used to model the realms of the real world for utilization in a number of applications related to environmental simulations including, urban planning, mapping the energy characteristics of buildings, noise mapping, flood modelling, etc. Apart from geometric and appearance/textural information, these applications have a requirement for complex urban semantics. Currently, a number of 3D standards are available in CAD, BIM and GIS related domains for the storage, visualization and transfer of 3D geospatial datasets. Initially, the 3D data models (such as COLLADA, VRML, X3D, etc.) were purely graphical/geometrical in nature and mainly used for visualization purposes. With the inclusion of thematic modules in OGC CityGML, the integration of geometry and semantics in a single data model paved the way for better sharing of virtual 3D city models. In spite of the availability of a wide range of 3D data standards, there are certain differences with respect to geometry, topology, semantics, LODs, etc., which complicates the integration of 3D geodata from heterogeneous sources. This paper serves to highlights the need for the innovative solutions with respect to the urban environmental related simulations primarily based on the use of virtual 3D city models. Four use cases are studied in this context namely, (1) urban solar potential estimation using CityGML models, (2) simulation of traffic noise level mapped on building walls from the urban road segments, (3) CityGML based 3D data models interoperability, and (4) 3D indoor logistics and subsurface utilities. However, for modelling majority of use cases, CityGML does not provide explicit thematic representations but provides support for extending the CityGML schema using Application Domain Extensions. In a nutshell, the study explores the semantic modelling capabilities of the CityGML for the transformation of native 3D virtual city models to one satisfying capabilities like semantic information and support towards interoperability.;Springer;Journal;Journal of the Indian Society of Remote Sensing;2018-06-01;https://api.elsevier.com/content/abstract/scopus_id/85047350452
882;Specification of graph translators with triple graph grammars;Data integration is a key issue for any integrated set of software tools. A typical CASE environment, for instance, offers tools for the manipulation of requirements and software design documents, and it provides more or less sophisticated assistance for keeping these documents in a consistent state. Up to now, almost all data consistency observing or preserving integration tools are hand-crafted due to the lack of generic implementation frameworks and the absence of adequate specification formalisms. Triple graph grammars are intended to fill this gap and to support the specification of interdependencies between graph-like data structures on a very high level. Furthermore, they are the fundamentals of a new machinery for the production of batch-oriented as well as incrementally working data integration tools.;Springer Verlag;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);1995-01-01;https://api.elsevier.com/content/abstract/scopus_id/84947918251
883;BIM applications of rule-based checking in construction site layout planning tasks;Site layout and logistics planning generally plays an important role for the successful execution of construction activities. The allocation of the right amount and size and the timely use of resources play critical roles. Compared to other industrial sectors the construction industry shows a lack of technological progress in site logistics and fabrication planning. The automotive or ship building industries, for example, have stringent production planning methods in place to the point that almost every step in the planning and manufacturing processes is supported by digital simulation and optimization. On the other hand, construction planning appears to remain a manual process slowly taking advantage of building information modeling (BIM) processes and techniques. Our work investigates automated rulebased checking in construction site layout planning tasks to simplify the existing manual processes. A gap analysis of the traditional site layout planning process is performed to identify key areas that are of high concern to practitioners. A rule-based checking algorithm for site layout planning embedded in a commercially-available BIM-platform was created and tested on specific cases in the site layout planning process of a realistic building. Promising results and a discussion to the existing limitations of rule-based checking approaches for site layout planning are presented. A short outlook towards future research gives a potential path forward in advanced construction site layout planning.;International Association for Automation and Robotics in Construction I.A.A.R.C)IIT MadrasChennai;Conference Proceeding;ISARC 2016 - 33rd International Symposium on Automation and Robotics in Construction;2016-01-01;https://api.elsevier.com/content/abstract/scopus_id/84994344859
884;Citygml modelling for Singapore 3D national mapping;Since 2014, the Land Survey Division of Singapore Land Authority (SLA) has spearheaded a Whole-of-Government (WOG) 3D mapping project to create and maintain a 3D national map for Singapore. The implementation of the project is divided into two phases. The first phase of the project, which was based on airborne data collection, has produced 3D models for Relief, Building, Vegetation and Waterbody. This part of the work was completed in 2016. To complement the first phase, the second phase used mobile imaging and scanning technique. This phase is targeted to be completed by the mid of 2017 and is creating 3D models for Transportation, CityFurniture, Bridge and Tunnel. The project has extensively adopted the Open Geospatial Consortium (OGC)'s CityGML standard. Out of 10 currently supported thematic modules in CityGML 2.0, the project has implemented 8. The paper describes the adoption of CityGML in the project, and discusses challenges, data validations and management of the models.;International Society for Photogrammetry and Remote Sensing;Conference Proceeding;International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives;2017-10-23;https://api.elsevier.com/content/abstract/scopus_id/85033445025
885;Achieving complete and near-lossless conversion from IFC to CityGML †;The Singapore Government has embarked on a project to establish a three-dimensional city model and collaborative data platform for Singapore. The research herein contributes to this endeavour by developing a methodology and algorithms to automate the conversion of Building Information Models (BIM), in the Industry Foundation Classes (IFC) data format, into CityGML building models, capturing both geometric and semantic information as available in the BIM models, and including exterior as well as interior structures. We adopt a Triple Graph Grammar (TGG) to formally relate IFC and CityGML, both semantically and geometrically, and to transform a building information model, expressed as an IFC object graph, into a city model expressed as a CityGML object graph. The work pipeline includes extending the CityGML data model with an Application Domain Extension (ADE), which allows capturing information from IFC that is relevant in the geospatial context but at the same time not supported by CityGML in its standard form. In this paper, we elaborate on the triple graph grammar approach and the motivation and roadmap for the development of the ADE. While a fully complete and lossless conversion may never be achieved, this paper suggests that both a TGG and an ADE are natural choices for supporting the conversion between IFC and CityGML.;MDPI AGPostfachBaselCH-4005indexing@mdpi.com;Journal;ISPRS International Journal of Geo-Information;2018-09-01;https://api.elsevier.com/content/abstract/scopus_id/85053703567
886;Model-based Performance Analysis for Architecting Cyber-Physical Dynamic Spaces;Architecting Cyber-Physical Systems is not trivial since their intrinsic nature of mixing software and hardware components poses several challenges, especially when the physical space is subject to dynamic changes, e.g., paths of robots suddenly not feasible due to objects occupying transit areas or doors being closed with a high probability. This paper provides a quantitative evaluation of different architectural patterns that can be used for cyber-physical systems to understand which patterns are more suitable under some peculiar characteristics of dynamic spaces, e.g., frequency of obstacles in paths. We use stochastic performance models to evaluate architectural patterns, and we specify the dynamic aspects of the physical space as probability values. This way, we aim to support software architects with quantitative results indicating how different design patterns affect some metrics of interest, e.g., the system response time. Experiments show that there is no unique architectural pattern suitable to cope with all the dynamic characteristics of physical spaces. Each architecture differently contributes when varying the physical space, and it is indeed beneficial to switch among multiple patterns for an optimal solution.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - IEEE 18th International Conference on Software Architecture, ICSA 2021;2021-03-01;https://api.elsevier.com/content/abstract/scopus_id/85107007456
887;Modeling and verification of evolving cyber-physical spaces;We increasingly live in cyber-physical spaces - spaces that are both physical and digital, and where the two aspects are intertwined. Such spaces are highly dynamic and typically undergo continuous change. Software engineering can have a profound impact in this domain, by defining suitable modeling and specification notations as well as supporting design-time formal verification. In this paper, we present a methodology and a technical framework which support modeling of evolving cyber-physical spaces and reasoning about their spatio-temporal properties. We utilize a discrete, graph-based formalism for modeling cyber-physical spaces as well as primitives of change, giving rise to a reactive system consisting of rewriting rules with both local and global application conditions. Formal reasoning facilities are implemented adopting logic-based specification of properties and according model checking procedures, in both spatial and temporal fragments. We evaluate our approach using a case study of a disaster scenario in a smart city.;Association for Computing Machineryacmhelp@acm.org;Conference Proceeding;Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering;2017-08-21;https://api.elsevier.com/content/abstract/scopus_id/85030787201
888;Adding static and dynamic semantics to building information models;Smart cyber-physical spaces indicate spatial environments which include both cyber and physical elements interacting with each other. In the construction industry, Building Information Models are the de facto standard for specifying complex information about building infrastructures, a representation which can also be extended for the specification of cyber-physical spaces. By providing formal static and dynamic semantics in terms of topological concepts of locality and connectivity of entities it is possible to support many forms of advanced analyses typically performed in software engineering. Static semantics aim to broadly support reasoning about latent qualities of a design. Dynamic semantics aim to deal with the dynamism that a space exhibits when additionally considering the ways it may change along with entities inhabiting it. Motivated by the setting of a smart hospital, we show how both qualitative and quantitative properties can be specified and verified.;Association for Computing Machinery, Incacmhelp@acm.org;Conference Proceeding;Proceedings - 2nd International Workshop on Software Engineering for Smart Cyber-Physical Systems, SEsCPS 2016;2016-05-14;https://api.elsevier.com/content/abstract/scopus_id/84973468695
889;On early statistical requirements validation of cyber-physical space systems;Cyber-physical space systems are becoming increasingly important. Such systems have to satisfy requirements that are heavily affected by the physical space they operate in and by the active entities inhabiting the space, whose dynamic behaviors generate continuous topological changes. Reasoning about requirements in the early design phases is extremely challenging. High-level design can be facilitated by systematic application of separation of concerns throughout modeling, analysis, and early requirements validation. We outline an approach that identifies key recurrent concerns arising in cyber-physical space systems, supports systematic and semi-automatic modeling of separate concerns, and a formally defined composition of the separately developed models. Early requirements validation is then supported by leveraging statistical model checking techniques. We illustrate our approach through an example disaster scenario in a smart city.;IEEE Computer Societyhelp@computer.org;Conference Proceeding;Proceedings - International Conference on Software Engineering;2018-05-27;https://api.elsevier.com/content/abstract/scopus_id/85051140871
890;Inferring analyzable models from trajectories of spatially-distributed internet of things;"Internet of things systems are increasingly common nowadays. They feature spatially-distributed, mobile entities with an arising collective behavior. Such entities bear radionavigation sensors that produce positioning information, then used by the (software-enabled) device to produce positioning information over time, referred to as trajectories. However, software applications built on top of this require composite models of space to be in place; such models can provide adaptive behaviors by observing, evaluating, and reacting to a constantly changing spatial environment. This is typically achieved by monitoring for changes, analyzing requirements violations and then planning and executing adequate countermeasures. We are concerned with the fact that model representations of space are highly pertinent to requirements reasoning of internet of things systems, and such spatial models can be very useful for engineering adaptation. To this end, we provide and implement a technique to infer analyzable models from general trajectories of spatially-distributed systems, which may be used for engineering analysis or planning facilities for the overall self-adaptive systems. Moreover, we illustrate how such spatial models are used for evaluation of requirements predicating about the structure of space, the spatial distribution of devices, temporal as well as quantitative aspects through formal spatio-temporal verification.";IEEE Computer Societyhelp@computer.org;Conference Proceeding;ICSE Workshop on Software Engineering for Adaptive and Self-Managing Systems;2019-05-01;https://api.elsevier.com/content/abstract/scopus_id/85068391551
891;Scalable Multiple-View Analysis of Reactive Systems via Bidirectional Model Transformations;Systematic model-driven design and early validation enable engineers to verify that a reactive system does not violate its requirements before actually implementing it. Requirements may come from multiple stakeholders, who are often concerned with different facets - design typically involves different experts having different concerns and views of the system. Engineers start from a specification which may be sourced from some domain model, while validation is often done on state-transition structures that support model checking. Two computationally expensive steps may work against scalability: transformation from specification to state-transition structures, and model checking. We propose a technique that makes the former efficient and also makes the resulting transition systems small enough to be efficiently verified. The technique automatically projects the specification into submodels depending on a property sought to be evaluated, which captures some stakeholder's viewpoint. The resulting reactive system submodel is then transformed into a state-transition structure and verified. The technique achieves cone-of-influence reduction, by slicing at the specification model level. Submodels are analysis-equivalent to the corresponding full model. If stakeholders propose a change to a submodel based on their own view, changes are automatically propagated to the specification model and other views affected. Automated reflection is achieved thanks to bidirectional model transformations, ensuring correctness. We cast our proposal in the context of graph-based reactive systems whose dynamics is described by rewriting rules. We demonstrate our view-based framework in practice on a case study within cyber-physical systems.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2020 35th IEEE/ACM International Conference on Automated Software Engineering, ASE 2020;2020-09-01;https://api.elsevier.com/content/abstract/scopus_id/85099193166
892;Model-Driven Design of City Spaces via Bidirectional Transformations;"Technological advances enable new kinds of smart environments exhibiting complex behaviors; smart cities are a notable example. Smart functionalities heavily depend on space and need to be aware of entities typically found in the spatial domain, e.g. roads, intersections or buildings in a smart city. We advocate a model-based development, where the model of physical space, coming from the architecture and civil engineering disciplines, is transformed into an analyzable model upon which smart functionalities can be embedded. Such models can then be formally analyzed to assess a composite system design. We focus on how a model of physical space specified in the CityGML standard language can be transformed into a model amenable to analysis and how the two models can be automatically kept in sync after possible changes. This approach is essential to guarantee safe model-driven development of composite systems inhabiting physical spaces. We showcase transformations of real CityGML models in the context of scenarios concerning both design time and runtime analysis of space-dependent systems.";Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2019 ACM/IEEE 22nd International Conference on Model Driven Engineering Languages and Systems, MODELS 2019;2019-09-01;https://api.elsevier.com/content/abstract/scopus_id/85073698508
893;A critical review of the integration of geographic information system and building information modelling at the data level;"The benefits brought by the integration of Building Information Modelling (BIM) and Geographic Information Systems (GIS) are being proved by more and more research. The integration of the two systems is difficult for many reasons. Among them, data incompatibility is the most significant, as BIM and GIS data are created, managed, analyzed, stored, and visualized in different ways in terms of coordinate systems, scope of interest, and data structures. The objective of this paper is to review the relevant research papers to (1) identify the most relevant data models used in BIM/GIS integration and understand their advantages and disadvantages; (2) consider the possibility of other data models that are available for data level integration; and (3) provide direction on the future of BIM/GIS data integration.";MDPI AGPostfachBaselCH-4005;Journal;ISPRS International Journal of Geo-Information;2018-02-01;https://api.elsevier.com/content/abstract/scopus_id/85043262560
894;Towards Architecting Digital Twin-Pervaded Systems;Digital twins are virtual models for representing, monitoring, and controlling real-world products, entities, and processes, and are fundamental for enabling digitalization and continuous engineering processes. The usage of digital twins for engineering software-intensive systems will significantly change current business models, development approaches, and technologies. In this regard, the application scenarios and starting conditions for companies to introduce digital twins are manifold depending on their experience in software and system engineering, the maturity of their development processes, and the strategic management support and motivation. This article describes (i) challenges and impacts on the system development activities and architecture design approaches that are caused by the introduction and exploitation of digital twins, and also (ii) proposals for tailoring and extending traditional architecture-centric engineering processes to consider digital twin concepts.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2019 IEEE/ACM 7th International Workshop on Software Engineering for Systems-of-Systems and 13th Workshop on Distributed Software Development, Software Ecosystems and Systems-of-Systems, SESoS-WDES 2019;2019-05-01;https://api.elsevier.com/content/abstract/scopus_id/85074976546
895;Automated provenance graphs for models@run.time;Software systems are increasingly making decisions autonomously by incorporating AI and machine learning capabilities. These systems are known as self-adaptive and autonomous systems (SAS). Some of these decisions can have a life-changing impact on the people involved and therefore, they need to be appropriately tracked and justified: the system should not be taken as a black box. It is required to be able to have knowledge about past events and records of history of the decision making. However, tracking everything that was going on in the system at the time a decision was made may be unfeasible, due to resource constraints and complexity. In this paper, we propose an approach that combines the abstraction and reasoning support offered by models used at runtime with provenance graphs that capture the key decisions made by a system through its execution. Provenance graphs relate the entities, actors and activities that take place in the system over time, allowing for tracing the reasons why the system reached its current state. We introduce activity scopes, which highlight the high-level activities taking place for each decision, and reduce the cost of instrumenting a system to automatically produce provenance graphs of these decisions. We demonstrate a proof of concept implementation of our proposal across two case studies, and present a roadmap towards a reusable provenance layer based on the experiments.;Association for Computing Machinery, Inc;Conference Proceeding;Proceedings - 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS-C 2020 - Companion Proceedings;2020-10-16;https://api.elsevier.com/content/abstract/scopus_id/85096778397
896;Requirements and design patterns for adaptive, autonomous, and context-aware digital twins in industry 4.0 digital factories;Digital factories are poised to achieve unseen levels of resiliency and flexibility, facing increasingly demanding requirements by customers and market conditions. Digital twins are one of the building blocks fueling this vision. They provide a software counterpart for industrial assets enabling control, simulation, analytics and “servitization” functionalities. To effectively fulfill their tasks, digital twins need to embed adaptive, autonomous, and context-awareness functionalities. In this work, we propose an organic vision of digital twin design and implementation with the goal of clearly identifying the primary steps towards this goal. First, we detail how current requirements for digital twins have to be enriched for supporting adaptivity, autonomy, and context-awareness. Second, we propose a set of reusable design patterns mostly popularized in the field of micro-services allowing engineers to meet these new demanding requirements while keeping complexity and management costs under control. Finally, we present our working prototype based on the identified design patterns and implemented with orchestrated micro-services, demonstrating the feasibility of our solution and quantifying its networking and computational overhead.;Elsevier B.V.;Journal;Computers in Industry;2023-08-01;https://api.elsevier.com/content/abstract/scopus_id/85152477901
897;Dimensions of digital twin applications - A literature review;The use of Digital Twins has gained attraction in research and practice in recent years. Digital Twins are virtual representations of physical objects and they can be connected with their physical counterparts. Through this connection, Digital Twins contribute to the convergence of the real and the virtual world. While existing literature reviews focus strongly on the manufacturing industry, this paper analyzes Digital Twin applications across industries. Based on a systematic literature review, this paper examines 87 Digital Twin applications and proposes a classification scheme with six dimensions to describe the applications identified. The concept of Digital Twins is currently still underrepresented in Information Systems research, which opens up further research opportunities.;Association for Information Systemspublications@aisnet.org;Conference Proceeding;25th Americas Conference on Information Systems, AMCIS 2019;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85084019743
898;Digital twin: Mitigating unpredictable, undesirable emergent behavior in complex systems;Systems do not simply pop into existence. They progress through lifecycle phases of creation, production, operations, and disposal. The issues leading to undesirable and unpredicted emergent behavior are set in place during the phases of creation and production and realized during the operational phase, with many of those problematic issues due to human interaction. We propose that the idea of the Digital Twin, which links the physical system with its virtual equivalent can mitigate these problematic issues. We describe the Digital Twin concept and its development, show how it applies across the product lifecycle in defining and understanding system behavior, and define tests to evaluate how we are progressing. We discuss how the Digital Twin relates to Systems Engineering and how it can address the human interactions that lead to “normal accidents.” We address both Digital Twin obstacles and opportunities, such as system replication and front running. We finish with NASA's current work with the Digital Twin.;Springer International Publishing;Book;Transdisciplinary Perspectives on Complex Systems: New Findings and Approaches;2016-01-01;https://api.elsevier.com/content/abstract/scopus_id/85006339863
899;Reference Framework for Digital Twins within Cyber-Physical Systems;Cyber-Physical Systems (CPSs) represent systems which integrate physical units and processes with computational entities over Internet and allow ubiquitous access of information and services. Although the application of CPSs promise to positively transform many application fields, there are still many open questions and challenges on how to design and realize a CPS. As indicated in the third level of the 5-level CPS architecture, the so-called cyber level, one of the challenges addresses the need for digital twins as high-fidelity mirroring images of CPSs entities. This is a prerequisite to realize the upper levels of the 5-level CPS architecture-the cognition and configuration level. In the scientific literature, the concept of a Digital Twin is introduced as a concrete realization for mirroring physical entities in the virtual world. However, a reference framework for the main building blocks of a Digital Twin framework is missing. This hinders a reuse of best practices and proven solutions for concrete realizations of a Digital Twin. In order to tackle this problem, we have established a reference framework for Digital Twins within a CPS. Our framework specifies the main building blocks of a Digital Twin in terms of structure and interrelations. To achieve this goal, we performed a systematic literature review, where we evaluated existing Digital Twin realizations used in different application domains of CPSs and we applied Grounded Theory and Framework Analysis as underlying methodologies. This reference framework serves a blueprint for developing Digital Twins of physical entities which are part of a CPS.;Institute of Electrical and Electronics Engineers Inc.;Conference Proceeding;Proceedings - 2019 IEEE/ACM 5th International Workshop on Software Engineering for Smart Cyber-Physical Systems, SEsCPS 2019;2019-05-01;https://api.elsevier.com/content/abstract/scopus_id/85072842816
900;The autonomic cloud: A vision of voluntary, Peer-2-Peer cloud computing;Autonomic computing - that is, the development of software and hardware systems featuring a certain degree of self-awareness and self-adaptability - is a field with many application areas and many technical difficulties. In this paper, we explore the idea of an autonomic cloud in the form of a platform-as-a-service computing infrastructure which, contrary to the usual practice, does not consist of a well-maintained set of reliable high-performance computers, but instead is formed by a loose collection of voluntarily provided heterogeneous nodes which are connected in a peer-to-peer manner. Such an infrastructure must deal with network resilience, data redundancy, and failover mechanisms for executing applications. We discuss possible solutions and methods which help developing such (and similar) systems. The described approaches are developed in the EU project ASCENS. © 2013 IEEE.;IEEE Computer Societyhelp@computer.org;Conference Proceeding;Proceedings - IEEE 7th International Conference on Self-Adaptation and Self-Organizing Systems Workshops, SASOW 2013;2013-01-01;https://api.elsevier.com/content/abstract/scopus_id/84901202096
901;Digital Twin in manufacturing: A categorical literature review and classification;The Digital Twin (DT) is commonly known as a key enabler for the digital transformation, however, in literature is no common understanding concerning this term. It is used slightly different over the disparate disciplines. The aim of this paper is to provide a categorical literature review of the DT in manufacturing and to classify existing publication according to their level of integration of the DT. Therefore, it is distinct between Digital Model (DM), Digital Shadow (DS) and Digital Twin. The results are showing, that literature concerning the highest development stage, the DT, is scarce, whilst there is more literature about DM and DS.;Elsevier B.V.;Conference Proceeding;IFAC-PapersOnLine;2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85052915281
902;Architectural aspects of digital twins in IIoT systems;Industrial Internet of Things (IIoT) systems enable the connectivity of numerous devices, which are heterogeneous in terms of their interfaces and supported protocols, into one system to derive more intelligent actions from data. Digital Twins are a key enabler for IIoT systems, which allow the acquisition, access, and exchange of far greater variety of data than today and previously unseen interoperability out of the box. This paper elaborates on the definitions of digital twins, their role in IIoT systems and the necessary architectural decisions that software/system architects have to make to design digital twins.;Association for Computing Machineryacmhelp@acm.org;Conference Proceeding;ACM International Conference Proceeding Series;2018-09-24;https://api.elsevier.com/content/abstract/scopus_id/85055721125
903;Runtime evolution of highly dynamic software;Highly dynamic software systems are applications whose operations are particularly affected by changing requirements and uncertainty in their execution environments. Ideally such systems must evolve while they execute. To achieve this, highly dynamic software systems must be instrumented with self-adaptation mechanisms to monitor selected requirements and environment conditions to assess the need for evolution, plan desired changes, as well as validate and verify the resulting system. This chapter introduces fundamental concepts, methods, and techniques gleaned from self-adaptive systems engineering, as well as discusses their application to runtime evolution and their relationship with off-line software evolution theories. To illustrate the presented concepts, the chapter revisits a case study conducted as part of our research work, where self-adaptation techniques allow the engineering of a dynamic context monitoring infrastructure that is able to evolve at runtime. In other words, the monitoring infrastructure supports changes in monitoring requirements without requiring maintenance tasks performed manually by developers. The goal of this chapter is to introduce practitioners, researchers and students to the foundational elements of self-adaptive software, and their application to the continuos evolution of software systems at runtime.;Springer Berlin Heidelberg;Book;Evolving Software Systems;2014-01-01;https://api.elsevier.com/content/abstract/scopus_id/84904816002
904;A six-layer digital twin architecture for a manufacturing cell;Industry 4.0, cyber-physical production systems (CPPS) and the Internet of Things (IoT) are current focuses in automation and data exchange in manufacturing, arising from the rapid increase of capabilities in information and communication technologies (ICTs) and the ubiquitous internet. A key enabler for the advances promised by CPPSs is the concept of a “digital twin”- the cyber representation of the physical twin, which in this paper is a manufacturing cell. This paper presents an architecture for such a digital twin that enables exchanging data and information between a remote emulation or simulation and the physical twin. The architecture comprises different layers, including a local data layer, an IoT Gateway layer, cloud-based databases and a layer containing emulations and simulations.;Springer Verlagservice@springer.de;Book Series;Studies in Computational Intelligence;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85059060745
905;Towards continuous monitoring in personalized healthcare through digital twins;Continuous and effective monitoring of chronic diseases and their associated treatments might have a decisive impact on reducing risks and improving life quality of patients. This, however, demands new and innovative methods for engineering systems that support the required capabilities. Research on the application of the novel concept of Digital Twin (DT) in healthcare might provide the means to revolutionize traditional medical practices. A DT comprises a set of virtual representations of both the structural elements and dynamics of any physical asset (e.g., a patient) throughout its lifecycle. In the healthcare domain, it might represent a significant step forward towards tightening and improving the interactions between systems, caregivers and patients. Moreover, integrating data-driven methods (e.g., Machine Learning) and DT could serve as a noteworthy mechanism to not only track patients' health continuously, but also to evaluate the application and evolution of medical treatments virtually. In this paper, we describe our vision for the application of DT in precision medicine. Our contributions are twofold. First, we describe our initial ideas for a reference model that leverages DT capabilities and research advances in self-adaptive systems and autonomic computing to engineer smart and flexible software systems in healthcare. We expect these systems to alleviate complexity and assist in the planning and decision-making processes when applying medical treatments to patients by healthcare professionals. Then, we elaborate on the definition of internal structures for DT to support precision medicine techniques in the context of continuous monitoring and personalized data-driven medical treatments.;Center for Advanced Studies on Collaborative Research;Conference Proceeding;CASCON 2019 Proceedings - Conference of the Centre for Advanced Studies on Collaborative Research - Proceedings of the 29th Annual International Conference on Computer Science and Software Engineering;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85081157740
906;Knowledge map and forecast of digital twin in the construction industry: State-of-the-art review using scientometric analysis;"With the advancement of Industry 4.0 and the development of science and technology, industries have seen the advantages of digital twin (DT) implementations and concepts. Although the construction industry is still in the early stage of DT development and implementation, it is urgent for the industry to have a DT agenda. This paper identifies 1158 related bibliographic records from the Web of Science and 745 records from the Derwent Patent Database and quantitatively analyzed them to describe patterns of publications. Two knowledge mapping tools were selected to visualize and analyze the literature in the relevant scientific domain. Then, we integrated clustering, knowledge mapping, and network analysis methods to show the current foci and future directions of DT-MT derived from the data of time distribution, journal areas, and subject distribution. The results indicate that DT is a cross-disciplinary information technology with great development potential, and its development in the construction industry is scattered with the leading advancement in the manufacturing of construction materials and components. The derived knowledge map shows three stages of construction DT, including (1) data collection and creation of DT framework and database; (2) implementation of planning and design modules in detail and control of construction sites; and (3) carrying out asset management and fault prediction in the operation and maintenance phase of projects. The novelty of this paper is the specific analysis of DT in the construction industry. This study adds value to the architecture, engineering, and construction industries by shedding light on the focus of DT practical applications and the formation of a development path of construction DT.";Elsevier Ltd;Journal;Journal of Cleaner Production;2023-01-10;https://api.elsevier.com/content/abstract/scopus_id/85143719809
907;A mutual certificate-based data privacy scheme for ubiquitous and sustainable computing system users;Ubiquitous sustainable computing systems are deployed for providing complex application services and processing for real-time applications. Data exchange and sharing are confidential for administering user security and privacy. The need for confidentiality is one of the significant obstacles to ubiquitous computing areas like human–machine interfaces and data security. It is crucial in ubiquitous computing to protect user and system security, privacy, and safety. Hence, this article introduces a Linearized Mutual Security Scheme (LMSS) to prevent data leakage and security breaches. The scheme provides mutual authentication based on security requirements depending upon the ubiquitous application. The user credentials are pre-shared with the service providers for determining the security level and certificate sharing. This sharing is updated at fixed intervals for deciding on authentication revocation and strength updates. In this scheme, federated learning is exploited for identifying user security demands and levels administered by different users. Based on the learning recommendations, the key authentication factors are updated in the certificate, preventing anonymous and tracking sessions in the sharing interval. Therefore, the proposed scheme achieves fair anomaly detection of 14.47%, reduces data leakage rate by 13.68%, and halts sessions by 10.26%. Besides, it improves the sharing ratio of 6.92% and application responses.;Elsevier Ltd;Journal;Sustainable Energy Technologies and Assessments;2023-08-01;https://api.elsevier.com/content/abstract/scopus_id/85164286157
908;Cyber-physical control over wireless sensor and actuator networks with packet loss;There is a growing interest in design and implementation of cyber-physical control systems over wireless sensor and actuator networks (WSANs). Thanks to the use of wireless communications and distributed architectures, these systems encompass many advantages as compared to traditional networked control systems using hard wirelines. While WSANs are enabling a new generation of control systems, they also introduce considerable challenges to quality-of-service (QoS) provisioning. In this chapter, we examine some of the major QoS challenges raised by WSANs, including resource constraints, platform heterogeneity, dynamic network topology, and mixed traffic. These challenges make it difficult to fulfill the requirements of cyber-physical control in terms of reliability and real time. The focus of this chapter is on addressing the problem of network reliability. Specifically, we analyze the behavior of wireless channels via simulations based on a realistic link-layer model. Packet loss rate (PLR) is taken as a major metric for the analysis. The results confirm the unreliability of wireless communications and the uncertainty of packet loss over WSANs. To tackle packet loss, we present a simple solution that can take advantage of existing prediction algorithms. Simulations are conducted to evaluate the performance of several classical prediction algorithms used for loss compensation. The results give some insights into how to deal with packet loss in cyber-physical control systems over unreliable WSANs. © 2011 Springer Science+Business Media, LLC.;Springer New York;Book;Wireless Networking Based Control;2011-12-01;https://api.elsevier.com/content/abstract/scopus_id/84889859450
909;Information systems as representations: A review of the theory and evidence;Representation theory proposes that the basic purpose of an information system (IS) is to faithfully represent certain real-world phenomena, allowing users to reason about these phenomena more cost-effectively than if they were observed directly. Over the past three decades, the theory has underpinned much research on conceptual modeling in IS analysis and design and, increasingly, research on other IS phenomena such as data quality, system alignment, IS security, and system use. The original theory has also inspired further development of its core premises and advances in methodological guidelines to improve its use and evaluation. Nonetheless, the theory has attracted repeated criticisms regarding its validity, relevance, usefulness, and robustness. Given the burgeoning literature on the theory over time, both positive and negative, the time is ripe for a narrative, developmental review. We review representation theory, examine how it has been used, and critically evaluate its contributions and limitations. Based on our findings, we articulate a set of recommendations for improving its application, development, testing, and evaluation.;Association for Information Systemspublications@aisnet.org;Journal;Journal of the Association for Information Systems;2019-01-01;https://api.elsevier.com/content/abstract/scopus_id/85070469299
910;Digital first: The ontological reversal and new challenges for information systems research;The classical view of an information system is that it represents and reflects physical reality. We suggest this classical view is increasingly obsolete: digital technologies are now creating and shaping physical reality. We call this phenomenon the ontological reversal. The ontological reversal is where the digital version is created first, and the physical version second (if needed). This ontological reversal challenges us to think about the role of humans and technology in society. It also challenges us to think about our role as IS scholars in this digital world and what it means for our research agendas.;University of Minnesotadegro003@umn.edu;Journal;MIS Quarterly: Management Information Systems;2020-06-01;https://api.elsevier.com/content/abstract/scopus_id/85088255354
911;Digital Twin in manufacturing: A categorical literature review and classification;The Digital Twin (DT) is commonly known as a key enabler for the digital transformation, however, in literature is no common understanding concerning this term. It is used slightly different over the disparate disciplines. The aim of this paper is to provide a categorical literature review of the DT in manufacturing and to classify existing publication according to their level of integration of the DT. Therefore, it is distinct between Digital Model (DM), Digital Shadow (DS) and Digital Twin. The results are showing, that literature concerning the highest development stage, the DT, is scarce, whilst there is more literature about DM and DS.;Elsevier B.V.;Conference Proceeding;IFAC-PapersOnLine;2018-01-01;https://api.elsevier.com/content/abstract/scopus_id/85052915281
912;A Review of the Roles of Digital Twin in CPS-based Production Systems;"The Digital Twin (DT) is one of the main concepts associated to the Industry 4.0 wave. This term is more and more used in industry and research initiatives; however, the scientific literature does not provide a unique definition of this concept. The paper aims at analyzing the definitions of the DT concept in scientific literature, retracing it from the initial conceptualization in the aerospace field, to the most recent interpretations in the manufacturing domain and more specifically in Industry 4.0 and smart manufacturing research. DT provides virtual representations of systems along their lifecycle. Optimizations and decisions making would then rely on the same data that are updated in real-time with the physical system, through synchronization enabled by sensors. The paper also proposes the definition of DT for Industry 4.0 manufacturing, elaborated by the European H2020 project MAYA, as a contribution to the research discussion about DT concept.";Elsevier B.V.;Conference Proceeding;Procedia Manufacturing;2017-01-01;https://api.elsevier.com/content/abstract/scopus_id/85029833606
913;OMiLAB: A Smart Innovation Environment for Digital Engineers;This position paper introduces a Smart Innovation Environment for experimentation related to digital transformation projects, for the consolidation of a proposed “Digital Engineer” skill profile (with a business-oriented facet labelled as “Digital Innovator”). In the Internet of Things era, this profile implies the ability to perform both digital design and engineering activities, to semantically bridge multiple layers of abstraction and specificity – from business analysis down to cyber-physical engineering. In the paper’s proposal, this integration is enabled by conceptual modelling methods and interoperable modelling tools, tailored to support the creation of Digital Twins for innovative digital business models. The architecture of the proposed environment is guided by a Design Research perspective – i.e., it is a treatment to an education “design problem” regarding the Digital Engineer skill profile in the IoT era. The proposed environment encompasses workspaces and toolkits are currently evaluated in “innovation corners” deployed across the OMiLAB ecosystem.;Springer Science and Business Media Deutschland GmbH;Book Series;IFIP Advances in Information and Communication Technology;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85097444837
914;Conceptual Modelling Methods: The AMME Agile Engineering Approach;"Current research in fields such as Business Process Management, Enterprise Architecture Management, Knowledge Management and Software Engineering raises a wide diversity of requirements for Conceptual Modelling, typically satisfied by Design Science artefacts such as modelling methods. When employed in the context of an Agile Enterprise, an underlying requirement for Conceptual Modelling agility emerges-manifested not only on model content level but also on modelling method level. Depending on the questions that must be answered and the systems that must be supported with modellingmeans, the need for agility may stem from the degree of domain-specificity, from gradual understanding of modelling possibilities, from evolving model-driven systems, etc. The hereby proposed Agile Modelling Method Engineering (AMME) approach thus becomes necessary to extend the traditional perspective of “modelling through standards”; consequently, the benefits of repeatability and wide adoption are traded for responsiveness to dynamic needs identified within an Agile Enterprise.";Springer International Publishing;Book;Domain-Specific Conceptual Modeling: Concepts, Methods and ADOxx Tools;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85134977072
915;Fundamental conceptual modeling languages in OMiLAB;Regardless of the application domain, both the analysis of existing systems and the creation of new systems benefit extensively from having the system modeled from a conceptual point of view in order to capture its behavioral, structural or semantic characteristics, while abstracting away irrelevant details. Depending on which relevant details are assimilated in the modeling language, modeling tools may support different degrees of domain-specificity. The boundaries of what domain-specific means are as ambiguous as the definition of a domain-it may be a business sector, a paradigm, or a narrow application area. However, some patterns and invariants are recurring across domains and this has led to the emergence of commonly used modeling languages that incorporate such fundamental concepts. This chapter focuses on the metamodeling approach for the hybridization of BPMN, ER, EPC, UML and Petri Nets within a single modeling method identified as FCML, with a proof of concept named Bee-Up implemented in OMiLAB.;Springer International Publishing;Book;Domain-Specific Conceptual Modeling: Concepts, Methods and Tools;2016-07-09;https://api.elsevier.com/content/abstract/scopus_id/85023161970
916;Domain-Specific Conceptual Modeling: Concepts, Methods and ADOxx Tools;This book demonstrates the significance of domain-specific conceptual modeling through new research and development approaches that are manifested in each of the chapters. They include novel modelling methods and tools that emphasize the recent results accomplished and their adequacy to assess specific aspects of a domain. Each chapter offers detailed instructions on how to build models in a particular domain, such as product-service engineering, enterprise engineering, digital business ecosystems, and enterprise modelling and capability management. All chapters are enriched with case studies, related information, and tool implementations. The tools are based on the ADOxx metamodelling platform and are provided free of charge via OMiLAB. Furthermore, the book emphasizes possible future developments and potential research directions. The collection of works presented here will benefit experts and practitioners from academia and industry alike, including members of the conceptual modeling community as well as lecturers and students.;Springer International Publishing;Book;Domain-Specific Conceptual Modeling: Concepts, Methods and ADOxx Tools;2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85158997130
917;Towards Interoperable Metamodeling Platforms: The Case of Bridging ADOxx and EMF;Metamodeling platforms are an important cornerstone for building domain-specific modeling languages in an efficient and effective way. Two prominent players in the field are ADOxx and the Eclipse Modeling Framework (EMF) which both provide rich ecosystems on modeling support and related technologies. However, until now, these two worlds live in isolation while there would be several benefits of having a bridge to exchange metamodels and models for different purposes (e.g., reuse of features and plugins that are only available on one platform, access to additional modeler and developer communities). Therefore, in this paper, we propose first steps toward establishing interoperability between ADOxx and EMF. For this, we thoroughly analyze the metamodeling concepts employed by both platforms before proposing a bridge that enables bidirectional exchange of metamodels. We evaluate the bidirectional bridge with several openly available metamodels created with ADOxx and EMF, respectively. Moreover, we quantitatively and qualitatively analyze the bridge by an evaluation that incorporates the instantiation and use of the metamodels on both platforms. We show that the metamodels can be exchanged without information loss and similar modeling experiences with respect to the resulting models can be achieved.;Springer Science and Business Media Deutschland GmbH;Book Series;Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics);2022-01-01;https://api.elsevier.com/content/abstract/scopus_id/85132711232
918;A survey of modeling language specification techniques;Visual modeling languages such as the Business Process Model and Notation and the Unified Modeling Language are widely used in industry and academia for the analysis and design of information systems. Such modeling languages are usually introduced in overarching specifications which are maintained by standardization institutions such as the Object Management Group or the Open Group. Being the primary – often the single – source of information, such specifications are of paramount importance for modelers, researchers, and tool vendors. However, structure, content, and specification techniques of such documents have never been systematically analyzed. This paper addresses this gap by reporting on a Systematic Literature Review aimed to analyze published standard modeling language specifications. In total, eleven specifications were found and comprehensively analyzed. The survey reveals heterogeneity in: (i) the modeling language concepts being specified, and (ii) the techniques being employed for the specification of these concepts. The identified specification techniques are analyzed and presented by referring to their utilization in the specifications. This survey provides a foundation for research aiming to increase consistency and improve comprehensiveness of information systems modeling languages.;Elsevier Ltd;Journal;Information Systems;2020-01-01;https://api.elsevier.com/content/abstract/scopus_id/85070716326
