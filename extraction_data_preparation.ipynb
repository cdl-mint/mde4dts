{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "install(\"pandas\")\n",
    "install(\"numpy\")\n",
    "install(\"matplotlib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Extraction Data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filepath_or_buffer=\"data/extraction consolidation results_V0_3.csv\",sep=\";\", encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df['Title'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "result = list(dict.fromkeys(result))\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"./data/search_results.csv\", sep=\";\", encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = metadata.drop_duplicates(subset=['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.merge(metadata, how='left', on='Title')\n",
    "#unique function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "del metadata\n",
    "del df\n",
    "del titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Title\n",
      "1 DT Definition\n",
      "2 virtual space\n",
      "3 Kritzinger\n",
      "4 DT is specific\n",
      "5 modeling language\n",
      "6 note on modeling language\n",
      "7 model type\n",
      "8 model processing technique\n",
      "9 model usage technique\n",
      "10 source\n",
      "11 target\n",
      "12 purpose of MDE application\n",
      "13 purpose of DT\n",
      "14 DTPurposeCategory\n",
      "15 use case domain\n",
      "16 system lifecycle phase\n",
      "17 twinning target\n",
      "18 twin lifecycle phase\n",
      "19 purpose /expected benefit of using models\n",
      "20 open challenges\n",
      "21 Technological Readiness Level\n",
      "22 notes\n",
      "23 Use Case\n",
      "24 Publication Title\n",
      "25 Authors\n",
      "26 Publication Year\n",
      "27 Document Identifier\n",
      "28 Publisher\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for row in data:\n",
    "    print(index, row)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create JSON from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelTrafos = 'modelTrafos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_menge_1 = {}\n",
    "for key in result:\n",
    "    out_menge_1[key] = {'DT_Definition':None,\n",
    "                        modelTrafos:{}, \n",
    "                        'open challenges':None,\n",
    "                        'Technological Readiness Level':None, \n",
    "                        'notes':None, \n",
    "                        'Use Case':None, \n",
    "                        'twinning target': None, \n",
    "                        'use case domain':None,\n",
    "                        'virtual space':None,\n",
    "                        'Kritzinger':None,\n",
    "                        'DT is specific':None,\n",
    "                        'modeling language':[],\n",
    "                        'purpose of DT':None,\n",
    "                        'DTPurposeCategory':None\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index()\n",
    "for title in result:\n",
    "    rownum = 0\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        if title == row['Title'] and not pd.isna(title):\n",
    "            rowcopy = row.__deepcopy__()\n",
    "            \n",
    "            if row['DT Definition'] is not None and not pd.isna(row['DT Definition']):\n",
    "                out_menge_1[title]['DT_Definition'] = row['DT Definition']\n",
    "\n",
    "            if row['purpose of DT'] is not None and not pd.isna(row['purpose of DT']):\n",
    "                out_menge_1[title]['purpose of DT'] = row['purpose of DT']\n",
    "\n",
    "            if row['DTPurposeCategory'] is not None and not pd.isna(row['DTPurposeCategory']):\n",
    "                out_menge_1[title]['DTPurposeCategory'] = row['DTPurposeCategory']\n",
    "\n",
    "            if row['use case domain'] is not None and not pd.isna(row['use case domain']):\n",
    "                out_menge_1[title]['use case domain'] = row['use case domain']\n",
    "            \n",
    "            if row['twinning target'] is not None and not pd.isna(row['twinning target']):\n",
    "                if out_menge_1[title]['twinning target'] is None:\n",
    "                    out_menge_1[title]['twinning target'] = row['twinning target']\n",
    "                else:\n",
    "                    out_menge_1[title]['twinning target'] += \";\"\n",
    "                    out_menge_1[title]['twinning target'] +=  row['twinning target']\n",
    "\n",
    "            if row['purpose /expected benefit of using models'] is not None and not pd.isna(row['purpose /expected benefit of using models']):\n",
    "                out_menge_1[title]['purpose /expected benefit of using models'] = row['purpose /expected benefit of using models']\n",
    "\n",
    "            if row['open challenges'] is not None and not pd.isna(row['open challenges']):\n",
    "                out_menge_1[title]['open challenges'] = row['open challenges']\n",
    "\n",
    "            if row['Technological Readiness Level'] is not None and not pd.isna(row['Technological Readiness Level']):\n",
    "                out_menge_1[title]['Technological Readiness Level'] = row['Technological Readiness Level']\n",
    "            \n",
    "            if row['notes'] is not None and not pd.isna(row['notes']):\n",
    "                out_menge_1[title]['notes'] = row['notes']\n",
    "\n",
    "            if row['Use Case'] is not None and not pd.isna(row['Use Case']):\n",
    "                out_menge_1[title]['Use Case'] = row['Use Case']\n",
    "\n",
    "            if row['Publication Title'] is not None and not pd.isna(row['Publication Title']):\n",
    "                out_menge_1[title]['Publication Title'] = row['Publication Title']\n",
    "            \n",
    "            if row['Authors'] is not None and not pd.isna(row['Authors']):\n",
    "                out_menge_1[title]['Authors'] = row['Authors']\n",
    "            \n",
    "            if row['Publication Year'] is not None and not pd.isna(row['Publication Year']):\n",
    "                out_menge_1[title]['Publication Year'] = row['Publication Year']\n",
    "\n",
    "            if row['Document Identifier'] is not None and not pd.isna(row['Document Identifier']):\n",
    "                out_menge_1[title]['Document Identifier'] = row['Document Identifier']\n",
    "\n",
    "            if row['Publisher'] is not None and not pd.isna(row['Publisher']):\n",
    "                out_menge_1[title]['Publisher'] = row['Publisher']\n",
    "            if row['DT Definition'] is not None and pd.isna(row['DT Definition']):\n",
    "                if row['virtual space'] is not None and not pd.isna(row['virtual space']):\n",
    "                    out_menge_1[title]['virtual space'] = row['virtual space']\n",
    "            \n",
    "                if row['Kritzinger'] is not None and not pd.isna(row['Kritzinger']):\n",
    "                    out_menge_1[title]['Kritzinger'] = row['Kritzinger']\n",
    "            \n",
    "                if row['DT is specific'] is not None and not pd.isna(row['DT is specific']):\n",
    "                    out_menge_1[title]['DT is specific'] = row['DT is specific']\n",
    "            \n",
    "            if row['modeling language'] is not None and not pd.isna(row['modeling language']):\n",
    "                out_menge_1[title]['modeling language'].append(row['modeling language'])\n",
    "\n",
    "            # multiple Trafos\n",
    "            arrayindexes = [0,1,2,3,4,5,6,13,10+4,11+4,13+4,15+4,16+4,17+4,18+4,19+4,20+4,21+4,22+4,23+4,24+4]\n",
    "            rowjson = rowcopy.drop(row.iloc[arrayindexes].index).to_json()\n",
    "            out_menge_1[title][modelTrafos][rownum] = rowjson\n",
    "            #out_menge_1[title]['data'][rownum].append(rowjson)\n",
    "            rownum+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "del rowjson\n",
    "del rowcopy\n",
    "del result\n",
    "del rownum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# export JSON to /json/data_consolidated_semistructured.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 183] Eine Datei kann nicht erstellt werden, wenn sie bereits vorhanden ist: 'target/'\n"
     ]
    }
   ],
   "source": [
    "json_object = json.dumps(out_menge_1, indent = 4) \n",
    "try:\n",
    "    os.mkdir('target/')\n",
    "    os.mkdir('target/img/')\n",
    "except OSError as error:\n",
    "    print(error)\n",
    "with open(\"target/json/data_consolidated_semistructured.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
